# See http://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# To ban all spiders from the entire site uncomment the next two lines:
# User-agent: *
# Disallow: /
# Load the sitemap
Sitemap: https://ir.library.oregonstate.edu/sitemap/sitemap.xml
User-agent: *
Crawl-delay: 16
Disallow: /advance
Disallow: /catalog
Disallow: /catalog
Disallow: /files/*/stats
Disallow: /oai
Disallow: /users*
Disallow: /roles*

User-agent: Googlebot
Allow: /catalog
Disallow: /files/*/stats
Disallow: /oai
User-agent: Amazonbot
Disallow: /
User-agent: bingbot
Disallow: /
User-agent: Bytespider
Disallow: /
User-agent: ChatGPT-User
Disallow: /
User-agent: ClaudeBot
Disallow: /
User-agent: GPTBot
Disallow: /
User-agent: Mail.RU_Bot
Disallow: /
User-agent: PetalBot
Disallow: /
User-agent: SemrushBot
Disallow: /
User-agent: YandexBot
Disallow: /
