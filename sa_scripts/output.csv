replace,abstract
http://hdl.handle.net/1957/35964,"The northern Los Angeles basin is influenced by two structural styles: the west-trending compressional Transverse Ranges to the north, and the strike-slip Peninsular Ranges to the south. The interaction of these two structural styles has resulted in a complex fold fault belt at the northern margin of the Los Angeles basin, which deforms a variable sequence of late Miocene through Quaternary marine strata. Subsurface mapping of Quaternary marine gravels by electric-log correlation documents the latest phase of deformation in the northern Los Angeles basin. The Quaternary marine gravels are folded at the Wilshire arch, the Hollywood basin, the central trough, the Newport-Inglewood fault, and the Santa Monica fault. The west-plunging Wilshire arch, which follows Wilshire Boulevard east of the Newport- Inglewood fault, is a broad fold identified and named in this study. Deformation of the Wilshire arch, which is underlain and caused by the potentially-seismogenic Wilshire fault, began around 0.8 - 1.0 Ma. A fault-bend fold model, based on the shape of the Wilshire arch, indicates a dip-slip rate of 1.5 - 1.9 mm yr for the Wilshire fault, whereas a three-dimensional elastic dislocation model indicates a right-reverse slip rate of 2.6 - 3.2 mm per year for the Wilshire fault. The finer-grained marine Pliocene strata include the late Pliocene to early Pleistocene Pico member, and the early Pliocene Repetto member, of the Fernando Formation. Thickness and lithology variations in the Pico and Repetto strata, which were influenced by syndepositional structures, indicate that the entire Pliocene and the latest Miocene were characterized by compression. The primary structure present throughout the Pliocene is a south-dipping monocline, which was underlain and caused by a deep reverse fault, dipping ~55 - 60° to the north, referred to here as the Monocline fault. Relative subsidence of the central trough resulted in deposition of up to 7000 ft (2135 m) of Pico strata, and up to 5000 ft (1525 m) of Repetto strata, compared to zero deposition on the monoclinal high. In the western part of the study area, the south-dipping monocline is interrupted by the secondary East Beverly Hills fold, which may be a rabbit-ear fold that accommodates excess volume by bedding-parallel slip. The East Beverly Hills fold was active in the latest Miocene through Pliocene, and was most active during early Pliocene Repetto deposition. In the eastern part of the study area, the monocline is interrupted by the Las Cienegas fold, which formed in the hangingwall of the Las Cienegas fault. The Las Cienegas fault was a normal fault in the late Miocene, and was reactivated in the Pliocene as a steep reverse fault. Folding and uplift on the Las Cienegas anticline occurred throughout the Pliocene, with the greatest amount occurring during lower and lower-middle Pico deposition."
http://hdl.handle.net/1957/26338,"The Middle Fork John Day Basin in Northeastern Oregon is prime habitat for spring Chinook salmon and Steelhead trout. In 2008, a major tributary supporting rearing habitat, Big Boulder Creek, was restored to its historic mid-valley channel along a 1 km stretch of stream 800 m upstream of the mouth. Reduction of peak summer stream temperatures was among the goals of the restoration. Using Distributed Temperature Sensing (DTS) Fiber Optic Technology, stream temperature was monitored prior to restoration in June 2008, and after restoration in September 2008, July 2009, and August 2009. Data gathered was used to determine locations of groundwater and hyporheic inﬂow and to form a stream temperature model of the system. The model was used both to develop an evaluation method to interpret components of model performance, and to better understand the physical processes important to the study reach. A very clear decreasing trend in surface temperature was seen throughout each of the DTS stream temperature datasets in the downstream 500 m of the study reach. Observed reduction in temperature was 0.5°C (±0.10) in June 2008, 0.3°C (±0.37) in September 2008, 0.6°C (±0.25) in July 2009, and 0.2°C (±0.08) in August 2009. Groundwater inflow was calculated to be 3% of the streamflow for July 2009 and 1% during the August 2009 installation. Statistically significant locations of groundwater and hyporheic inﬂow were also determined. July 2009 data was used to model stream temperature of the 1 km (RMSE 0.28°C). The developed model performance evaluation method measures timelag, offset, and amplitude at a downstream observed or simulated point compared with the boundary condition, rather than evaluating the model based on error. These measures are particularly relevant to small scale models in which error may not be a true reﬂection of the ability of a model to correctly predict temperature. Breaking down model performance into these three predictive measures was a simple and graphic method to show the model's predictive capability without sorting through large amounts of data. To better understand the model and the stream system, a sensitivity analysis was conducted showing high sensitivity to streamﬂow, air temperature, groundwater inﬂow, and relative humidity. Somewhat surprisingly, solar radiation was among the lowest sensitivity. Furthermore, three model scenarios were run: a 25% reduction in water velocity, a 5°C increase in air temperature, and no groundwater inﬂow. Simulations of removal of groundwater inflows resulted in a 0.5°C increase in average temperature over the modeled time period at the downstream end, further illustrating the importance of groundwater in this stream system to reduce temperatures."
http://hdl.handle.net/1957/11592,"Surface and subsurface data are combined to determine the structure of the western half of the Simi fault system in the Las Posas and Camarillo Hills area. Cretaceous to Eocene sedimentary rocks, present only in the subsurface, are overlain by late Eocene to early Miocene nonmarine stata (Sespe Formation) and middle Miocene volcanics and sedimentary rocks (Conejo Volcanics and Topanga Formation undifferentiated), in part exposed in the Las Posas Hills. Late Miocene marine beds (Modelo Formation) are present in the subsurface in the Camarillo Hills and may crop out in the eastern Santa Rosa Valley. These rocks are overlain unconformably by marine Pliocene-Pleistocene beds (Saugus Formation), older and younger Quaternary alluvium, and alluvial fan deposits. Normal faults cause the Sespe to subside towards a thick volcanic pile, built up in the Conejo Hills in the middle Miocene. Volcanic rocks buttressed against and later overtopped these Sespe subsidence structures. Reverse faults in the Oxnard plain and the left-lateral Somis fault are truncated by the unconformity at the base of the Saugus. Miocene and older strata were broadly folded in the Las Posas anti-cline and Santa Rosa syncline prior to deposition of the Saugus Formation and displacement on the Simi fault zone. The Bailey fault, a northwest-trending range-front fault, shows reverse separation, commonly follows Sespe subsidence structures and north-dipping normal faults which cut the Sespe. The Camarillo Hills anticline, Springville dome and post-Saugus Las Posas anticline appear to be pressure ridges adjacent to the Simi fault system on the north. Older alluvium deposits are uplifted and warped. The Camarillo fault cut and warped older alluvium."
http://hdl.handle.net/1957/11752,"The Middle and West Forks of Little Sheep Creek in the southern Tendoy Range have incised valleys across Cenozoic structural features exposing strata that range in age from the Mississippian to the Neoene. Paleozoic strata are 1,349 m thick and belong to the Mission Canyon Limestone, the Big Snowy, Amsden, Quadrant, and Priosphoria FormationS. The Scott Peak Formation of the White Knob Group of Idaho is allochtononous and forms the upper plate of the Medicine Lodge thrust. Paleozoic and Triassic strata of the thesis area represent sedimentation across a transition zone between a stable craton to the east and the Cordilleran miogeosyncline to the west. Regional unconformities are recognized locally at the top of the Mission Canyon Limestone and the Phosphoria and Thaynes Formations, but not at the top o the Big Snowy, Amsden, or Quadrant Formations, Mesozoic strata have a total thickness of 1,404 m and belong to the Dinwoody, Woodside, and Thaynes Formations, the newly recognized Gypsum Spring Tongue of the Twin Creek Formation, the Sawtooth and Rierdon Formations of the Ellis Group, the Morrison and Kootenai Formations, the Colorado Shale, and the Beaverhead Formation. Cenozoic strata are represented by the newly named Round Timber limestone (informal) of the Medicine Lodge beds (Miocene) and the Edie School rhyolite (Pliocene). Detailed stratigraphic and petrographic analyses were made of the Triassic Dinwoody, Woodside, and Thaynes Formations, the Jurassic Gypsum Spring Tongue, and the Niocene Round Timber limestone in order to determine environments of deposition. The limestones, calcareous siltstones, and silty limestones of the Dinwoody and Thaynes Formations were deposited in a shallow marine shelf environment as a result of two transgressive pulses separated by an Early Traissic regression. The Triassic seas had transgressed eastward onto the craton from the miogeosyncline. The Dinwoody arid Thaynes fauna indicate normal salinities and open marine conditions; the widespread regional distribution of the limestone-siltstone facies indicates broad equable conditions for sedimentation. Deposition was primarily a tractive process genarated by storm-driven, tidal, and long-shore currents within a maximum depth of approximately 50 m. The Early Triassic regressive phase is represented by the deposition of the variegated siltstone, sandstone, limestone, and dolomite of the Woodside Formation in a tidal flat environment. The Gypsum Spring Tongue consists of interbedded variegated siltstone, sandstone, limestone, dolomite, and limestone conglomerate that were deposited in a tidal flat and restricted marginal marine environment extending east from southwestern Montana and eastern Idaho across Wyoming arid southern Montana. The Middle Jurassic sea transgressed South across the North American continent. The Miocene Round Timber limestone was deposited in a fresh-water lake in which calcite was being deposited as encrustations on the green algae Chara and as a precipitate directly from solution. The folding and faulting within the thesis area are the result of cratonic and miogeosynclinal responses to Cretaceous-Early Tertiary orogenesis. A southwestward-plunging anticline has been refolded into northeastward-yielding, overturned, doubly-plunging folds oriented northwest-southeast. High angle reverse faults of minor displacement have occurred along the southeastern limb of Garfield anticline and within the axis of the Seybold syncline. Post-Laramide relaxation of compressional forces has caused north- and northwest-oriented normal faults that transect earlier structures. Sandstone and limestone of the Scott Peak Formation of the White Knob Group were implaced along the Medicine Lodge thrust."
http://hdl.handle.net/1957/41209,"This thesis is an effort to formalize and document some of the changes occuring in the Warwar Valley of Gongola State, Nigeria, West Africa. The documentation will comprise a photographic study over time accompanied by an ethnographic narrative. Information gathered from photographic images, field notes and the anthropological record will then be applied to a cultural-ecological model based on the theory of Julian Steward. The Mambilla people inhabiting the Warwar Valley are changing their traditional agricultural land use patterns and value system due to the influx of new ideas, notably the introduction of a cash economy. This cultural change has affected environmental change, observable in soil erosion."
http://hdl.handle.net/1957/20612,"Benton County has experienced substantial growth in the past 30 years, and is expected to continue growing (BCWP 2008). Continued development has occurred in the Willamette Valley, housing development in the nearby hills of the Coast Range is growing. New houses in the foothills of the Coast Range may not use municipal water supply and are generally supplied by domestic or community wells, which pump groundwater sourced from the local uplifted formation of the Siletz River Volcanics (SRV). Continued population growth is expected to rely heavily on the groundwater resources of the SRV.  The SRV are a series of accreted Tertiary submarine and subaerial basalt formations stretching from Northern California to Vancouver Island, composed of porous pillow basalt flows with interbedded semi-impermeable silts and shales. Flow occurs via basalt fractures and interflow zones in the SRV. The aquifer structure and flow mechanisms result in discontinuous perched and confined aquifers. Due to the structure and higher gradients of the flow zones in the SRV, aquifers are presumed to be heterogeneous, anisotropic, and leaky. Wells usually penetrate multiple saturated zones before sufficient yield is provided to supply a domicile.  The complex, unpredictable nature of the SRV has discouraged hydrogeologic studies, and the majority of studies are performed by consultants to evaluate a new water supply. The most recent comprehensive study of groundwater in Benton County that included the SRV as a water-bearing unit was a USGS Water-Supply Paper by F.J. Frank in 1974. The substantial recent development of the SRV has provided a large amount of new data, including well logs digitized by OWRD.  This thesis characterizes the SRV by developing hydrogeologic spatial datasets for Benton County. The study applies GIS methods to spatially distribute well log entries by Public Land Survey System (PLSS) units and by Address, resulting in a representative subset of the original data, with good spatial coverage, moderate resolution, and decent accuracy. Wells located within the SRV are spatially subset to provide insight about the formation, and spatial interpolations of common hydrogeologic parameters are performed leveraging the well distributions.  This study found that (relative to Benton County): the SRV have a lower well density, a higher percent of wells in the SRV have positive yields (84%), SRV wells have lower average well yields (19-22 gpm), appear to have a higher frequency of confined groundwater, and have much lower mean specific capacity (0.03 - 0.3 gpm per ft). More importantly, this study has taken a first step towards accomplishing some of the data needs established by Benton County. Additionally, fundamental LIDAR and spring location datasets were prepared for upper Oak Creek Watershed in association with this study, opening the door for subsequent topography-groundwater studies."
http://hdl.handle.net/1957/11208,"The Pennsylvanian rocks in south-central Idaho and adjacent areas consist of three main facies: a platform facies, a shelf facies, and a marginal basin facies. The platform facies is represented by the Amsden, Quadrant, and Tensleep Formations, in southwestern Montana and western Wyoming, and contain Middle and probably Lower Pennsylvanian strata. The shelf facies is represented by the Pennsylvanian part of the White Knob Limestone, which extends from the Lemhi Range to the White Knob Mountains west of the Lost River Range in south-central Idaho, and contains Lower, Middle, and Upper Pennsylvanian strata. The marginal basin facies is represented by clastics of the Middle and Upper Pennsylvanian part of the Wood River Formation, in the Wood River region in south-central Idaho, and the Lower, Middle, and Upper Pennsylvanian part of the Wells Formation in southeastern Idaho. Broad epeirogenic upwarps or eustatic sea level caused the shelf and platform to be alternately positive and negative during Pennsylvanian time. Pennsylvanian seas reached maximum inundation during Desmoinesian time after which a temporary offlap developed during Missourian through Middle Virgilian time on the platform and shelf areas, and epicontinental seas were restricted to the Wells and Wood River basins. During Late Virgilian time the seas spread to the east over former areas of post-Desmoinesian erosion on the shelf area Generalized isopachous and lithofacies maps of Pennsylvanian time-stratigraphic units are presented, with interpretations of the positions and periods of activity of positive and negative elements."
http://hdl.handle.net/1957/60340,"In volcanic systems, magma is generally stored in the shallow crust prior to eruption. The conditions of this storage directly impact whether the magma eventually erupts, or crystallizes within the crust to form a pluton. In this dissertation I present four studies that investigate the storage conditions of a number of volcanic systems and their timescales. A widespread method to quantify the timescales of magmatic processes is diffusion modeling of compositional variations in zoned crystals. Obtaining timescale information from diffusion modeling relies on fitting modeled diffusion profiles to measured compositional gradients. Therefore, the spatial resolution of the geochemical analysis technique used to characterize these gradients has the potential to limit the accuracy and precision of calculated diffusion timescales, especially when the resolution of the individual analyses approaches the width of the observed diffusion gradient. A probabilistic modeling approach is presented to assess the accuracy of short diffusion timescale estimates with respect to the spatial resolution of the geochemical measurement of compositional zoning. We develop a generalized method to quantify these shortest timescales that can be accurately calculated for given spatial resolutions and diffusivity. This provides a simple method to assess the accuracy of short diffusion timescales. Olivine-rich picrites are a relatively common eruptive product of ocean island and flood basalt volcanism. This rock type has a primitive bulk-rock composition similar to mantle-derived melts; however, picrites are olivine-rich. The common interpretation for the formation of picrites is the accumulation of olivine in more evolved, basaltic liquids. Many picrites contain two textural populations of olivine, one with deformation features (kink bands, subgrains or undulose extinction), and one without deformation. Deformation textures in olivine is traditionally thought to form by plastic deformation during storage in a deforming cumulate zone. However, recently it has been proposed that deformation textures could be the result of growth phenomena. We use textural (crystal sizes, deformation textures and minor element zoning patterns) and geochemical analysis (trace element compositions and minor element diffusion) of olivine from the 1959 eruption of Kīlauea Iki to show that these two olivine populations are derived from different sources and that the deformed population experienced longer residence times than the undeformed population. Our results are consistent with the interpretation that olivine is deformed in cumulate zones, and later entrained in unrelated magmas. The conditions of upper crustal magma storage in arc settings are fundamentally important to the evolution and ultimate fate of arc magmas. Current thermal models suggest that accumulation of significant bodies of eruptible magma require either high magma influx and storage at elevated temperatures, or lower flux and storage as low temperature crystal mushes that are later thermally rejuvenated. We use textural (crystal sizes) and geochemical (plagioclase trace elements and trace element diffusion in plagioclase, quartz and sanidine) analyses of samples from several arc systems ranging in eruptive volume from < 1 km³ to > 5,000 km³ to obtain observational evidence for the thermal conditions of arc magma storage. In particular we quantify the maximum amount of time a given crystal could have resided in a mobile magma (< 50% crystals, i.e., below the rheological lockup). This study is split into two parts, the first is focused on the large, caldera-forming eruptions (≥ 10 km³) and the second on the smaller, more typical arc eruptions (≤ 13 km³). Diffusion timescales from 11 caldera-forming eruption reveal three types of magmatic systems: 1) relatively small volume systems (< ~100 km³) that record short residence times (< ~1200 years) at or above the rheological lockup temperature, 2) large volume systems (> ~100 km³) that record long residence times (< 160,000 years) for plagioclase diffusion and short timescales for quartz and sanidine, and 3) large volume systems that record variable to low residence times. This suggests that the smaller systems experience cold storage conditions where rejuvenation is needed to remobilized magma that is locked up as a crystal mush. The longer residence times for the larger systems suggests that thermal conditioning of the crust and or higher magma fluxes allow these magmas to be stored at elevated temperatures longer than the smaller systems. The second part of the study of the storage conditions of arc magmas gives evidence for two different storage conditions. The smaller (<13 km³), more typical arc magmatic systems all record short residence times (10¹-10³ years) at hightemperatures. However these timescales are the result of two different processes. The first is observed in the relatively crystal-poor systems (<20% crystals), where diffusion records the timing of crystal growth after silicic melt extraction from crystal mushes. The second process, recorded in crystal-rich systems (25-50% crystals), suggests that they are stored as relatively cold crystal mushes that must be rapidly remobilized prior to eruption. We conclude that the majority of these systems were stored at low temperatures for much of their lifetimes."
http://hdl.handle.net/1957/4059,"Coral reef ecosystems are the most diverse on earth, and their subsistence is being threatened by natural and adverse anthropogenic patterns and processes. In an effort to understand and protect these marine environments, several programs have outlined strategies and initiatives. For example, the United States Coral Reef Task Force’s Mapping and Information Working Group has outlined a specific goal to map all coral reefs below 30 m depth by 2009. This study contributes to achieving that goal for three sites around the island of Tutuila, American Samoa, lying in the heart of the South Pacific. American Samoa, a U.S. territory, is home to the Fagatele Bay National Marine Sanctuary, the smallest and most remote in the United States, and to the National Park of American Samoa. Extensive modern scientific surveys were implemented around the territory in 2001 and have since continued and increased. The presence of protected areas and the existence of scientific data collected with state of the art technology have made the site a priority for the Coral Reef Task Force. In this study, methods for classifying surficial seafloor characteristics as bathymetric position index (BPI) zones and structures were developed and applied to the study sites. BPI zones and structures were classified by using algorithms that combine high-resolution (1 m) multibeam bathymetry and its derivatives: bathymetric position index at multiple scales and slope. The development of algorithms and the classification scheme involved the use of historical and current classification studies and three-dimensional visualization. In addition, the BPI zones and structures were compared to limited biological, geological, and physical attributes recorded during accuracy assessment surveys (photos) and towed diver surveys (video). A rugosity (surface ratio) analysis was added to the study to give a picture of the seafloor roughness. The BPI zone and structure classifications overlap and extend existing classifications from Ikonos satellite imagery for water depths shallower than 30 m. Methods, data and classifications developed and applied in this study will be available to the public as a benthic habitat mapping tool (ArcGIS extension), in an online GIS data archive, and on a compact disc attached to this thesis. They contribute to a broader understanding of the marine and coastal environment and will serve as a baseline of information for benthic habitat mapping and future biological, ecological, and geological surveys. The baseline gives a good indication of characteristics that may indicate areas of high biodiversity. The final maps presented here are especially useful to managers, researchers and scientists that seek to establish and monitor a wider and more effective network of marine and coastal protection."
http://hdl.handle.net/1957/28578,"A comprehensive tribal-level classification for the world's subfamilies of Hesperiidae, the skipper butterflies, is proposed for the first time. Phylogenetic relationships between tribes and subfamilies are inferred using DNA sequence data from three gene regions: 943 bp of cytochrome oxidase subunit I (COI) (in the mitochondrial genome), 739 bp of elongation factor-lα (EF-lα) and 403 bp of wingless (both in the nuclear genome). Morphological character scores were then added to the molecular matrix, for a combined simultaneous analysis. In both analyses, branch support for each clade is investigated, and conflict among data partitions is assessed using the partition congruence index. Monophyly of the family Hesperiidae is strongly supported, as are some of the traditionally recognized subfamilies, with the following relationships (from the combined molecular and morphological analysis): (Coeliadinae + (Euschemoninae + (Eudaminae + (Pyrginae + (Trapezitinae + (Heteropterinae + Hesperiinae)))))). The formerly recognized subfamily Pyrrhopyginae, while strongly supported as a monophyletic group, is downgraded to a tribe of Pyrginae. The former subfamily Megathyminae is considered to be an infra-tribal group of Hesperiinae (Erionotini), although its phylogenetic position therein remains uncertain. The Australian endemic Euschemon rafflesia is a hesperiid, given subfamily-status. Most of the traditionally recognized generic groups and subgroups currently employed to partition the subfamilies of Hesperiidae are not monophyletic. Seven subfamilies of Hesperiidae are recognized: Coeliadinae, Euschemoninae (confirmed reinstated status), Eudaminae (new status), Pyrginae, Trapezitinae, Heteropterinae (confirmed status) and Hesperiinae. Pyrrhopygini (reinstated status), Tagiadini (confirmed reinstated status), Celaenorrhinini (confirmed new status), Carcharodini (reinstated status), Achlyodini (new status), Erynnini (confirmed new status) and Pyrgini (confirmed status) are treated as tribes of Pyrginae, but the circumscription of Achlyodini and Pyrgini requires further elaboration. Tribes of Hesperiinae include Aeromachini (new status), Erionotini (new status), Baorini (new status), Taractrocerini (confirmed reinstated status), Thymelicini (confirmed reinstated status), Calpodini (reinstated status), Anthoptini (new tribe), Moncini (new tribe), and Hesperiini (confirmed reinstated status), but the circumscription of Erionotini should be considered tentative.-  "
http://hdl.handle.net/1957/16081,"Many publications, documents, codes and guidelines exist related to the seismic evaluation and rehabilitation design of existing buildings. This report discusses the assumptions and methods employed for investigation of two wood structures using four references: FEMA 154, FEMA 356, ASCEI per SEI 31, and 1997 UBC. The screening performed using FEMA 154 demonstrates the importance of conducting pre-inspection investigation of existing documentation such as construction drawings. In the absence of this information, the screening indicated that the structures would not require additional evaluation. A plans check revealed a deficiency in the structural systems, that if included in the evaluation, would mark them for additional analysis. This investigation examines the demand-to-capacity ratios for shear walls and roof diaphragms in the two wood-framed structures. It was expected that requirements for the design of new structures in the 1997 UBC would be the most conservative of these references. It was also expected that the rehabilitation design provisions of FEMA 356 would be more conservative than the existing building evaluation provisions in ASCE per SEI 31. The results of this study show that the new building design provisions in the 1997 LJBC are not necessarily conservative when compared to the rehabilitation design provisions in FEMA 356. In addition, the provisions in the design documents FEMA 356 and the 1997 UBC are not necessarily conservative when compared to existing building evaluation provisions in ASCE per SEI 31. The likely cause of the unexpected results is the conservative Linear Static Procedure and associated m factors for wood in the FEMA 356 and ASCE per SEI 31 documents. Additional research is needed to better calibrate these factors and associated acceptance criteria to account for duration of shaking, the number of cycles of nonlinear behavior, redundancy, etc."
http://hdl.handle.net/1957/61730,"In transboundary river basins, political borders oftentimes trace shared rivers across a basin. A border between territories can be seen as a space that is separated; however, it is actually one with the potential to unite populations and environments. A river basin is generally defined by its topography and hydrology. New paradigms in river basin management point towards expanding this definition to include culture, values and placed-based knowledge (Jackson 2011; Jackson et al. 2015). By including these aspects, we can have more informed and comprehensive planning that addresses the needs of river basin residents (Wolf 2008; Jackson 2011). This research explores and addresses how incorporating culture and values is being implemented and included in river basin management plans (Wolf 2008; Cosens 2012; Jackson and Palmer 2012) through a case study of the Sixaola River Basin— an international transboundary river basin located in Central America that is shared between Costa Rica, Panamá and five indigenous communities: the Bríbrí, Naso, Cabecar, Brunca and Ngöbe. This case study exemplifies how these practices are being applied to water resources management at international, national and local levels. Through collaborative participatory research, videography, photography and storytelling, I explore lessons learned in the Sixaola River Basin and take note of how this approach can be used in other international transboundary river basin management plans worldwide (Jackson et al. 2015). Findings in this work include: 1) the importance of integrating culture and values in river basin management, 2) the effectiveness of co-managed research, and 3) the value of increasing communication and information exchange of river basin residents."
http://hdl.handle.net/1957/61884,"Offshore renewable energy (ORE) has the potential to be a significant source of future global electricity production, reduce carbon emissions, decrease dependence on energy importation, and stimulate economic growth in coastal and remote areas. The availability and abundance of ORE, paired with growing coastal population centers, position offshore wind, wave, and tidal energy technologies as viable means for providing power to coastal areas. The key to making these technologies feasible is providing electricity through reliable, efficient technology, and at competitive prices. The objective of this research is to explore novel approaches to improving ORE performance, cost, and reliability. In the first two studies, I propose methods to optimize co- located wind-wave installments, investigating the feasibility and potential benefits of placing offshore wind turbines and wave energy converters (WECs) in the same leased ocean area. In the third and fourth studies, I explore the feasibility of emergency wave energy generation during sustained outages in coastal areas. To characterize which machine learning methods are best suited to predict storm-related, sustained transmission outages on the Oregon coast, I compare multiple machine learning regression methods. I then use the results of this study in an analytical cost model for emergency wave energy generation after a sustained outage. The final study reviews reliability-based design optimization applications in offshore renewable energy systems, highlighting areas for future work."
http://hdl.handle.net/1957/61836,"Approximately 2700 years ago, Greek settlers from the Northwestern Peloponnese region of Achaea emigrated to the central coast of Southern Italy along the Gulf of Taranto. The city they founded, Metapontum, served as an important center for Magna Graecia, the lands on the Southern Italic peninsula wholly populated by Hellenic peoples. With growing population came the need for increased agricultural production, with the Khra of Metapontum (those administrative areas separate from the city proper) expanding rapidly inland within 50 years of initial settlement. This study, located in the Venella River Valley approximately 7 kilometers Northwest of the ancient center of Metapontum (now the modern town of Metaponto), seeks to identify and characterize the agricultural soils from this early phase of expansion, in an area known as one of the first utilized for the purpose. To that end, a type sequence was identified and described in the valley bottom containing a buried soil believed to be the ancient agricultural surface. Carbon dating of in situ terrestrial snail shells from this soil was completed, and it was determined to be the appropriate age. Eleven other soil sequences throughout the valley were described, with two of them containing horizons believed to be continuations of the buried soil from the type section. Four of them were located within an archaeological site dating to the early Greek occupation of the valley. From this, each sample collected was subject to X-ray Fluorescence and Mehlich Analysis, to identify the geochemical signature and plant-available nutrients present (the latter serving as proxy record of ancient fertilizer use). This data was then subject to statistical analyses in order to determine both the potential extent of the buried agricultural soil as well as its connection to the soils present within the archaeological site. Furthermore, a first chemostratigraphic framework for the valley was completed, allowing future researchers to directly compare, via geochemical analysis, samples to the framework created by this research. Ultimately, it was determined that the buried soil identified in the type section is geochemically linked to those soils present at the archaeological site, making it highly reasonable that it was the Greek occupation surface. The results of the Mehlich Analysis revealed that some locations possess elevated levels of necessary plant nutrients that may be indicative of ancient agricultural practices, however more work would be necessary to reveal the true extent of modification."
http://hdl.handle.net/1957/61759,"DNA is often described as the “blueprint for life”. In eukaryotes this information is contained within linear chromosomes of varying size and number. During cell division, the chromosomes must be faithfully segregated into each daughter cell to avoid disease and sustain life. This process is carried out by the kinetochore complex, linking each chromosome to the spindle microtubules during anaphase. Advances over the past several decades have shed light on the characteristics of centromeric DNA sequence, as well as the mechanisms by which the proteins of the kinetochore recognize this locus and build a bridge to microtubules. However, the extent of sequence variability within the centromere has only recently become clear, requiring us yet again to address questions about the role of DNA sequence in centromere function. Divergence also is a hallmark of kinetochore proteins. Examination of the centromeres and kinetochores of a more diverse array of organisms should provide insights into the conserved sequence elements and protein interactions that are fundamental to chromosome segregation. In this dissertation, I describe extensive characterization of the centromere sequence of numerous N. crassa strains, revealing a large degree of variability but no observed functional differences. This work provides insight into the extent, and mechanisms, of centromere sequence evolution. I also describe studies of the kinetochore proteins of N. crassa, including a full set of tools for extensively probing the inner workings of the kinetochore of this filamentous fungus. This work emphasizes the extent of variability in this critical protein complex and suggests the need for similar work in more diverse organisms."
http://hdl.handle.net/1957/11553,"Error-correcting output coding (ECOC) is a method for converting a k-classsupervised learning problem into a large number L of two-class supervised learningproblems and then combining the results of these L evaluations. Previous researchhas shown that ECOC can dramatically improve the classi cation accuracy of supervisedlearning algorithms that learn to classify data points into one of k   2 classes.An investigation of why the ECOC technique works, particularly when employedwith decision tree learning algorithms, is presented.It is shown that the ECOC method is a compact form of voting amongmultiple hypotheses. The success of the voting depends on that the errors committedby each of the L learned binary functions are substantially uncorrelated.By employing the statistical notions of bias and variance, the generalizationerrors of ECOC are decomposed into bias and variance errors. Like any votingmethod, ECOC reduces variance errors. However, unlike homogeneous voting, whichsimply combines multiple runs of the same learning algorithm, ECOC can alsoreduce bias errors. It is shown that the bias errors in the individual functions are uncorrelated and that this results from non-local behavior of the learning algorithmin splitting the feature space.ECOC is also extended to provide class probability information. The problemof computing these class probabilities can be formulated as an over-constrained systemof linear equations. Least squares methods are applied to solve these equations.Accuracy of the posterior probabilities is demonstrated with overlapping classes anda simple reject option task."
http://hdl.handle.net/1957/13186,"Regression equations applicable to biomass components of standsof western hemlock [Tsuga heterophylla (Raf.) Sarg.} were developedby destructive sampling of a thinned and an unthinned stand ofwestern hemlock near Seaside, Oregon. Equations predicted more live-branchbiomass and less dead-branch biomass per tree for the thinnedstand, but equations for biomass of foliage, twigs, stern wood andstem bark did not differ significantly between stands. Concentrationsof N, F, K, S, Ca, Mg, and Mn in tree components were determined and aboveground tree biomass and nutrient content were estimatedfor both stands.The biomass data was used in conjunction with published data tomodify an existing computer model in order to simulate growth andnutrient cycling of western hemlock stands. The FORCYTE computermodel, originally developed for Douglas-fir forests in BritishColumbia by J. P. Kimmins and K. Scoullar, was used. Calibration runs indicated that yield in FORCYTE was extremely sensitive to theparameter defining the rate of mineralization of soil organic matter,a process which supplied the majority of N available for tree uptake.The mineralization rate was set initially so that yield remainedconstant in three succesive 90 year rotations, which resulted in a4.1% loss of soil organic matter over the 270 year period. Simulationsof 6 different 270 year management scenarios of varying intensityindicated that more intensive management (e.g., whole-tree harvestingand commercial thinning) caused faster depletion of soilorganic matter and site N capital, resulting in an eventual declinein site productivity in later rotations. Simulations suggested thathemlock forests may not begin to accumulate soil organic matter untilthey approach old-growth status. Predicted declines in soil organicmatter caused by intensive management were compared to documentedlosses of organic matter in agricultural systems. FORCYTE predictedsoil organic matter would eventually equilibrate in about 1500 yearswhen inputs to the soil organic matter pool balanced decomposition,resulting in an equilibrium yield level well below that of the firstrotation, but sustainable in perpetuity. The strengths and weaknessesof the FORCYTE model are discussed. The predicted trends arebased on currently available information, but it must be realizedthat as more information becomes available, predictions will inevitablychange."
http://hdl.handle.net/1957/17023,"An important factor affecting the strength and ultimate load of wood structures is the strength, stiffness and durability of itsjoints. Therefore, the behavior of nailed joints must be given properconsideration when designing and analyzing wood structures. Presently,formulas for determining the strength of nailed joints under withdrawalloads, as outlined in the National Design Specifications and theUniform Building Code, are based on the statistical regression betweenmaximum withdrawal load (W) and the material properties of the wood andnail.New models were developed which predict W, withdrawal resistance(WR) and withdrawal stiffness (WK) based on the actual forces responsiblefor holding the nail in the wood. These include a normal forceto the nail due to the elastically compressed wood around the nail andthe resulting friction between the wood and nail surfaces. Theaccuracy of these models were compared to the accepted formulas in thedesign codes and were found to be superior in predicting W, WR and WK."
http://hdl.handle.net/1957/18332,"Over-the-counter (OTC) wood preservatives canprovide wood with both a moisture barrier and fungicidalprotection against biodeterioration, yet there is littlecomparative data on the performance of thesepreservatives. In this study, the potential of variouslow-toxicity, OTC preservatives was evaluated on fivewestern wood species, western redcedar (Thuja plicata),western hemlock (Tsuga heterophylla), Douglas-fir(Pseudosuga menziesii),lodgepole pine (Pinus contorta),and coastal redwood (Sequoia sempervirens). The activeingredients tested were copper-8-quinolinolate, coppernaphthenate, zinc naphthenate, 3-Iodo 2-propynylbutlycarbamate(IPBC), Bis (tri-n-butyltin) oxide(TBTO), TBTOIPBC, TBTOchlorothalonil, and TBNtrichloromethylthio-phthalimide (Folpet). Small blocksand stakes of each species were dipped for 3 minutes inone of twelve OTC preservatives to simulate homeowner application. To examine the efficacy of thesepreservatives, treated blocks were subjected to amodified American Society of Testing and MaterialsStandards (ASTM) D2017-81 soil-block test to evaluateabove ground decay resistance as measured by wood weightloss following exposure to Postia placenta (Fr.) Cookeor Trametes versicolor (L:Fr.) Pilat, a brown and whiterot fungus, respectively. Test stakes were placed insoil-beds maintained in an environmentally controlledgreenhouse. The stakes were evaluated for the degreeof decay at 3 month intervals for the first year,followed by 18 and 24 month ratings. Preservativetreatments improved performance of most species exceptlodgepole pine; improvements were most noticeable insoil-bed trials with redwood and western redcedar. Theresults suggest that topical application of commerciallyavailable preservatives has merit for enhancing theperformance of naturally durable woods in soil contact,but their value for less durable woods is questionable.Wood used above-ground will benefit most from suchtopical treatments, however, for best performance ayearly reapplication might be necessary for the lessdurable wood species."
http://hdl.handle.net/1957/18864,"Tolerance analysis and synthesis plays a vital role in the success of a product design because it directly affects product quality and manufacturing cost. It also affects manufacturing process selection and planning. This research provides a review of several commonly used assembly tolerance analysis models and evaluation of their limitations. A new assembly tolerance analysis model is proposed based on process capability indices, mean shifts and tolerance specifications which can be used to bridge the gap between design and manufacturing. A computer tolerance analysis system that integrates the proposed tolerance analysis model as well as several other assembly tolerance analysis models with a parametric CAD package and a manufacturing process database is described. This system can aid the user to perform tolerance analysis and design concurrently with CAD modeling, and discover potential manufacturing and assembly problems at the design stage. The integration of various modules of the system involves dynamic data exchange(DDE) and object linking and embedding(OLE) under Windows environment. The system allows determination of tolerances on critical assembly dimensions and updating of CAD drawing. Furthermore, allocation of part dimension tolerances may be performed by making use of the data on various manufacturing process capabilities. Examples are presented to explain the use of the developed model and the tolerance analysis system."
http://hdl.handle.net/1957/18946,"This research examines how marketing strategies of produce managers affectconsumer expenditures for fresh apples and pears. The objective of this study is todetermine how display size, point-of-purchase material, product origin, productinformation and display placement impact consumer expenditures for fresh applesand pears. These variables were incorporated into a non-linear Almost Ideal DemandSystem with share equations for Gala, Fuji, Red Delicious, Other Sweet Apples, TartApples, and Pears. Forty-four weeks of data on weekly store sales were collectedfrom two grocery stores in the Portland, Oregon metropolitan area. Share influencesand elasticities are provided for price inputs and for other variables whereappropriate. Product origin, e.g. state and national, influenced consumers'expenditures for Red Delicious apples and pears; it was insignificant in other shareequations. Product information, e.g. tart or sweet, only influenced expenditures onapple varieties that are less familiar to the consumer. The size of point-of-purchasematerial had a significant effect on expenditures as did display sizes to a lesser extent.This research provided valuable information to produce managers and apple and pearproducers on factors that influence consumers' expenditures at the retail level."
http://hdl.handle.net/1957/22333,"California bighorn sheep (Ovis canadensis californiana) were studied on Hart Mountain, Oregon, during the summer and fall of 1976, and the spring of 1977. The population consisted of a minimum of 196 sheep in June, 1977. The high number of lambs observed and high lamb:ewe ratios throughout both years of the study indicated that the population was expanding rapidly. Sheep occupied about 85 percent of the length of the mountain; ewe-lamb groups occupied 25 percent. Both ewes and rainsoccurred on two distinct ranges during all seasons, and interchange of individuals between the two ranges was minimal during the study. Most rutting activity occurred during November. Lambs were born between mid-April and late May. Fifteen habitats within the ewe-lamb range were identified and sampled for plant species composition. A habitat preference value (HPV) was calculated for each habitat on Hart Mountain, based on use by ewe groups. Bluebunch wheatgrass (Agropyron spicatum) and big sagebrush (Artemisia tridentata) were the two most widely distributed plant species in the ewe-lamb range; Idaho fescue (Festuca idahoensis) provided thegreatest amount of herbaceous cover. Daily activities of ewe groups centered around four contiguous bedding grounds and three principal feeding areas. Topography, as well as vegetational composition, appeared to influence the preference of ewes for certain locations, particularlyfor major cliff formations and adjacent feeding areas. Habitat factors unique to the present ewe-lamb range are discussed as possible determinants of its location."
http://hdl.handle.net/1957/27380,"The major portion of Pacific whiting (PW) is commercialized in the form of frozensurimi. Alternative products for PW were investigated focusing on fresh surimi andtexturized meat from PW mince. Fresh surimi is made without additives and keptrefrigerated instead of frozen. Texturized meat is a meat-like product made from PWmince through freeze-texturization.Fresh surimi was stored at 5°C and analyzed for its total aerobic plate count(APC), shear stress, shear strain, and color during 7 days storage. Frozen surimi from PWwas prepared with 0, 3, 6, and 9% cryoprotectants and was compared with fresh surimifor its gel forming ability. Fresh surimi had a shelf life of 5 days and the gel forming abilityremained unchanged throughout storage time. Shear strain of fresh surimi was not different from frozen surimi with 9% cryoprotectants but shear stress was almost 3 timeshigher than the frozen one.Texturized meat from PW mince was prepared from unwashed or 1-washed mincekept frozen for 6-8 mo with or without the addition of 6% cryoprotectants. The minceswere comminuted into a protein slurry, formed into patties, and frozen at -7, -18, and-50°C. The evaluations of ice formation (by microscopic study), hardness, cook loss,color, and water holding capacity were carried out during 20 days storage. The resultsshowed that texturized meat with parallel layers was made from 1-washed PW mince.Unwashed PW mince created a sponge-like texture and had rapid quality deterioration,thus it is not recommended for this product. Cryoprotectants did not significantly affectthe texture formation of the product and are not required to store mince as raw materialfor the texturized meat. The optimum freeze-texturized temperature for this product was-18°C or lower because it minimized quality changes during storage depending on thedesirable texture. The lower the temperature (higher freezing rate), the finer the layerscreated."
http://hdl.handle.net/1957/29844,"The epoxide deoxygenation reaction is formally the reverse of theepoxidation reaction. Compared to epoxidation, which has reached its fullmaturity, epoxide deoxygenation has not been as intensively developed.Among the few deoxygenation reagents, a handful are catalytic in a metalcomplex, show high stereospecificity and operate under mild conditions. Acommon feature of all present deoxygenation reagents is that they do notperform asymmetric deoxygenation of racemic epoxides.Rhenium (VII) trioxo complexes are emerging as pliable catalysts forepoxide deoxygenation. Designing a chiral rhenium (VII) trioxo complexwas our goal. Guided by the mechanism of rhenium (VII) trioxo catalyzedepoxide deoxygenation and the mechanism of the stereogenic informationtransfer, we have designed and prepared a chiral rhenium(VII) trioxocomplex. This complex is void of stereogenic centers and the source ofasymmetry is the restricted rotation around a carbon-carbon bond.Detailed conformational analysis of the new chiral complex was done byextensive NMR measurements and molecular modeling. The rotationbarrier for the diolate was experimentally and computationally estimated tobe 9.72 kcal by mol and 8.06 kcal by mol, respectively.Unsuccessful attempts were made to prepare a camphor basedscorpionate because of the extreme steric congestion. A menthone basedscorpionate was successfully prepared. The related rhenium (TII) trioxocomplex with this scorpionate revealed contradicting chemical andspectroscopic features."
http://hdl.handle.net/1957/3206,"The Mixteco primarily reside in the Mexican State of Oaxaca in Southwestern Mexico. They have been arriving in larger numbers then ever before to this part of the North American continent in the last twenty years.Their experience is composed of different dynamics compared to those of their mainstream Mexican counterpart.  One of these dynamics is based on the discrimination they receive, not only from Anglo-Americans, but also mainstreamed Mexicans and Mexican-Americans. Their vulnerability is partly due to language and cultural differences.By exploring their experiences and subjectively capturing nine individual’s stories of migration, my intent is to make direct and indirect comparisons of how global socio-economic forces impact communities that until recently were self-sufficient and autonomous.  Their stories are not much different than those of their counterparts who, because of economic factors, are force to immigrate or face permanent economic destitution. The Mixteco subjects’ lives and trials serve as witnesses to help explain the intricate web of micro-events, which collectively influence and respond (most negatively) to macro events of which we are now witnessing as the planet’s population polarizes between the haves and have nots. The focus of the research is the experiences of nine Mixtecos families and individuals who migrated from their homeland in Oaxaca to the state of Oregon, USA.  The interviews focus on their personal experiences as they confronted the challenges of coming north, first to northern Mexico and then to the United States."
http://hdl.handle.net/1957/36604,"The purposes of this study were:1) to review the land use history of Oak Creekwatershed since European settlement. And 2) toconsider the human-caused impacts and their effectsassociated with different land uses. The study areawas classified into three land use patterns: residential,agricultural, and forested areas.Since the European settlement in the mid 1840's, theOak Creek watershed has experienced changes of land usesimultaneous with the development of the city of Corvallisand its vicinity. Associated with this, different impactshave occurred on riparian areas. By and large, theseimpacts were inherent to each land use."
http://hdl.handle.net/1957/37239,"Many ecological systems follow a seasonal cycle affecting primary production,carbon flux, and vegetative gas emissions. The seasonal variation of ecologicalsystems are both affected by and have effects upon climatic factors. A quantitativeestimate of the seasonal variation of vegetation is required to characterize ecologicalsystems and their interaction with climate. Monitoring the spaliotemporalvariation of foliar biomass density (FBD) over one year will provide a quantitativeestimate of the annual cycle and regional variation of photosynthetic activity. FBDis a quantitative measure of leafy material per unit of area produced by photosyntheticallyactive vegetation. This seasonal variation in FBD is an important parameterfor global and other large scale investigations of ecological, hydrological, andbiogeochemical systems which require data and expertise from a variety of sourcesand disciplines. Therefore, FBD is potentially of great utility for ecologists,hydrologists, climatologists, and atmospheric scientists.Recent regional scale investigations of ecological systems concluded that therepetitive coverage and synoptic view of remotely sensed measurements providedata to monitor the seasonal variation of biomass. A method to estimate the seasonalvariation of FBD at global scales has not been developed. The objective ofthis research is to develop a methodology that could be used to estimate theseasonal variation of FBD for the entire terrestrial biosphere. By coupling globalsatellite data, measured field data, and a vegetation classification, a model wasdeveloped to estimate the global spatiotemporal variation of FBD.Comparisons between literature estimates of FBD and estimated FBD fromthis model were made as a means of validation. A more specific comparison wasconducted between grasslands based on work conducted in the Senegalese Sahelregion in Africa. Finally, a sensitivity analysis was performed to characterize thepotential propagation of error associated with the literature FBD estimates used todrive this model."
http://hdl.handle.net/1957/3825,"Hop derived bitter compounds, including alpha-acids, reduced and non-reduced iso-alpha-acids, were evaluated for their contribution to peak bitter intensity in lager beer.  Alpha-acids are the precursors to the major bittering components in beer (iso-alpha-acids).  Typically, alpha-acids do not survive the brewing process, but if a product is dry-hopped, they may solubilize into the finished beer depending on the system pH, temperature and ethanol content.  The impact of alpha-acids on the bitterness of lager beer was investigated using a trained panel and a  test with a consumer panel.  The trained panel evaluated samples with and without alpha-acids to offer initial analysis on aroma and bitterness intensity, and a triangle test comparing an unhopped lager with and without 14 ppm alpha acids (the solubility limit in beer) was presented to over 100 consumers for  evaluation.  Both panels found no significant difference between the samples.  Furthermore, statistical similarity of the samples with and without alpha-acids was validated.  This confirmed that alpha acids contribute negligibly to the overall bitterness of lager beer.Iso-alpha-acids are a hop derived compound formed from thermally induced isomerization of the alpha-acids.  When exposed to ultra-violet light (UV), the iso-alpha-acids are degraded forming off-odors and flavors.  Therefore, where UV degradation is of concern, it is important to brewers to find an alternative to iso-alpha-acids.  The reduced iso-alpha-acids, rho-iso-alpha-acids, hexahydro-iso-alpha-acids, and tetrahydro-iso-alpha-acids, can be used as a substitute for iso-alpha-acids and provide bitterness and UV stability.  The reduced iso-alpha-acids offer varying degrees of change to the temporal bitterness qualities of a beer when compared to iso-alpha-acids.The relative bitterness relationships of reduced to non-reduced iso-alpha-acids were measured using a time-intensity protocol, in which a trained panel evaluated seven concentrations of each compound in an unhopped lager beer. The peak intensities were identified, and a non-linear dose-response curve, called a change-point model, was fit to the data.  Three parameters, a, b, and θ, identified the shape of the model.  Panelist’s replicated well but varied in sensitivity to the compounds and how they rated bitter intensity.  Per-panelist and panel-wise equi-bitter equations were constructed from the parameters.  Statistical analysis was performed to identify differences in bitter impact. Accordingly, rho was significantly less bitter than iso-alpha-acids, and hexahydro-iso-alpha-acids and tetrahydro-iso-alpha-acids were not different significantly in bitter impact over a range of iso concentration. The predicted equal bitter concentrations for each reduced iso-alpha-acids to iso-alpha-acids were validated by a consumer panel at a single concentration of iso-alpha-acids.	In conclusion, each hop compound researched (alpha-acids, iso-alpha-acids, rho-iso-alpha-acids, hexahydro-iso-alpha-acids, and tetrahydro-iso-alpha-acids) differed in the contribution to peak bitter impact of lager beer.  Alpha-acids did not contribute significantly to the bitterness of an unhopped lager as validated by a consumer panel.  This is particularly important for brewers that dry-hop their beers.  And for those brewers wanting to use reduced iso-alpha-acids to replace iso-alpha-acids as a method for eliminating UV degradation, it is important to understand the peak bitter relationship for each of the compounds. By applying the change-point model, the natural variation among panelists was accommodated and compound differences that were not initially quantifiable were revealed and defined."
http://hdl.handle.net/1957/39343,"From July 1985 to April 1987 the pelagiczooplankton community of Crater Lake, Oregon was studiedto determine taxonomic structure, absolute and relativedensities, and spatial and temporal distributionalpatterns. Samples were collected using vertically-towedzooplankton nets. The community structure consisted oftwo cladoceran and nine rotifer species, which were eitherphytophagous, polyphagous, or triptophagous; none waspredaceous. The community numerically was dominated byrotifers, and the majority of the populations occurredwithin the hypolimnion. Taxonomic structure, abundance,and distribution of the zooplankton community wererelatively stable. While the stability was attributed tothe extremely high numerical dominance of the rotifer,Keratella cochlearis, some of the observed variations wereattributed to depth and season. This stability may be short-term. Historic data suggest that the density of thecladoceran, Daphnia pulicaria. is cyclic, being highlyabundant in some years and rare in others. During thisstudy, D. pulicaria abundances were low but appeared to beon an increasing trend. Changes in Daphnia densities maybe due to fluctuations in food supply or in densities ofthe zooplanktivorous kokanee (Oncorhynchus nerkakennerlyi). Such fluctuations in the daphnid populationmay be related to and integrated with changes andfluctuations in the zooplankton and phytoplanktoncommunities, primary production, and water clarity."
http://hdl.handle.net/1957/39847,"This study is primarily concerned with the measurement of thelocal radiative component of total heat transfer around a horizontaltube immersed in a large particle fluidized bed at elevated temperatures.Total heat transfer was also measured in order to assess therelative radiation contribution.The radiation measurement probe employs a silicon window mountedflush with the tube wall to transmit the radiative heat flux. Athin-film thermopile-type heat flow detector placed behind the windowsensed the transmitted radiation. The thermal conductivity of siliconis sufficiently large to prevent the conduction error (less than3%) resulting from the convective component of heat transfer. Siliconalso has a wide spectral transmission wave band extending from1.3 um to 12.0 um. The total heat transfer probe uses a similar heatflow detector bonded to the tube wall and covered tightly with astainless steel foil to protect the detector against abrasion.The radiation probe was calibrated using a narrow-angle blackbodysource. The purpose of the calibration was to establish therelation between the heat flux detected by the radiation probe andthe incident radiative flux to the tube wall. This relation wasfound to be linear and insensitive to the tube wall temperaturevariations encountered in this study.The instrument has been used to measure local radiative andtotal heat transfer at 0, 45, 90, 135, and 180 degree positionsaround a horizontal tube immersed in a fluidized bed. Measurementswere obtained at bed temperatures of 812 K and 1050 K with 2.14 mmand 3.23 mm mean diameter particles at gas velocities up to two timesthe minimum fluidization velocity.A sharp increase was noted for spatial average radiative, totaland convective heat transfer coefficients when the gas velocity exceededthe minimum fluidizing velocity. Generally, these coefficientsshowed little variation with further increase in gas flowrate.The radiative heat transfer coefficient was increased with anincrease in particle size and bed temperature, the latter having amuch more pronounced effect, as expected. The radiation contributionto overall heat transfer was found to increase from 9% to 15% for3.23 mm particles and from 8% to 13% for 2.14 mm particles when thebed temperature was elevated from 812 K to 1050 K at the optimum gasvelocity (maximum total heat transfer).Finally, fast sampling rate (25 samples sec) data were obtainedusing the radiation probe with a measured response time of about 120 msec. This data was treated as instantaneous and an attempt was madeto obtain hydrodynamic parameters such as emulsion residence time andbubble contact fraction. However, this analysis did not yield satisfactoryresults."
http://hdl.handle.net/1957/40275,"Upper Cambrian through Middle Devonian carbonate andclastic sequences of the northern part of the Fish Creek Rangerepresent shallow-shelf sedimentation in the Cordilleranmiogeosyncline. The lower and middle Paleozoic section exposedin the northern Fish Creek Range fits well within regional facies patterns and paleogeographic reconstructions.The Upper Cambrian Dunderberg Shale was deposited in amuddy outer shelf embayment which extended eastward into theEureka area. The embayment was eliminated as seas regressed inlate Dresbachian time and marine carbonate sedimentation (represented by the Catlin Member o-f the Wind-fall Formation) wasestablished. The argillaceous Bullwhacker Member of theWindfall was deposited in deeper shelf waters as the seatransgressed briefly during Trempeleauian time.Shallow-shelf carbonates of the Lower Ordovician GoodwinLimestone are succeeded by Ninemile Formation strata representing deposition in a muddy embayment, similar to the LateCambrian embayment in the Eureka area. Regression followed, anda shallow-water Girvanella-rich carbonate bank prograded westward during Whiterockian (early Middle Ordovician) time,represented by the lower part of the Antelope Valley Limestone.Mudstone and wackestone of the upper part of the Antelope ValleyLimestone was deposited in quieter, deeper, or more protectedenvironments shoreward of the bank margin.Basal sands of the Eureka Quartzite prograded westwardacross the carbonate shelf during the Middle Ordovician.Carbonate sedimentation persisted in some areas in siltyembayments, and is represented by the Copenhagen Formation.Transgression began during Eureka deposition, and shelf-lagooncarbonates of the Hanson Creek Formation were deposited astransgression continued during Late Ordovician and earliestSilurian time .The lower part of the Silurian-Lower Devonian Lone MountainDolomite in the Fish Creek Range is transitional to outerplatform carbonate-bank deposits at the type section to thenorthwest, and to restricted, inner-platform deposits of thepartly correlative Laketown Dolomite to the east. Rhythmicallyalternating, shallow subtidal and restricted peritidal depositsform the upper part of the Lone Mountain in the study area, andreflect progradation of peritidal environments as the earliestDevonian sea regressed.Younger Devonian rocks in the Fish Creek Range lie within anorth-trending transitional belt in which shallow, eastern lithofacies(predominantly dolomite) and deeper-water, limestonelithofacies intertongue. Peritidal deposits of the Beacon PeakDolomite prograded westward during the mid-Early Devonian. Subtidal, fossiliferous limestone of the Bartine Member of theMcColley Canyon Formation was deposited as transgression beganduring Emsian time (qronberoi to inversus conodont Zones). Limemudstone, wackestone, and packstone of the Coils Creek Member ofthe McColley Canyon Formation was deposited in quieter, slightlydeeper, shelf waters during late Emsian time (inversus Zone).Regression followed during latest Emsian time (serotinusZone). Dolomite and crinoidal dolomite of the Sadler RanchFormation (latest Emsian to Eifelian) was deposited in shallowwaters of the outer shelf. The overlying Coarse CrystallineMember of the Oxyoke Canyon Sandstone is a regressive sequence ofquartzose dolomite and dolomite-cemented sandstone deposited onthe inner platform, where beach and intertidal environments wereseparated by a low-relief coastline.Thick-bedded, peritidal dolomite of the lower part of theSentinel Mountain-Bay State interval represents progradation ofperitidal facies across the shallow platform during early MiddleDevonian time. The upper part of the Sentinel Mountain-Bay Stateinterval was deposited in more circulated, shallow-marinecarbonate-bank environments.The lower part of the Devils Gate Limestone in the study areareflects deposition in shallow, agitated shelf waters and quieter,deeper, shelf lagoons and embayments. Inundation of the carbonateplatform followed and is reflected by a shift to deeper waterfacies during Frasnian (early Late Devonian) time.The Fish Creek Range was affected by Sevier hinterland deformation during the Late Mesozoic; N to N15E-trending folds reflect overall east-west compression. Upper Cretaceous granitic rockswere emplaced at depth beneath the southwest side of the studyarea, where conodont alteration indices from Paleozoic collectionsindicate paleotemperatures of 500-600 C. Two-mica granitic dikes,exposed at McCulloughs Butte, intrude Ordovician rocks.Thermal effects may have promoted initial gravity slidingof the Silurian-Devonian section off of the Ordovician sectionat the Hanson Creek level (Upper Ordovician-Lower Silurian).Low-angle normal faulting within this stratigraphic level ispervasive in the northern part of the Fish Creek Range. It isinterpreted that faulting at the Hanson Creek level wasinitiated at about the same time that the Upper Cretaceousintrusion was emplaced. Movement along the faults may havecontinued or been renewed during Oligocene extension.Low-angle normal faulting at the Silurian and LowerDevonian levels post-dates faulting at the Upper Ordovicianlevel. It is interpreted that these faults developed duringOligocene uplift and extension.Volcanism and shallow intrusive activity affected thenorthern Fish Creek Range during earliest Oligocene time, and isrepresented by the Ratto Springs Rhyodacite. High-angle normalfaults typical of basin-and-range extension are common throughout the area and represent the most recent phase of deformation."
http://hdl.handle.net/1957/40285,"The late Eocene Spencer Formation crops out in the low hills on thewestern edge of the central Willamette Valley, Oregon. Surfaceexposures in eastern Benton and southeastern Polk Counties and oil by gaswell records and cuttings in Polk, Marion and Linn Counties werestudied to determine Spencer stratigraphy, regional lithologicvariations, and depositional environment. Methods used include: studyof outcrops, petrography, texture, and well cuttings, as well as thecorrelation of well logs and microfossil data of McKeel (1984, 1985).The distribution of the underlying early-late Eocene Yamhill Formationis also briefly considered.The Yamhill Formation consists of the Miller sandstone memberenclosed between mudstones. The lower and middle Yamhill recordshoaling from bathyal to marginal marine depths, and they are overlainby bathyal upper Yamhill mudstones. The Miller sandstone is lens-shaped,trends parallel to the Corvallis fault, and reaches a maximum thicknessof approximately 2,000 feet on the east side of the fault. The Millersandstone grades westward into bathyal mudstones, and eastward into volcanic tuffs and flows. Thinning of the Miller sandstone and upperYamhill mudstone along the Corvallis fault suggests movement duringearly late Eocene. The absence of Yamhill strata along the outcropbelt to the southwest may be related to this tectonic activity.Alternatively, Yamhill strata may have been misidentified as TyeeFormation or Spencer Formation.The Spencer Formation was deposited in a tectonically activeforearc basin during a transgression which was interrupted by severalshort-term regressional progradational events. The Spencer isstratigraphically divided (informally) into a lower sandstone-richmember and an upper mudstone member; it is also divided geographically(informally) into northwestern, east-central, and southern provinces.The lower member is 700 feet thick in the northwestern and southernareas, and thickens to 1400 feet in the east-central area. As comparedto the north and south areas, sandstones in the east-central area arecoarser (fine to medium versus very fine to fine), the sandstone tosiltstone ratio is higher, and volcanic interbeds are more common.Deposition is thought to have been at inner shelf and shoreface depths,grading eastward into nonmarine. In the northwestern area, abundanthummocky cross-bedding of arkosic to arkosic-lithic lower Spencersandstones suggests deposition on a storm wave-dominated shelf.Periods of shoaling to shoreface depths are indicated. In the south,sandstones are markedly more volcanic-rich (dominantly arkosiclitharenites), contain more fossils, and are more highly bioturbated.Shelf-storm deposits in the south are normally graded with a basal lagof coarse volcanic grains and fossils. Besides a more proximalvolcanic source, a shoal barrier within-the southern part of the basin may have caused the different sediment character. Deposition wasprobably at middle to inner shelf depths at the outcrop belt. It mayhave deepened slightly eastward before shoaling to nonmarine in theeasternmost part of the study area. Volcanism was active nearby on theeastern and southeastern margins of the basin. Small volcanic centerswithin the basin may have created highs and acted as localized volcanicsources.As transgression continued, upper Spencer mudstones were depositedat middle to upper bathyal depths. Volcanic activity increased on theeastern edge of the basin. Mudstones grade eastward and upward intotuffs and flows of the eastern Willamette volcanic facies."
http://hdl.handle.net/1957/40298,"The Ataspaca prospect is in the Cordillera Occidental, 45 km northwest of Tacna, Peru. Epizonal intrusions satellitic to the Caplina- Ataspaca pluton were emplaced 41 m.y. ago into limestones of the Lower Jurassic Pelado Formation along the northeast-trending Chucchuco fault system. Depths of emplacement ranged from 4.5 to 6.0 km. The intrusions record the differentiation of a calc-alkalic, I-type magma system from diorite to monzogranite by fractionation of augite, plagioclase feldspar, hornblende, and biotite, and by mixing of granitic and dioritic magmas. This magmatic system is compositionally similar to the Arequipa segment of the Coastal Batholith of Peru. Seven hydrothermal systems correlate temporally and spatially with the emplacement of granodiorite and monzogranite stocks, and two magmatic-hydrothermal breccias. Replacement lodes, fissure veins, and disseminations of base metal sulfides and molybdenite are hosted by compositionally zoned, porphyry-related garnet-diopside skarn that formed within and adjacent to an aureole of potassic alteration. Base metal sulfide fissure veins formed at temperatures of 170-280 °C, based on sulfur isotopic calculations. Sulfur isotopic values (-3.3 to +1.1 permil) are consistent with a magmatic source. Elsewhere, marmatite-arsenopyrite mineralization is hosted by unzoned idocrase-garnet skarn adjacent to a shattered stock of pyrite-bearing, seriate-textured monzogranite. Most intrusive rocks have been altered to endoskarn or Ca-Na assemblages. Endoskarn is characterized by the progressive replace ment of ferromagnesian minerals by actinolite, tremolite, and diopside and formed by reciprocal exchange of Fe for Ca derived from nearby silicated limestone. Ca-Na alteration is characterized by similar calc-silicate minerals, but is distinguished by the replacement of orthoclase by plagioclase feldspar, and (or) magmatic andesine by oligoclase. Alteration temperatures are estimated from recent data (Carten, 1986) to have been between 400 and 500 °C, and fluid salinities were in excess of 23 % NaCl-equivalent. Ca-Na and potassic alteration constitute a metasomatic couplet whereby alkalies were exchanged as fluids passed through thermal gradients adjacent to intrusive contacts. Regions of inflow and out flow are characterized by Ca-Na and potassic alteration, respectively. The distribution of these alteration-types indicates that the tops and bottoms of several porphyry-type alteration systems are exposed at Ataspaca. Additional base metal lodes may be localized by northeast-trend ing faults within and near the aureole of potassic alteration, and at depth in skarn-type deposits where these structures cut limestone of the middle Pelado Formation. Regional exploration potential for porphyry- and skarn-type mineralization is high."
http://hdl.handle.net/1957/41212,"Rubber-modified asphalt pavements have been used in Sweden andthe United States since the 1970's. In these applications groundrecycled tire particles (0.25 inch minus) are added to a gap-gradedaggregate and then mixed with hot asphalt cement. The benefits ofadding rubber to the mix include increased skid resistance under icyconditions, improved flexibility and crack resistance, elimination ofsolid waste, and reduced traffic noise. The major disadvantage ofthese rubber-modified mixes is their high cost in relation to conventionalasphaltic concrete pavements.This research project consisted of a laboratory study of mixproperties as a function of variables such as rubber gradation andcontent, void content, aggregate gradation, mix process, temperature,and asphalt content. Twenty different mix combinations were evaluatedfor diametral modulus and fatigue at two different temperatures (-6°C,+10°C). Also, five different mix combinations were evaluated forstatic creep and permanent deformation. Layered theory was used toevaluate the effects of mixture variations on pavement life. Theresulting information was used to develop guidelines for use of rubberasphalt mixes in United States road systems.The findings of the field survey indicate that the rubber-modifiedasphalt mixture is more susceptible than the conventionalmixtures to preparation and compaction problems when adverse weather orequipment problems occur. However, with adequate equipment andfavorable weather conditions, the rubber-modified asphalt mixtureplacement is similar to conventional mixture placement. The fieldstudy also indicates that stopping distances can be reduced 20 percentfor the rubber-modified pavements in icy conditions. In view of thesignificant reductions in wintertime stopping distances under icy orfrosty road surface conditions, the use of coarse rubber in asphaltpavements should be seriously considered. This is particularly truefor areas such as bridge decks, on and off freeway ramps or insulatedroadway sections.The findings of the laboratory study indicate that the rubbergradation and content, aggregate gradation, and use of surcharge duringsample preparation have considerable effect on modulus and fatigue lifeof the mix. The results of static creep and permanent deformationtests indicate that the rubber asphalt mixes had low stability and highelasticity. Also, due to greater allowable tensile strain in rubber-modifiedmixtures, the thickness of the modified mixture can bereduced, using a layer equivalency of 1.4 to 1.0."
http://hdl.handle.net/1957/41220,"The purpose of this study was to examine the relativeeffectiveness of functional isometric squats on thedevelopment of dynamic strength, static strength and powerof college males. Ten college males volunteered for thestudy. The subjects trained two days per week for a totalof eight weeks which consisted of a two week preconditioningperiod followed by a six week functionalisometric squat training period. The test data werestatistically treated using a paired t-test and one-wayanalysis of covariance. The .05 level of significance wasselected for accepting or rejecting the null hypotheses.The results of the imposed training program revealed asignificant increase in dynamic strength. There were nosignificant increases in power between groups; however, asignificant increase in power was found within the functionalisometric and dynamic squat training groups. Theresults of this study have several implications towardsstrength training of athletes and students enrolled in aphysical education weight training activity class."
http://hdl.handle.net/1957/41224,"This study employed ethnographic methodology to investigateand record the post-camp, pre-assimilation period of Laotian refugees.The primary goal was to document the special problems andexperiences of the Laotian population as they attempted to adjustto new roles and expectations within mainstream North Americansociety.Oral histories and biographical statements focused on theperceptions and observations of the members of the refugee populationas they arrived and interacted with American culture.Data gathered during fieldwork were analyzed within a frameworkof selected educational and anthropological theories.Fieldwork within the Laotian refugee community during itspost-camp interfacing with North American culture generatedconclusions and recommendations which focused on and relatedto the entire spectrum of human activity. Particular emphasiswas placed on Laotian and American cultural structures as wellas on the psychological and cultural difficulties and challengeseach population encountered during the first stages of assimilation or acculturation. This study was conducted with heavyemphasis on participant observation and analyzed within theanthropological tradition of reflexivity."
http://hdl.handle.net/1957/41233,"Adequate lubrication is of the utmost importance ininternal combustion engines. Low temperature operationwith low-proof alcohol may create some operational problemsif alcohol and or water accumulates in the crankcaseoil. Condensates of unburned alcohol and water may beblown into the crankcase oil with blowby gases. Thesecondensates may form an emulsion with the crankcase oilthat may restrict the supply of oil for adequate lubrication.Three engine tests were performed to identify theeffect of low-proof ethanol fueling on crankcase oil dilutionand degradation.The first test was hydrous ethanol carburetion in a2.3 liter, 4 cylinder, 1974 Ford gasoline engine. Thesecond test was a mixture of low-proof ethanol fumigationand normal diesel fuel injection (at reduced rate) in anAllis-Chalmers Model 2900 turbocharged diesel engine. Thethird test was also a mixture of ethanol fumigation anddiesel injection in an Allis-Chalmers Model 2800 naturallyaspirated diesel engine.Ethanol of 130 and 160 proof was used in these tests.The duration of each test was six hours steady operation.Independent parameters of crankcase oil temperature, engineload and speed, percent of total energy in the formof ethyl alcohol and proof of the ethyl alcohol wereconsidered and varied. After each test the oil was sampledfor American Society for Testing and Materials (ASTM)laboratory tests for determination of flash points, firepoints, water by centrifuge, water by distillation, andviscosity at room temperature.Results for the first test indicate that the use ofethanol of 130 proof or less may result in accumulation ofwater in the crankcase oil that may be harmful to theengine. In the second and third tests although there wasa decrease in fire and flash points as well as in the viscosityof the oil, no appreciable amount of water oralcohol was detected in the crankcase oil. It is importantto mention that there was a maximum alcohol fuel flowrate beyond which the diesel engine starts to knock ormisfire."
http://hdl.handle.net/1957/41235,"The purpose of this thesis is to extend onedimensional recursive fast Fourier transform (1-D RFFT)into two dimensions, by which the two dimensional signalcan be processed recursively and the desired spectrum canbe obtained.Compared with FFT, RFFT has the followingadvantages: (1) No requirement that the number of inputdata should be equal to the number of frequencies. (2)Fourier transform can start before all the data areobtained. The latter makes this algorithm suitable foron-line spectral analysis.In this thesis, a two dimensional RFFT algorithm isproved mathematically, and an application to signaldetection is demonstrated. Also, this algorithm can beapplied to image processing and other two dimensionalsignal processing problems."
http://hdl.handle.net/1957/41306,"This study measured muscular strength and perceivedexertion of active men, 25 to 64 years old. The subjectswere 80 members of a large YMCA, with 20 active men chosenfrom each of the following age groups: 25-34, 35-44, 45-54,and 55-64. Measurement of strength consisted of assessingthe maximum weight that could be lifted, through a completerange of motion, 10 times (10-RM) for each of six strengthexercises; leg press, leg extension, leg curl, declinepress, seated rowing, and behind neck pulldown. Uponcompletion of the last strength test, each subject indicateda rating of perceived exertion (RPE) from the Borg scale.Total Body Strength (TS) represented the sum of theweight lifted in each of the six strength tests. To adjustfor body size, TS was divided by the subject's Body MassIndex (BMI) and this ratio was termed Relative Strength(RS). The RS of the 55-64 age group was approximately 72per cent of the value recorded by the 25-34 age group. Thisdifference was significant (p = .0000) and linear (p =.0000). The means of the two older age groups weresignificantly different from the two younger groups, but notfrom each other. RPE for both the 25-34 and 35-44 agegroups was significantly greater (p = .0072) than the RPEfor either of the two older age groups; however, thedifference between the means of any two age groups was lessthan 1.6, and the correlation between age and RPE was low(-.3139).It was concluded that (1) RS was less for successivelyolder age groups of active men. The difference between agegroups followed a linear trend and by age 60, RS was 72 percent of the value at age 30. (2) The RPE for the 10-RMstrength tests was similar for all age groups."
http://hdl.handle.net/1957/41308,"A characterization of the antigenic determinants (epitopes) of theglycoprotein (G) of infectious hematopoietic necrosis virus (IHNV) wasmade with different regions of the G gene expressed in Escherichia coli. AcDNA copy of the G gene was divided into four fragments after Taq Idigestion and these fragments were subcloned into the pATH vectorswhich put expression of each G gene fragment under the control of the trpEpromoter. The resulting plasmids encoded trpE-G fusion proteinscontaining different regions of the viral glycoprotein. The three plasmids,pXL2, pXL3, and pXL7, were found to encode fusion proteins that weredetected with anti-IHNV sera in Western immunoblots. A comparision ofreactivities of the fusion proteins encoded by these plasmids was madewith a number of anti-G specific monoclonal antibodies (Mabs) by Westernimmunoblot and radioimmuoassay. The non-neutralizing monoclonalantibody, 136J, was found to react with the trpE-G fusion proteinencoded by pXL3 and the fusion proteins encoded by plasmids, p52G andp618G, which were identified in previous studies (Gilmore et al., 1988). Another non-neutralizing Mab, 2F, was able to bind to the pXL3 fusionprotein and the neutralizing Mab, RB B5, recognized the pXL7 fusionprotein. Competitive radioimmune studies with a synthetic peptidederived from the amino acid sequence encoded by pXI_3 was found toinhibit the binding of a neutralizing Mab, 127B, to purified IHN virus."
http://hdl.handle.net/1957/41309,"Initial sites of localization and multiplication of Pasteurellamultocida were examined in chickens intravenously inoculated withvarying doses of bacteria. Sections of lung, liver, kidney, bonemarrow and spleen were prepared for light microscopic examination.Tissue sections were stained with the hematoxylin and eosin stain,Gram's stain or the avidin-biotin-peroxidase complex immunoenzymatictechnique. Of the three, immunohistochemistry proved to be far moresensitive in localizing bacteria within the various organs. Asearly as five hours postinoculation, bacteria were evident in lownumbers in splenic and hepatic mononuclear phagocytes. Bacteriawere not observed within the other organs or the blood. Withincreasing time, bacteria were observed in large numbers withinthese cells, causing necrosis of phagocytes, and liberating bacteriainto the sinusoids. In birds succumbing to the infection, bacteriawere seen in large numbers in all organs and in the blood, bothintracellularly and extracellularly. These results are consistentwith the hypothesis that P. multocida multiplies within hepatic andsplenic phagocytes in an early phase of infection. The possibilitythat Pasteurella multocida may be able to resist intracellularkilling and may in fact multiply within the mononuclear phagocyte isdiscussed."
http://hdl.handle.net/1957/41310,"It was previously shown that vaccinia virus is unable to complete its replicative cycle in cells that have been subjected to cytochalasin-B mediated enucleation prior to infection. Likewise, in the presence of the drug α-amanitin, a potent inhibitor of host RNA polymerase II but not of viral transcription, the replication of vaccinia virus is inhibited by approximately 95%. These findings led to the conclusion that active participation of the host cell transcriptional apparatus is required for the production of infectious vaccinia virus progeny. In order to identify the viral gene(s) that interacts with the host cell transcriptional apparatus during viral replication, I isolated and characterized a vaccinia virus mutant (α-27) capable of replicating in the presence of the drug α-amanitin. A biochemical analysis of the replication of α-27 versus wild-type vaccinia virus in the presence and absence of the drug revealed no differences with respect to DNA synthesis or viral protein synthesis. However, a marked difference was observed in the ability of the two viruses to direct the proteolytic processing of the two major core precursor polypeptides, P94 and P65, in the presence of the drug. The processing reaction was completely blocked by α-amanitin in wild-type vaccinia virus-infected cells, but proceeded normally in α-27-infected cells. In an attempt to map the mutation responsible for α-amanitin resistance, an α-amanitin-resistant temperature sensitive vaccinia XT virus mutant (α[superscript r]ts7), in which both phenotypes were the result of one or two very closely linked mutations, was isolated. Marker rescue experiments using the cloned Hindlll DNA fragments from wild-type vaccinia virus, mapped the a-amanitin-resistant mutation to the 1.5Kb Hindlll-N fragment. As a preliminary step toward determining the nature and number of the gene(s) encoded within the Hindlll-N fragment, I sequenced this region of the genome using the Sanger dideoxynucleotide chain termination method. The sequencing data showed that there are two open reading frames in this area of the genome. One of the open reading frames is translated into a 20K polypeptide while the second one is translated into a 48K polypeptide."
http://hdl.handle.net/1957/41728,"Plans for farm buildings should efficiently explaininformation about their construction. User understandingand actual use made of plans has received little study.The format used for plans should enhance their wider useand greater satisfaction by individuals concerned withconstructed buildings.This study addressed two research questions: (1) Isthere a relationship among typical formats used forportraying a farm building plan and understanding theinformation therein by typical users, and (2) whatcomponents used in the portrayal format of farm buildingplans are preferred by typical users? A pole frame building plan was developed that usedorthographic, perspective and exploded drawings. Twentyquestions about this plan were asked a sample of 278typical users in 20 different North Dakota locations.Eight additional questions queried user preferences forplansheet color, size, extent of written explanation onuse of the finished building and use made of plans.The study determined that users of plan formatsemploying pictorial drawings (perspective and exploded)gained a better understanding of the plan than those whoused the orthographic format. Typical farmer, lender andcounty agent plan users gained a better understanding inless time than did younger students. Plan understandingand time needed for understanding a plan was unaffected bythe indicated carpenter experience or training on planningfarm buildings by users. Plan understanding was affectedby the relationship of detail size, clarity and planformat.Typical users of farm building plans preferred aminimum explanation on the plan about use of the finishedbuilding. Plansheets were preferred with blue lines onwhite 11 x 17-inch paper. The use of plans for actualconstruction was secondary to their use for planning."
http://hdl.handle.net/1957/41852,"Subsurface mapping was used to determine the structure andgeologic history of the South Cuyama dome and part of the Russellfault in the South Cuyama oil field area. Deformed Late Cretaceousand or early Tertiary marine strata are unconformably overlain bythe late Oligocene to early Miocene Vaqueros Formation (QuailCanyon Sandstone Member, Soda Lake Shale Member, and Painted RockSandstone Member) northeast of the Russell fault. Rapid subsidenceabruptly downdropped shelf deposits in the transgressive QuailCanyon Sandstone, ending shallow-marine deposition. Warping of theQuail Canyon shelf formed elongate west-northwest-trending submarinetroughs and highs at the same time as the basinal Soda Lake ShaleMember was deposited. Locally, the Soda Lake Shale ponded in topographiclows floored by Quail Canyon Sandstone. In addition, progradingturbidites of the Soda Lake Shale Member and shelf depositsof the Painted Rock Sandstone thinned over the highs, including theproto-South Cuyama dome. Renewed subsidence during the late Saucesianaccompanied deposition of the Saltos Shale Member of the MontereyFormation. Late Saucesian-early Relizian movement along thenortheast-trending Cox normal fault set in part controlled furthergrowth of the proto-South Cuyama dome and thinning of the SaltosShale over structural highs. Shelf and shallow-marine depositsof the Branch Canyon Sandstone and overlying undifferentiatedBranch Canyon Sandstone-Santa Margarita Formation (BCSM) progradedacross the basin during the middle and late Miocene. Major rightslipalong the Russell fault juxtaposed contrasting coeval stratigraphicsections prior to deposition of the Pliocene(?) Morales(?)Formation. Northeast-trending normal faults and northwest-trendingstrike-slip faults formed across the dome during deposition of theBCSM in response to right-lateral wrench faulting on the Russellfault. The Morales(?) Formation conformably overlies the BCSM andprobably represents the transition from marine to nonmarine deposition;the uppermost part possibly includes Pleistocene alluvialdeposits. Right slip along the Russell fault was accompanied byfolding of at least the lowermost Morales(?) into the present-daySouth Cuyama elongate dome subparallel to the Russell fault.Right-stepping en echelon axial culminations on the dome were offset4,500 feet right-laterally by the Russell fault.The south-dipping South Cuyama thrust fault tectonically overrodethe Russell fault, South Cuyama dome, and Pleistocene alluvialdeposits, folding and thrusting Eocene and younger strata of theSierra Madre Mountains northward. The north-dipping Morales faultthrust Paleocene to Miocene strata of the Caliente Range southwardover Pliocene(?)-Pleistocene alluvial deposits during the latePleistocene. Between these two thrust faults is the present-dayCuyama Valley.Structures in the South Cuyama oil field and adjacent areasformed in response to recurrent right-lateral wrench tectonismalong the Russell fault during the middle to late Miocene andpossibly from latest Oligocene to Pliocene time. The complexfaulting and folding associated with wrench tectonism are obscuredby the Pleistocene-Holocene contractile regime."
http://hdl.handle.net/1957/42687,"During much of the Early and Middle Devonian, shallow normalmarine and peritidal sediments were deposited in northwestern ClarkCounty, Nevada. Lack of a standard stratigraphic nomenclature for thearea necessitates utilizing terminology from central Nevada andwestern Utah.The Sevy Dolomite represents Early Devonian deposition in a tidalflat environment. A Zlichovian transgression initiated deposition ofthe normal marine McColley Canyon Formation in the area. Continuationof that transgression was responsible for the deposition of the lowerpart of the Pintwater Formation, a new formation which consists ofsilty, argillaceous dolomite with abundant secondary chert. A Dalejanregression occurred during deposition of the upper part of the PintwaterFormation; it was during the later phases of this regressionthat the Oxyoke Canyon Sandstone was deposited in a complex barrierbar system which paralleled the coastline.Three Middle Devonian transgressions of varying magnitude have beenrecognized in southern Nevada. The first transgression, during theearly Eifelian, was responsible for the widespread deposition of theCoarse Crystalline Member of the Simonson Dolomite. The CoarseCrystalline Member represents an entire transgressive-regressive cycle.The second Middle Devonian transgression, which occurred later in theEifelian, initiated deposition of the restricted, shallow subtidal tosupratidal Alternating Member of the Simonson Dolomite. Deposition ofthis unit was marked by periodic minor rises in sea level. Eachdark-light dolomite couplet represents a single transgressive pulsefollowed by upward-shallowing sedimentation. Peritidal sedimentationwas brought to an end by the third Middle Devonian transgression.This transgression, which occurred during the middle to late Givetian,brought the deeper water lithotope of the Guilmette Formation intothe area.The tectonic setting in southern Nevada during the Early Devonianwas significantly different than that in central Nevada; southernNevada facies are different than central Nevada facies, and a relativelycondensed conodont sequence indicates a slower rate of subsidence.During the Middle Devonian, however, facies throughout southern andeast-central Nevada are markedly similar, as is the timing of depositionalevents. This indicates that the tectonic setting along the southernCordilleran margin was more uniform by Middle Devonian time."
http://hdl.handle.net/1957/42690,"The DeLamar Silver Mine is in the north-trending OwyheeMountains of southwest Idaho. As part of the Silver City regionit is included in the Basin and Range physiographic province.The lithologic units of the Silver City region, surroundingthe DeLamar Silver Mine, are composed mostly of Cretaceous graniticrocks and Miocene volcanic rocks. The volcanic rocks which varyin composition from basalt to rhyolite are predominant in aerialextent. Regional structure is dominated by a set of N10-20°Wtrending oblique-slip, high angle faults and a less pronounced settrending N75°W. These faults may be related to crustal extensionin the Basin and Range province and to rifting in the Snake RiverPlain. The mineral deposits of the Silver City region occur mostlyas epithermal vein fillings of fractures and faults. The predominanttrend of the veins is north-northwest.The DeLamar Silver Mine is in a complex Miocene volcanicsequence. Units of various compositions including basalt, latite,rhyolite, and andesite were emplaced as coalescing flows,exogeneous domes, and necks. A porphyritic rhyolite is the mostwidespread unit in the mine area.Epithermal silver and gold mineralization at DeLamar is mostcommonly concentrated in the well-fractured, silicified, upperpart of the porphyritic rhyolite. The most continuous mineralizationis below the clay-altered base of an overlying fine-grainedbanded rhyolite.Mineralogy of the deposit is dominated by sulfides andselenides. Naumannite is the dominant silver mineral commonlyoccurring as small disseminated grains in quartz. Other silverbearing minerals include; acanthite, argentopyrite, and pyrargyrite.Fine-grained free gold is highly disseminated in the gangue. Pyriteis the most dominant and widespread sulfide of the deposit followedin abundance by marcasite.The gangue consists almost entirely of quartz. Several varietiesoccur including lamellar quartz; white, gray, and black common veinquartz; and well formed crystalline quartz. Hydrothermal alterationminerals at DeLamar include sericite, secondary quartz, kaolinite,alunite, chlorite, and zeolites.Mineralogy of the veins and alteration at DeLamar suggeststhat hydrothermal solutions were probably at temperatures 100 to300°C. These solutions are believed to have been highly dilutedsodium-chloride waters closely related to the rhyolitic volcanism."
http://hdl.handle.net/1957/43035,"The study was a creative endeavor in which researchfindings from the areas of medicine, mental health andeducation concerning effects of background music were combinedinto an experimental musical form designed to promote andfacilitate the relaxation response. This experimental musicwas cormared with Baroque largo musical background, as recommendedin Lozanov's method of accelerated learning, and with ano-music control.Three groups of 19 subjects each were selected fromvolunteers enrolled in classes at Oregon State Universityfor Summer Term 1983. Participants were randomly assignedto one of three treatment groups. Group A listened toan audio tape of voiced relaxation instructions. Group Blistened to voiced instructions with Baroque largo musicalbackground. Group C listened to voiced instructions withexperimental musical background.Pre-post measurements of pulse, respiration, andsystolic and diastolic blood pressures were taken for eachtreatment as indices of relaxation. Participants also respondedsubjectively by means of a questionnaire and through informalinterviews with the investigator at the end of each session.Results indicated that the experimental music treatmentwas statistically significant over the no-music control inpromoting the relaxation response at the .05 level of confidencefor all measurement parameters. The experimental music treatmentwas significantly more effective than Baroque over the no-musiccontrol in three areas - changes in rate of respiration, andreduction of systolic and diastolic blood pressures. The experimentalmusic treatment was dramatically more effective thanBaroque in facilitating the reduction of diastolic blood pressure.Subjective response indicated that while all three groupsreported the relaxation sessions enjoyable, 10 out of 19 subjectsin the experimental group requested tapes of what they had heard,2 out of 19 who listened to the Baroque background requestedtapes of their treatment, and no one in the no-music group requestedtapes of the voice alone. Participants reported feelingsof increased general well-being after listening to the tapes.Recomuendations for further study included testing theexperimental music as background in classrooms, offices, andas part of the Lozanov method of accelerated learning. Testingof variables of sex, age and time of sessions was recommended."
http://hdl.handle.net/1957/43715,"The purpose of this study was to determine the nature and amountof genetic variation and possible associations between winterhardinessand earliness in winter x spring wheat crosses.Four winter wheat cultivars selected for differences in earlinessand winterhardiness were crossed with a nonhardy, day length insensitivespring wheat cultivar. The following year, experiments containing parents, F₁, BC, and F₂ populations were planted at twoenvironmentally diverse sites located at the Sherman Branch ExperimentStation, Moro, Oregon (250 mm of moisture) and the HyslopAgronomy Farm, Corvallis, Oregon (1000 mm of moisture).The amount and nature of genetic variation involved were determinedby obtaining broad and narrow sense heritability estimates,evaluating the degree of dominance and estimating the number of genes influencing both earliness and winterhardiness. Also frequency distributionswere developed for each of the populations.Both broad and narrow sense heritability estimates for earlinesswere higher than those observed for winterhardiness. Both winterhardinessand earliness appeared to be conditioned by both additive andnonadditive gene action. Degree of dominance estimates for the fourwheat crosses grown at two locations differed for each cross andlocation. Earliness was influenced by one to six genes while winterhardinessappeared to be controlled by two genes. The estimation ofgenetic advance indicated that the crosses with high narrow senseheritability estimates and high phenotypic variance in F₂ generationwould result in greater gains under selection for both traits.Based on the results of this study, it seems that Moro is aproper site to select for winterhardiness and Corvallis for earliness.However, it might be better to select for both traits at the same timeat another site such as Pendleton, Oregon, where a realistic selectionpressure can be applied for winter survival and drought would notinfluence the selection procedure. Such a site could also provide anopportunity to evaluate earliness at the same time. Correlationcoefficient estimates showed the presence of a positive associationbetween earliness and winterhardiness. The possibility of using leafdamage readings to measure the winterhardiness levels in wheat populationsalso appears promising."
http://hdl.handle.net/1957/44159,"The Quartzburg District is seven miles north of Prairie City ineast-central Grant County, Oregon. The District is in a pre-Tertiarywindow of volcanic, plutonic, and sedimentary rocks ranging fromPermo-Triassic to Eocene-Oligocene in age. The Permo-TriassicDixie Butte volcanics consist of thick basalts and andesites with minorvolcanic breccias and intercalated argillite, chert, and conglomerate.This unit was moderately to intensely fractured by closely spacedfaults prior to the emplacement of plutons of Early or Middle Triassicage. These plutons include spinel peridotite, gabbro, and granodiorite.Serpentinite is found in and adjacent to the ultramafic plutons. Asecond episode of intrusion is represented by the Late Jurassic DixieCreek granodiorite. The Dixie Creek granodiorite is a concentricallyzoned pluton, which changes in composition gradationally from a thin(less than 30 meters in width) marginal diorite, through granodiorite,to a core of quartz monzonite. The granodiorite portions of the plutonfed north-striking dacite porphyry dikes. Magmatic segregations ofchalcopyrite and pyrite are present in the diorite phase. A potassiumargonage determination on biotite from this pluton yielded a 145 m. y.date (Thayer and Brown, 1964). Sedimentary rocks of mid-Cretaceousage are present in the northern and southwestern parts of the District.They include chert pebble conglomerate, sandstone (lithic arenite),and a single exposure of mudstone. Dikes of basaltic and andesiticbreccia, rhyolite, and basalt of the Eocene-Oligocene Clarno Formationintruded the older pre-Tertiary terrain and fed flows that coveredlarge portions of the Quartzburg District. Deposits of air-fall tuffbreccia and minor siltstone and calcareous mudstone are intercalatedwith the flow rocks. During mid-Miocene time, the rocks of theDistrict were covered by flows of the Strawberry volcanics and theColumbia River Group. Uplift of the Blue Mountains Anticline andsubsequent erosion has exposed the pre-Tertiary rocks. Erosion ofthe mineral-bearing veins has produced rich placer deposits in DixieCreek and the John Day River. Explosive eruption of Mt. Mazamaduring Recent time left deposits of volcanic ash along hill slopes andin topographic depressions.Structural evidence suggests a post Eocene-Oligocene age formineralization. The Clarno Formation is crosscut by west-northwestto northeast-trending faults. These are in turn crosscut by northeastto east-trending faults which, along with the permeable contact zonesof the dacite porphyry dikes, guided the mineralizing fluids from a source at depth. These fluids formed rich mesothermal gold-quartzveins and hypothermal copper-tourmaline massive sulfide veins andreplacement deposits."
http://hdl.handle.net/1957/44741,"Larvae of the Pacific Oyster, Crassostrea gigas, at Whiskey Creek Shellfish Hatchery (WCH) in Netarts Bay, Oregon, are negatively impacted by high-CO₂ water and exposure during the initial shell formation period appears to be particularly damaging. To investigate the mechanism of this early susceptibility, several cohorts of larvae at WCH were monitored for stable isotope incorporation and biochemical composition: one in May 2011 and two in August 2011. The observations presented here focus on the isotopic shifts associated with initiation and rate of feeding, and the catabolism of C-rich (lipid) and N-rich (protein) pools. Persistent ontological patterns in bulk composition among the cohorts suggest that the creation of the initial shell is energetically expensive, and that the major energetic source during this period is maternally-derived egg lipids. The May cohort did not isotopically reflect their food source as rapidly as the August cohorts, indicating slower feeding, higher metabolic demand or lower maternal energy investments. All cohorts turned over organic carbon faster than organic nitrogen. Shell carbon isotopes of all cohorts show a decreasing dependence on ambient dissolved inorganic carbon (DIC) carbon with time and subtle differences in this trend between the May and August cohorts are explored. Patterns in shell δ¹³C suggest greater exposure to ambient conditions during initial shell development, which could be an important process linking ambient carbonate chemistry and larval susceptibility. Scanning electron microscopy (SEM) images are used to document the initial shell formation. Kinetic isotope fractionation, dissolved organic matter (DOM) utilization, and the dissolvability of shell microstructures are also briefly considered in the context of larval susceptibility."
http://hdl.handle.net/1957/44991,"The crawfish enterprise of South Louisiana is shown to haveexpanded as much as 18-fold since the 1950's. It is estimated(1973) that there are about 44,000 acres of managed crawfish ponds.Of the 334 ponds identified and mapped in the thesis, 231 are classedas open ponds, 45 as rice field ponds, and 58 as swamp ponds. Thetotal Louisiana harvest of crawfish is estimated to be about elevenmillion pounds annually valued at about $2. 2 million.The predominance of the crawfish enterprise and its locationswithin South Louisiana are correlated with the French LouisianaCulture areas. The thesis analysis is summarized in a system modelof the crawfish enterprise which visualizes the complexity and interrelationshipsbetween the pond bio-subsystem and the societal-economicsubsystem. In addition the thesis collates information on theecology of the crawfish in South Louisiana, includes original mapsof pond locations, and provides a comprehensive bibliography.Future expansion of pond acreage is envisioned but will belimited by availability of physically suitable sites. Increased crawfishproduction may also result from intensified pond management. However,increases in crawfish production and harvest, it is suggested,will depend upon further research leading to improvement of thecrustacean, especially for greater percentage of edible meat; developmentof markets for crawfish waste; research leading to moreefficient processing and longer shelf-keeping time; and a more stable,adequate price to provide the economic incentive."
http://hdl.handle.net/1957/45149,"With too many demands placed on too little water, the Klamath Basin and itsresidents - human and otherwise - are in dire need. There exists a significant opportunityfor mitigation in the purposeful conversion of seasonal wetlands to permanent wetlandsmanaged to increase baseline water storage levels in the Upper Basin. A thirteen-yearsurvey of Landsat data coupled with contemporary flow information and a semiautonomousclassification method shows that more than 37,000 acres exist in the UpperKlamath Basin that naturally flood when water is plentiful, and so would have a naturaladvantage as storage mediums to buffer the time of maximum availability further into thesummer, possibly retaining up to 60,000 acre-feet of water - nearly a 10% increase overbaseline storage capacity. Managing these lands to maximize storage capacity wouldrequire policy changes in the basin targeted on both public and private lands. Public landsmanagement for this objective would reduce available National Wildlife Refuge land thatis currently leased to area farmers, while private lands management for this purposewould require an effort to provide incentives for voluntary participation, likely theenrollment of affected lands in federal conservation easements under the USDA and aregional water bank market system. In either the public or private case, such a policymust be presented to regional stakeholders while considering their cultural values."
http://hdl.handle.net/1957/45692,"Passage of blood through a sorbent device for removal of bacteria and endotoxin by specific binding with immobilized, membrane-active, bactericidal peptides holds promise for treating severe blood infections. Peptide insertion in the target membrane and stable binding is desirable, while membrane disruption and release of degradation products to the circulating blood is not desirable. Here we describe interactions between bacterial endotoxin (lipopolysaccharide, LPS) and the membrane-active, bactericidal peptides WLBU2 and polymyxin B (PmB). Analysis of the interfacial behavior of mixtures of LPS and peptide using air-water interfacial tensiometry and optical waveguide lightmode spectroscopy strongly suggested insertion and stabilization of intact LPS vesicles by WLBU2, while no such peptide-LPS interactions were evident with PmB. Analysis with dynamic light scattering showed in fact that LPS vesicles appear to undergo peptide-induced destabilization in the presence of PmB. Circular dichroism spectra confirmed that WLBU2, which shows disordered structure in aqueous solution and substantially helical structure in membrane-mimetic environments, is stably located within the LPS membrane in peptide-vesicle mixtures. Interactions between LPS and WLBU2 were also evaluated following immobilization of the peptide at uncoated and polyethylene oxide (PEO)-coated hydrophobic surfaces. PEO layers were prepared by radiolytic grafting of selected PEO-polypropylene oxide (PPO)-PEO triblock surfactants to silanized, hydrophobic surfaces. Immobilization of WLBU2 at the PEO layers was achieved by its noncovalent entrapment among the pendant PEO chains and in separate experiments, its covalent coupling to PEO chains that had been end-activated with pyridyl disulfide groups. Analysis of peptide-LPS interactions using a quartz crystal microbalance with dissipation monitoring showed that upon introduction of LPS suspension to a flow cell housing a surface presenting tethered WLBU2, LPS located at the interface in a fashion irreversible to elution. Circular dichroism spectra recorded for suspensions of LPS and (silanized) hydrophobic silica nanoparticles to which WLBU2-triblock constructs had been adsorbed, confirmed that binding of LPS by tethered WLBU2 is mediated through peptide insertion and conformational change within the LPS membrane. LPS capture by tethered WLBU2 was detected in the presence of fibrinogen as well. However, that outcome is best considered tentative, as it was associated with potentially complex interactions between fibrinogen, LPS, and WLBU2, that remain uncharacterized. In summary, the results of this study strongly suggest that presentation of tethered WLBU2 within a sorbent device will enable the capture of endotoxin from suspension without reintroduction of degradation products to the circulating stream. Thus, they provide a rationale for hypotheses to drive further development of perfusion for the treatment of severe blood infections."
http://hdl.handle.net/1957/46042,"A novel, low-cost instrument capable of measuring surface water PCO₂ was designed for use in dynamic, shallow-water environments. The instrument was tested in the Yaquina River Estuary, a macrotidal estuary known to experience a wide range of conditions ranging from dominance by the coastal ocean during summer upwelling to substantial freshwater discharge events resulting from winter storms. This instrument depends on gas equilibration by the diffusion of CO₂ molecules through a microporous, hydrophobic membrane between the aqueous environment and an enclosed gaseous volume, and subsequent quantification of the concentration of CO₂ molecules in the equilibrated air via Non-Dispersive Infra-Red (NDIR) absorbance technology. The field-testing occurred between January and December 2013, collecting over 200 discrete samples and 30 hours of in situ data. The data collected by this instrument was compared to discrete samples analyzed in the laboratory and found to have an absolute average deviation, or imprecision, of 7%. Preliminary area-weighted average air-sea CO₂ flux estimations for the Yaquina River Estuary (3 mol C m⁻² y⁻¹) show the same order of magnitude as other estuarine studies where comparable PCO₂ measurement techniques were used, but significantly lower than studies where PCO₂ was not directly measured. The discrete sampling program executed in combination with the instrument development process allowed a closer look at the seasonality of this ecosystem. This study discusses the evidence of both physical and biogeochemical processes occurring in the study area."
http://hdl.handle.net/1957/46544,"This study was designed with two major aims. The first was toexamine certain characteristics of both Departmental and Non- Departmentalteachers who were teaching matriculation chemistry in SouthAustralian secondary schools during 1967. The numbers of teacherswho participated were: Departmental 40, and Non - Departmental 23.The second was to ascertain certain learning outcomes of matriculationchemistry students. The learning outcomes investigated were:critical thinking, understanding of science, and achievement in chemistry. The students were divided into four groups for comparison,viz. City Departmental, Country Departmental, Independent andRoman Catholic. There were approximately 200 students in each ofthe school groups.In order to secure the required information, the participatingN chemistry teachers were asked to complete a Questionnaire for ChemistryTeachers while the students were asked to complete a Questionnairefor Students. A measure of two of the learning outcomes wasobtained by administering the following tests:1. Watson - Glaser Critical Thinking Appraisal, Form Ym.2. Test on Understanding Science, Form W.The measure of achievement in chemistry was taken from the resultsof the public examination in leaving chemistry.The responses to the student questionnaire were not treated byany specific statistical test. However, the responses revealed thatnearly three quarters of the students desired a tertiary educationwhile only six percent expressed any intention of becoming scienceteachers. A little more than half the students were doing chemistrybecause they had an interest in it. The average age of the studentswas 16. 10 years.The conclusions from the teacher questionnaire as well as thetwo tests are that the following null hypotheses should be accepted:1. There is no difference in the teaching methods used byteachers in Departmental and Non - Departmental systems.2. There is no difference in the objectives of science teachingheld by the teachers in the two systems.3. There is no difference in the teacher factors of the teachersin the two systems.  There is no difference in the critical thinking abilities ofthe graduates from the four school groups, viz. City Departmental,Country Departmental,Independent and Roman Catholic. .5. There is no difference in the understanding of science betweenthe graduates from the four school groups.The following null hypotheses should be rejected:6. There is no difference in the achievement in chemistrybetween the graduates from the four school groups.7. There is no correlation between critical thinking ability andunderstanding of science of the graduates from the fourschool groups.8. There is no correlation between the learning outcomes andthe achievement in the public examination in chemistry ofthe graduates from the four school groups."
http://hdl.handle.net/1957/46576,"Disc gel electrophoresis of the vegatative cell -free extracts ofstrains of Clostridium botulinum types A, B, C, E, and F and therelated nontoxic group showed limited value as a means for identifyingthese closely related microorganisms, since separation,though not consistent in all cases, could only be based on the numberof protein fractions in the gel,Enzyme staining of the protein -laden polyacrylamide gels ofthe strains showed single or multiple molecular forms for malic(NAD and NADP), isocitric (NAD), succinic (NAD), and lactic (NAD)dehydrogenases and alkaline phosphatase. Analyzing the enzymepatterns of the strains revealed that most of these enzyme systemsare useful for distinguishing the types and the nontoxic strains.A method which allowed two samples to he run in the samepolyacrylamide gel showed that the differences between the total1 protein patterns of two strains can be demonstrated clearly.A type of iron bound protein (ferredoxin) was isolated from C.botulinum using a modification of the method recommended by L. E.Mortenson for isolating ferredoxin from Clostridium pasteurianum.The protein exhibited maximum absorption in the ultraviolet regionnear 260 mμ. Portions of the isolated iron bound protein wereseparated by disc electrophoresis, and following specific iron boundprotein staining, showed a positive reaction in the same position inthe gel column as first demonstrated using cell -free extract.Evidence accumulated using cell -free extract of C. botulinumsuggests that pyruvate is metabolized through a phosphoroclasticsystem as demonstrated in other clostridia. It is probable that theferredoxin has the important role of electron mediator betweenpyruvic oxidase and hydrogenas a for hydrogen evolution and acetylphosphate formation.A purposed system for the synthesis of aspartate and glutamatein C. botulinum incorporating the above enzymes including those ofthe phosphoroclastic system in a partial citric acid cycle andglyoxylate bypass was described."
http://hdl.handle.net/1957/49237,"Twenty Questions, a Screenplay: Writing in Pictures is a film adaptation of my published novel, Twenty Questions. This is a story about a woman whose proximity to a murder leads to terrible truths about her own life. Set during the invasion of Iraq, the story is a comment on violence while, at the same time, exploring class, identity and the meaning of fidelity. Because I adapted a novel, I was able to concentrate on the screenplay form, rather than content.  At the same time, it heightened the contrast between writing prose and writing a screenplay. Because this was an adaptation of my own work, it challenged my allegiance, forcing me to figure out how to be true to the story yet leave the book behind. I am an interior writer. I write impressions, feelings, thoughts. Much of the novel, Twenty Questions, takes place inside my character's head. The screenplay forced me to turn the story inside out, to make the invisible visible, to show the physical and imply the unseen. Writing a screenplay taught me think, not in words, but in pictures."
http://hdl.handle.net/1957/52326,"Microscale reactors operate in sub millimeter space dimensions. Their small length scale enables process intensification of mass, heat and momentum transport that influence reaction rates. Hence it's possible to observe the true intrinsic reaction kinetics occurring for a set of reactions. In this work a novel microscale reactor for producing biohydrodeoxygenated diesel is developed and its performance investigated. Biohydrodeoxygenated diesel was produced by removal of oxygen from vegetable oils in presence of hydrogen at high temperatures and pressures on conventional NiMo Al₂O₃ solid hydrotreating catalysts.Reactor was fabricated with photochemical etching to pattern post features on catalyst plates, laser ablation was used to make integrated oil slots and hydrogen hole mixer. Laser welding was used to seal reactor to provide a hematic seal. Six sigma methodologies were used to ensure fabrication method was in control, capable and stable.Sol gel method was used to deposit high surface area alumina on catalyst plate and wet impregnation method used to deposit active NiMo metal catalyst on support. Phosphorus was added to the preparation mixture as a structural promoter. Initial test of reactor with palm olein showed reactor was able to achieve complete conversion to mainly n-alkane liquid products at temperature 325°C, pressure 500psig under 3minutes of liquid residence time.  Increase in palm olein concentration showed reaction was limited by stoichiometric hydrogen requirement.Model study of hydrotreating process was done with oleic acid. A 3³ factorial experimental design was done to optimize reaction conditions. Temperature was found to be most important followed by reactor pressure and liquid residence time. Effect of catalyst loading was done at 5wt%, 10wt% and 20wt% to study effect on conversion products. 10wt% loading was found to achieve maximum conversion and hydrodeoxygenation.A detailed mathematical model of reactor system was developed, encompassing flow, mass transport and reaction kinetics. From model developed, mass transport limitation free reaction rate constants was found from a simplex optimization algorithm using Comsol Matlab Live link. Model showed good agreement with experimental data and was used to predict maximum conversion and hydrodeoxygenation conditions."
http://hdl.handle.net/1957/53199,"Indoor positioning systems can be used for many applications such as indoor navigation,emergence response, asset monitoring, and shopper assistance. Due to the weak received signal and multipath reflection, the global positioning system (GPS) generally does not work in indoor environments. There are a variety of radio frequency (RF) signals and systems available for indoor localization, e.g., radio-frequency identification (RFID), cellular network, Bluetooth, WiFi, and ultrawideband (UWB) systems. For high-precision localization using RF signals, commonly used techniques include time-of-arrival (TOA) and time-difference-of-arrival (TDOA). Although various aspects of TOA and TDOA systems have been studied extensively, new techniques are still needed to improve two key position estimation aspects: accuracy and complexity.In the first part of this dissertation, we focus on position estimation methods assuming line-of-sight (LOS) propagation. Anchor layout is an important area that affects localization performance. Generally the CramRao lower bound (CRLB) can be used to find the optimal anchor layout. However, it is computationally expensive and not suitable for fast deployment. We propose an incremental anchor layout method (ICALM) based on the largest range measurement change criterion, which is very easy to implement.For TOA systems, an improved method of moments (IMOM) algorithm is proposed to improve the estimation accuracy at the expense of a slightly increased computational complexity. For TDOA systems, we propose a maximal likelihood (ML) based coarse position estimation method to provide the initial position for the nonlinear least squares (NLLS) method. The goal of this proposed method is to substantially increase the stability of the NLLS method. In order to reduce estimation complexity, we propose a nonlinear expectation maximization (NLEM) based estimator. This estimator transforms the high-dimensional estimation problem into several 1-dimensional problems, which does not need any matrix manipulations and is much simpler to implement than the NLLS and ML methods.In practice, none-line-of-sight (NLOS) links often exist. In the second part of this dissertation, we focus on methods for NLOS mitigation. When all the range measurements suffer from severe NLOS errors, no methods could work well without additional information. However, when only part of the range measurements suffer from NLOS propagation, and the LOS range measurements are sufficient for position estimation, it is possible to improve the accuracy without any {a priori} information. We propose an improved least median squares (ILMedS) algorithm, which uses the residue to weight all the anchors and adaptively searches for the largest group of the reliable links for final estimation. It greatly decreases the probability of reaching the outliers and increases the accuracy. At the same time, all the methods developed for the LOS scenarios can be directly applied as the core estimator.Since ILMedS needs to calculate a location estimate for each subset, its computational complexity is high. We propose a particle filter based position estimation (PFPE) method for NLOS mitigation, which uses particles to represent the potential target. Each particle utilizes the range measurements to update its position. It is much easier to implement than the ILMedS method, while their performances are very similar."
http://hdl.handle.net/1957/541,"This thesis presents a Z-parameter based model to predict the substratenoise coupling between two contacts in a heavily doped substrate for frequenciesless than 2 GHz. The empirical model is scalable with contact size and spacingsbetween the contacts and model parameters can be readily extracted from simu-lated or measured data. The error is within acceptable limits and computationalcosts associated with extraction of substrate parasitics is significantly reduced byusing this model compared to numerical techniques. An application of the modelto analyze the substrate noise coupling between a digital and analog block is alsodemonstrated."
http://hdl.handle.net/1957/55572,"IO transactions within a computer system have evolved along with other system components (i.e., CPU, memory, video) from programmed IO (PIO).  In current mainstream systems (spanning from HPC to mobile) the IO transactions are CPU-centric descriptor-based DMA transactions.   The key benefit is that slower IO devices can DMA write system receive traffic to system memory and DMA read system transmit data at slower device throughput relative to the CPU.  With the advent of more cores in a CPU, power restrictions and latency concerns, we show this approach has limitations and based on measurements we propose alternatives to descriptor-based DMA IO transactions.  We explore and quantify performance improvement in three options:1) iDMA: Embedded smalller core to offload DMA descriptor processing from the larger application-oriented cores, reducing latency up to 16% and increasing bandwidth per pin up to 17%.2) Hot-Potato:  Where latency is a concern we re-visit using WC-buffers for direct IO CPU transactions and avoiding CPU hardware changes.  While keeping a specialized receive IO device DMA engine, we reduce latency for small messages by 1.5 μs.3) Device2Device: For applications moving data between devices, we propose how to bypass the CPU, improving latency, power, and CPU utilization."
http://hdl.handle.net/1957/56102,"Automation of computational chemistry, while only an engineering feat, has the potential to accelerating computational research be removing all by the science. The work in this thesis mainly discusses fundamental understanding of complex chemical systems. What is not obvious are the numerous tasks necessary for this fundamental understanding. Under the surface automation and acceleration of many tedious and otherwise intractable tasks has made the research possible.Density functional theory computations of the Cu-catalyzed ring expansion of vinyloxiranes is mediated by a trace less dual Cu(I)-catalyst mechanism. Overall, the reaction involves a monomeric Cu(I)-catalyst, but a single key step, the Cu migration, requires two Cu(I)-catalysts for the transformation. This dual-Cu step is found to be a true double Cu(I) transition state rather than a single Cu(I) transition state in the presence of an adventitious, spectator Cu(I). Both Cu(I) catalysts are involved in the bond forming and breaking process. The single Cu(I) transition state is not a stationary point on the potential energy surface. Interestingly, the reductive elimination is rate-determining for the major diastereomeric product, while the Cu(I) migration step is rate-determining for the minor. Thus, while the reaction requires dual Cu(I) activation to proceed, kinetically, the presence of the dual-Cu(I) step is untraceable. The diastereospecificity of this reaction is controlled by the Cu migration step. Suprafacial migration is favored over antarafacial migration due to the distorted Cu π-allyl in the latter.The origins of differential catalytic reactivities of four Rh(I) catalysts and their derivatives in the (5 + 2) cycloaddition reaction were elucidated using density functional theory. Computed free energy spans are in excellent agreement with known experimental rates. For every catalyst, the substrate geometries in the transition state remained constant (<0.1 Å RMSD for atoms involved in bond-making and -breaking processes). Catalytic efficiency is shown to be a function of how well the catalyst accommodates the substrate transition state geometry and electronics. This shows that the induced fit model for explaining biological catalysis may be relevant to transition metal catalysis. This could serve as a general model for understanding the origins of efficiencies of catalytic reactions.The cross-coupling of allylzinc halides with aryl and vinyl electrophiles provides an effective means to access a wide range of prenylated arenes and “skipped dienes” in a completely linear-selective fashion, as demonstrated by a concise synthesis of the anti-HIV natural product siamenol. DFT calculations shed light on the origin of the excellent regioselectivity observed with the current Pd-based catalyst system.We computed band gaps of amorphous oxides within the In-Ga-Zn triad. These included ZnO, Ga₂O₃, In₂O₃, Ga₂ZnO₄, Ga₂Zn₈O₁₁, In₂ZnO₄, InGaZnO₄, and InGaO₃. Comparing the computed band gap to experimental measurements, the results were promising with a mean unsigned error of 0.28 eV and an unsigned standard deviation of 0.28 eV. Unfortunately drastic over prediction of the band gap for ZnO and InGaZnO₄ was observed.The ever acceleration of computational speed and efficiency is allowing for accurate computations of large and complex chemical systems. As these systems grow in size and complexity the number of data points grow exponentially. Traditionally computational chemists would do the tedious work of manually creating, submitting, examining and parsing all files and data points. With the use of both GPU acceleration and ηScripts, a library of tools, we have changed the intractable into the achievable and tedious into the pleasant."
http://hdl.handle.net/1957/56258,"Cells represent microcosms of spatial and temporal structural organization, with the achievement of internal spatial organization relying upon a collection of macromolecular motor complexes to transport and localize components throughout the cell. Cytoplasmic dynein is one such motor complex, and is the principal ATP-dependent motor for retrograde transport along microtubules in the cell. The large (~1.2 MDa) cytoplasmic dynein complex is comprised of multiple protein subunits, including two copies of the intermediate chain (IC), the N-terminal half ('N-IC') of which, is central to the dynein cargo attachment sub-domain. N-IC is a prototypical example of the intrinsically disordered protein (IDP) class, serving as a primarily disordered polybivalent molecular scaffold for its numerous binding partners (including regulators of the dynein motor complex), itself often becoming more ordered upon binding interaction. This dissertation presents studies aimed at the biophysical characterization of N-IC itself and also its interactions with several of its binding partners to elucidate structure-dynamics-function relationships, and to gain insights into how these binding interactions might be regulated, as these protein-protein interactions can ultimately determine the sub-cellular targeting and function of dynein within the cell.Chapter 1 opens with a brief introduction to IDPs, as they are a relatively new class of proteins whose recognition and presence in the reported scientific literature have grown exponentially in the past decade-and-a-half. The prevalence of intrinsically disordered proteins and protein regions in the proteome, the peculiarities in their binding interactions with partners, and their functionality in the absence of fixed, three-dimensional structure are outlined. This sub-section is followed by a thorough review of cytoplasmic dynein motor functions in the cell and its protein subunit composition, with particular emphasis placed upon the intermediate chain--the central protein of this thesis. A thorough review is also given for regulatory complexes of the dynein motor including dynactin, ZW10 RZZ, and NudE EL. Chapter 2 presents a review of the premier biophysical technique for the study and characterization of IDPs--solution-state protein NMR spectroscopy--and enumeration of particular considerations that must be taken into account (stemming largely from the conformational dynamics and motional freedom of these polypeptide chains) in the interpretation of data garnered from these techniques when applied to IDPs or unfolded proteins.Chapters 3 and 4 present original research work on the characterization of the N-terminal 143 residues (IC:1-143) of the Drosophila melanogaster dynein intermediate chain and its interactions with binding partners. The work presented in Chapter 3 demonstrates that, although predominately disordered, IC:1-143 deviates from random coil behavior, particularly in the form of two regions of α-helical structure near the N-terminus. Furthermore, these helical segments were determined to exist in two non-contiguous segments of IC that interact with the regulator dynactin p150[superscript Glued] protein, and the results of this study provided insights into the biophysical basis by which the IC–p150[superscript Glued] interaction (and thus the association between dynein and dynactin) might be regulated. In Chapter 4 a more detailed conformational and dynamical examination was performed on IC:1-143 using NMR residual dipolar couplings (RDCs) and paramagnetic relaxation enhancement (PRE) experiments, revealing unprecedented detail concerning further deviations of this protein from random coil behavior. The Tctex1 and LC8 light chains binding regions in IC exhibit enhanced polyproline II conformational sampling (relative to a random coil description), and the IC:1-143 protein exhibits further deviations from random coil behavior in the form of significant transient tertiary structure, shedding light on how the association state of IC with dynactin p150[superscript Glued] vs. NudE might be controlled in Drosophila melanogaster when both regulatory proteins are simultaneously present.Chapter 5 presents a summary of the key findings of the work presented in this dissertation, as well as an assessment of outstanding questions in this field and proposed work to help fill these gaps in knowledge. Overall, the results presented in this dissertation provide detailed descriptions of the structure and dynamics of the N-terminal half of N-IC (which constitutes a 'hotbed' for binding activity), revealing both subtle and pronounced deviations from random coil behavior in the form of secondary structure of varying degrees, as well as transient tertiary structure, all of which underlie interactions of IC with its binding partners, and also provide insights into the biophysical bases for regulation of these binding interactions."
http://hdl.handle.net/1957/56259,"Photonic sintering of nanoparticles is a relatively new process for sintering of nanoparticles, deposited on a substrate, into functional solid structures. The working principle of this process is the incidence of large-area broad-spectrum light onto deposited nanoparticles, which results in heat generation in the nanoparticles and their subsequent densification. Key advantages of photonic sintering include rapid, scalable and ambient condition operation. For these reasons there is significant interest in using this process as a manufacturing solution for nanoparticle sintering in emerging applications like RFID tags, flexible electronics, solar cells, and sensors. Despite preliminary demonstrations of photonic sintering, there is little knowledge on the underlying process physics, which results in limited physics-based control of the process. The goals of this work are to (1) expand the state of knowledge on the physics of photonicsintering; and (2) develop a system that can leverage the advantages of photonic sintering for low-cost additive manufacturing using nanoparticle building blocks.Four key topics in photonic sintering are investigated. First, the effects of nanoparticle size on densification and the temperature (of deposited nanomaterial and substrate) are experimentally characterized. Both the temperature and nanoparticle densification are found to be highly dependent on the nanoparticle sizes used. Secondly, a multiphysical model of photonic sintering is developed to link particle size, optically-induced heat generation, resulting temperature rise and consequent interparticle necking. In addition to reflecting experimentally observed trends, the developed model also provides an improved understanding of the underlying physics behind photonic sintering. Thirdly, densification and temperature evolution in photonic sintering of non-metallic nanoparticles is characterized.Lastly, photonic sintering and inkjet deposition are combined into one system to demonstrate the potential of using photonic sintering for a low-cost, multi-material, desktop additive manufacturing system. With further hardware and software development and greater understanding of the physics behind photonic sintering, the developed additive manufacturing system can be further refined. Further development and commercialization of the system developed here has the potential to increase accessibility of low-cost, multi-material additive manufacturing (metals, semi-conductors and ceramics) similar to the currently increased accessibility of polymer 3D printing."
http://hdl.handle.net/1957/56261,"Substations are a crucial element at the transmission and distribution level of electric power systems. The primary substation equipment (power transformers and high voltage switching equipment) is used to transfer and transform electric energy by stepping up or down the voltage in transmission substations. Secondary equipment (such as IEDs, Intelligent Electronic Devices) is used to control, protect and monitor primary equipment and the rest of the substation while relying on a variety of communication protocols.The IEC 61850 standard is a viable candidate for current Substation Automation Systems (SAS) as well as for future Smart Grid (SG) substations. SG is the next generation power grid, which aims to improve reliability and efficiency, reduce the cost of electric energy, and minimize environmental impacts. SG will be relying on effective and reliable communication, and the IEC 61850 standard shows the potential for providing such a communications framework. Currently, the delay performance evaluation of this standard has been carried out at the distribution level. At the transmission level, where data rates are high and there is a low latency requirement, this standard has yet to show its performance.In future Smart Grids, transmission substations will be part of a self-healing network that identifies the faults blackouts and automatically connects disconnects the feeders and re-routes power to ensure security of the grid. According to IEC 61850, the communication requirements for transmission substations will be more time-critical. In this work, the IEC 61850's delay performance is evaluated at a transmission substation between different bays in the case of one outgoing feeder’s failure. OPNET software is used as a simulation tool. In OPNET, devices such as Analog Merging Units (MUs) and IEDs were implemented according to the IEC 61850 standard. Delay performance for Generic Object Oriented Substation Events (GOOSE) messages is evaluated in terms of End-to-End (ETE) GOOSE message delay, with without Virtual Local Area Network (VLAN) attributes according to IEEE 802.1Q and with or without Quality of Service (QoS) attributes according to IEEE 802.1p."
http://hdl.handle.net/1957/56320,"This thesis uses a series of non-fiction vignettes to explore objects, agencies, and networks, applying theories of rhetoric and composition directly to experience and vise versa. Focusing on agency--as understood through sociology's actor-networks, post- humanism’s Object Orientated Ontology, and Ecocriticism's ecological approach--I look at events, landscapes, and partnerships that have shaped who I am and why I write. I find that when life is viewed as a nexus of agencies instead of as a hierarchy, with humans as dominant agency, wilderness becomes a quality of existence that humans already possess in the form of creativity. Once we tap into that quality to examine existence, we discover that we cannot exist without partnerships, and we owe much of our experience, writing, and creativity to the unseen influences of these partners."
http://hdl.handle.net/1957/56322,"This thesis covers the use of a quarter car model to select damping rates for aFormula Student (FS) car, focusing on minimizing vertical tire force variation to improvegrip. A 2 degree of freedom (DOF) quarter car model is cycled over the road frequenciesof interest and the results compared with the 2 DOF optimum damping proposed by inreferences [1, 2, 3].Using the Global Formula Racing (GFR) 2011 FS combustion vehicle, four differentdamper configurations are evaluated on FS style courses. Strain gauges on the suspensionlinks are used measure all six tire forces and moments, compare between setups, andevaluate the relationship between vertical load variation and in-plane grip. Finally, theresults of the simulation and physical tests are compared and the validity and utility ofthe 2 DOF quarter car model is assessed. Three standardized test tracks are utilized aswell an artificial bump similar to that studied in reference [4]."
http://hdl.handle.net/1957/56324,"Natural ground color is useful for reference maps as well as maps where a realistic representation of the Earth's surface matters. Natural color schemes are less likely to be misinterpreted, as opposed to hypsometric color schemes, and are generally preferred by map readers. The creation of natural-color maps was once limited to manual cartographic techniques, but they can now be created digitally with the aid of raster graphics editing software. However, the creation of natural-color maps still requires many steps, a significant time investment, and fairly detailed digital land cover information, which makes this technique impossible to apply to global web maps at medium and large scales. A particular challenge for natural-color map creation is adjusting colors with location to create smoothly blending transitions. Adjustments with location are required to show land cover transitions between climate zones with a natural appearance. This study aims to take the first step in automating the process in order to facilitate the creation of medium- and large-scale natural-color maps for the web. A coloring method based on two grid inputs is presented. Here, we introduce an algorithmic method and prototype software for creating large-scale web maps with this technique. The prototype software allows the map author to interactively assign colors and design the appearance of the map in an automated way. This software can generate web map tiles at a global level for medium and large scales. Example natural-color web maps created with this automated coloring technique are provided."
http://hdl.handle.net/1957/56326,"Pactamycin, a potent antitumor antibiotic produced by the soil bacterium Streptomycespactum, is a structurally unique aminocyclopentitol-containing natural product. Itconsists of a highly functionalized cyclopentitol core unit, two aromatic rings [3-aminoacetophenone (3AAP) and 6-methylsalicylic acid (6MSA)], and a 1,1-dimethylurea moiety. Despite its potent biological activity, the development of thisantibiotic was hampered by its high-toxicity profile. Earlier efforts to modulate itspharmacological properties by modifying the chemical structure using conventionalsynthetic chemistry were hampered by the complexity of the molecule, requiringalternative strategies for structure modifications, e.g., biosynthetic approaches. Thisdissertation describes an investigation of pactamycin biosynthesis in S. pactum and thedevelopment of new pactamycin analogs using biosynthetic approaches.Earlier studies have shown that the aminocyclopentitol unit of pactamycin is derivedfrom glucose, possibly via N-acetylglucosamine (GlcNAc), whereas the 3AAP unit isderived from 3-aminobenzoic acid (3ABA). Although direct involvement of glucoseand 3ABA in pactamycin has previously been established, the processes underlyingtheir conversions to the aminocyclopentitol and 3AAP moieties were unknown. Usinga combination of gene inactivation, chemical complementation, and biochemicalstudies, we demonstrated that 3ABA is processed by a set of discrete polyketidesynthase (PKS) proteins, i.e., an adenosine monophosphate-forming acyl-coenzyme A(AMP-forming acyl-CoA) synthetase (PtmS), an acyl carrier protein (ACP) (PtmI),and a β-ketoacyl-ACP synthase (PtmK), to produce 3-[3-aminophenyl]3-oxopropionyl-ACP (3AP-3OP-ACP). We also found that the hydrolase PtmO isresponsible for the cleavage of a β-ketoacyl product from ACP, which then undergoesa spontaneous decarboxylation. This study also revealed that neither free 3AAP nor itsglycosylated form are directly involved in pactamycin biosynthesis.One of the most intriguing aspects of pactamycin biosynthesis is its high degree oftailoring modifications, e.g., N-carbamoylation, N-methylation, C-methylation,hydroxylation, an 6MSA attachment, which are all confined within the highlycompacted core structure. Due to the promiscuity of some of the tailoring enzymes inthe pactamycin pathway, the sequence or the timing of the tailoring processes werepreviously unclear. However, using a multiple gene inactivation strategy, we wereable to establish the tailoring steps involved in pactamycin biosynthesis. Additionally,we produced two novel pactamycin analogs, TM-101 and TM-102. TM-101 wasgenerated from a triple knockout mutant of ptmH (a radical S-adenosylmethionine(SAM) C-methyltransferase gene), ptmD (N-methyltransferase), and ptmQ (a PKS),whereas TM-102 was generated from a double knockout mutant. Thechemical structures of TM-101 and TM-102 were elucidated by MS, ¹H NMR, ¹³CNMR, COSY, HMBC, and HSQC. Both compounds showed antimalarial activity butlacked significant antibacterial activity and were less toxic than pactamycin towardmammalian cells.Previous studies have also shown that the type I iterative PKS PtmQ is a 6MSAsynthase that supplies 6MSA for pactamycin biosynthesis. However, the enzyme thatis responsible for the attachment of 6MSA to the aminocyclitol unit was unknown.Through genetic and biochemical characterization, we discovered that PtmR, a β-ketoacyl-acyl carrier transferase (ACP) synthase (KAS) III-like protein, is responsiblefor the direct transfer of the 6-methylsalicylyl moiety from PtmQ to theaminocyclopentitol unit. The enzyme also recognizes a wide array of syntheticallyprepared acyl-N-acetylcysteamines (acyl-NACs) as substrates to generate a suit of newpactamycin derivatives with diverse functionalities."
http://hdl.handle.net/1957/56327,"Methane is a flammable gas that is the main component of natural gas. It is a highly potent greenhouse gas, and accounts for about 20% of greenhouse gas emissions. Methane is routinely flared in many industrial processes without harnessing any of its energy. The environmental impact and wasted energy potential make it highly desirable to find an economically feasible process to use this methane.One possibility is to convert methane into liquid fuels for transportation and energy generation. Current technologies to convert methane gas to liquid fuels (GTL) are complex, and the facilities are only economical at huge scales. Methane gas is very difficult to transport and store, so GTL plants must be located at the source of the methane, typically at large petroleum fields or refineries.Biological conversion of methane to liquid fuels is an attractive alternative to traditional GTL processes, as microbial oxidation of methane can produce liquid fuels (e.g. methanol) at ambient temperatures and pressures. When biological organisms are combined with microfluidic technologies, which provide enhanced mass and heat transfer along with a high degree of process control, a very efficient conversion process can be attained at much smaller scales. A further advantage of microfluidics is that the reactors are inherently modular, allowing them to be adapted to practically any required size. This enables the economical conversion of small or remote methane streams to liquid fuels.In this thesis, techniques are described for the immobilization of Methylosinus trichosporium OB3b in a biolamina-plate microreactor (BLP) for conversion of methane to methanol. Effective immobilization requires that the cells remain viable and immobile in the reactor, and that the encapsulation medium is stable and does not degrade during reactor operation. Calcium alginate gels were identified as an ideal immobilization medium, as they are inexpensive, non-toxic, and widely used for the immobilization of cells. Three main requirements must be met in immobilization of cells in the alginate: gel cohesion, gel adhesion, and cell viability. The alginate gel must remain cohesive throughout the entire reactor process, without substantial swelling, disintegration or degradation. The alginate must also adhere stably to the reactor surface, to prevent sloughing which may cause clogging and loss of biological activity. The immobilized cells also must remain metabolically active over the duration of the reactor run. Stable, thin (300-μm) calcium alginate films were achieved by combining an “internal gelation” process to uniformly cross-link the hydrogel, electrostatic adhesion of alginate gel on stainless steel reactor plates modified with aminopropyl-trimethoxysilane (APTMS), and buffering using 4-(2-hydroxyethyl)-1-piperazineethanesulfonic acid (HEPES) to minimize chelation of stabilizing calcium ions from the gel. The alginate-encapsulated OB3b cells retain viability and metabolic activity in these films, although their metabolism of methane to methanol appears to be slowerthan pelagic cells. Overall encapsulation of OB3b in calcium alginate films is an effective method for immobilization, although further optimization is necessary."
http://hdl.handle.net/1957/56331,"Dot mapping is a traditional method for visualizing quantitative data, but current automateddot mapping techniques are limited. The most common automated method places dotspseudo-randomly within enumeration areas, which can result in overlapping dots and verydense dot clusters for areas with large values. These issues affect users’ ability to estimatevalues. Graduated dot maps use dots with different sizes that represent different values.With graduated dot maps the number of dots on a map is smaller and the likelihood ofoverlapping dots is smaller. This research introduces an automated method of generatinggraduated dot maps that arranges dots with blue noise patterns to avoid overlapping dotsand uses clustering algorithms to replace densely-packed dots with dots of larger sizes. Auser study comparing graduated dot maps, pseudo-random dot maps, blue noise dot maps,and area-proportional circle maps with almost 300 participants was conducted. Resultsindicate that map-users can interpret graduated dot maps more accurately than the othermap types. In addition, map users appear to prefer graduated dot maps to the other maptypes. These findings suggest that graduated dot maps are more effective and more appealingthan conventional dot maps."
http://hdl.handle.net/1957/56368,"In the first part of this work, thin films of Al₂O₃ deposited via atomic layer deposition (ALD) are demonstrated to improve the thermal stability of cellulose nanocrystal (CNC) aerogels. ALD is a chemical vapor deposition (CVD) like method in which sequential precursor exposures and self-limited surface reactions produce a conformal thin film with precise thickness control. The conformal nature of ALD is well suited to coating the porous microstructure of aerogels. SEM micrographs of coating thickness depth profiles are shown to agree with trends predicted by precursor penetration models. Thermogravimetric analysis shows samples coated with ALD Al₂O₃ have increased decomposition temperatures.In the second part of this work, ALD zinc tin oxide (ZTO) is used to demonstrate a technique for measuring the substrate inhibited growth in multicomponent and laminate ALD systems. The thickness control of ALD makes it attractive for multicomponent and laminate systems. However, the surface reactions of ALD mean that the first few cycles, while the film nucleates, may have a different growth per cycle (GPC) than when the film is growing on itself in a bulk growth regime. A model for the substrate inhibited ALD of ZTO is derived from two complementary sets of laminates. The thickness and composition predictions of our model are tested against the bulk GPC of ZnO and SnO₂.In the final part of this work, prompt inorganic condensation (PIC) is explored as a potentially more environmentally friendly alternative to ALD for planar thin film applications. Whereas ALD requires expensive vacuum systems and has low precursor utilization, solution based methods, such as PIC, allow atmospheric processing and precursor recycling. The water based PIC solutions use nitrate counter ions which evaporate at low temperatures. Combined with the low energy required to convert the hydroxide precursor clusters into an oxide film makes PIC a promising low temperature route to dense solution processed thin films. The dielectric performance of PIC Al₂O₃ is shown to be comparable to ALD Al₂O₃ films on Si though a large interfacial SiO₂ layer is found to be dominating the behavior of the PIC films. This interfacial layer is shown to form very quickly (≤ 2 min) at low temperatures (≤ 50°C). This low temperature interfacial oxide growth could be a benefit in passivating solar cells."
http://hdl.handle.net/1957/56625,"Commercial methodologies for producing fungal pigments are of worldwide interest due to the desire to move away from synthetic dyes. Chlorociboria species and Scytalidium species have been reported to produce sufficient yields of pigments for commercial production and have attracted special attention because of their use in spalted wood applications. However, there are few data about the toxicity of these pigments on humans or the ecosystem. The main objective of this thesis was to examine fungal pigment mixture toxicity and its effects on living organisms using a zebrafish embryo acute toxicity bioassay. Pigment mixtures from wood agar cultures and liquid malt media were screened. There were significant adverse effects from both the DCM-extracted pigment and the liquid malt medium although there was variability in the toxicity endpoints. The results from this study suggest that all dichloromethane (DCM) pigment extracts followed a dose  response curve and caused higher mortality in higher concentrations after a short time of exposure except the DCM-red pigment extract which follow a non monotonic dose response curve.  The response from both DCM pigment extracts and liquid malt pigment depended on the solubility and bioavailability factors in the water. Overall, the results indicate that the pigments extracted from these fungi are likely toxic to humans. However, as no completely purified compounds were tested, it is possible that other secondary fungal metabolites and wood extractives that were also retrieved during the extraction process might also have played a role in the toxicity."
http://hdl.handle.net/1957/57162,"Ecoroofs have become more prominent in recent years. However, there is currently no enforceable standard or building code for the design and construction of ecoroofs across the United States (Kraupa, 2014). Further research is needed to determine how ecoroofs respond to roof motion and to develop an appropriate design standard.The work herein attempts to examine the complete ecoroof system and its response when subjected to motion. Direct shear interface testing was performed to determine the coefficient of friction at the interface between each layer of the ecoroof. The interfaces were tested under both dry and submerged conditions for soil depths of 100 mm (4 in), 300 mm (12 in), and 900 mm (36 in) to model both extensive and intensive soil conditions. These coefficients of friction tell at which interface the system is most susceptible to sliding, and at what point this sliding will begin. When root barrier is used, its interfaces are critical to sliding. When root barrier is excluded from the ecoroof system, the insulation board Tremco drain mat & filter fabric interface is most susceptible to sliding.Additionally, a shake table was designed and built to subject model ecoroofs to linear motion. Model ecoroofs of varying soil densities, moisture conditions, and slopes were subjected to haversine acceleration pulses. The goals of this testing were to access the potential for soil decoupling from the roof, to determine the extent of this decoupling, to determine how decoupling is impacted by roof slope, soil density, and moisture conditions, and to determine which intensity measure or measures best predicted the observed decoupling. It was determined soil decouples from the roof when velocity exceeds a critical threshold. The magnitude of decoupling is greatest under submerged soil conditions, greater for loose than for dense soil placements, and generally increases with increasing roof slope. Such information is paramount in the development of an ecoroof design standard to ensure public safety."
http://hdl.handle.net/1957/57189,"This thesis describes an investigation of the natural products chemistry of two fungal species of the genus Tolypocladium. Natural products are small organic molecules that are considered non-essential for cell growth and reproduction, and thus part of secondary metabolism. Chemical profiling of these secondary metabolites using a combination of high-performance liquid chromatography (HPLC) and mass spectrometry (MS), as well as ¹H nuclear magnetic resonance (NMR) spectroscopy, identified a number of known and unknown natural products of Tolypocladium inflatum and T. geodes. In particular, putative new peptaibols were detected by LC- MS MS profiling, although these data were insufficient for structural characterization. To determine the effect of a putative secondary metabolite regulator, comparative metabolomic profiling was performed of T. inflatum wild-type and a knockout mutant in which the genes for a homolog of the histone methyltransferase KMT6 had been deleted. A preliminary result on the deletion of the kmt6 gene homolog suggests a knockdown of CsA and possibly the putative new peptaibols. Finally, to demonstrate the potential of T. inflatum to produce medicinally-relevant molecules with new biological activities, extracts and fractions were screened against the human pathogen Neisseria gonorrhoeae. Some test samples appeared to possess potent activity and, suggesting that they contain compounds, which inhibit the growth of N. gonorrhoeae."
http://hdl.handle.net/1957/57190,"Polycyclic aromatic hydrocarbons (PAHs) and oxygen-substituted PAHs (OPAHs) are environmental contaminants present in urban air, dust, soil and water resulting from incomplete combustion of organic materials or fossil fuels; found in crude oil and coal; and formed through photoxidation or biotransformation of microbial. It is widely recognized that PAHs pose risks to human health, especially for the developing fetus and infant, where developmental exposures to PAH have been linked to complex human diseases later in life. To investigate potential developmental toxicity and long-term effects resulting from early in-life stage exposure to PAHs and OPAHs, we utilized the embryonic zebrafish model.In our first study, we conducted a comprehensive toxicity screen of 38 environmentally relevant OPAHs. Zebrafish embryos were exposed throughout development (6 to 120 hours post fertilization, hpf) to a broad concentration range and evaluated for dose response, malformation profiles and CYP1A protein expression. We subsequently clustered the OPAHs based on the concentration that induced 50% adverse effect (EC50) for eachendpoint and found distinct groupings based on structure and AHR activation. In addition, further analysis of a selected OPAH from each group revealed oxidative stress to be a main driver of OPAH toxicity.Once we evaluated the developmental toxicity of this large class of OPAHs, we selected three OPAHs: benz(a)anthracene-7,12-dione (7,12-B[a]AQ), 1,9-benz-10-anthrone (BEZO), 9,10-phenanthrenequinone (9,10-PHEQ), and PAHs: benzo[a]pyrene (B[a]P), and dibenzo[a,l]pyrene (DB[a,l]P) to evaluate adverse long term effects of exposure. Using concentrations that did not result in any visible malformations at 120hpf, we measured in vivo mitochondrial respiration and found at 26hpf, B[a]P, BEZO, and 9,10-PHEQ resulted in a significant decrease in oxygen consumption rates and maximum oxygen capacity. Larval behavior was evaluated at 120hpf, and resulted in a hyperactive phenotype in B[a]P, BEZO, and 9,10-PHEQ, while 7,12-B[a]AQ and DB[a,l]P displayed a hypoactivity in the dark. To further evaluate the effects of developmental exposure, we raised a subset of exposed animals (from 6-120 hpf) to adulthood to evaluate physiological fitness and behavior. Using the AutoResp oxygen probe and swimtunnel (Loligo Systems) we measured differences in oxygen consumption rates, which revealed altered oxygen utilization associated with developmental PAH and OPAH exposures. By using shuttleboxes to test for cognitive learning, we identified that 9,10-PHEQ exposed animals were the most adversely affected, and B[a]P, BEZO and DB[a,l]P exposed animals showed a moderate learning deficiency, while7,12-B[a]AQ exposure resulted in only minor physiological and behavioral changes.Finally, we used mRNA-SEQ analysis at 48hpf to begin to tease apart early transcriptional changes and misregulated biological processes that preceded the onset of these phenotypes and hoped to gain insight into the differential response in adults. B[a]P, BEZO, and 9,10-PHEQ exposed animals showed similar effects in 24hpf oxygen consumption, larval behavior, and adult OCR which we used to correlate to biological processes at 48hpf. Preliminary results illustrated a positive correlation of 5dpf larval behavior and the neurophysiological pathway of visual perception. Further analysis of behavior and mitochondrial function phenotypes will help confirm the biological pathways involved in larval and adult phenotypes and help create a better model for these adverse outcomes. In the work presented here, we used the embryonic and adult zebrafish model to characterize short and long term effects resulting from early exposure to environmentally relevant OPAH and PAH contaminants."
http://hdl.handle.net/1957/57200,"The Cook-Austral island chain has been the center of debate for many years. Contrary to the classical hotspot hypothesis, this volcanic island chain does not exhibit a linear age progression with a single node of active volcanism, but instead shows evidence of young volcanism at several points along the chain. While several hypotheses have been put forth to explain these age systematics, including multiple mantle plumelets, small-scale convection and lithospheric extension, exploring these different possibilities has been limited by the uncertainty surrounding the reliability of the age database for these islands. The vast majority of the ages that have been published for the Cook-Australs were obtained using the K Ar method, a technique that has been shown to be susceptible to the effects of weathering and alteration, with concurrent loss of radiogenic Ar. Here we present 56 new Ar age determinations for eight of the Cook-Austral islands. This incremental heating technique is both more accurate and more precise than the Ar and total fusion Ar techniques. We found that these new ages are on average 10-40% different from and generally older than the K Ar ages for the same samples. We show that these ages are more reproducible within a single lava flow, as well as exhibit less scatter among ages from a single island, and therefore are expected to be more reliable than published Ar age determinations. With less variability in the ages at each island, at least two clearly defined and matching age-progressive trends with origins at Macdonald and Arago seamounts appear in the data, supporting the hypothesis that the Macdonald and Rurutu hotspot tracks were formed by multiple, contemporaneous mantle plumelets aligned in the direction of plate motion. In relation to other volcanic chains on the Pacific plate, the Cook-Austral hotspot tracks record angular rotational plate velocities (0.96 ± 0.05 to 1.09 ± 0.04° Ma) that are similar to that of Hawaii (1.15° Ma) and faster than that of Samoa (0.63° Ma). Over the last 30 Myr both the Cook-Austral and Hawaii hotspots have been located truly intra-plate and thus far away from any tectonic boundary, as opposed to Samoa's hotspot position alongside the active Tonga-Kermedec subduction zone. This implies that hotspot location relative to tectonic boundaries may have an effect on the age progressions recorded by volcanic chains. Furthermore, the similarity between the primary Hawaiian hotspot, which is thought to have a deep origin, and the shallower secondary hotspots of the Cook-Austral islands suggests that these different types of hotspots may behave more similarly than previously hypothesized and can therefore both be used to reconstruct past plate motion, provided they are located far away from any plate tectonic boundary."
http://hdl.handle.net/1957/57253,"Many trace elements (e.g., Zn, Cd, Mo) are essential phytoplankton micronutrients, making them crucial to the marine ecosystem and ultimately the carbon cycle. Because of this association trace metals are also utilized in paleoceanographic studies (e.g., Mo, Cd).  However, not much is known about what controls the cycling of these trace metals in seawater. The primary goal of this study was to improve our understanding Ag, Mo and Cd cycling, focusing on the particulate phase, so that we can understand what influences their delivery to the seafloor.The concentrations of trace metals (i.e., Ag, Mo, and Cd) and minor elements (i.e., Al, Ba, Mn, Zn) were measured in sediment trap samples collected at three sites in the western Arabian Sea; two high productivity nearshore sites (MS2 and MS3) and one oligotrophic gyre site (MS5). The concentrations of these metals were converted to fluxes and compared to four commonly utilized productivity proxies; particulate organic carbon (POC), total barium (Ba), opal, and carbonate (CaCO₃). Particulate Ag flux increases with increasing trap depth at both MS2 and MS3, but decreased with increasing trap depth at MS5. Ag flux also shows a strong positive correlation with particulate organic carbon (POC), as well as opal and Ba. These data suggest that at the high productivity sites, Ag is accumulates in settling, organic-rich particles.  There is no evidence that the intense Oxygen Minimum Zone, which characterizes the Arabian Sea, is influencing Ag accumulation.  Nor is Ag simply related to the opal flux, refuting the idea that Ag is delivered to the seafloor by diatom frustules. Instead, dissolved Ag concentrations and POC and or total particle flux are probably the main controls on particulate Ag formation. Particulate Mo flux also positively correlates well with POC flux, suggesting it might be scavenged onto particulate organic matter.  There is also evidence of Mo scavenging by Mn oxyhydroxides in the deep trap. Therefore particulate Mo flux to the seafloor seems to be controlled by both POC flux and Mn oxyhydroxide formation.  Particulate Cd is organic, despite the fact that Cd and POC fluxes do not correlate particularly well due to the unusual behavior of POC.In summary, all three of the trace metals studied show evidence of a link to organic carbon flux.  Particulate Cd and Mo, as well as Ag at MS5, are found within, or possibly absorbed on to, the organic matter.  They are cycled with this organic matter and thus their fluxes decrease with water depth.  Very little of these metals will make it to the seafloor in deep ocean.  Particulate Ag at the high productivity stations (MS2 and MS3) behaves differently.  It is scavenged by sinking organic-rich particles and fluxes increase with water depth.  Therefore, large amounts of particulate Ag could reach the seafloor, at least in regions characterized by high productivity."
http://hdl.handle.net/1957/57270,"Humans and viral disease are inextricably intertwined. Viral disease plays an immeasurable role in human life, from the disease and economic burden associated with every facet of contending with human viral disease, to managing the consequences of viral disease in organisms important to our food supply, economy, and entertainment. The studies within this dissertation encompass crucial areas of viral research: host-pathogen interactions and diagnostics. Chapters 2 and 3 of this dissertation describe both the study and manipulation of viral-pathogen interactions. The next two chapters describe the application of recombinase polymerase amplification (RPA) for the detection of two prominent viral pathogens in need of improved diagnostic strategies. In Chapter 2, a host-viral pathogen interaction was exploited in an effort to develop a method for increasing influenza virus in the context of cell culture-based viral propagation for vaccine production purposes. PPMO antisense technology was employed to target and suppress the expression of the host gene Interferon alpha (IFNα), which is mainly involved in innate immune response against viral infection, in chicken embryo fibroblast (DF-1) cells. Suppression of IFNα by PPMO resulted in significantly reduced levels of IFNα protein in treated wells measured by ELISA and was shown to not have any cytotoxicity to DF-1 cells at the effective concentrations tested.  Treatment of the self-directing PPMO increased the ability of the influenza virus to replicate in DF-1 cells. Over a three-fold increase in viral production was observed in PPMO treated wells compared to those of untreated controls, which was observed to be independent of the initial viral input. Our results indicate that the use of PPMOs to target host protein expression can result in increased production of influenza virus; a technology that could be used on its own for improvement of vaccine production strategies or as a screening tool for subsequent permanent alterations in cell culture lines that would have similarly increased influenza virus production.In Chapter 3, host-viral pathogen interactions were examined in an attempt to understand an aspect of the host response to Respiratory Syncytial Virus (RSV) infection. The host gene, Myeloid Cell Leukemia 1 (Mcl-1), is upregulated early in RSV infection and is thought to have anti-apoptotic function. Mcl-1 knockout and wild type (WT) mouse embryonic fibroblast (MEF) cells were used to characterize the viral response to the absence of the host protein Mcl-1. The lack of Mcl-1 caused MEF cells to become highly permissive to RSV infection and resulted in extremely high levels of RSV compared to viral replication in WT MEF cells. Mcl-1 knockout cells also exhibited uncharacteristic morphology during RSV infection with increased and enlarged syncytial formation. Interestingly, apoptosis, which Mcl-1 helps regulate, was not induced in knockout cells until late in infection. The work presented in Chapter 3 provides evidence that Mcl-1 upregulation in RSV infection would not be beneficial to the virus, rather Mcl-1 upregulation is most likely an antiviral strategy and suggests a possible function for Mcl-1 separate of apoptosis regulation.In Chapter 4, we have developed a quick, sensitive, and adaptable recombinase polymerase amplification (RPA) diagnostic assay to detect a significant human pathogen, dengue virus (DENV). Dengue is considered the most important arbovirus worldwide and the World Health Organization has listed improved diagnosis as a key step in the fight to reduce the burden of DENV. We demonstrate that our DENV2 specific RT-RPA assay is sensitive and specific, as it is able to amplify DENV2 with as little as 50 copies per reaction within 20 minutes at a constant temperature, and was able to amplify both laboratory and clinical isolates strains. Our results provide justification for future development of RPA as a diagnostic strategy for detection of DENV in a clinical setting at point-of-care, thus eliminating the need for a costly thermocycler. In Chapter 5, RPA is applied to the herpes virus, cyprinid herpes virus 3 (CyHV-3). This DNA virus has had a considerable impact on koi and common carp that leads to devastating economic losses to both fishery and koi hobbyist. One problem with current diagnostics is the inability to reliably detect latently infected fish, capable of acting as carriers to nascent fish populations. The RPA assay to detect CyHV-3 was specific and sensitive, yielding results in approximately 20 minutes, and was able to detect the virus in latently infected koi more efficiently than a real-time PCR assay, when directly compared. RPA products were detected by a simple colorimetric lateral flow assay that could allow for detection outside of the diagnostic lab, allowing for sensitive and accurate surveillance and early diagnosis of CyHV-3 in the laboratory and field.Overall, the studies herein provide valuable knowledge about viral diseases. The data collected provides insights into the characterization of host-pathogen interactions of RSV. These insights are informative for the disease pathogenesis of this significant pathogen but may also apply to closely related viruses. In addition, a methodology is described in a new format that could prove to be valuable for influenza vaccine prevention strategies, as well as for any vaccine produced in cell culture. This work also describes the application of an isothermal amplification strategy for detection of two viral diseases that are in desperate need of improved diagnostics. RPA as a diagnostic tool is easily adaptable and can improve the speed, sensitivity, and resource consumption of viral diagnostics leading to the ability to detect viral disease at point-of-care or in low resource settings."
http://hdl.handle.net/1957/57271,"Nonthermal plasmas generate high concentrations of excited species that can simultaneously exist at high energy and far from thermodynamic equilibrium, making them useful tools in chemistry and engineering. Microplasmas, roughly defined as plasmas that are generated within sub-millimeter dimensions, provide enhanced stability, improved excited species density, increased nonequilibrium properties, higher electron temperature, and better energy efficiency along with reduced onset voltages compared to traditional nonthermal plasmas, making them promising candidates for novel chemical processing pathways. This work summarizes current knowledge regarding the advantages gained by generating nonthermal microplasmas in constricted spaces, on reduced timescales, and with engineered electrodes. Those insights are then used in the experimental evaluation of DC microplasma reaction systems in methane processing and the oxidation of model refractory sulfur compounds in fuel-like media.The reaction environment generated by nonthermal plasmas is well suited for the activation of non-spontaneous gas phase reactions. Here, a microreactor capable of generating low power atmospheric pressure glow discharges is used in methane processing. The reactor effectively performs oxidative methane coupling to C2 and C3 hydrocarbons with methane conversions up to 50% and selectivity to C2 C3 products greater than 90%, achieving one pass yields that surpass state-of-the-art catalysis.The generation of DC nonthermal plasmas in fuel-like media for the oxidative desulfurization of dibenzothiphene has also been investigated. At discharge gaps around 250 microns, plasmas can be initiated with DC potentials above 6 kV for short periods of time before carbon bridges are formed that short the reactor. These simple DC discharges show little promise for continuous flow desulfurization processes. However, in flat plate reaction systems with silver epoxy electrode surfaces with discharge gaps less than 50 microns, electrically driven reactions can occur at much less than 1,000 volts. These discharges warrant further investigation and characterization in future works, and could be promising systems for the oxidative desulfurization of diesel fuel.Complementary to experimental investigations, COMSOL multiphysics models have been developed to provide insight into the kinetics of gas phase plasmachemical reactions, as well as the electric field of point-to-plane microplasma reactor designs. The kinetic models of the oxidative coupling of methane are preliminary, however, the current simulations produce the same compounds as the experimental system with realistic kinetic parameters. These models provide an excellent platform for more complicated kinetic modeling. Increasing the number of modeled plasmachemical reaction pathways will likely allow the model to converge on experimental data and be used in predictive analysis of the constructed microplasma reactor in the oxidative coupling of methane."
http://hdl.handle.net/1957/57272,"African-born population is one of the fastest growing group in the United States. Very little is known about their socio-demographic characteristics, health behavior practices and long-term health. The purpose of this study was to examine hypertension prevalence, health behavior practices and the impact socio-demographic factors have on these outcomes among Sub-Saharan African immigrants in the U.S.This dissertation conducted a cross-sectional, quantitative descriptive research study that utilized a comparative, correlational design. Using the 2003 New Immigrant Survey (NIS), secondary data analysis of 763 Sub-Saharan African immigrants was conducted. Descriptive statistics and binary logistic regression were conducted using SPSS, version 22. Descriptive variations were assessed between Sub-Saharan Africans and foreign-born populations from other regions including Eastern Europe, [(Russia (n=115); Poland (n=196); Ukraine (n=145)], and China (n= 467), as well as Mexico (n=1163).Variables in the study included socio-demographic characteristics such as: age, gender, education attainment, marital status, household income, country region of origin, English Proficiency, and duration since leaving country of birth, as well as visa type when entered theUnited States. Health variables included smoking, alcohol consumption, and physical activity, pre-immigration self-rated health, current self-rated health, and health care utilization in the last year as well as hypertension status.Descriptive analysis indicated that Sub-Saharan African population was fairly young and highly educated. The average age was 34.7 years and about 50% of the sample held a bachelors or an advanced degree. This population was also relatively new to the U.S and fairly healthy. As a group, African-born population has been living outside of their countries of origin for approximately 5 years. A majority did not smoke or drink alcohol, and most of them engaged in light or vigorous physical activity. Hypertension prevalence among this population was 9%. A majority (65%) of the Sub-Saharan immigrants rated their overall health to be in very good or excellent condition.Descriptive results of other immigrants groups showed the average age to be 45 years for those born in China and Mexico, 37 years for participants born in Poland, 41.5 years for Russian-born, and 38.5 years for those born in Ukraine. A majority of Russian-born and Ukrainian immigrants (~59% and 53% respectively) reported having a bachelors and or an advanced degree. A small proportion (about 9%) of individuals born in Mexico indicated having a bachelors and or an advanced degree. Individuals born in China have resided outside of their country of birth for as long as 66 years with a mean of 37 years.Across the board, all immigrant populations were physically active, with over 95% of each group participating in either light or vigorous physical activity. Over 30% of Russian-born smoked, about 40% of Mexican-born drank alcohol. Hypertension prevalence was approximated 11% among those from Ukraine and Poland, 10% among Mexican-born, about 8% and 7% among Russian and Chinese born respectively. Similar to Sub-Saharan African immigrants, mostof the other foreign-born populations indicated that their health was better after emigrating to the U.S. and rated their current health as excellent, very good or good. The majority of all the immigrant groups in the study did not see a health care provider in the last year.Binary logistic regression results revealed that being married (OR=. 529), having household income of $50,000 or more (OR=. 068), engaging in vigorous physical activity (OR=. 413) and having entered the United States on visitor-type visa (OR=. 405) were all statistically associated with lower likelihood of reporting high blood pressure. Health behavior analyses indicated that female African immigrants had lower odds (OR = .708) of consuming alcohol compared to male counterparts. Also, an increase in education attainment was associated with lower odds of smoking (OR=. 233).More studies on factors impacting health outcomes of Sub-Saharan African immigrants are needed. In particular, longitudinal studies with an ecological perspective can help to identify complex factors that shape health trajectories of this population and contribute to effective health interventions."
http://hdl.handle.net/1957/57430,"Hafnium Oxide thin films has had growing attention due hafnium oxide being used as a gate dielectric for MOSFET transistors and a potential next generation photoresist for sub 20 nm patterns. Extreme Ultra-Violet (EUV) lithography has been identified as the primary candidate technology for generation of sub-20 nm patterns. Current polymer based resists exhibit significant limitations at these resolutions due to high edge roughness, low etch resistance and high aspect ratio. Inorganic resists have gained much attention recently due to the high achievable resolution, high etch resistance and low edge roughness but generally suffer from low sensitivity to EUV photons. The low intensity of current EUV sources necessitates significantly higher sensitivity than what has been demonstrated for purely inorganic high resolution resists. A hybrid organic inorganic approach shows significant promise for potential next generation resists by binding photo sensitive organic ligands onto a metal oxide to produce a negative tone photoresist. In this study we sought to characterize the sol-gel deposition of HfO₂ thin films and the interactions of molecular and atomic species from carboxyl functionalized HfO₂ thin film to gain insight into the thermal and radiation induced desorption characteristics that ultimately enable sensitivity improvement of inorganic films. Two different carboxylic acid ligands (Methacrylic Acid and Benzoic Acid were used in this surface characterization study. The Hafnium Oxide films with a self-assembled monolayer of carboxylic acids were characterized via ATR FT-IR, water droplet contact angle, X-ray photoelectron spectroscopy (XPS), Temperature Programed Desorption (TPD) and Electron Stimulated Desorption(ESD)."
http://hdl.handle.net/1957/57432,"Use of high-strength steel (HSS) reinforcing bars could provide constructability and economic benefits for the construction of structures, reducing the initial and ultimately the life-cycle cost of bridge and building structural elements. This thesis summarizes work performed in a research project on the use of HSS reinforcing bars for concrete shear friction interfaces. Particularly, this research investigated the behavior of ASTM A706 Grade 80 reinforcing bars. This thesis includes two manuscripts. First, an overview of the testing program and main results are provided in manuscript 1, which describes twenty push-off test specimens that were subjected to interface shear forces along a concrete-concrete interface. The twenty specimens included five specimens of:(i) #4 ASTM A706 Grade 60 reinforcing bars; (ii) #4 ASTM A706 Grade 80 reinforcing bars; (iii) #5 ASTM A706 Grade 60 reinforcing bars; and (iv) #5 ASTM A706 Grade 80 reinforcing bars. Results indicate that the shear interfaces with the #4 reinforcing bars showed no significant difference in peak interface shear force resistance. In addition, the shear interfaces with the #5 reinforcing bars showed significantly higher peak interface shear force resistance. These results are the focus of manuscript 2 that address in more detail the new findings, which ultimately can lead to modifications to current design equations available in US standards and codes. Overall, the results in this thesis show a promising step to understanding and implementing the use of HSS reinforcing bars in shear friction applications so that the full yield strength of the grade of reinforcing steel can be utilized."
http://hdl.handle.net/1957/57434,"Climate change is predicted to affect ecosystems, including systems already stressed by human impacts. One ecosystem that is already highly impacted by human land use is the cold headwater stream system of the Pacific Northwest. One method of assessing the function of an ecosystem is by using an indicator species. Rhyacotriton variegatus is one such indicator species, sensitive to disturbance, and especially to temperature elevation.  This study combines field measurements from the warmest edge of the range of R. variegatus, laboratory determination of thermal tolerance, and modeling. These diverse experimental sources combine to clarify the potential risks of climate change on R. variegatus, and the headwater streams they occupy. 	Abiotic factors are important determinates of the range of species. Predicted range shifts under climate change are based on the assumption that temperature increases will make habitat at the edge of the known range unsuitable in the future. In order to accurately predict such changes, a quantification of the current thermal boundary is needed. In Chapter Two, I placed temperature loggers and measured other environmental variables in 28 streams: 8 in the cool core of the range of R. variegatus, 10 as far east and south as R. variegatus has ever been found, and 10 outside the known range of R. variegatus. The variables which best defined the range edge were degree days (number of days over specific temperatures), and the slope of the stream bed. 	Specific physiological tolerance information is also essential for accurate modeling of species habitats. Physiological limits should be determined experimentally using procedures that mimic natural conditions as closely as possible, so that the results will be applicable to natural systems. Forecasting the effects of human activities on populations also requires an understanding of how specific abiotic changes will impact different life stages.  I used a realistic cycling temperature treatment in Capters Three and Four, based on the data collected in Chapter One. I tested the survival of larval R. variegatus at a chronic exposure (21 days), and the level of stress as measured by corticosterone in adult R. variegatus. Larval R. variegatus survived up to a daily maximum of 23° C, beyond this the larvae died (LT 50 value of 24° C). I found that daily maximum temperatures over 18° C caused a doubling of corticosterone. 	There are many ways of modeling future climate change and the effect of this change on species' distribution. I chose to use large array of potential climate futures, modeling methods, and time periods to forecast the change in R. variegatus' range. This allowed me to compare the variation between the predictions for climate change, and find averages across the models. I used two correlative models, and one mechanistic model. The mechanistic model incorporated the relationship between air and water temperature from Chapter Two, and the physiological limits from Chapters Three and Four. All models predicted decreases in areas of the map classified as excellent habitat for R. variegatus. As expected, the reduction in range was most severe at longer time periods into the future, with higher CO₂ amounts in the atmosphere, and in models that incorporated more abiotic variables. R. variegatus are sensitive indicators for headwater stream ecosystem function, and will have a reduced range under climate change."
http://hdl.handle.net/1957/58139,"Ocean circulation is an important component in Earth's climate system.  Predicting future climate and circulation changes requires an improved understanding of the past relationship between climate and ocean currents.  The neodymium isotope composition (εNd) of water masses is frequently used as a quasi-conservative tracer to reconstruct ocean circulation.  The current budget of Nd in the ocean cannot account for upwards of 95% of the Nd entering the ocean, hindering interpretations of the εNd tracer.  This study aims to determine the magnitude of the sedimentary source of Nd to the global ocean, characterize the influence of the flux of Nd on the εNd distribution in the global ocean, and identify the diagenetic factors that control the magnitude of the flux. To address these goals, I compare pore fluids, overlying water column, and sediments from eight sites on the continental margin off Oregon and California (USA). These sites lie above, within, and below the Northeast Pacific's oxygen minimum zone and represent shelf-to slope settings at water depths between 80 and 3000 m. 	Concentrations of the rare earth elements (REEs), including Nd, in the pore fluids are up to two orders of magnitude higher than the REE concentrations in seawater. All pore fluid REE profiles exhibit shallow subsurface (2-10 cm) concentration maxima.  Fractionation of the REEs occurs during mobilization and transport through the sediment column, indicated by changes in the rare earth patterns above and below the pore fluid REE concentration maximum. Based on the pore fluid concentration gradient, I calculate the benthic flux from the pore fluids to the ocean.  These calculations show a flux of Nd to the ocean increasing from 3 pmol cm⁻² yr⁻¹ at our 200 m site to 32 pmol cm⁻² yr⁻¹ at our 3000 m site. No corresponding change in pore fluid phosphorous, iron, organic carbon, or silica among sites is observed.  Additionally, the major mineralogy remains constant among sites. Extrapolating our flux estimates over the global ocean, I estimate a global benthic Nd flux between 18 × 10⁶ and 110 × 10⁶ mol annually.  I conclude that the benthic flux of Nd to the ocean is the dominant source of Nd to the global ocean.  The εNd of this flux ranges from -0.2 at our 200 m site, to -1.5 at our 1200 m site and, -1.8 at our 3000 m site.  At our deepest (3000 m) site, the bottom water εNd (-2.3) is between the value expected for the water mass (-3.3) and the εNd of the flux (-1.8). The magnitude of this flux and the time a water mass is exposed to this flux determines the distribution of εNd.  The degree of change in bottom water εNd depends on the difference between the initial εNd of the bottom water and the εNd of the flux. The benthic flux can determine the εNd of bottom water in a short enough time to create the heterogeneous εNd observed in the modern ocean. Additionally, the benthic flux provides a mechanism for the observed alterations in εNd in the deep North Pacific in the absence of Pacific deep-water formation.Based on εNd of the pore fluids, total sediment, and sediment leachates, I propose that the magnitude of the flux is a function of the authigenic coatings formed during sediment diagenesis. Because the pore fluid Nd represents less than 0.001% of the Nd in any given volume of the upper sediment column, changes in Nd must be driven by larger Nd reservoirs in the solid phases. The leachable Nd (acid leachable: 1 - 7 μg Nd g⁻¹ sediment; reducible 2 - 8 μg Nd g⁻¹ sediment) represents a large reactive Nd reservoir, accounting for ~50% of the Nd in any given volume. Because the total sediment digest and leachates are less radiogenic than pore water at our 200 m site, I infer that there are radiogenic trace mineral phases undergoing active exchange with the pore fluid reservoir. When present, this trace mineral disproportionally influences the εNd of the flux.The exchange of Nd between the authigenic coatings and the pore fluid in the upper sediment column means that the εNd of the true coatings will be the same as the pore fluids.  However, leaching procedures result in a contaminated authigenic coating εNd signature, especially in the presence of reactive trace minerals.  In regions with a large benthic flux, the authigenic coatings determine the εNd of the bottom water.  Therefore, in these regions the coatings will resemble εNd of the bottom water.  The εNd of the bottom water cannot drive the εNd of the coatings because the amount of Nd in the bottom water is quantitatively insignificant. Based on the findings that the benthic source is the dominant source of Nd to the ocean, the εNd of this flux can determine the εNd of the bottom water, and the εNd of the authigenic coating is not determined by the εNd of the bottom water, a reinterpretation of the εNd records is necessary. Because the εNd of bottom water is not conservative, the εNd record cannot be strictly interpreted as water mass mixing.  The inverse relationship between ocean circulation speed and exposure time can result in differing εNd values with no change in circulation path.  Additionally, the end member water mass εNd values are likely to have changed through time.  Specifically, any shift in deep-water formation would result in the bottom water being exposed to a different εNd from the benthic flux.  With reinterpretation that recognizes these influences, the εNd tracer may remain a useful proxy of past ocean circulation."
http://hdl.handle.net/1957/59129,"Atmospheric pressure changes do not stop at the permeable snow surface but rather propagate into it. These pressure changes range from high-amplitude, low-frequency events caused by seasonal cycles and synoptic weather systems to small-amplitude, high-frequency events caused by topographic features and turbulence. The effect of pressure changes on interstitial air movement is locally weak but geographically pervasive and temporally persistent so the cumulative impact may be significant over seasonal timescales. Near the snow surface, pressure changes in the high-frequency range caused by turbulence and windflow over topographic features can enhance fluxes of chemically and radiatively active trace species between the snow and atmosphere. Deeper, in multi-year snow that overlays continental ice sheets, low-frequency pressure changes can stimulate air movement. This ventilation process adds complexity for paleoclimate analysis of ice cores to the extent that air trapped in ice has a different age structure than the ice matrix. For decades, investigators have recognized ventilation as a mechanism that enhances mass flux and interstitial air mixing but its effects are indeterminate because the relationship between wind forcing and interstitial air response is poorly constrained.This dissertation addresses the experimental question: what is the effect of wind on interstitial air movement in snow? To address this question, in situ field experiments were designed and performed to measure the depth in seasonal snow affected by wind-generated pressure changes as a function of frequency of the pressure changes. One experimental result was that high-frequency pressure changes have greater amplitude than theory predicted. At first, this result may seem to indicate that high-frequency pressure changes affect interstitial air motion more than predicted but for another finding that high-frequency pressure changes (perturbations) also attenuate more with depth than current theory predicts. Therefore, strong high-frequency attenuation relegates the effect of high-frequency pressure changes to a very thin air layer near the snow surface. Enhanced perturbation pressure attenuation at high frequencies does not directly address the question of the degree to which low frequencies attenuate with depth. However, the high-frequency mismatch between experimental evidence and theory underscores the necessity for future endeavors to test anticipated low-frequency perturbation pressure attenuation with deep snow pressure measurements.More accurate measures of the relationship between wind forcing and the spectral response of pressure changes acquired in this series of field experiments enabled characterization of the distribution of perturbation pressure amplitude as a function of frequency and wind forcing. It was found that kinetic energy of the wind as given by the horizontal and vertical components of the wind is a better diagnostic for perturbation pressure than vertical velocity variance. This finding is relevant when parameterizing perturbation pressure forcing using wind characteristics. A simplified model that convolves perturbation frequency with the spectral distribution of amplitude was used to diagnose frequencies for which water vapor flux (sublimation) is maximized for hydrostatic pressure changes. Applying the meteorological conditions measured in the case studies for this experiment sublimation enhancement was maximized for pressure oscillations with period ranging from 5 to 20 minutes. For shorter time periods the amplitude was too small to achieve a threshold (taken as the roughness length) and for longer time periods amplitude was sufficient but the frequency of the oscillation was insufficient to drive much air exchange between the snow and atmosphere.Finally, interstitial air movement was calculated under various wind conditions by measuring the evolution of a trace gas plume (carbon monoxide) as detected by a network of thin film sensors. Near surface data revealed an advection signature oriented with the prevailing wind. The plume centroid propagated downwind but upwind dispersion was greater than crosswind dispersion. This dispersion signature is consistent with turbulent eddies that propagate downwind. When the measurement network was oriented in a vertical plane, the center of mass of the plume propagated upwards indicating that upward vertical dispersion was enhanced relative to downward dispersion. This finding indicates that the residence time of a neutrally buoyant gas in the upper portion of the snow column is significantly shorter than the same gas located lower in the snowpack."
http://hdl.handle.net/1957/59319,"The goal of dissertation research was to use geochemical, statistical andgeological methods to constrain and understand climate variability over severaldifferent time scales. Specifically, I have addressed three questions regarding pastclimate change: (1) how does the record of Irish cirque glaciers constrain thedimensions of the Irish Ice Sheet during and since the Last Glacial Maximum (LGM);(2) what is the record of millennial-scale glacier variability in Ireland during the lastglaciation; and (3) how did variability of various components of the climate systeminteract to contribute to the evolution of climate over the last 800,000 years.The first chapter involves constraining the vertical and spatial extent of theIrish Ice Sheet (IIS). Reconstructions of the LGM IIS are widely debated, in large partdue to limited age constraints on former ice margins and due to uncertainties in theorigin of the trimlines used to identify vertical ice limits. The greatest differencesexist in southwestern Ireland where reconstructions either have complete coverage bya contiguous IIS that extends onto the continental shelf or a separate, southernsourcedKerry-Cork Ice Cap (KCIC) with more limited spatial and vertical extent.New ¹⁰Be surface exposure ages from two moraines in a cirque basin in this regionprovide a unique constraint on ice thickness for this region insofar as the presence ofa cirque glacier at a given time clearly indicates that the site was not covered by theIIS. My new ¹⁰Be ages from these two moraines show that the central mountains insouthwestern Ireland were not covered by the IIS or a KCIC since at least 24.5±1.4ka, thus supporting the more-limited reconstructions of the IIS at the LGM, indicatinga reduced contribution to sea-level change and a smaller loading of the solid Earth,which is consistent with models of glacial isostatic adjustment to the IIS.The second chapter presents research that has developed a record ofmillennial-scale variability in former Irish cirque glaciers between ~25 ka and 10 ka.Small alpine glaciers are sensitive to climate, and the paleo record of past smallglacierfluctuations offers an outstanding opportunity to use this glacier sensitivity fordeveloping centennial- to millennial-scale records of climate variability. BecauseIreland is immediately adjacent to, and downwind of, the North Atlantic, glacialrecords there are ideally located to record past climate changes associated withchanges in North Atlantic Deep Water (NADW) formation and attendant feedbacks. Ihave developed a high-precision ¹⁰Be surface-exposure chronology of multiplemoraines deposited by glaciers in eight cirque basins across Ireland to constrain thisvariability. The data show a remarkable record of persistent millennial-scalevariability between 24.5±1.4 ka and 10.8±0.7 ka. Several of these events areassociated with known climatic events during the last deglaciation such as onset ofthe Bølling-Allerød and end of the Younger Dryas. However, this persistent signalextends back to the Last Glacial Maximum (LGM), suggesting a previouslyunidentified mode of climate variability unrelated to large changes in the NADW.Multi-decadal to multi-centennial variability identified in Greenland ice cores presenta mechanism for the variability recorded in the Irish glaciers.The third chapter of this research involves characterizing and explainingclimate variability at orbital timescales across the mid-Brunhes Transition (MBT;~430 ka). The MBT involved a change in the amplitude of variability associated withcooler interglacials prior to 430 ka and warmer interglacials after. The key questions Iaddress include determining whether other components of the climate system changedat this time, and identifying the mechanism for the MBT. Statistical tests of multipleproxies (sea-surface temperature, ∂¹⁸O, ∂¹³C, CO₂, CH₄, and dust) indicate that theMBT was largely a reorganization of the global climate system perhaps driven by anincrease in interglacial CO2 concentrations. Changes in marine ∂¹³C may provideinsights into this change in the carbon cycle, perhaps associated with changes inglobal ocean circulation. In particular, there is a large positive ∂¹³C excursion duringthe interglacial immediately prior to the MBT, suggesting an enrichment of theAtlantic basin at this time relative to other interglacials of the past 800 kyr.Variability in the depth gradient of ∂¹³C from the North Atlantic show increasedcorrelation with South Atlantic ∂¹³C records after the MBT, indicating morehomogenous mixing of the northern- and southern-component water masses. This isaccompanied by a greater difference in the ∂¹³C latitudinal gradient in the Atlanticbasin prior to the MBT that is reduced afterwards."
http://hdl.handle.net/1957/59388,"The economically viable production of value added fuels and chemicals from lignocellulosic feedstocks hinges on our ability to quickly and efficiently transform structural carbon molecules to end products. The sugars in lignocellulosic biomass are held primarily within cellulose and hemicellulose. Cellulose is composed primarily of glucose monomers which are quickly and efficiently consumed by a variety of organisms. Hemicellulose is comprised mainly of xylose. Xylose is less well utilized by industrial yeasts and completely unusable to wild-type Saccharomyces cerevisiae, the most commonly used industrial yeast.Strains of S. cerevisiae capable of fermenting xylose have been developed, but the specific rate of xylose utilization in these strains is slow and product yield is low. Developing a strain capable of fermenting xylose both efficiently and with high product yield would be a massive step towards realizing the sustainable production of lignocellulosic bioethanol.Significant work has gone into identifying the bottlenecks within S. cerevisiae that may be contributing to slow xylose utilization. Research groups have suggested the pentose phosphate pathway, the xylose reductase xylitol dehydrogenase (XR XDH) pathway, xylulokinase deficiency, xylose transport, and cofactor redox imbalance as possible bottlenecks. These groups have further shown that expanding the capacity of any of these pathways can increase xylose utilization under certain conditions. Unfortunately, without a thorough understanding of the interplay between these bottlenecks and the conditions under which they increase the rate of xylose utilization or ethanol production it is nearly impossible to rank their importance and direct the course of future strain development.This dissertation works to identify the most important bottlenecks and strategies to alleviate them. Specifically, this describes the development of a series of S. cerevisiae strains harboring the XR XDH xylose utilization pathway and expressing STB5 (a transcription factor responsible for pentose phosphate pathway regulation) and PGI1 (a required glycolytic enzyme normally down-regulated by STB5p) under the control of a novel xylose-inducible promoter (TEF-X2-2). This novel use of transcription factors to regulate the entire pentose phosphate pathway was an attempt to optimally regulate the pathway using evolutionarily optimal enzyme expression ratios. These strains were then characterized using batch fermentations and high throughput transcriptomic tools to understand pentose phosphate pathway regulation and xylose utilization bottlenecks. These characterizations identified a correlation between cell density and the maximum specific rate of xylose utilization suggesting that oxygen was limiting both respiration and fermentation. Since fermentation is normally performed anaerobically, it was hypothesized that fermentation was actually limited in this case by NADH availability, the production of which would decrease under anaerobic conditions because of the stoppage of the TCA cycle. The high throughput data collected was further used to constrain a regulatory model framework around the previously developed genome scale reconstruction of S. cerevisiae known as iMM904. This model considered pentose phosphate pathway regulation linked to STB5 expression, xylose transport mediated by the HXT family of glucose specific transporters, and the kinetics of oxygen uptake and mass transfer. The novel use of high throughput data and regulatory modeling techniques allowed for a more thorough understanding of the bottlenecks in xylose utilization, supported the hypothesis that NADH availability was limiting fermentation, and suggested that the glyoxylate pathway might allow for anaerobic replenishment of NADH allowing an increased rate of xylose fermentation. Although regulation of the glyoxylate pathway has been considered before, the suggestion that it could increase the rate of xylose utilization and ethanol production is novel."
http://hdl.handle.net/1957/59427,"Today nano scale materials are being used for wide range of applications. One promising topic in nano scale materials is using them for reinforcement of different polymeric materials to reach desirable stiffness properties. The stiffness of these materials is mostly found experimentally because the nanocomposite community lacks a decent analytical model that can provide a reliable prediction. Modeling can be done using both numerical and analytical methods. Numerical methods can be time-consuming, expensive and need the expertise to implement right assumptions and extrapolate useful data. But they can be more reliable, if done correctly, compared with the analytical method. Analytical methods use a mathematical equation that has been derived considering the physics of the problem. Analytical methods are equations that predict properties on nanocomposites based on properties of components at different conditions (e.g., temperature, and more) and are more desired. For this work, we used a new Monte Carlo finite element analysis (FEA) method as a numerical method to model the stiffness of different nanocomposites and compared them with different analytical models to find the most accurate model that can predict the stiffness of nanocomposites as a function of its components? properties. We then com- pared different models with experimental results using cellulose nanocrystal composites."
http://hdl.handle.net/1957/59449,"Forest soils and topography have long been known to influence forest productivity in complex terrain such as Oregon’s Coast Ranges. Incorporating physical site characteristics into predictions of forest growth and yield, however, has been problematic because of the high spatial variability of soil properties and the challenges associated with representing topography and soil properties at the stand level. We assessed the efficacy of using a combination of a spatially intensive surface soil sample and terrain indices derived from a digital elevation model for explaining local variability in forest productivity across a forested watershed in northwestern Oregon. Analysis of correlations between several textural characteristics of the surface soil horizon and the average values for the top 100 cm showed that surface soil samples could provide an index of deeper-soil water holding capacity. Analysis of a time series of soil moisture observations from 34 locations in the Panther Creek Watershed revealed that surface soil texture, topographic wetness index, and slope can be used to predict relative soil moisture availability near the end of the growing season.We integrated the findings of the first two analyses to assess the influence of sur- face soil texture, hydrology, and topography on fine-scale variability of basal area periodic annual increment, height increment, and site index across five intensively- managed Douglas-fir plantations within the Panther Creek Watershed. Basal area periodic annual increment was maximized on sites that slope approximately to the south-southwest on the shoulder of ridges, and did not appear to depend on any surface soil characteristics. In contrast, site index was maximized in north-facing draws and increased with clay content of the surface soil."
http://hdl.handle.net/1957/59453,"Bone strength and fracture resistivity are related to a variety of factors encompassed in what is referred to as bone quality. However, bone quality is not a well-defined concept; therefore individual fracture risk cannot be predicted accurately, and osteoporosis treatment monitoring remains di cult. Clinically available imaging modalities use bone mineral density (BMD) as a proxy for bone strength despite its well-known shortcomings, and current research seeks to link microstructural measurements to bone strength. This research investigates the pre-clinical application of a new imaging modality, Medipix all resolution system computed tomography (MARS CT), for diagnostic imaging assessment of bone quality. Data from four cadaveric femoral necks was acquired with MARS CT, computed tomography (CT), dual energy x-ray absorptiometry (DXA), and high resolution peripheral computed tomography (HR-pQCT). Results were analyzed to test whether MARS CT could provide information equivalent to that currently used to investigate bone quality, as well as additional 3D material information and other related quantities.Four cadaveric femurs were scanned with CT, DXA, and HRpQCT to obtain clinically relevant measurements including bone mineral density (BMD) and microstructural measurements of the femoral neck. The femurs were sectioned prior to HRpQCT imaging to meet the size limitations of HRpQCT and MARS CT. The specimens were then shipped to the University of Otago in Christchurch, New Zealand for analysis with MARS CT. Since these were the first human femoral necks scanned with MARS CT, a scanning protocol was developed and optimized. Finally, the femoral neck specimens were scanned with MARS CT, and the data was analyzed and compared with the results from other modalities.This research shows that MARS CT can quantify various indicators related to bone quality. These include, but are not limited to: cortical, trabecular, and total-bone BMD; trabecular thickness and spacing; and cortical thickness. Images of the calcium hydroxyapatite contained in the specimens were also obtained and used to measure slice-specific trabecular BMD. The comparability of the MARS results with the HR-pQCT results was limited by air in the trabecular spacing, contouring differences between MARS and HR-pQCT images, and the difference in voxel size. These issues served as a lesson in methodology for future cross-modality bone quality studies. This research established a baseline for what can be accomplished with the current MARS scanner and will lead to future refinement of MARS CT and improvement of bone quality assessment."
http://hdl.handle.net/1957/59455,"Student engagement with faculty is positively associated with increases in the retention and graduation rates of students enrolled in institutions of higher education. Although a considerable amount of research has focused on understanding the engagement experiences of students enrolled at four-year colleges and universities, little emphasis has been placed on the experiences of Students of Color whose first experience in higher education within the community college system.The overarching purpose of this study was to investigate the factors which contribute to the frequency of engagement of Students of Color with institutional agents. Three research activities sought to address the factors which influence engagement for Students of Color. Manuscript I is a synthesis of the research related to student engagement with faculty, specifically the engagement practices of Students of Color with institutional agents. Nora, Barlow and Crisp’s (2006) Student Engagement Model and Stanton-Salazar’s (1997) concept of institutional agents served as the conceptual model for manuscripts II and III and guided the selection of the dependent (interaction with institutional agents) and independent (factors which influence engagement) variables. The second manuscript sought to examine the demographics, pre-college experiences, environmental pull factors, and undergraduate experiences which influence frequency of informal or social interaction with institutional agents outside of the classrooms and office hours during the first year. Finally, the third manuscript investigated the pre-college student factors and undergraduate experiences which influence frequency of interaction with institutional agents outside of the classroom and office hours to discuss academic matters during the first year of enrollment.Manuscripts II and III utilize descriptive statistics and regression analysis to explore (a) the factors which influence the frequency of informal interaction outside of class with institutional agents for Students of Color and (b) the factors which influence the frequency of interaction for Students of Color with institutional agents to discuss academic matters outside of class or office hours. Both manuscripts utilize the publicly available data of the Beginning Postsecondary Students Longitudinal Study (BPS), a national probability sample representative of about 4 million students who began their post-secondary education in 2003 2004. The BPS collected data from students beginning their educational career at colleges and universities across the United States for the first time in the academic year 2003 2004. The final sample in this study is limited to degree-seeking students and the approximately 35.3% (n~2,400) of students who self-identified as Black, Asian American Pacific Islander, Latino Hispanic students who first enrolled in a community college in the 2003 2004 academic year.Results from manuscript I underscored the importance of engagement on personal (Komarraju et al., 2010; Sax et al., 2005) and academic (Kim, 2010; Kuh et al., 2007; Tinto et al., 1993) gains leading to increased retention and graduation (Price & Tovar, 2014) of Students of Color. Manuscript II demonstrated that Students of Color have low informal engagement with institutional agents, specifically, less than one third (31%) of all Students of Color met informally with faculty. Additionally, Latinos as had lower frequencies of engagement with institutional agents in comparison to their Black peers after controlling for pre-college experiences, environmental pull factors, and undergraduate experiences. Participation in study groups and social integration, on the other hand, were positive predictors of informal engagement with institutional agents. Manuscript III underlined the importance of undergraduate experiences for Students of Color as predictors of interaction with institutional agents, since there were five positive predictors of engagement for Students of Color, including: enrolling full- time, declaring a major, taking remedial courses, participating in study groups and social integration. Two demographic variables were also predictors of engagement: Females had higher frequencies of engagement in comparison to males whereas Latinos as had lower frequencies of engagement in comparison to their Black peers when discussing academic matters outside of the class or office hours.The results of this study underscore the importance of undergraduate experiences of engagement with institutional agents for Students of Color and highlight several implications for policy, research and practice, including: (a) addressing the effects of campus climate on Students of Color engagement with institutional agents, (b) creating institutional practices that support students’ selection of a major within the first year of enrollment, (c) requiring students to participate in orientation and advising services with faculty, also within the first year of enrollment, (d) supporting part-time faculty in the development of their own information networks, (e) providing financial incentives for part-time faculty to engage with students."
http://hdl.handle.net/1957/59458,"Plethodontid salamanders have served as an informative vertebrate system for studying the role of chemical signals in facilitating social and reproductive behaviors. Individuals produce complex mixtures of chemicals from multiple glandular regions. In total, these secretions convey a wide variety of information, and are important for numerous inter- and intraspecific interactions. In order for a signal to convey complex information, it must vary in its composition. This research explores additional aspects of pheromone variation, within and between species, and discusses how this variation may affect the many functions of chemical signals in these species. Chapter One provides an overview of communication, chemical signaling, and essential background for the system in study. Chapter Two documents the degree of intraspecific variation in a major courtship pheromone protein, Plethodontid Receptivity Factor (PRF). Chapter Three explores the evolution of an additional level of signal complexity (post-translational modification via glycosylation) in the same pheromone, and documents substantial inter- and intraspecific variation in this trait. Lastly, Chapter Four uses high-throughput RNA sequencing to provide the first detailed description of the genes expressed by three other signaling glands: the cloacal glands, postcloacal gland, and the dorsal tail base. These tissues are involved in different aspects of reproductive, territorial, and other social behavior. Finally, Chapter Five summarizes the findings of this dissertation, incorporates these findings into an integrated model of chemical communication in plethodontids, and discusses key hypotheses to consider and directions for future research."
http://hdl.handle.net/1957/59459,"Despite more than two centuries of exploration, including more than six million deep wellbores with depths exceeding 40,000 feet in some parts of the world, our ability to constrain subsurface processes and properties remains limited.  Characteristics of the subsurface vary and can be analyzed on a variety of spatial scales.  Characterization and prediction of subsurface properties, such as depth, thickness, porosity, permeability, pressure and temperature, are important for models and interpretations of the subsurface.  Subsurface studies contribute to insights and understanding of natural system but also enable predictions and assessments of subsurface resources (water, heat, hydrocarbon, mineral, storage capacity) and support environmental and geohazard assessments.  However, the availability of data to characterize these systems as well as the techniques that utilize those data vary significantly.  There is a wealth of data and information in structured and unstructured datasets stemming from subsurface characterization and interpretation studies.  In addition, the geo-data science landscape is shifting, becoming more open.  This affords opportunities to fill knowledge gaps, mine large, interrelated datasets, and develop innovative methods to improve our understanding of the subsurface and the impacts of its exploration.  This study demonstrates different approaches, at a range of scales, for evaluating subsurface properties using a combination of “small” and “big” data approaches.  In particular, focusing on wellbore data which can be used to investigate questions at the individual well or the global scale.  Wellbore related datasets, such as those associated with India’s NGHP-01 Site 17A, are the primary source of direct subsurface measurements.  In this work, small-scale analyses from a single wellbore were used to establish that diagenetic mineralization is responsible for anomalous porosity preservation and enhanced permeability in sediments from NGHP-01 Site 17A.  This relationship explains and further constrains how geologic history and architecture influences gas hydrate distribution both within the lithostratigraphic record at NGHP-01 Site 17A and in other sedimentary settings worldwide.  In addition, collections of wellbore data are increasingly used in spatial statistical analyses to improve prediction of subsurface properties at the field to basin-scale.  These analyses typically have disregarded contextual geologic information because of its complex and unstructured format.  This results in the loss of valuable information.  This study presents a structured, hybrid deductive-probabilistic approach that integrates both contextual geologic information with quantitative analytical tools to improve prediction of subsurface properties and reduce uncertainty.  The Subsurface Trend Analysis approach is demonstrated and validated in the prediction of subsurface pressure for the north-central region of the Gulf of Mexico.  Finally, this study assembles and presents together information for the global catalog of deep subsurface wells.  This global dataset spans over two centuries of drilling and includes more than six million wellbore records.  Spatial and temporal analyses performed using this dataset provide insights into the implications of human engineering of the subsurface worldwide. Collectively, these data were used to assess to what degree the subsurface has been perturbed by drilling related activities, and investigated how human changes to deep subsurface systems contrast with the effects of other species and processes on the planet."
http://hdl.handle.net/1957/59471,"This study uses an existing database of dynamic loading tests of driven piles installed in the Puget Sound Lowlands to improve the reliability of axial performance. First, the unit shaft resistances developed from stress wave signal matching to dynamic records of pile installation are used to develop an effective stress-based shaft resistance model. New, statistically unbiased unit shaft resistance models are proposed for piles driven at End-of-Drive (EOD) and Beginning-of-Restrike (BOR) and for a range of specific soil types and relative densities and consistencies. The accuracy and uncertainty of each model is quantified and compared. Then, the observed unit shaft resistances and proposed design models are used to characterize the magnitude of time-dependent capacity gain. Although these models allow estimation of the range of capacity gain anticipated following pile installation, no reliable time-dependent relationship could be proposed. The study concludes with the quantification of accuracy and uncertainty in dynamic wave equation-based and existing static analysis procedures and calibration of resistance factors for use with load and resistance factor design (LRFD). These resistance factors indicate, in some cases, dramatic improvement in the useable pile capacity at a given reliability owing to the use of a database from a specific region. The results from this work may be immediately applied in practice in the Puget Sound Lowlands."
http://hdl.handle.net/1957/59519,"As the effect of ocean acidification (OA) on marine calcifiers is better understood, a range of potential mitigative strategies have been proposed, many of which are plagued by concerns of scale and feasibility. One oft-cited option is to increase the biomass of photosynthetic organisms to remove CO₂ from the water column and facilitate organic carbon burial. Seagrasses show much promise in this regard, owing to their highly refractive tissue. Timescales of carbon burial with respect to this strategy are on the order of years to decades. Recent studies, however, demonstrate that some marine bivalves experience short windows of heightened sensitivity to OA, especially during the early larval and early post-metamorphic “juvenile” stages, which occur on timescales of hours to days. In coastal areas, carbonate chemistry is highly variable on similar timescales, due in part to photosynthetic cycles, the pattern and magnitude of which will vary due to the ecological make-up of the habitat. Therefore, we must consider the highly complex and variable nature of CO₂ dynamics in seagrass habitats on short timescales when we consider their potential role in OA mitigation.We examined patterns of growth and survival in the juvenile Pacific Oyster (Crassostrea gigas) outplanted within and outside beds of two different species of seagrass, the native Zostera marina and the non-native Z. japonica, in Netarts Bay, Oregon. Z. marina and Z. japonica differ in the timing and magnitude of their growth and decay cycles and allocation of biomass above or below ground. Z. marina increased both growth and survival of C. gigas spat with the magnitude of the effects decreasing aftermid-season as seagrass growth slows and there is a transition to an upwelling-dominant hydrodynamic regime. Z. japonica appeared to have a slightly negative, but not statistically significant, effect on juvenile C. gigas growth, compared to the associated bare-sand control site, with the notable exception of a reversal of the trend in June, co-incident with this seagrass’s short period of growth. We have compared bivalve success metrics (growth and survival) with P[subscript CO2] measurements within each habitat. Patterns in bivalve success metrics appear to inversely correlate with trends in daily CO₂ minima over the course of the season, suggesting that bivalve success may be attributed to compensatory growth during daily low-CO₂ periods associated with the seagrass’s respective growing seasons."
http://hdl.handle.net/1957/59520,"Although only a minority of introduced species become established and have noticeable consequences in their new communities, some can displace native species, alter food webs, and cause local extinctions. Studying these invasive species can provide new insights into basic ecological questions as well as inform management strategies. Pacific lionfish (Pterois volitans miles) are the first non-native marine fish to become established throughout the tropical and sub-tropical western Atlantic. Since the early 2000s, lionfish populations have spread rapidly and grown exponentially, reaching densities that are several orders of magnitude greater than those in their native range. Combined with these high population sizes, lionfish have strong negative effects on native coral-reef fish populations via direct predation. The main goals of this dissertation were to determine how the local density of lionfish influences their demographic rates and behavior, and in turn, how lionfish affect native fish populations at different lionfish densities, across multiple habitats, and via non-consumptive effects.In the first experiment, I manipulated densities of juvenile lionfish on ten small artificial patch reefs The Bahamas and for 8 weeks monitored their demographic rates (Chapter 2) and effects on native-fish communities (Chapter 4). Although there was no evidence for density-dependent per capita rates of loss (mortality and emigration) or gain (recruitment and immigration), individual growth rates decreased at higher densities. For each increase in lionfish density by 1 fish m², lionfish grew an estimated 0.02 mm day slower. In addition, native fish abundance and biomass declined non-linearly with increasing lionfish density, such that lionfish had diminishing per-capita effects on native fishes at higher densities. Observations of lionfish conducted on sixteen coral patch reefs encompassing a natural range of lionfish densities revealed that lionfish foraging behavior and movements also vary with local lionfish density (Chapter 3). At higher densities, lionfish exhibited greater activity levels and increased time away from shelter, including more short-term foraging movements between coral patch reefs and surrounding seagrass habitats. Combined, these patterns suggest that invasive lionfish experience intraspecific competition for food.The foraging movements of lionfish may also have implications for which native species are susceptible to lionfish predation. By manipulating sixteen patch reefs in The Bahamas to have either high or low lionfish densities and comparing changes in native fish populations on and around the reefs for 7 weeks, I determined that lionfish first caused an approximately 60% reduction in the abundance of native fishes on the patch reefs and then caused similar declines on small structures in seagrass beds that surround these reefs (Chapter 5). Unlike the effects of native predators on prey fishes, the effects of lionfish did not diminish rapidly with increasing distance from coral patch reefs, likely because lionfish have few natural predators and thus may forage with impunity over extended distances.The negative effects of lionfish predation both on and around coral reefs are likely compounded by the fact that some prey fishes are naïve to the threat posed by lionfish. During a critical life-history transition from pelagic larvae to reef-associated juvenile (‘settlement’, measured as ‘recruitment’), some coral-reef fishes recognize cues from predators and consequently preferentially settle to reefs without predators. To test whether lionfish have similar non-consumptive effects on the recruitment of coral-reef fishes, I manipulated the presence, identity, and diet of prior resident fishes and measured daily recruitment to fifteen small standardized reefs in Bonaire (Chapter 6). Regardless of predator diet, one species of reef fish had 55-59% lower recruitment to reefs with a native predator compared to predator-free control reefs and reefs with lionfish, suggesting that they recognize and avoids cues from native predators but not invasive lionfish.Overall, this research clarifies the extent and mechanisms underlying the ecological effects of invasive lionfish. In terms of management, the lack of density- dependent gain and loss rates suggest that current efforts to reduce local densities via manual removal by divers are likely to remain the most effective management strategy for the foreseeable future. Due to the non-linear effects of lionfish on native fish populations on coral patch reefs and their effects in surrounding areas, management efforts that greatly reduce lionfish densities on coral patch reefs will have the greatest benefit for native fishes across multiple habitats. Finally, because at least one species of reef fish has lower recruitment to reefs with native predators compared to lionfish, monitoring strategies that simply compare the abundance of native fishes on reefs with lionfish to reefs with native predators will likely underestimate the consumptive effects of lionfish.This research also reveals that invasive lionfish are different than native coral-reef mesopredators in many ways: they do not experience density-dependent population gain and loss rates at current high densities, they forage over broad distances encompassing multiple habitats, and they are unrecognizable to at least some native prey fishes. In addition, typical anti-predator strategies of small native fishes, including inhabiting seagrass beds instead of coral patch reefs and avoiding reefs with predators at settlement, are ineffective against lionfish. These characteristics likely at least partially explain why lionfish have such strong negative effects on native coral-reef fishes, and some of these traits are likely shared by other successful invasive predators."
http://hdl.handle.net/1957/59566,"Biological invasions have been identified as one of the prominent drivers of global environmental change.  In particular, invasive predators typically have substantial negative effects on populations of native prey, even driving species to extinction in extreme cases.  However, beyond direct predatory effects, little is understood regarding the specific mechanisms by which invasive predators influence native communities and ecosystems.  Therefore, the objective of this dissertation was to investigate whether and how an invasive predator, the Pacific red lionfish (Pterois volitans), alters native community interactions on Atlantic coral reefs.  The lionfish invasion is unprecedented for a marine fish in the extent of rapid geographical spread, successful establishment across numerous habitats, and strong predatory effects on native species.  By conducting behavioral observations and manipulative experiments in both the laboratory and field settings, I tested for a variety of direct and indirect mechanisms by which invasive lionfish potentially influence native fish communities and coral-reef ecosystems.  I first conducted a model-bottle experiment in The Bahamas and Cayman Islands (Chapter 2) to test for aggression of a native territorial damselfish, Stegastes planifrons, toward invasive lionfish.  Such territoriality could provide a possible source of biotic resistance that may provide behavioral refugia for native coral-reef fish recruits from lionfish predation.  However, the behavior of this damselfish in response to invasive lionfish in a clear plastic bottle did not differ from the minimal response exhibited toward the empty bottle control.  Therefore, the territories of this damselfish are unlikely to provide such biotic resistance to the invasion.  To investigate whether invasive lionfish alter competition between native prey fishes, I then performed a manipulative field experiment in The Bahamas whereby I simultaneously tested for the effects of both competition and lionfish predation on two congeneric coral-reef fishes, the fairy and blackcap basslets (Gramma loreto and G. melacara, respectively).  In the absence of invasive lionfish, competition within local populations of basslets under reef ledges had symmetrical effects on the juveniles of both species (Chapter 3).  Interference between species drove juvenile basslets further back under ledges where feeding and growth rates of individuals were reduced.  Within reefs with the invasive predator present (Chapter 4), lionfish reduced the density of juvenile fairy basslet, thereby reducing the effects of competition on juvenile blackcap basslet, and tipping the balance of competition between juveniles of these species from symmetrical to asymmetrical effects.  Differential predation of invasive lionfish may be explained by a preference for fairy basslet, as demonstrated by a laboratory experiment (Chapter 5).  Lastly, I examined possible mechanisms underlying a potential invasive lionfish-herbivorous fishes-macroalgae trophic cascade on large reefs in The Bahamas (Chapter 6).  During a two-year field experiment, lionfish caused a decline in the density of small herbivorous fishes on reefs, and behavioral observations revealed that the presence of lionfish reduced grazing by both small and large fishes, which resulted in 66-80% less algae removed from reef substrata.  Therefore, invasive lionfish have both consumptive and non-consumptive effects on the important ecosystem function of native herbivorous fishes: reducing the abundance of benthic algae that could otherwise displace corals.  In sum, this dissertation indicates that throughout native coral reefs, invasive lionfish (1) are not attacked by native territorial damselfish that could otherwise provide local refugia for native recruit fishes; (2) alter the outcome of interspecific competition between native basslets via differential predation that tips the balance of competition from symmetrical to asymmetrical; and (3) have both consumptive and non-consumptive effects on native herbivorous fishes, which reduces grazing and indirectly benefits benthic macroalgae to the possible detriment of corals.  This research broadens our mechanistic understanding of predation in the context of invasive species, which further informs predictions relevant for management and conservation initiatives."
http://hdl.handle.net/1957/59581,"The effects of alfaxalone (A-HPCD), propofol (P), ketamine-diazepam (KD) and tiletamine-zolazepam (TZ) administered IV in dogs on cardiovascular and respiratory systems, acid-base balance and electrolytes have been reported in the literature, but a study that compares IV TZ to the other induction protocols (IP) is needed. Six dogs enrolled in a randomized-crossover study were anesthetized with sevoflurane and instrumented. After at least 30 minutes post-recovery, baseline values for cardiovascular and respiratory parameters were determined, cardiac output (CO) measured via thermodilution, and arterial (Art) and mixed venous (MV) blood samples collected. Anesthesia was induced with A-HPCD (4 mg kg), P (6 mg kg), KD (7 and 0.3 mg kg, respectively), or TZ (5 mg kg) administered IV in quarter increments to effect, and maintained with isoflurane (Et[subscript Iso] 1.14 ± 0.32%) for 60 minutes. Immediately post-induction (PI) and at 10, 20, 40, and 60 minutes all measurements were repeated and blood sampled. Derived hemodynamic parameters were calculated. Cardiorespiratory and acid-base parameters compared with RM-ANOVA and a post-hoc t-test were considered significant when p < 0.05. The parameter most affected by protocol was heart rate (HR), with TZ producing the highest HR PI and at 40 and 60 minutes. Oxygen delivery (DO₂) was best maintained by TZ in the first 20 min, while A-HPCD maintained the highest DO₂ at 60 minutes. No significant differences for CO, cardiac index, mean arterial pressure, and systemic vascular resistance were found among IP. Although still within normal limits, mean MV pH, Art and MV potassium were similarly increased with TZ and KD compared to P and A-HPCD. Although statistical significance was found for EtCO₂, pH, lactate, and serum potassium, values stayed in the normal clinical range. TZ produced comparable respiratory changes to KD. Intravenous induction of general anesthesia with TZ maintained on isoflurane is a safe alternative to A-HPCD, KD, and P in healthy dogs and it is recommended for short anesthetic procedures."
http://hdl.handle.net/1957/59651,"Energy consumption has become a great deal for cloud service providers due to financial as well as environmental concerns. Studies show that cloud servers operate, most of the time, at only between 10% and 50% of their maximal utilizations. These same studies also show that servers that are kept ON but are idle or lightly utilized consume significant amounts of energy. In this thesis, we develop new resource management techniques that enable automated, energy-efficient allocation of cloud data center resources, thereby reducing energy consumption and hence cutting down on the electricity bills of service providers. Specifically, our developed techniques consist of the following four complimentary frameworks:1.	Workload Prediction Framework. It predicts the number of Virtual Machine (VM) requests along with their amounts of CPU and memory resources using k-Means clustering and adaptive Wiener filter prediction techniques. This proposed prediction framework provides accurate estimations of the number of needed servers, thus reducing energy consumption by putting to sleep unneeded servers.2.	Resource Scheduling Framework. It reduces the time during which servers are kept ON by placing VMs with similar completion times on the same server while allocating more resources to the VMs that need more time to accomplish their tasks.  The framework also allocates more resources for the delay-sensitive tasks whose charging cost is dependent on how fast they accomplish so that they finish earlier which generates higher revenues. This is all done by solving a convex optimization problem that guarantees that all the scheduled tasks meet their hard deadlines.3.	Resource Overcommitment Framework. It consolidates data center workloads on as few ON servers as possible by assigning VMs to a server in excess of its real capacity, anticipating that each assigned VM will only utilize a part of its requested resources. The framework first determines the amount of server resources that can be overcommitted by predicting the future resource demands of admitted VMs. It then handles server overloads by predicting them before occurring and migrating VMs from overloaded servers to other under-utilized or idle servers whenever an overload occurs or is predicted to occur.4.	Peak Shaving Control Framework. It spreads the data center's power demands more evenly over the entire billing cycle by making smart workload shifting and energy storage decisions which leads into great monetary reductions in the grid's peak demand penalties. The framework accounts for real energy storage losses and constraints, and considers a heterogeneous cloud workload that is made up of multiple classes, with each class having different delay tolerance and price.Several experiments based on real traces from a Google cluster show that our proposed frameworks achieve significant utilization gains, energy reductions, and monetary savings when compared to state-of-the-art cloud resource management techniques."
http://hdl.handle.net/1957/59739,"Red clover (Trifolium pratense L.) seed yield can be affected by plant growth regulators (PGR) and irrigation; however, the effects of these factors on physiological maturity (PM), harvest maturity (HM), and seed quality are unknown. The objectives of this study were to: 1) determine how irrigation and trinexapac-ethyl (TE, a PGR) affect PM, HM, seed viability, and seed vigor of red clover at different stages of maturity, 2) evaluate the effect of irrigation, TE and their interaction on seed yield, its components, and the quality of red clover seeds at harvest, 3) investigate changes in gibberellic and abscisic acid contents in red clover during seed development and maturation, and 4) determine the potential of red clover seed storability under different storage conditions over two years. A field study was conducted over a two-year period at Hyslop Research Farm, Corvallis, Oregon. A single irrigation was applied at first flowering stage (BBCH 55). Five rates of TE, ranging from 0 to 700 g a.i. ha⁻¹, were applied at stem elongation and bud emergence stages (BBCH 32 and BBCH 51, respectively). Seed viability and vigor tests were conducted at Oregon State University Seed Laboratory to measure the effects of treatments on seed quality.Irrigation delayed PM by four days compared to the non-irrigated treatment. The TE applications did not alter seed maturation. At PM, the flower heads contained light brown petals with brownish-green sepals and seeds were pale green to pale yellow. Heads at HM contained dark brown petals and sepals, whereas seeds turned to yellow or yellow-dark grayish purple. Seed dry weight did not change significantly from PM to HM. Seed moisture content at maximum seed dry weight (PM) ranged from 340 to 540 g kg⁻¹ and decreased to below 140 g kg⁻¹ at HM. Seed quality as determined by tetrazolium (TZT), standard germination (SGT), and cold tests (CT) were gradually increased during seed development and maturation. The accelerated aging test (AAT) was not a reliable indicator for evaluating vigor of young seeds. At HM, seeds reached maximum quality for all treatments, with 92 - 98% viability by TZT and SGT, and 90 - 94% vigor by CT. Seed yield was increased by irrigation and TE application, but the interaction between these two treatments was not significant. Irrigation increased seed yield in both years by 10% due to the greater seed weight. However, TE increased seed yield by up to 18% only when applied at stem elongation stage in the second year. The increase in seed yield by TE was attributed to greater number of heads per stem. Neither irrigation nor TE had significant effect on above-ground biomass or stems m⁻². Seed viability and vigor were slightly correlated with thousand-seed weight and stems m⁻², respectively. However, none of them significantly affected seed quality. The study revealed that seed yield can be increased by: 1) a single irrigation application during first flowering stage (BBCH 55) in both years; and 2) TE application at a rate of 280 g a.i. ha⁻¹ at the stem elongation stage (BBCH 32) in the second-year stand of red clover.  Gibberellic acid (GA₃) and abscisic acid (ABA) are two major phytohormones that affect seed germination. Changes in the contents of GA₃ and ABA from seed development to maturation was conducted using seeds from untreated, TE-treated, irrigated, and TE plus irrigated plots. The GA₃ and ABA were extracted from seeds using the solid phase method and were quantified by the liquid chromatography-tandem mass spectrometry (LC-MS MS). The ABA content was high (1242 pg g⁻¹ DW) at the early stage of seed development, and then gradually decreased to 388 pg g-1 DW at HM. The GA₃ content did not change significantly during seed development until HM, ranging from 173 to 187 pg g⁻¹ DW. Irrigation and TE application did not significantly affect the endogenous production of GA₃ and ABA in the seeds. The ABA:GA₃ ratio was high (6.7) at the early stage of seed development, but seed germination was low (24%). When seeds reached HM, the ABA:GA₃ ratio dropped to 2.2 and seed germination increased to 93%. These results suggest that physiological dormancy is not a substantial concern in red clover seeds. However, before scarification, seed with hard seed coat at HM was approximately 34%. Hard seeds were scarified before conducting the germination tests. Maintaining seed quality during storage is essential to ensure value until the time of planting. Two red clover seed lots, untreated and field treated with TE, were stored for 24 months in three conditions: 1) uncontrolled environment of open warehouse (WH), 2) controlled room temperature (RT) at 20°C, and 3) controlled cold storage (CS) at 10°C. Seed quality, i.e., viability and vigor, was determined at 6-month intervals to measure the rate of deterioration after each storage period. Relative humidity (RH) was observed as 55% in RT and 90% in CS. Average seed viability of both seed lots stored in WH and RT and were 96% and 95%, respectively, throughout the 24-month storage period. Seeds stored at RT for 24 months maintained high vigor of 87% as determined by the AAT, whereas seeds stored at WH maintained vigor of 81% for 18 months and then dropped to 67% at the end of the 24-month storage period. In CS, seed viability and vigor gradually dropped, reaching 0% at the end of the 24-month storage period due to the adverse effect of the high RH (90%) in the CS. Seed maintained acceptable viability and vigor standards of above 80% when seed moisture content was less than 10%. This study suggests that red clover seeds from untreated and TE-treated plots can be stored safely under similar WH conditions used in this study for 18 months and in RT for 24 months when the initial seed moisture content is under 10%.  The results of this study improved our understanding of the potential storability of the red clover seed in response to TE application."
http://hdl.handle.net/1957/59742,"There are many links between exposure to environmental pollution and risks to human health. While advances in the fields of toxicology, exposure science, and environmental chemistry have shown light on many of these links, many more research challenges remain. One major challenge is how to accurately characterize the toxicity of a mixture of chemical pollutants. There is evidence to suggest that assuming the toxicities of chemicals in a mixture are additive is an oversimplification. Additionally, there are many chemicals that are commonly found in the environment or that are potentially toxic, but that remain under-studied. All of these caveats apply to polycyclic aromatic hydrocarbons (PAHs).           Another challenge is how to best quantify an individual’s exposure to environmental pollutants. Traditionally this is done using a combination of self-reported exposure information from questionnaires, extrapolation of data from stationary monitors to the exposures of mobile individuals, and occasionally data from personal monitors. Passive sampling is an effective tool for measuring the fraction of chemical pollutants people are exposed to in the environment. The work presented in this dissertation uses passive sampling to measure PAH contamination in air, water, and the personal environment, and to predict PAH concentrations in crayfish. It also estimates carcinogenic human health risks associated with exposure to this PAH contamination.          Shellfish contamination data is needed for use in consumption advisories. However, existing methods of measuring this contamination are often prohibitively time and resource-intensive. It has been observed that passive samplers, coupled with predictive models, can accurately estimate PAH contamination in shellfish. In Chapter 2 we further validated the ability of passive water samplers and predictive models to predict PAH contamination in the resident signal crayfish, Pacifastacus leniusculus. This work was conducted within and outside of the Portland Harbor Superfund Megasite. We estimated PAH concentrations in crayfish from PAH concentrations measured by passive samplers in water, using a simple linear regression model that included 34 PAHs. The model predicted PAH concentrations in crayfish within an average factor of 2.4 of PAH concentrations that were measured in crayfish. Additionally, we observed substantially higher PAH levels, and carcinogenic PAH levels, in crayfish visceral tissue than in crayfish tails. This indicated that eating only the tail of a crayfish would drastically reduce a consumer’s cancer risk compared to eating the whole crayfish. We also demonstrated the importance of appropriately characterizing the toxicity of chemical mixtures. For instance, benzo[c]fluorene was identified as the main contributor to carcinogenic potency in crayfish tissues. However, this PAH is not traditionally included in analyses of environmental samples. Additionally, we saw strikingly similar profiles of carcinogenic PAHs in crayfish tissues collected in this Superfund site in 2003 and 2013. This demonstrated that there are chemical mixtures that commonly occur at this Superfund site. Knowing this could enable researchers to drastically reduce the number of chemical mixtures to prioritize for toxicological study. 	Natural gas extraction (NGE) activity has expanded rapidly in the U.S. in recent years. This rapid expansion has been met with minimal study of potential environmental or health effects, leading to concern among scientists and the public. In Chapters 3 and 4 we present two studies assessing the impact of NGE on environmental PAH levels, in a community heavily affected by the recent natural gas boom. In Chapter 3 we used passive air samplers to assess how proximity to the nearest active NGE well affected PAH concentrations in ambient air. In this study we saw decreasing PAH concentrations, as well as carcinogenic PAH concentrations, as air samplers moved farther from active NGE wells. We also saw predominantly petrogenic signatures of PAH mixtures measured closer to NGE wells. This suggested that measured PAH mixtures were impacted by fugitive emissions of PAHs during NGE, and that this impact was stronger closer to active NGE wells.           In Chapter 4, we more thoroughly assessed spatial patterns of PAH concentrations in air using passive air samplers, at sites with and without active NGE wells. In this study we observed higher PAH concentrations in air at sites with NGE wells than at sites without. Again, we saw more petrogenic PAH mixtures at sites with active NGE wells than at sites without wells. This gave us further evidence that PAH mixtures in air near NGE wells are affected by direct releases from the earth during NGE. In this study we also assessed the impact of NGE on the personal PAH exposure of people living and working in this community. We did this using a novel personal passive sampler, the silicone wristband. PAH concentrations measured in wristbands demonstrated that living or working closer to an active NGE well was associated with increased PAH exposure. However, all carcinogenic PAH concentrations measured in air in both NGE studies were below the U.S. EPA’s acceptable threshold. Thus, even the highest carcinogenic PAH concentrations measured in air closest to NGE wells would not be expected to increase lifetime cancer risk of people living or working nearby above background risk levels. 	The work presented in this dissertation further validates the ability of passive samplers to predict PAH contamination in crayfish, provides evidence for PAH emissions coming from NGE, and comments on the estimated health risks associated with exposure to these PAH mixtures. Taken together these findings help solve the current challenges in environmental toxicology research, and provide ideas for solving the remaining challenges facing this field."
http://hdl.handle.net/1957/59770,"This thesis provides a comparison of advanced econometric frameworks to account for unobserved factors in crash reported data (also referred to as unobserved heterogeneity) while identifying contributing factors by roadway classification for heavy vehicle injury severity and crash rates. The presented thesis provides two manuscripts that expand the literature regarding these advanced econometric methods using Idaho heavy vehicle crash reported data as a case study.The first manuscript utilizes two advanced analytical techniques, namely the random-parameter multinomial logit (also referred to as the mixed logit) and latent class logit, to identify injury severity contributing factors while exploring the empirical results of the two methods.  Recent efforts suggest that more studies examining the results of the two approaches be completed to facilitate the identification of a superior framework that can used for future analyses.  In comparing overall model fit (log-likelihood values), marginal effects and actual severities versus predicted severities, it was found that the latent class framework for heavy vehicle injury severity analysis performed better for the Idaho crash data.  Further, through a model separation test, it was found that road classifications need to be analyzed separately with 99.99% confidence.In regard to the second manuscript, two additional advanced econometric approaches were utilized to investigate the factors that contribute to the number of crashes per million-vehicle-miles-traveled.  Again, analysis was completed by road classification, as it was discovered in manuscript one that road classifications need to be analyzed separately.  Due to the skewed distribution of heavy vehicle crash rates, Tobit regression was applied and compared to the empirical results of a latent class Tobit regression framework.  To determine the most statistically significant method, overall model fit, partial effects and actual crash rates versus predicted crash rates were evaluated.  The latent class Tobit regression framework outperformed that of the traditional Tobit regression approach for the Idaho dataset.Through the comparison of the crash analysis framework, latent class logit and latent class Tobit regression were found to outperform their traditional counterparts.  In the midst of evaluating the empirical results, this thesis has statistically determined that road classifications need to be analyzed individually.  The current thesis extends the literature in regard to heavy vehicle injury severity analysis and fills the noticeable gap that exists for heavy vehicle crash rate analysis.  An analytical foundation has been provided and can be used for future studies that need to model discrete outcomes or continuous response variables.  Although agencies typically do not use such advanced methods, the results from this thesis can help the Idaho Department of Transportation facilitate crash countermeasures with more precision and allow them to prioritize accordingly."
http://hdl.handle.net/1957/59782,"Hereditary variation is a vital component in the development of new and improved cultivars of landscape plants.  Sources of hereditary variation include naturally occurring variation, recombination due to controlled crosses, artificial mutagenesis, and genetic modification via biotechnology.  Here I explore all methods with the exception of genetic modification via biotechnology.  In Acer I evaluated naturally occurring cytometric variation.  Cytometric variation refers to variation in genome size and ploidy.  Genome size and ploidy data can be used in the development of targeted breeding projects including interploidy hybridization.  I used flow cytometry and traditional root squashes to measure genome size and determine ploidy.  Chemical mutagenesis through the application of ethyl methane sulfonate was utilized to induce hereditary phenotypic variation in Ornithogalum candicans (cape hyacinth).  Phenotypic variation was evaluated by collecting field data of mutant seedlings.  Interspecific hybridization through controlled crosses was evaluated as a method to increase phenotypic variation in Sections Dasanthera, Saccanthera, and Penstemon of Penstemon.I found that there is indeed natural ploidy and genome size variation in Acer.  Genome size and ploidy data collected in this survey will add to the growing body of knowledge relative to angiosperms.  Additionally, the identification of natural polyploids will be of use in developing breeding programs focused on sterile cultivar development.  Ethyl methanesulfonate is an effective means of inducing phenotypic variation in Ornithogalum candicans and was shown to lead to a reduction in both plant height and fertility.  Interspecific hybridization of sections of interest in Penstemon has some challenges.  Challenges include identifying the appropriate environment for controlled crosses and ascertaining the fertility and crossability of target species and garden cultivars used in breeding germplasm."
http://hdl.handle.net/1957/59832,"The implementation and construction of Mechanically Stabilized Earth (MSE) walls has undergone substantial expansions in recent years, owing to its relatively low cost, ease of construction, and high efficiency compared to conventional retaining methods.  As a result, MSE walls are being constructed to greater heights with complex features (e.g. multiple tiers, equivalent batter angles, close reinforcement spacing) even though impacts on wall response associated with these characteristics are not well understood.  Available methods to predict wall responses are limited to empirical databases of single tiered walls less than 20 m and designers are left to complex finite element modelling to estimate the behavior of tall walls (walls with heights greater than 20 m).  The current study aims to provide practitioners with a better understanding of the working stress behavior of tall MSE walls during and after construction through the use of a calibrated  numerical model that incorporates pressure dependent soil, panel-soil interaction, non-linear soil reinforcement interaction, facing rigidity, foundation stiffness, and compaction stresses.  First, an extensive laboratory investigation is conducted to characterize the plane strain and three dimensional stress-strain and stress-dilatancy response of a well-graded gravelly soil.  Laboratory pullout tests are performed to characterize the influence of reinforcement spacing on load-displacement response.  Results from the high quality laboratory investigations are used to calibrate specific numerical elements in FLAC (e.g. reinforcement-soil interface, facing-soil interface, soil constitutive response) incorporating pressure dependent constitutive responses.  A numerical model representing a 46 m tall MSE wall is developed in FLAC, incorporating calibrated element parameters.  Measurements made during the construction of a 46 m tall MSE wall are used to establish those factors within the model that most accurately simulate the observed wall performance.  Results from a geometric parametric study conducted to assess the influence of boundary conditions on wall response are presented, focusing on impacts associated with tier height, tier offset, and wall height.  The synthesis of the results from the geometric parametric study are used to establish a more thorough understanding of wall response, with specific emphasis on wall displacements and reinforcement strains."
http://hdl.handle.net/1957/59833,"Multiple Sclerosis (MS) is an autoimmune condition that affects the central nervous system, and impacts the lives of over 400,000 individuals in the US. These individuals face unpredictable relapses of disabling conditions, are less active and experience poorer quality of life than the general population. Health professionals are challenged to find ways to increase engagement in health promoting behaviors that can improve function and overall wellness for this population. The major objective of this dissertation was to expand the literature on promoting health behaviors and wellness through self-compassion for individuals with MS. One theoretical model that has the potential to help researchers and program developers understand how to effectively improve engagement in health behaviors for individuals with MS is Reyes’ model of self-compassion. The first aim of the first study was to cross-validate Reyes conceptual model of self-compassion among individuals with MS. Although the model is promising, recent studies suggest fatigue may play a unique role for individuals with MS. The second aim of the first study was to examine the utility of an alternative model, which expands upon Reyes’ model. Furthermore, self-compassion has been shown to improve resilience and quality of life in the general population. The second study aimed to understand the relationship between self-compassion, resilience and health-related quality of life for individuals with MS. Individuals (N = 259) participated in a survey measuring their perceived fatigue, self-compassion, psychological needs related to exercise, resilience, health-related quality of life, and self-reported physical activity, as well as a demographic questionnaire. Participants were predominately white (90%) females (84%), with a relapse-remitting MS course (73%), and a mean age of 48.60 (SD = 10.46). Study 1 validated the use of Reyes’ conceptual model of self-compassion. However, the alternative model, which added direct paths to psychological needs and fatigue, showed improved fit over Reyes’ model for this population. Results demonstrated that fatigue predicted engagement in physical activity in both models, which was expected. However, in the alternative model, fatigue significantly negatively predicted psychological needs for engaging in exercise, but showed a non-significant, weak relationship with physical activity behavior, which was unexpected. Study 2 examined the relationship between self-compassion, resilience, and health-related quality of life for individuals with MS using mediation analysis. Results from this study showed that resilience was a partial mediator between self-compassion and health-related quality of life. The results from these studies can inform future health interventions seeking to improve health-related quality of life and engagement in physical activity in this population. Both of these studies contribute to the theoretical knowledge of self-compassion, wellness, and behavior change for individuals with MS."
http://hdl.handle.net/1957/59837,"The multifaceted role of the environment in regulating the structure and dynamics of biological communities has long fascinated ecologists and motivated much debate and research. Now, in a time of accelerated global changes due to human impacts, the need to understand how the environment shapes communities has gained new urgency. The environment acts directly on communities by causing direct mortality and changes to vital rates of individuals. However, the environment can also exert indirect effects on communities by changing the nature of biotic interactions. This occurs either through changes to the physiological performance of interacting species or through shifts in the abundance of other species in the community. Much of the effort to understand how global change will influence communities has focused on direct effects of environmental conditions. However, the essential influence of biotic interactions suggests that we will need to improve our conceptual understanding of indirect environmental effects to better predict outcomes of anthropogenic change.Understanding how the interactions of predators and prey are vulnerable to environmental context may provide a useful pathway to link relatively well-resolved individual effects of climate change to a broader community context. Predators are often important in determining community structure and stability through their control of lower trophic levels. However, predators also tend to be particularly sensitive to environmental stress. As a result, environmental stress models predict that the impacts of predators will lessen as stress increases, which could weaken existing processes regulating communities. Top predators, which often have the strongest impacts, may be especially vulnerable to climate change because of their large body size, energy needs, range requirements, and dependence on prey populations. The effects of environmental change on top predators have been justifiably well-studied, yet changing contexts require a more comprehensive view of which species may be important in novel environmental contexts. Subordinate predators are often weak interactors in communities, but they may play increasingly critical roles if top predators decline. Similarly, because weak interactions are highly variable, shifting environmental contexts could lead to different outcomes with subordinate predator interactions.Communities that experience high environmental variability across short spatial and temporal scales, such as rocky intertidal communities, are particularly useful for examining effects of environmental context on predator-prey interactions. The rocky shores along the US west coast have a rich history of study, enabling us to combine new insights and existing knowledge to build a greater context for predicting the impacts of environmental changes. Due to anthropogenic climate change, communities along rockyshores in the NE Pacific are predicted to experience warmer air temperatures, intensified upwelling, and greater exposure to low pH waters. These abiotic changes are likely to influence biotic changes, such as shifting species abundances and distributions, reductions in performance, and increases in disease and mortality.This dissertation explores how three different environmental contexts – two abiotic and one biotic – influence the interactions between a predator and its prey species. My focal predators are two gastropod congeners, the whelks Nucella canaliculata and N. ostrina that feed on mussels and barnacles. Whelks are abundant predators in the mid-intertidal zone, and we know their interactions can be sensitive to environmental conditions. My aim in this dissertation is to expand our understanding of predation in the rocky intertidal and how it is affected by 1) ocean acidification, 2) existing variability in the environment, and 3) the disease-driven decline of the keystone sea star Pisaster ochraceus, which are all contexts relevant to climate change.In Chapter 2, I explore how interactions between whelks and mussel prey are affected by ocean acidification (OA), an abiotic stressor that can influence species physiology and behavior. I use two separate mesocosm experiments designed to capture mechanistic changes in the two pairwise predator-prey interactions. Specifically, I test how the feeding rate and handling time of whelk predators is influenced by elevated CO₂, which has the effect of lowering the pH and reducing the saturation state of carbonate minerals used by both whelks and mussels for building shells. The results show that whelks consume fewer mussels in elevated CO₂, and that this may be caused in part by substantially longer handling times of prey. These results are consistent with the idea that predators are more vulnerable to the stresses associated with OA than prey, at least on shorter time scales.In Chapter 3, I use a comparative experiment at eight sites in Oregon to assess how variability in the interaction between whelks and mussels is shaped by dynamic conditions in the field. Previous experiments have focused on local-scale gradients such as wave exposure and tidal elevation in testing environmental stress models. I expand on these studies to test how predation rate responds to larger-scale variability in upwelling and temperature, both of which are relevant to climate change in the intertidal. In three similar experiments that span 14 years, I observe patterns in mussel survival and assess whether the importance of environmental variables has changed through time. I find that predation by whelks is relatively consistent in the field context, but is explained in part by upwelling. In the final year of study (2013), there was evidence that variability in air temperatures decreased predation, which may point to shifting environmental influences on whelk predators.In Chapter 4, I follow the population responses and community effects of whelks after the striking decline of the keystone sea star Pisaster ochraceus along rocky shores in Oregon. Sea star wasting disease has caused declines in P. ochraceus populations by up to 80%, greatly reducing the population impact of this keystone species. Past research has demonstrated that when P. ochraceus is removed, it often results in the formation of a near-monoculture of the mussel M. californianus in the low intertidal zone. I hypothesize that whelks will be able to minimize mussel invasion following declines in P. ochraceus because whelks will be able to control sessile prey species, like barnacles, that facilitate mussel establishment. However, my field experiment provides no evidence of compensation by whelks; instead, they weakly facilitate mussel establishment. To understand whelk population responses to keystone species loss, I also monitor whelk abundance, distribution with tidal elevation, and population size structure. My results indicate the potential for a lagged whelk population response suggested by a shift of the size structure towards smaller individuals.Overall, my dissertation highlights the sensitivity of rocky intertidal predator-prey interactions to environmental contexts relevant to anthropogenic change. It also points to the need to continue studying predation in relevant environmental contexts in order to scale existing knowledge in species responses to the community level. Further, my results reveal that at both the per capita and population levels, weak interactors have variability in their interactions with other species that will likely influence their role in communities undergoing change. Even in a well-understood system, our results were often unexpected and did not necessarily match the predictions of environmental stress models and other existing frameworks. This suggests we need to build further conceptual and empirical frameworks to determine how sensitivity in species interactions will ultimately affect community structure, functioning, and the provision of ecosystem services."
http://hdl.handle.net/1957/59838,"Cognitive radio technology emerges as a promising solution for overcoming shortage and inefficient use of spectrum resources. In cognitive radio networks, secondary users, which are users equipped with cognitive radios, can opportunistically access spectrum assigned to primary users, the spectrum license holders. Although it improves spectrum utilization efficiency, this opportunistic spectrum access incurs undesired delays that can degrade the quality of service (QoS) of delay-sensitive applications substantially. It is therefore important to understand, model, and characterize these delays, as well as their dependency on primary user behaviors. Moreover, the lack of access priority leads to significant performance degradation when the network is under jamming attacks. It turns out that addressing jamming attacks while maintaining a desired QoS is very challenging. In this thesis, we characterize the properties of the random process that describes the availability of the opportunistic resources, and analytically model and analyze cognitive network average delays. Furthermore, we propose and study new techniques that mitigate jamming attacks in mobile cognitive radio networks. More specifically, this thesis consists of the following three complimentary frameworks:Bechir Hamdaoui1. Stochastic Resource Availability Modeling and Delay Analysis. In this framework, we define and characterize the properties of the random process that describes the availability of the opportunistic network resources. We apply the mean residual service time concept to derive an analytical solution for the cognitive network queueing delay. We model the service mechanism, and determine the manner in which it depends on spectrum availability. We show that the delay becomes unbounded if spectrum dynamics are not carefully considered in network design.2. Mitigating Jamming through Pseudorandom Time Hopping. In this framework, we propose and evaluate jamming countermeasure approaches for mobile cognitive users. We propose two time-based techniques which, unlike other existing frequency-based techniques, do not assume accessibility to multiple channels and hence do not rely on spectrum handoff to countermeasure jamming. In these two techniques, we allocate data over time based on cryptographic and estimation methods. We derive analytical expressions of the jamming, switching and error probabilities. Our findings show that our proposed technique outperforms other existing frequency-based techniques.3. Optimally Controlled Time-Hopping Anti-Jamming Technique. In this framework, we propose a jamming and environment aware resource allocation method for mobile cognitive users. We propose to mitigate jamming based on an optimal allocation of data over time. In addition, we optimally control network mobility to meet a desired QoS. Our findings show that our proposed technique achieves better QoS than those achieved by existing cryptographic methods while not compromising jamming resiliency."
http://hdl.handle.net/1957/59847,"There is increasing awareness that human activities are altering the ways that natural systems operate and that local shifts in species composition and abundance can lead to abrupt and irreversible global change.  Therefore, understanding the processes that buffer biological communities from critical shifts and how our actions affect natural stabilizing feedbacks are important goals of ecology.  One human activity with far reaching consequences for global ecosystems is the introduction of exotic species outside of their native ranges.  Introduced predators, whose effects may be exacerbated by lack of shared evolutionary history with native prey, can have particularly strong effects on recipient communities.  As trophic interactions play a central role in both population regulation and community persistence, it is essential to determine the extent to which introduction of novel predators can alter the function of stabilizing mechanisms.     The goals of this dissertation were to use a combination of manipulative field experiments and theoretical modeling to explore how introduced predators influence invaded communities through their effects on the processes that naturally maintain bounded prey population dynamics and promote community coexistence.  Density-dependent predation can regulate prey populations by providing a negative feedback in response to changes in population size.  In my first experiment (Chapter 2), I investigated the effects of invasive Indo-Pacific red lionfish (Pterois volitans) on density-dependent mortality patterns previously documented to regulate a common native Atlantic prey species, the fairy basslet (Gramma loreto) on coral reefs in the Bahamas.  By repeating a pre-invasion density-manipulation experiment, now in the context of predation by both native piscivores and lionfish, I demonstrated that per capita loss of fairy basslet remained density-dependent in the presence of lionfish, but the overall magnitude of loss was substantially greater compared to pre-invasion rates.  Per capita loss was higher in 13 out of 16 basslet populations with an average increase of over 60% in the presence of the invader.  The before-and-after design provided no evidence for a change in the intensity of density dependence between experiments, indicating the addition of destabilizing density-independent mortality caused by lionfish. In my second experiment (Chapter 3), I employed a split-plot, cross-factored experimental design, manipulating both fairy basslet density and lionfish presence absence such that differences in per capita loss rates were attributable only to predation by the invader.  Over four weeks, mortality of fairy basslet was far greater on lionfish reefs compared to reefs with only native predators, displaying 2.4 times higher net loss on recruitment-enhanced fairy basslet populations and a five-fold increase in net loss at unmanipulated prey populations.  Per capita loss was density-dependent in both predator treatments, but high mortality rates at low prey density on lionfish reefs resulted in extirpation of 15% of unmanipulated fairy basslet populations.  In contrast, no prey populations were extirpated on reefs with only native predators.   In addition to field experiments, this dissertation includes a theoretical model (Chapter 4) that explored the effects of predator novelty on the coexistence of an intraguild predation web with adaptive antipredator defense in the shared prey.  Adaptive prey responses can promote multi-predator coexistence by creating a stabilizing tradeoff in the allocation of predator-specific defense effort.  Yet to date, all such theory has assumed that prey have accurate perception of predation risk and appropriate antipredator responses, assumptions that may not be justified when considering a novel predator.  The model showed that the parameter region of IGP coexistence is dramatically reduced by an exotic predator but that effects of novelty on community persistence are complex and context-dependent.  Specifically, the model predicts that predator novelty can weaken the effect of adaptive defense, causing exclusion of native predators that would persist in the absence of novelty.   Coexistence is predicted to be more sensitive to the effects of suboptimal defense compared to naïveté and differentially leads to exclusion of native predators in highly productive environments and when defense costs are low.  Moderate novelty of the omnivore can increase resource density via a trophic cascade, while consumer novelty can either lead to omnivore exclusion or facilitate three-species coexistence by providing a subsidy to the otherwise excluded native omnivore.  The results suggest that models of adaptive defense are sensitive to assumptions regarding predator-prey eco-evolutionary experience and that predator novelty has significant implications for food web dynamics. Overall, the research described in this dissertation illuminates the mechanisms by which introduced predators can disrupt the boundedness and persistence of otherwise stable systems and provides insight into how predator novelty can alter biological communities via novel trophic and non-trophic interactions.  As natural systems across the globe face multiple stressors that can alter their functioning, it is increasingly vital to understand the stabilizing mechanisms that buffer these systems from change, and how species introductions may modify the capacity for communities to respond to natural and human-caused disturbance."
http://hdl.handle.net/1957/59882,"Quantitative assessments of post-fire effects are key to improving our understanding of ecosystem resilience. While remote sensing technology has allowed us to assess post-fire landscape effects, we are often limited by the lack of information related to pre-fire forest attributes. As a result, our ability to interpret  fire effects in relation to landscape-scale canopy fuel distributions is severely inhibited. We used discrete-return multi-temporal Light Detection and Ranging (LiDAR) to quantify pre-fire basal area, basal area mortality, and post-fire basal area. Observed pre-fire basal area values were reconstructed from field measurements taken 2-years after fire. We modeled pre-fire basal area using a log-linear model, whereas, basal area mortality was modeled with beta regression and change estimation. Model performance was compared using bias, RMSE, RMSPE, AIC, and BIC. We also modeled basal area mortality using a combined approach, where we included RdNBR within the selection process. Intensity values were not used in combined models. In general, LiDAR models outperformed combined models (RMSPE of 0.1293 vs. 0.1347 with 3 and 4 variables, respectively) when quantifying basal area mortality. Intensity metrics improved pre-fire basal area models (reduction in AIC BIC values ≈ 10-20; not shown). Lastly, we provide multiple examples of practical applications for renewed perspectives by clearly defining fire effects, directly quantifying, and calibrating remotely sensed LiDAR information to field observations."
http://hdl.handle.net/1957/59906,"This project determines the short term and long term effective stiffness values for Cross Laminated Timber (CLT) with a reinforced concrete topping. The reinforced concrete was attached to the CLT panels with interface connections, and different types of interface connections were tested. Throughout this project, there are 31 tests with composite CLT floor panels. Described in this report are:• Eight 2 ft. by 10 ft. 8 inch composite floor panels with different interface shear connections. All these 2 ft. by 10 ft. 8 inch panels were tested to failure in positive bending moment under simply-supported conditions.• Three 8 ft. by 8 ft. composite floor panels with inclined self-tapping screws. The panels were tested to estimate the initial stiffness in strong and weak axis bending, under positive and negative bending moments. In addition, two-way bending flexural (warping) stiffness values were obtained from testing results. Lastly, the floor panels were tested to failure under weak-axis direction, positive moment bending, and in strong and weak axis bending under negative moment bending.• One 37.5 ft. long by 8 ft. test specimen with inclined self-tapping screws was tested to failure.• One 20 ft. by 4 ft. specimen and one 13.5 ft. by 4 ft. specimen under positive and negative bending moment, respectively, tested under creep loading.These tests aided in the determination of effective stiffness values that can be used for design of floor panels that have a total thickness of 9 inches, including a 2-1 4 inch concrete lamina, over a five-ply CLT panel. In addition, estimates of failure loads and moments presented in this thesis provide information needed for future structural designs of the CLT concrete composite floor systems."
http://hdl.handle.net/1957/59930,"The rapid scaling of network bandwidth and data center throughput has motivated the wide adoption of high speed transceivers. Silicon photonics (Si-Photonic) is one of the most promising techniques to realize tightly integrated optical transceivers for next-generation high speed I O standards. This dissertation focuses on the design techniques of Si-Photonic transceivers for a data rate of 25Gb s and beyond. A 25Gb s transmitter design is demonstrated based on depletion-mode Microring modulators. An AC-coupled differential driver is proposed to realize 4×VDD output swing as well as tunable DC-biasing. The proposed transmitter incorporates 2-tap asymmetric pre-emphasis to effectively cancel the optical nonlinearity of the Microring modulator. An average-power-based dynamic wavelength stabilization loop is also demonstrated to compensate for thermal induced resonant wavelength drift. At 25Gb s operation, each transmitter channel consumes 113.5mW and maintains 7dB extinction ratio with a 4.4V[subscript pp-diff] output swing in the presence of thermal fluctuations. On the receiver side, the design of a 25Gb s PAM2, 40Gb s PAM4 Si-Photonic receiver design is investigated. The proposed receiver design employs a pseudo-different trans-impedance amplifier (TIA) as well as a direct-feedback decision feedback equalizer (DFE) to enhance the sensitivity for both PAM2 and PAM4 operation."
http://hdl.handle.net/1957/60106,"The ternary system (Bi₀.₅Na₀.₅)TiO₃-(Bi₀.₅K₀.₅)TiO₃-Bi(Mg₀.₅Ti₀.₅)O₃ (BNT-BKT-BMgT) was explored along the [75-(x 2) ]Bi₀.₅Na₀.₅TiO₃ - [25-(x 2)]Bi₀.₅K₀.₅TiO₃ - [x]Bi(Mg₀.₅Ti₀.₅)O₃ composition line. Thin films were fabricated using chelated mixing route solutions spin cast onto platinized silicon substrates. Processing parameters such as: excess cation molar%, solution molality, and crystallization temperatures, for composition where x=0, 5, 10, 20, 30, were optimized. The thin films of ~ 200nm thickness displayed ~15% and ~5% change in piezoelectric properties over the composition range for d₃₃,f* and Smax, respectively. The ferroelectric properties showed a minimum at x=10 for the coercive field and maximum at x=5, 30 for maximum polarization. Additionally, the fatigue characteristics at x=0, 5, 10 were studied using bipolar cycling up to 10⁹ cycles. A drop in d₃₃,f*  and S[subscript max] is seen beginning at 10⁷ cycles for all compositions while polarization increased for compositions where x=0, 5, but not for x=10. The coercive field also increased with increasing number of cycles starting at 10⁵ and 10⁷ for compositions where x=0, 5 and x=10, respectively. The polarization vs electric field hysteresis loops for the fatigued samples show a transformation from saturated slim loops to unsaturated broad loops, indicative of lossy behavior, for compositions where x=0, 5, however, hysteresis loops for the composition where x=10 displayed saturated slim loops for 1→10⁹ cycles. The piezoelectric properties for x=0, 5, 10 showed a 27%, 28%, and 34% drop in d₃₃,f* at 10⁹ cycles, respectively. Here the optimal processing conditions were found for the compositions with increasing mol% of BMgT. The piezoelectric and ferroelectric properties of resulting thin films were compared for the composition range and films of selected composition were subjected to bipolar field cycling for up to 10⁹ cycles. The BNT-BKT-BMgT derived thin films demonstrated piezoelectric characteristics desirable for actuators, such as minimal negative strain and maximum strains comparable to bulk ceramic embodiments. The composition study revealed differences in the observed piezoelectric properties vs. composition for thin films vs. bulk ceramics, mainly the lack of a maximum in d₃₃,f* as a function of composition for the thin films as it is observed for bulk ceramics. Fatigue resistance for selected compositions demonstrated improvement over other bismuth sodium titanate binary and ternary systems and were comparable to doped lead compounds for up to 10⁹ cycles."
http://hdl.handle.net/1957/60120,"We demonstrated a low-cost and high-sensitivity DNA detection method using quantum dot-fullerene based molecular beacons (MBs) and magnetic nanoparticles. The MB tethered magnetic nanoparticles can be well dispersed in analytes for efficient DNA capture and concentrated by an external magnetic field for enhanced fluorescence signal detection. The detection requires only 5 µl analyte samples and takes about 20 minutes. The high signal-to-noise ratio produced by the quantum dot-fullerene pairs and magnetic concentration yield a detection limit as low as 100 fM."
http://hdl.handle.net/1957/60125,"This work is inspired by problems in natural resource management centered on the challenge of invasive species. Computing optimal management policies for maintaining ecosystem sustainable is challenging. Many ecosystem management problems can be formulated as MDP (Markov Decision Process) planning problems. In a simulator-defined MDP, the Markovian dynamics and rewards are provided in the form of a simulator from which samples can be drawn. Simulators in natural resource management can be very expensive to execute, so that the time required to solve such MDPs is dominated by the number of calls to the simulator. This thesis studies MDP planning algorithms that attempt to minimize the number of simulator calls before terminating and outputting a policy that is approximately optimal with high probability. This thesis addresses three questions on unconstrained MDPs: (a) what confidence interval should be employed to bound the optimality of the policy and (b) how should samples be drawn to shrink the confidence interval as quickly as possible? (c) how can we find the optimal policy with high probability efficiently? Many computational sustainability problems involving MDPs must also be concerned with catastrophic outcomes such as species extinction. These problems can be formulated as constrained MDPs. We define the downside risk as the probability of reaching catastrophic states and then constrain the MDP solution to bound the probability of entering such states. We then develop the first PAC-Safe-RL algorithm for constrained MDPs. We evaluate our algorithms on an invasive species problem as well as on standard reinforcement learning benchmarks."
http://hdl.handle.net/1957/60134,"Appropriate representations of variational software simplify the analysis of their properties.This thesis proposes tailored representations of two kinds variational softwares:difference files of merge commits in Git and feature models. For the former, we use theChoice Edit Model, which is based on the choice calculus, to represent changes introducedby merge commits. This approach identifies merge conflicts and automaticallydetects conflicts that can be ignored because they are semantically irrelevant. An experimentof 50 Git repositories shows that in some cases about 10% of merge conflictshaving no semantical effects. For feature models, this thesis provides Choice DependencyGraphs to show relationships of features. Choice Dependency Graphs provide asuccinct representation that supports 4 analysis operations for feature models effectively."
http://hdl.handle.net/1957/60135,"Soft robots are designed to utilize their compliance and contortionistic abilities to both interact safely with their environment and move through it in ways a rigid robot cannot. To more completely achieve this, the robot should be made of as many soft components as possible. Here we present a completely soft hydraulic control valve consisting of a 3D printed photopolymer body with electrorheological fluid (ER) as a working fluid and gallium indium tin liquid metal alloy as electrodes. This soft 3D printed ER valve weighs less than 10 grams and allows for onboard actuation control, furthering the goal of an entirely soft controllable robot. The soft ER valve pressure holding capabilities were tested under unstrained conditions, cyclic valve activation, and the strained conditions of bending, twisting, stretching, and indentation. It was found that the max holding pressure of the valve when 5 kV was applied across the electrodes was 264 kPa, and that the holding pressure deviated less than 15% from the unstrained max holding pressure under all strain conditions except for indentation, which had a 60% max pressure increase. Additionally, a soft octopus-like robot was designed, 3D printed and assembled, and a soft ER valve was used to stop the fluid flow, build pressure in the robot, and actuate six tentacle-like soft bending actuators."
http://hdl.handle.net/1957/60136,"Public attention and concern about per- and polyfluoroalkyl substances (PFASs) are increasing due to detection of PFASs in drinking water supplies, the environment, including remote locations, and wildlife and to the lowering of the federal health advisory levels of perfluorooctane sulfonate (PFOS) and perfluorooctanoate (PFOA) in drinking water.  Aqueous film-forming foams (AFFFs), which typically contain anionic, zwitterionic, and cationic PFASs, are one route of environmental entry for PFASs.  AFFFs were routinely applied since the 1960s to extinguish hydrocarbon-based fuel fires during emergencies and fire fighter training.  Routine releases of AFFF into the environment have resulted in high concentrations (mg L) of PFASs in groundwater.  Attention typically focuses on the well-known homologs of the perfluoroalkyl carboxylates (PFCAs) and perfluoroalkyl sulfonates (PFSAs), including PFOA and PFOS, and other anionic, zwitterionic, and cationic PFASs receive little attention.	Recent data on AFFF-impacted groundwater indicates that ~ 25% of the PFASs are currently unidentified.  A complete understanding of the composition of PFASs in AFFF-impacted groundwater is needed in order to investigate biodegradation pathways and to develop effective remediation techniques that capture PFASs with a wide range of water solubilities and subsurface mobilities.	Zwitterionic and cationic PFASs present in groundwater, soil, and sediment have not been characterized with respect to partitioning (sorption) behavior.  Sorption studies typically focus on a select number of well-known PFCAs and or PFSAs, and a limited number of studies simulate AFFF discharge field conditions.  By enhancing understanding of zwitterionic and cationic PFAS sorption, transport and likely subsurface location (i.e. predominantly in groundwater or sorbed to soil) can better direct subsurface remediation efforts and mitigate off-site migration.	Chapter 2 discusses a data analysis test for non-target analysis and the subsequent serendipitous discovery of two ultrashort chained PFSAs.  Select 3M AFFFs and AFFF-impacted groundwater samples, each from 11 different U.S. military bases were analyzed using quadrupole time-of-flight mass spectrometry (qTOF-MS).  Kendrick mass defect plots were used to identify known homologs within a homologous series.  Careful inspection of the PFSA homologous series led to the serendipitous discovery of the C₂ and C₃ PFSAs in 3M AFFF and AFFF-impacted groundwater.  The C₂ and C₃ PFSAs were quantified using liquid chromatograph tandem mass spectrometry.	Chapter 3 uses the developed non-target data analysis strategy to attempt to close the mass balance of PFASs in AFFF-impacted groundwater.  Select 3M and fluorotelomer AFFFs, commercial products, and AFFF-impacted groundwater samples from 15 different sites were used to identify the remaining PFASs.  Liquid chromatography qTOF-MS was used for compound discovery.  Nontarget analysis and suspect screening were conducted.  For nontarget analysis, a ‘nontarget’ R script in combination with Kendrick mass defect plots aided in compound identification.  Suspect screening compared detected masses against a list of previously reported PFASs.  Forty novel classes of anionic, zwitterionic, and cationic PFASs were discovered, and an additional 17 classes of previously reported PFASs were observed for the first time in AFFF and or AFFF-impacted groundwater.  All 57 classes received an acronym and IUPAC-like name.	Overall, of the newly discovered PFASs, ~ 68% were zwitterionic or cationic PFASs.  Chapter 4 selects the representative National Foam AFFF to determine the soil properties influencing the sorption of model anionic fluorotelomer sulfonates (FtSs), zwitterionic fluorotelomer sulfonamido betaines (FtSaBs), and the cationic 6:2 fluorotelomer sulfonamido amine (FtSaAm).  Batch sorption experiments were conducted using the whole National Foam AFFF, with initial aqueous phase concentrations of the 6:2 FtSaB ranging from 1,000 to 138,000,000 ng L, which represent concentrations of dilute groundwater plumes up to the application of 3% AFFF used in fire fighter training and emergency responses.  Six blank soils with varying organic carbon, cation exchange capacity (CEC) and anion exchange capacity as well as a select soil buffered to pH 4 and 7 were used to determine the factors predominantly impacting sorption.  A new, aggressive soil extraction method was developed due to incomplete mass balance of the FtSaBs and the 6:2 FtSaAm using published extraction methods.  Hydrophobic interactions drove the sorption of the anionic FtSs, while the FtSaBs were influenced primarily by CEC.  The 6:2 FtSaAm was depleted from the aqueous phase in all but one soil, and therefore, sorption is likely driven by a combination of CEC and organic carbon."
http://hdl.handle.net/1957/60138,"The focus of this dissertation was to understand protein function and structure ona molecular level. To do this successfully, a variety of biochemical and biophysicaltechniques were employed. A wide variety of techniques were applied to study theproteins of interest in this dissertation to probe protein-protein interactions, proteinfunction, protein structure, and protein regulation. In addition, the use of bioinformaticshas placed the similarities and differences of these proteins compared to homologs inperspective within their protein families.There are three chapters of original research presented here, the second chapter ispublished, the third contains my contribution to a work that is published, and the fourthwill be submitted for publication. The second chapter of this thesis describes the studieson the protein dysferlin. Mutations in dysferlin are responsible for late onset musculardystrophies where muscle cells are deficient in resealing the cell membrane upon routineinjury. We demonstrate that dysferlin catalyzes the rate-limiting step of membrane fusionand mediates lipid mixing in a calcium sensitive manner. This work was the first in thefield to determine a mechanism of action of dysferlin and suggests a molecular basis forwhy mutations that abrogate dysferlin's activity result in muscular dystrophy.The third chapter includes my contribution to the complete structural solution ofthe enzyme ValA involved in the synthesis of the crop protectant validamycin A. Thiswas the first structure of a sedoheputlose-7-phoshpate cyclase, and the overall foldreflects that of similar sugar cyclase proteins. But, the sequence and structural analysis ofValA with respect to other related proteins revealed the first novel theory regardingsubstrate specificity of ValA. It is postulated that due to sequence alignment andstructural data, ValA selectively binds the β-anomer of its substrate which pre-assignsstereochemistry of the enzymatic product.In the fourth chapter of this dissertation we design several variants of the proteinmerlin involved in cell contact growth inhibition. Whereas a complete structural solutionwas never obtained for merlin in this study, we used in vitro techniques to test the role ofmerlin's central domain in the conformational regulation of the protein. This was the firststudy on merlin, or the homologous proteins ezrin, radixin, and moesin, that focused onthe role of the central domain. Our results confirm that this domain is not merelystructural, but mediates key interactions that modulate merlin's degree of intramolecularassociation. That merlin's activity is central to cell contact growth inhibition and that thisactivity is modulated by merlin's degree of intramolecular association, it is clear now thatthe central domain plays a key role in the activity of merlin.In the final chapter and fifth chapter I conclude this dissertation."
http://hdl.handle.net/1957/60534,"Earth’s atmosphere is unequivocally warming due to CO₂ and other greenhouse gas (GHG) emissions from human activities and this is having widespread impacts on forest ecosystems that provide important services to human societies. Forest ecosystems help regulate atmospheric CO2 concentrations by sequestering carbon in tree biomass and soils, which is a valuable ecosystem service that is sensitive to climate change and forest management. Rising air temperatures contributed to increased aridity and drought during recent decades among forests in the western United States and projections suggest that many parts of this region could become hotter and drier over the coming century barring significant reductions in GHG emissions. Managing regional forests and GHG emissions in a warming world requires better understanding of how forest carbon cycling is influenced by climate, including climate-mediated disturbance (e.g., fires). The objectives of this dissertation were to assess (1) forest response to water availability and (2) tree mortality from disturbance during recent decades in the western US.  Forest response to water availability was assessed, in part, by quantifying changes in forest productivity and live biomass across sites that varied widely in average water availability. Bioclimatic relationships were developed using (1) field measurements from 12 sites in the eastern Cascade Mountains, (2) inventory and ancillary plot measurements from 1,953 sites in Washington, Oregon, and California (WAORCA), and (3) remote sensing measurements spanning 18 Mha of mature forest in the western US. In each case, forest productivity and live biomass increased markedly across sites as average water availability increased. For instance, median forest productivity increased from 2.2 to 5.6 Mg C ha⁻¹ yr⁻¹ between the driest and wettest 5% of sites in WAORCA, while live biomass increased from 26 to 281 Mg C ha⁻¹. These bioclimatic relationships illustrate that forests are widely sensitive to changes in water availability, suggesting that continued warming and drying could reduce carbon sequestration over the coming century in parts of the region.Tree mortality from fires, bark beetles, and timber harvest was quantified from 2003-2012 across the region using remote sensing, federal harvest statistics, and ancillary information. Tree mortality was quantified in terms of carbon storage in aboveground biomass killed by disturbance. Regional tree mortality from these disturbances together averaged 45.8±16.0 Tg C yr⁻¹ (±95% confidence interval), with harvest, beetles, and fires accounting for 50%, 32%, and 18% of mortality, respectively. Tree mortality from timber harvest was concentrated in the high-biomass forests of the Washington and Oregon. Tree mortality from bark beetles occurred largely in Colorado, Wyoming, and Montana, where tree defenses were suppressed by drought and beetle populations bolstered by rising winter temperatures. Tree mortality from fires was highest in California, Idaho, and Montana, which also experienced very dry conditions during this decade. Tree biomass killed by disturbance will gradually decompose and emit CO₂ to the atmosphere over decades to centuries, where it will act as a GHG. This analysis illustrates both opportunities and challenges to managing GHG emissions from forest ecosystems in the region. Swift and significant reductions in GHG emissions are needed to curtail adverse impacts of climate change on forest ecosystems and human societies."
http://hdl.handle.net/1957/60552,"State Departments of Transportation (DOTs) are the primary owners of roadway infrastructure in the United States. Many of the employees of state DOTs work on roadway work sites, putting them at disproportionately higher risks of injury or fatality. A review of the literature determined that a combination of policies, standards, and data can be used to potentially reduce these risks. Understanding current practices at state DOTs for promoting and documenting the safety of their employees is critical to understanding successes and deficiencies to improve resource allocation. To determine the state of the practice, a survey of state DOT practices followed-by state DOT safety program case studies were conducted. The results confirmed that state DOTs are diverse agencies that have different scopes and priorities. The survey results provided evidence of this diversity from how incidents are recorded and archived to how data is collected and used at each agency. The case studies demonstrated a variety of safety programs that use various levels of data in the processes of program development and evaluation. Overall, data is not well integrated into state DOT safety programs and there is significant opportunity to expand the ways in which data is used to reduce risk to highway workers."
http://hdl.handle.net/1957/60553,"Large quantities of the chemical oil dispersant Corexit were applied in the Gulf of Mexico (Gulf) in response to the Deepwater Horizon oil spill. Large data gaps regarding the potential transport, persistence and impact of Corexit in the Gulf existed at the time of the emergency response. Analytical methods for the quantification of the individual surface-active-agent (surfactant) components of Corexit in seawater and sediments did not exist and needed to be developed for the support of environmental monitoring and laboratory experiments. The work presented in this thesis addresses important questions about the persistence and transport of the surfactant components of Corexit, namely DOSS, Span 80, Tween 80, and Tween 85 in marine systems. Unique challenges were uncovered and overcome along the way to answering these questions. Chapter 2 describes laboratory microcosm experiments quantifying the biodegradation of the Corexit surfactants in the presence and absence of oil using large volume injection liquidchromatography tandem quadrupole mass spectrometry (LC-MS MS). The extent of primary biodegradation differed for each surfactant and between treatments. Additionally, the microbial and abiotic hydrolysis of DOSS to its transformation intermediate EHSS was quantified. Significant biodegradation of DOSS was observed but mass balance with EHSS was not achieved, indicating that other transformation intermediates are formed during DOSS biodegradation. In contrast to a previous literature report, the abiotic hydrolysis of DOSS was not observed, suggesting that the abiotic losses observed by others were the result of the chemical biocide (sodium azide) employed in that study. Aqueous-phase surfactant concentrations were lower when Corexit was mixed with excess oil, due to partitioning of the surfactants into oil. The implication of this finding is that surfactant exposure concentrations depend on how Corexit is prepared. Chapter 3 describes the development and demonstration of an analytical method for the extraction and quantification of DOSS in marine sediments and sediment-trap materials using liquid chromatography quadrupole time of flight mass spectrometry (LC-QTOF). The use of QTOF resolved interferences without the need for sample cleanup that were observed in some samples analyzed by LC-MS MS. Chapter 4 describes the application of the method developed in Chapter 3 to a large set of sediments collected in the Gulf between 2010 and 2015. Publicly available, but unpublished data, on DOSS in gulf sediments generated as part of the natural resource damage assessment (NRDA) were also incorporated and use to identify an area of DOSS-impacted sediments. The temporal trend in DOSS concentration from 2010-2015 indicates long-term persistence of DOSS with quantifiable DOSS concentrations remaining for more than 5 years after the application of Corexit during the Deepwater Horizon oil-spill. Chapter 5 describes the quantification of Corexit surfactants in aerosols generated under laboratory conditions that simulate bursting bubbles that occur under breaking waves. The ejection of the Corexit surfactants as aerosols was demonstrated. Collectively, the research presented in this thesis overcame analytical challenges in the measurement of the Corexit surfactants and informed the transport and persistence of DOSS and other surfactants in marine systems."
http://hdl.handle.net/1957/60554,"Iodine-129 is a key risk driver at sites where nuclear materials have been fabricated or processed, and it is a predominant isotope of concern in long-term waste storage strategies. I-129 exists primarily as iodate in the subsurface at the Hanford Site in south-central Washington State. Between 15 and 40% of I-129 in the Hanford vadose zone is present in organoiodine form, with the remainder being iodide. Very few alternatives are available for immobilization of dissolved I-129, and the complex biogeochemical behavior of iodine in multiple forms makes it particularly challenging in the context of immobilization. In this work, two Bi-based layered materials for the sequestration of radioactive iodate and iodide were synthesized and characterized. Each material showed remarkable selectivity for iodate, with a maximum K[subscript d] of 2810 mL g observed in groundwater containing high concentrations of carbonate and other competing anions. One of the sorbents displayed nearly quantitative uptake of total iodine, including organoiodine, from Hanford groundwater. Iodide removal was dominated by ion exchange, while iodate immobilization appears to have occurred through a combination of redox and ion-exchange processes. Each sorbent outperformed previously reported non-redox active hydrotalcites in removing iodate from groundwater. Together, these materials comprise a significant step forward for subsurface iodine removal strategies.Another radioactive contaminant of concern present in the Hanford subsurface is strontium-90. Sr-90 is a fission product of uranium, and it has entered the environment as a consequence of nuclear weapons testing, fuel reprocessing activity, and accidental or intentional releases. When ingested, strontium is deposited in bone tissue and teeth. Exposure to Sr-90 increases the risk of leukemia, bone sarcoma, and a number of other health problems. Removing it from contaminated groundwater and preventing its migration in subsurface sediments is of major importance to ongoing remediation efforts at the Hanford Site. Three inorganic sorbent materials--IONSIV™ IE-911, IONSIV™ IE-96, and bone charcoal--were studied in this work. Each sorbent effectively removed strontium from groundwater simulant (GWS) formulated to match groundwater collected at the Hanford Site. Sorption isotherms and kinetics were established for each sorbent in this system, and their maximum sorption capacities for strontium in GWS determined.A third major contaminant at the Hanford Site is uranium, which has entered the vadose zone through multiple routes, including leaks from high-level waste storage tanks and percolation into soil from unlined cribs and retention trenches. Removal of uranium from groundwater simulant by IONSIV™ IE-911, IONSIV™ IE-96, and bone charcoal was evaluated. The impact of uranium on strontium uptake by the sorbents in GWS was quantified, and the influence of uranium on speciation of strontium and calcium was examined. In order to discern actual sorption from precipitation of uranium, the fate of uranium in the contact solutions and sorbents was determined spectrophotometrically. Aqueous speciation of uranium in the GWS was modelled in simulations performed with two geochemical modelling software packages, MINTEQ and PHREEQC. Results of the simulations were compared to experimental data. The formation of aqueous ternary alkaline earth carbonate species of uranium (VI) and mechanisms of uranium sorption via surface complexation were considered."
http://hdl.handle.net/1957/60562,"This dissertation consists of a general introduction, three manuscripts, and general conclusions. The research integrates research on (1) the effects of barley genetics and production environment on the contribution of barley to beer flavor, (2) the effects of degree of malt modification on barley contributions to beer flavor and (3) a genetic analysis of low temperature tolerance (LTT) and vernalization (VRN) sensitivity. The first manuscript reports the relative impacts of barley genotype and environment on sensory descriptors of beers brewed from a subsample of a bi-parental mapping population grown at three locations. The second manuscript addresses the effects of genotype and degree of malt modification on beer flavor based on two experiments involving: a) length of grain storage prior to malting using samples from one of the environments utilized in the first experiment and b) alterations of malting protocol to produce three levels of malt modification in two varieties. The third manuscript describes the results from association mapping of LTT and VRN sensitivity in a large sample of diverse barley accessions that were extensively phenotyped and genotyped. The results of the analysis are applied in the context of facultative growth habit – a tool for dealing with the challenges of climate change on barley production. These manuscripts comprise a roadmap for integrating sensory science with contemporary breeding methods for the development of value-added barley varieties."
http://hdl.handle.net/1957/60570,"Historically fire has been the primary disturbance factor in the sagebrush-steppe. The settlement of the West by Euro-Americans, grazing by domestic livestock, and the concomitant spread of invasive species have altered the historical fire regime.  Understanding the long-term vegetation structure and fuel succession of the various sagebrush-dominated communities of this biome is important for managing the landscape in a way that will facilitate the complicated life histories of wildlife species of concern. The objectives of this study were to address the following current knowledge gaps: a lack of studies examining long-term post-fire fuel succession, a lack of studies that address repeated burns, and a lack of studies in basin big sagebrush (Artemisia tridentata spp. tridentata) and low sagebrush (Artemisia arbuscula). 	To assess long-term fuels succession, the effects of repeated burns, and basin big and low sagebrush fuel structures, I conducted 2 different studies. I resampled previous fire effects studies where pre-fire and immediate post fire fuels data existed at Hart Mountain National Antelope Refuge (HMNAR), John Day Fossil Beds National Monument, Sheep Rock Unit (JODA), and on Prineville BLM land adjacent to Bear Creek (BEAR). Two of these studies were conducted in basin big sagebrush communities (JODA, BEAR), and one of these studies had re-burned since the study’s inception (JODA). The studies were designed so that fuel loads could be statistically tested and compared to their corresponding past studies. Fuels were first stratified into overstory and understory fuels. Overstory fuels consisted of all living and dead shrubs. Understory fuels consisted of downed wood (DWD); duff and shrub-related litter, bryophitic materials; and herbaceous fuels. Herbaceous fuels where then further divided into living grasses and forbs, standing dead grasses and forbs, and detached grass and forb litter.In Wyoming big sagebrush communities at HMNAR that are now seventeen years post fire (YPF), overstory fuels only recovered to 13% of pre-fire levels and understory fuels only reached 25% of pre-fire levels. When compared to adjacent un-unburned control plots, the 17YPF plots had herbaceous fuels that were 5 times greater than controls (17YPF=154±20 kg ha⁻¹, controls=30.2±6 kg ha⁻¹; P<0.01). However, total fuel loads were >7x greater in unburned controls (6014.88±779.76 kg ha⁻¹) than in burned sites (831.2±192.8 kg ha⁻¹; P<0.01).In contrast, in the Basin big sagebrush sites of BEAR and JODA, (25-26YPF) fuels recovered to 7-191% of pre fire levels (pre-fire, 36.2-16.8 Mg ha⁻¹; 25 years after fire, 69.1-2.3 Mg ha⁻¹ [BEAR]), and to 113-209% (pre-fire, 6.2 Mg ha⁻¹; 26 years after fire, 13.0-7.1 Mg ha⁻¹[JODA]). Repeated burns at JODA significantly altered fuels composition. Fifteen years post a single fire (15YPF), herbaceous fuels made up 44%, and shrubs were 39% of total fuels.  The fuel loads (aboveground biomass) of twice-burned sites (2xB;burned 26 years and 15 years prior) had a composition of 71% herbaceous and 12% shrub mass. Total fuel loads in 15YPF and 2xB sites ranged from 3.5-6.0 Mg ha⁻¹ and did not differ by site (P=0.85).Sites from these study all showed high levels of resilience to disturbance by fire, with none of them converting to an alternative state dominated by invasive annual grasses. This is encouraging, and managers and scientists interested in exploring the use of fire as a tool to manage sagebrush steppe ecosystems in a way creates a mosaic of various habitats and fuel loads can use results from this study to facilitate their specific needs"
http://hdl.handle.net/1957/60586,"Increasingly congested surface transportation network in urban areas and growingland values make underground transportation systems more attractive for highways(i.e., tunnels) and metro system compared to other options [1]. An undergroundtransportation system can preserve the land above for recreational parks, commercialbuildings, residential homes, or other purposes while providing an efficient, cost-effective underground corridor to move people and goods by separating from the surfacesystem [1]. However, the underground transportation systems present safety andoperational challenges as well if incidents (e.g., fire, flood, terrorist attacks) occur.Major tunnel incidents since 1995 have killed 713 people worldwide [1]. From 1999 to2001, several tunnel fires with multiple deaths occurred in Europe. For example, 39people died in the fire in the Mont Blanc Tunnel between France and Italy in March1999, 12 people died in the fire in the Tauern Tunnel in Austria in May 1999, and11 people died in the fire in the Gotthard Tunnel in Switzerland in October 2001 inwhich the temperature reached 1,000 degrees Celsius (°C) (1,832 degrees Fahrenheit(°F)) within a few minutes [1]. These incidents caused significant safety concernsregarding underground transportation system safety. This problem is complex formultiple reasons: (1) how people will react in tunnel emergencies is unpredictable, (2) fixed entrances and exits, (3) evacuation is likely to be self-initiated, (4) high-densitypresence of pedestrians, and (5) difficult to access for first responders and emergencyvehicles.The objective of this thesis is to present an interdisciplinary agent-based evacuationmodeling framework for emergencies in underground transportation systems.Through this established framework, we will identify and validate the critical factorswhich a effect life safety in underground emergency scenarios. The identification of thecritical factors is validated by empirical data from historic underground tunnel accidents.The evacuation model is built through an agent-based platform: Anylogic.Then, a multi-discipline framework is introduced to analyse and identify problemsrelated to evacuation in underground transportation systems. Finally, we study indetail and simulate the effects of ticket gate type, walking speed, gender, group size,pedestrian's density, and smoke on evacuation time. The research results from thisthesis will provide decision-making support and guidance for government decision-makers, design engineers, and agency professionals to optimize underground stationdesign. The experiment results indicate that the proposed agent-based undergroundtransportation emergency evacuation modeling framework in this thesis is effective atevaluating the impacts of the identified critical factors on evacuation efficiency andlife safety."
http://hdl.handle.net/1957/60587,"This thesis proposes a novel technique that exploits spectrum occupancy behaviors inherent to wideband spectrum access to enable efficient cooperative spectrum sensing. The proposed technique reduces the number of required sensing measurements while accurately recovering spectrum occupancy information. It does so by leveraging compressive sampling theory to exploit the block-like occupancy structure of wideband spectrum access. The proposed technique is also adaptive in that it accounts for the variability of spectrum occupancy over time. It does so by leveraging supervised learning models to provide and use accurate, real time estimates of the spectrum occupancy. Using simulations, I show that the proposed technique outperforms existing approaches by making accurate spectrum occupancy decisions with lesser sensing communication and energy overheads."
http://hdl.handle.net/1957/60616,"Whitebark pine (Pinus albicaulis) is an iconic North American high-elevation tree species currently threatened by climate change, mountain pine beetle, and white pine blister rust (WPBR), a lethal disease caused by the non-native fungal pathogen Cronartium ribicola. In collaboration with the USDA Forest Service Dorena Genetic Resource Center, germplasm was collected from whitebark pine trees throughout the Cascade Range in Oregon and Washington to evaluate the frequency and variation in genetic resistance among naturally occurring populations. Based on operational resistance screening trials, progeny of ‘Shadow Lake 39’ from Mt. Rainier National Park exhibited significant within-family variation in resistance and were the primary focus of bioinformatic investigation. In an effort to identify candidate genes associated with WPBR resistance, we designed an inoculation experiment to investigate differential gene expression in needle tissues that distinguished resistant from susceptible seedlings in this whitebark pine half-sibling family. Seedlings were distributed in a randomized complete block design and exposed to C. ribicola inoculum (~3000 spores cm²) for 24 hours in a fog chamber to initiate WPBR infection. Three days after inoculation, needle tissue was sampled and flash-frozen to preserve each individual's RNA expression profile. While half of the seedlings were inoculated with C. ribicola prior to needle sampling, the other half were inoculated after sampling, allowing us to capture the expression profiles of uninoculated seedlings. This sampling strategy permitted comparisons between both experimental treatments (inoculated vs. uninoculated), while still revealing the resistance phenotype of each individual tree seedling. Needle tissues from four representative seedlings were sequenced with RNA-Seq and used to assemble a reference transcriptome de novo. These assembled sequences were annotated with inferred transcript function, gene ontology terms, and predicted proteins to create an annotated reference transcriptome for P. albicaulis ‘Shadow Lake 39’ needle tissue. To identify candidate genes that are differentially expressed in association with WPBR resistance, individual libraries were generated for 24 representative seedlings and sequenced using RNA-Seq. This design allowed for group comparisons between uninoculated susceptible, uninoculated resistant, inoculated susceptible, and inoculated resistant trees. Comparative transcriptomic analyses produced a list of differentially expressed genes, which were curated to reveal the top candidate genes associated with blister rust resistance in whitebark pine. We identified a variety of differentially expressed genes with annotations related to the plant defense response to fungal diseases, including several encoding pathogenesis-related proteins, enzymes involved in the biosynthesis of secondary metabolic compounds, and a suite of other gene products putatively related to WPBR resistance. We also searched the P. albicaulis ‘Shadow Lake 39’ needle transcriptome for SSR and SNP variants and designed corresponding primer sequences for future investigations. Following validation, these markers may help to expedite and economize resistance breeding programs by enabling forest geneticists to screen individual whitebark pines for blister rust resistance. In summary, this exploratory survey of the P. albicaulis ‘Shadow Lake 39’ seed family has produced an annotated reference needle transcriptome, lists of differentially expressed candidate genes putatively associated with blister rust resistance, and primer sequences designed to validate potential markers, representing a significant contribution toward WPBR resistance breeding in whitebark pine."
http://hdl.handle.net/1957/60621,"Polyethylene terephthalate (PET) polymer has been the material of choice for packaging industry as a result of its excellent mechanical and physical properties. These properties are highly dependent on the microstructure, chemistry, and processing conditions of this material. PET is often oriented in the machine direction (MD), the transverse direction (TD) or both MD and TD, depending upon the resultant properties required. The orientation process causes polymer chain alignment and hence changes the original crystallinity, thermal properties, and lattice structure. In this work, differential scanning calorimetry (DSC) and X-ray diffraction (XRD) techniques were utilized to gain microstructure knowledge about the orientation of PET.PET is often copolymerized with different diacids or diols to produce desired film properties such as thermoforming, heat sealing, heat shrinking, solvent seaming, etc. In this work, PET copolymerized with neopentyl glycol (NPG) was investigated. These films can shrink about 75% in TD on appropriate heat treatment. Their ability to solvent seam with tetrahydofuran (THF) solvent make them an excellent material for shrink-sleeve bottle-label applications. The solvent induced crystallization of these copolymer films was also studied at different exposure times varying from 0 min to 40 min. Tensile tests of seals made from solvent exposed film samples indicated that increased crystallinity in the film significantly decreases the solvent seaming ability. Hence, the hypothesis was proposed that amorphous material provides better surface for solvent adsorption, which results into stronger solvent seams and better printability."
http://hdl.handle.net/1957/60829,"The proliferation of mobile users and internet content has advanced a plethora of research areas. Among these areas include mobile networks, transport layer protocols, and smart cities. Research shows that global mobile data traffic will increase sevenfold reaching 49 exabytes per month by 2021, most of which will be mobile video content, with a percentage projected to reach up to 78% by 2021. This resulted in efforts to integrate various wireless access technologies for improved performance, increased services and inter-connectivity of end users. The recent growth in data demand has prompted researchers to come up with new wireless techniques (e.g., MIMO, cooperative communication, femtocells, etc.) and develop new technologies (e.g., cognitive radio, LTE, etc.) to be able to meet this high demand. However, mobile user quality of experience (QoE) at the transport layer has largely been overlooked. As users become more mobile they are bound to encounter multiple wireless technologies and are thus equipped with multiple network interfaces. In addition, mobile users frequently experience handoffs when associating with wireless networks across a path. The contributions of this dissertation are threefold where our focus mainly encompasses timely delivery of internet content to mobile users through transport and physical layers and network infrastructure solutions. First, we investigate transport layer issues when mobile users encounter handoffs to and from fast and slow links. Specifically, cross-layer techniques are applied to the NewReno variant of the Transmission Control Protocol (TCP) to adapt to network conditions related to mobility. Our analysis shows that cross-layer modifications to TCP allows for less queuing delays, lower round-trip times, improved throughput and minimal packet jitter. Second, we investigate a promising transport protocol known as Multi-Path TCP (MPTCP) which allows for mobile devices to leverage a device's multiple network interfaces to maintain network connections even when endpoints of the connection change. This allows for connections to remain active during less than ideal scenarios when multiple Wi-Fi networks and cellular base stations are encountered across a mobile user's path. Default MPTCP congestion control protocols still experience service continuity issues when multiple networks are encountered across a path. A coupled, handoff-based cross-layer assisted, MPTCP congestion control algorithm and framework is proposed and designed to address these issues. Our system model monitors a device's received signal strength (RSS) in anticipation of a network handoff and congestion windows are proactively adjusted for a more seamless transition and experience for the end user. Lastly, the integration of the aforementioned wireless access technologies allows large geographic locations to be serviced providing millions of end users with continuous connectivity and optimal QoE. However, the world has seen unprecedented urban population growth over the years. By 2050, it is estimated that 70% of the world's population will be living in cities. Urban communication networks and content delivery networks have been introduced to leverage these technologies to better service cities and users alike. Content delivery networks are designed to improve overall network performance by bringing data closer to the geographical locations of users. However, traditional, regional content delivery nodes do not suffice for efficient and timely content delivery in large urban communication networks. We propose a fundamental shift to content-centric networks by consolidating these large urban communication networks with standalone edge cloud devices known as cloudlets and introducing geographically distributed content delivery cloudlets (CDC) which store popular Internet content. Advanced cooperative caching techniques are proposed, designed and employed at individual CDCs to push content closer to end users. Our proposed solutions are validated using, LinkNYC, a first-of-its-kind urban communications network aiming to replace all payphones in the five boroughs of New York City (NYC) with kiosk-like structures providing free super fast gigabit Wi-Fi to everyone. The amalgamation of urban population densities, multiple CDC placements and smarter caching techniques helps exploit the ultimate benefits of a content-centric urban communications network and dramatically improves overall network performance and responsiveness."
http://hdl.handle.net/1957/61477,"One of the recent additions to the panoply of engineered wood products is cross-laminated timber (CLT). CLT is a prefabricated, large-scale, solid wood panel that consists of multiple layers of lumbers stacked together, with each layer arranged perpendicular to the next layer, glued with structural grade adhesives, and pressed. The use of massive CLT panels in wood construction provides several advantages over the traditional wood frame systems, making it particularly attractive for tall wood building construction. These main advantages are satisfactory distribution of defects, adequate seismic performance, ability to carry large loads, improved strength and stiffness, adequate acceptable fire performance, acceptable acoustic performance, and improved pre-fabrication.It is expected that as the CLT market will continue to mature, more diversified grades and special CLT products will be introduced into the markets. One special CLT product developed in at Oregon State University has been designated as hybrid CLT. Hybrid CLT refers to CLT panels manufactured with layers of high- and low-grade and low-density species, which aims at improving the economic efficiency and sustainability of the CLT industry with focus on the North America market.One of the potential issues with hybrid CLT panel application is related to the unknown performance of the connection systems which are highly dependent on the density of the wood in which the fasteners embed. Most of the existing models that have been developed for estimation of the fasteners capacities in withdrawal and lateral loading scenarios are developed based on the assumption of uniform density profile across the layers to which fasteners penetrate. In a hybrid CLT panel, there is a possibility of a variation in density profile along the panel thickness so that the fasteners can be driven into wood of different densities and driven in directions parallel and perpendicular to grain. Because of the potential variation in density profile in the hybrid CLT, the connection system performance cannot be predicted using design models used for uniform density profile applications similar to the models in National Design Specification (NDS) [1]. Therefore, there is a need for evaluation of connections performance in hybrid layup.The main objective of this work is to characterize the performance of connection systems for hybrid CLT. This is achieved through testing and modeling of single fastener connections and then testing and modeling of the typical connection systems. So, the specific objectives are: (1) evaluate the single fasteners performance to account for density variation and compare the results to a proposed modified model, (2) perform an experimental program to test different connection systems with different hybrid CLT panel layups, (3) develop a numerical algorithm based on the use of meta-heuristics tools to fit the optimal parameters for constitutive models to match the experimental data for the connection systems, (4) obtain the optimal parameters for constitutive models of the connection systems tested."
http://hdl.handle.net/1957/61543,"Shock, Honey, is a collection of five stories that explore themes of illness, domesticity, religion, and the intersection between adulthood and childhood. The narratives examine societal gender norms, and are connected by the female point of view as experienced through various roles: mother, friend, girlfriend, and wife. Most of the stories take inspiration from places and landscapes in Oregon."
http://hdl.handle.net/1957/61550,"Symbioses are a spectrum of interactions between organisms living in closeassociation. These intimate interactions range from mutualism, in which bothorganisms benefit, to parasitism, where one organism benefits at the expense ofthe other. Horizontal gene transfer is the acquisition of genes independent ofvertical transmission and demonstrably promotes the transition of bacteria fromfree-living to symbiotic. The horizontal acquisition of plasmids allows members ofthe Agrobacterium and Rhodococcus genera to cause disease to plants, many ofwhich are important for the ornamental plant industry. Therefore, the accurate andrapid diagnosis of these pathogens is critical for management, and failure toproperly diagnose or respond can result in severe economic losses. Indeed, somediagnostic methods have the potential to be misleading and assign nonpathogenicRhodococcus as the causative agents of disease. I test the hypothesis thathorizontal gene transfer can elicit the transition of Rhodococcus between beneficialand pathogenic states.I demonstrate that most Rhodococcus isolates are beneficial and promotechanges to the root system, such as those that are frequently associated with plantgrowth promoting bacteria. I further demonstrate that beneficial Rhodococcusstrains transition to pathogens upon the acquisition of a virulence plasmid. Theseare virulent on plants and can cause disease symptoms to both roots and aerialportions of plants. Lastly, I develop reagents for use in a sensitive and specificnovel diagnostic test that accelerates identification of pathogenic strains ofRhodococcus and Agrobacterium. This work highlights the fluidity in the evolutionof plant-associated bacteria and how transitions in symbiotic state can confounddiagnosis."
http://hdl.handle.net/1957/61551,"Monitoring marine ambient sound using standardized methods supports assessments of ocean sound levels across widespread ecosystems. This thesis quantifies differences among coastal and deep-water marine soundscapes in the Atlantic and Pacific oceans. The sources of sound in a soundscape are compartmentalized into three components and compared over time and among different areas to give insight into the status of ocean ecosystems, revealing the presence of vocalizing animals, anthropogenic activity, and environmental changes such as weather (e.g., wind, rain) and ice coverage. Assessment of acoustic differences across discrete soundscapes supports the work of policy and planning leaders to address issues dealing with monitoring protected areas and marine species (marine mammals, fish), and the contribution of anthropogenic sources to ambient sound associated with energy production (oil exploration, renewable energy development) and socioeconomic activity (container shipping, commercial fisheries, and sport watercraft). These data also define a baseline to evaluate changes over time, including the presence of anthropogenic activities, and the efficacy of management approaches addressing both protected areas and species."
http://hdl.handle.net/1957/61552,"This thesis examines alternative modes and forms of production in texts by Willa Cather and Virginia Woolf. Applying queer methodologies drawn from the work of Michel Foucault, Eve Kosofsky Sedgwick, Lee Edelman, and Elizabeth Freeman, I show how Cather’s The Professor’s House and Woolf’s To the Lighthouse demonstrate and interrogate the intricate crossings and relations of time, space, sexuality, history, identity, and systems of regulation and power. I argue that, in doing so, these novels depict queer alternatives not only to heteronormativity, but also to capitalist notions of production as they shaped late nineteenth and early twentieth century U.S. and British culture and texts. These alternatives include performances, emotions, art, and even birth itself. In describing these forms of production, this thesis provides a nuanced analysis of the ways queerness and alterity are embedded within and utilized by heteronormativity and capitalism, as well as the ways certain forms of alterity can question conventional modes of thought and understanding."
http://hdl.handle.net/1957/61553,"There is growing evidence that humans and other animals can taste certain starch hydrolysis products, namely, maltooligosaccharides (MOS), and that their detection is independent of the known sweet receptor, T1R2 T1R3. The overall goal of this study was to further investigate the taste perception of low degree-of-polymerization (DP) MOS in humans. However, research in this area is limited, presumably due to a lack of MOS with specific, narrow DP profiles that are safe for human testing. In order to achieve the overall goal, a method was first developed to prepare specific groups of food-grade MOS (DP 3, 3-4, 5-6, and 6-7) by fractionating commercial mixtures of glucose oligomers and polymers. Psychophysical testing using the four prepared MOS stimuli in addition to glucose (DP 1) and maltose (DP 2) at the same concentration showed that all six stimuli were detected with similar discriminability in normal tasting conditions. In order to assess the potential role of T1R2 T1R3 in MOS taste detection, the stimuli were additionally prepared with lactisole, a sweet inhibitor. All stimuli in both lactisole treatments were prepared with acarbose to prevent oral digestion of glucosidic bonds by salivary α-amylase. Here, it was found that subjects could not detect DP 1, 2, or 3, but could still detect the MOS mixtures (DP 3-4, 5-6, and 6-7). Together, these results support the presence of a MOS taste perception mechanism independent of the T1R2 T1R3 taste receptor, and suggest it is stimulated by MOS greater than three units. After completing psychophysical testing, modifications to the MOS fractionation protocol were found to allow isolated MOS products from DP 3 to 7 to be collected. A second study thus presents the method to obtain these isolated products in a food-safe quality. Differential solubility using aqueous ethanol is first used to obtain a refined MOS preparation, which can then be further refined using column chromatography. A cellulose-based column in conjunction with aqueous ethanol mobile phases is used to separate the MOS preparation into linear, isolated MOS DP 3 to 7 in high purity. This fractionation method will not only be of high relevance to researchers interested in studying the physiological impacts of MOS consumption in humans, but will also be useful to future studies involving human taste perception of these saccharides."
http://hdl.handle.net/1957/61554,"Current technological shortcomings limit the economic viability of capturing and utilizing small sources of methane. The development of a reactor to overcome these limitations would unlock economic opportunity and incentivize reduced methane emissions. A microfluidic bioreactor containing immobilized methanotrophs has the potential to overcome these limitations by profitably converting small quantities of methane to more valuable liquid products.The material used for immobilizing bacteria in a microfluidic bioreactor must meet four criteria: biocompatibility, mechanical stability, reactor adhesion, and economic viability. This paper describes the development of a novel blend of agar and cross-linked polyvinyl alcohol (PVA) that meets these requirements. The properties of agar PVA blend hydrogels strongly depend on the ratio and absolute concentration of the constituent polymers, and the processes by which the polymers are cross-linked. The microscopic morphology of these blend hydrogels is theorized to be two interacting and competing phases formed by agar and PVA molecules mutually interfering with cross-linking via hydrogen bonding, and separating due to spinodal decomposition. Evidence for the proposed morphology is discussed.Blend hydrogels of 2 5% agar PVA are particularly promising, combining the desirable properties of both agar (low swelling) and PVA (strength and adhesion). The 2 5% agar PVA gels exhibited little swelling in water and nitrate mineral salts-based media. They also adhered to polycarbonate and stainless steel surfaces treated with ozone or oxygen plasma. Cultures of Methylomicrobium buryatense 5GB1 (5GB1) immobilized in these gels showed a reduction of metabolic activity rates, partly due to exposure to high concentrations of sulfate and phosphate during cross-linking. Shortening cross-linker exposure time from 2 hours to 30 minutes greatly improved activity rates, and immobilized cells exhibited increased activity rates over time as fresh methane was added. Based on these results, the 2 5% agar PVA blend hydrogels are suitable for the immobilization of 5GB1 in a microfluidic bioreactor. Further improvement of activity rates may be possible.Preservation of 5GB1 by lyophilization was unsuccessful. Cultures preserved in solutions of 5% bovine serum albumin and 10% sucrose or trehalose maintained metabolic activity rates after freezing at -80°C, but showed no activity after lyophilization."
http://hdl.handle.net/1957/61555,"The water status of grape vine throughout the growing season is a primary determinant of vine vigor and berry composition. The concentrations of volatile compounds and precursors in grape berries are highly influenced by viticultural practices. Imposing a water deficit on the vine during berry development is an important vineyard management strategy to alter grape and wine quality. Although much literature has reported the impact of vine water status on grape composition and volatile compounds, the results are still inconclusive due to the variations in irrigation regimes, cultivars and other agronomical conditions. The detailed chemical compound responsible for the flavor attribute differences need to be fully studied. Accordingly, this study was conducted to evaluate the impacts of regulated deficit irrigation (RDI) on the volatile composition of Malbec and Syrah grapes and wines.Malbec and Syrah grape chemical and volatile composition was investigated over three consecutive growing seasons (2014-2017) in established field trials located at the University of Idaho Parma Research and Extension Center in Parma, ID (lat: 43´78°N; long: 116´94°W; 750 m asl). Four irrigation regime (70 % ETc from fruit set to veraison, 35 % ETc from veraison to harvest (70 35), 70% ETc sustained from fruit set to harvest (70 70), 35 % ETc from fruit set to veraison, 70 % ETc from veraison to harvest (35 70), and 35% ETc sustained from fruit set to harvest (35 35)) was applied to the vines with two irritation frequencies (1x= one event per week, 3x=same irrigation amount apportioned into three irrigation events per week). Berry volatile compositions were analyzed by Solid Phase Micro Extraction-Gas Chromatography-Mass Spectrometry (SPME-GC-MS). Results showed that different irrigation frequency barely affected the volatiles in Malbec grapes but have greater influence on volatile composition of Syrah grape. ETc variation before veraison and after veraison influenced C13-norisoprenoids precursor content in Malbec and Syrah berries. 70% ETc before veraison contributed to higher bound-form trans-β-damascenone concentration in Malbec berries, while both 35% ETc before and after veraison resulted in a higher bound-form TDN and vitispirane concentration in Syrah berries. In this study, the YAN (yeast assimilable nitrogen) showed a correlation with irrigation amount in 2015’s and 2016’s Syrah grapes and 2016’s Malbec grape berries. The 70 70 irrigation amount resulted in a relatively lower YAN concentration in grape must of 2016’s Malbec and 2015 and 2016’s Syrah. Wines were made with experimental grape samples, and wine compositions were analyzed using GC-FID, GC-PFPD and GC-MS. Results showed that wine volatile compositions of both Malbec and Syrah were affected by irrigation amounts, but barely affected by irrigation frequency. The terpenoid concentrations in wine were more related with the bound-form terpenes in grapes rather than free form terpenes. Irrigation frequency and amount showed no influences on either free form or bound form C13-norisoprenoids in Syrah wines, but bound form TDN and vitispirane concentrations in Malbec wines were affected by irrigation amount. The esters, higher alcohols and fatty acids content in wines were closely related with the YAN levels in grape must before fermentation. The lower YAN concentration led to a higher ethyl acetate and lower Phenylethyl alcohol, isobutyl alcohol and isoamyl alcohol concentrations in corresponding wines. The YAN level in grape juice was affected by water status of the grape vine, while the YAN level can be associated with aroma-active compounds in wine. Thus, imposing water deficit to the grape vine can alter the volatile composition of the final wine."
http://hdl.handle.net/1957/61556,"Deburring of machined parts is a crucial task in the aerospace and automotive industry. This process is still performed manually to a large extent due to the unpredictability of burr formation as well as the complex interactions between the human arm and the workpiece. Poor ergonomics, repetitive stress and strain injuries for the human operators, as well as high cost are all reasons to automate this process. In this work, we  first study how skilled operators perform deburring, which is a hybrid force and position control task, by using a motion capture system, force sensor and an IMU to record and recreate the process. Next, we explore the interaction dynamics and explain the importance of the dynamic characteristics of a spring-mass system to successfully deburr an edge. We come up with control strategies that allow a backdrivable robot to accomplish the same task using a hybrid controller made up of a sliding mode controller and a proportional controller acting in parallel."
http://hdl.handle.net/1957/61557,"Model Predictive Control (MPC) has previously been investigated on ocean waveenergy converters (WEC) to improve the amount of power captured, while respectingthe system constraints. Previous research done in the same area, focused onbuilding a control scheme by using the knowledge of the past & current statesof the system and predicting the future states of the system based on which thecontrol action was taken for the power-take-o  (PTO) to maximize power capture.This was done by maximizing the product of force and velocity and at the sametime, staying under the permissible limits of both force and velocity (constraints).Our research attempts investigate if an integrated approach for power maximizationis possible by trying to modify the way power maximization is done. Thisis made possible by integrating a state-space generator model with a state-spaceWEC model. This combined generator-WEC model is then used with an MPCcontroller. So rather than having PTO-force as the input for the wave energy converter,dq reference frame voltages are used as inputs and the product of voltagesand currents for the d and q axes (i.e. the electrical power) is maximized."
http://hdl.handle.net/1957/61558,"This thesis examines the bilingual poetry of indigenous, Mexican poet Irma Pineda Santiago. In her work, she composes mirrored poems in Isthmus Zapotec and Spanish. I analyze the ways in which her work brings Zapotec and Spanish into contact with one another, demanding that readers acknowledge narratives of erasure that denigrate indigenous language, voice, and cultural expression. In the thesis, I argue that Pineda Santiago’s work can be described as a “bleeding assemblage” or a network of permeable relations. Through this model, I theorize that the work occupies, redefines, and expands a host of contact zones. I further conceptualize Pineda Santiago as a poet-translator, such that her poetry offers an alternative model of relationality that is transcontextual, transnational, translingual, and transformative. I propose that her work demonstrates the powerful ability of language and poetry to cross, blur, and deconstruct a binary notion of borders and turn such divides into contact zones where both connection and division, similarity and difference, pain and joy might co-exist. Through this thesis, I propose that Pineda Santiago’s poetry demonstrates a new form of relationality that rewrites cultural mythologies of violence and erasure."
http://hdl.handle.net/1957/61559,"As the future electrical power systems tend towards smarter and greener technology, thedeployment of self-sufficient networks, or microgrids, becomes more likely. Microgridsmay operate on their own or synchronized with the main grid, thus control methodsneed to take into account islanding and reconnecting said networks. Isolation of subnetworks may be necessary to protect either the main grid or the subnetworks themselves.With the ever growing concern of cyber-attacks on power systems, the ability to isolatenetwork locations potentially targeted by adversaries, or exhibiting signs of cascadingfailures, is necessary. It is possible to create unique attacks that may leverage networkoperating points to maximize damage to the main grid even when the attack is confinedto a microgrid. Upon isolation of a subnetwork, a control technique must be used tosafely reconnect it to the main grid. The ability to optimally and safely reconnect aportion of the grid is not well understood and, as of now, limited to raw synchronizationbetween interconnection points. A support vector machine (SVM) leveraging real-timedata from phasor measurement units (PMUs) is proposed to predict in real time whetherthe reconnection of a sub-network to the main grid would lead to stability or instability. A dynamics simulator fed with pre-acquired system parameters is used to createtraining data for the SVM in various operating states. The classifier was tested on avariety of cases and operating points to ensure diversity. Accuracies of approximately85% were observed throughout most conditions when making dynamic predictions of agiven network."
http://hdl.handle.net/1957/61560,"In her 2016 article “Beyond Rights as Recognition, Black Twitter and Posthuman Coalitional Possibilities,” Pritha Prasad argues that the hashtag, one of the decade’s most omnipresent features of digital communication, functions as “a performative composing medium that not only demands relationality” and “call[s] for the recognition of both the Black body and human beyond humanist, economic, and juridical frameworks” (56). Though work like Prasad’s is timely and insightful, my own project examines the racist and inimical, rather than humanist and embodied, qualities of digital spaces that circulate images of the black body. From the violation of Kara Walker’s sculpture A Subtlety on Instagram to the proliferation of a racist meme called “Trayvoning,” my paper suggests that by flattening the contexts and histories of black death, supposedly “disembodied” forms of digital media more often serve to enact and reenact forms of violence against the black body. This phenomenon recalls the history of similar circulations in American history, from lynching postcards shared as “souvenirs’ in the 19th century to the release of torture images in America’s Abu Ghraib prison complex. Using these racist images as its stable context, my project employs Claudia Rankine’s mixed-media compilation of images and poems, Citizen: An American Lyric, to argue that the artistic practice of reassembling historically-contingent media has the critical function of intervening in the rapid and inescapable spectacularization and circulation of black death. With her attention to obfuscating assemblages--in both her own text and in her use of the opaque visual art--Claudia Rankine effectively challenges the powerful “mastering” gaze of the digital age without removing the context or corporeality of racist violence."
http://hdl.handle.net/1957/61561,"This project examines two understudied female characters from Geoffrey Chaucer’s Canterbury Tales who emerge as subversive figures by striving to maintain control over their bodies and being. Through my analyses of the Knight’s and Second Nun’s Tales, I reveal how virginity correlates with bodily autonomy for the narratives’ respective protagonists, Emelye and Cecilia. I discuss how the personal sovereignty their virginal condition affords them becomes not only problematic in terms of the heteronormative ideology that grounds patriarchal values but also inherently threatening to the stability of masculine power. Specifically, this project investigates the correlation between virginity and bodily autonomy for these female protagonists, as well as how they exercise agency to the extent that their individual circumstances allow. Employing Sara Ahmed’s Willful Subjects as a theoretical framework, I demonstrate how Emelye and Cecilia emerge as trans-historically “willful” women worthy of additional attention in scholarly conversation, at the same time that their nuanced characterization recommends modifications for our analytical approach to gender and relationships in the Canterbury Tales. While this project demonstrates how sexual control of women’s bodies was, in the Middle Ages – as it continues to be today – a central feature of masculine power structures, it also reveals a lineage of willful behavior by women that has afforded them agency when they would otherwise have none."
http://hdl.handle.net/1957/61562,"This collection traces the evolution of family, specifically the relationship between a father and daughter, beginning with the speaker as a child mirroring the father and ending with the father’s death. The poems make use of extended metaphors with comparisons to the Berlin Wall and redwood trees, processes of creation by circular or destructive means. The collection also concerns itself with the vitality of life, the decay of a body, and the cycles of time."
http://hdl.handle.net/1957/61563,"The following pages represent the first six chapters of a novel-in-progress, tentatively titled, The Clearest Way into the Universe. The novel is a dystopian narrative set in a post-plague America. The story follows two sisters on opposite coasts who attempt to reunite."
http://hdl.handle.net/1957/61564,"The LGBTQ population is widely recognized as an at-risk demographic—as a result ofstigma, studies report sexual and gender minorities experience elevated risk for depression,suicide, anxiety, and substance abuse, as well as greater exposure to sexual, physical, andinterpersonal violence (Logie 1244). Asexuality, a marginalized population traditionallyexcluded from the LGBTQ acronym, poses a unique set of challenges to existing health carepolicies and procedures. As neither queer nor asexual literature have adequately attended to suchchallenges, this study aims to address present limitations through two key inquiries: (1) How doace individuals approach and navigate discussions about their health and wellness with healthcare providers? and (2) What is the relationship between asexual identity and the ways oneaccesses health care? To critically engage with the research questions, this thesis employs adiscourse analysis of pre-existing public forum and blog posts collected from online asexualcommunity spaces which include narratives that allude to the impact of the naturalization ofsexuality, the medicalization of asexuality, and the conflation of libido with sexual attraction onaccess to health and wellness. Analysis of the collected data centers on the pathologization ofqueerness, existing wellness support networks, and perhaps most importantly, access to andcomfortability with current health care models."
http://hdl.handle.net/1957/61565,"Inadequate access to clean water is an ongoing problem in many developing areas of the world. In developed nations, it is important to plan for access to clean water following natural disasters. In situations without reliable access to electricity and chemical treatment methods, there is a need for an inexpensive water treatment solution that can be used in a wide range of environmental conditions. The Puralytics SolarBag aims to meet these needs by providing a product that can purify water through the use of solar activated nanotechnology. The SolarBag contains a titanium dioxide nanoparticle laced mesh that reacts under sunlight to help inactivate potential microbial contaminants. This work aims to evaluate the effectiveness of the SolarBag and a new prototype, the SolarBag Plus, to treat 3L of surface water in 3 hours of exposure to sunlight. Tests were conducted using two synthetic test waters, a general test water and a challenge test water, which contained higher levels of salts, humic acids, and higher turbidity. To evaluate inactivation of microbial contaminants, synthetic test waters included representative bacteria (Escherichia coli), viruses (bacteriophages MS2 and ΦΧ174) and protozoa (Cryptosporidium parvum). This work additionally aimed to characterize the contributions of various photochemical and thermal processes to the overall treatment of the water. The results from this study indicate that E. coli is primarily inactivated by UV photoinactivation and suggest that inactivation is greatly increased at temperatures above 45˚C. Bacteriophage MS2 appears resistant to treatment by solar irradiation, but shows consistent removal under different environmental conditions. It is hypothesized that this removal is the result of the synergistic treatment by heat and light or a physical removal process like adsorption. Bacteriophage ΦΧ174 is inactivated by a combination of UV light and heat. Finally, C. parvum removal was generally low in the SolarBag under all conditions. Physical removal by filtration contributed to the greatest removal of oocysts in the treatment process, though improvement in inactivation was noted with higher UV intensity. The addition of ClO2 to the water treatment process removed all detectable microorganisms within 2 hours. Some data suggests that the use of ClO2 enhances the activity TiO2, but it was determined that chemical disinfection was the predominant mechanisms of disinfection when present."
http://hdl.handle.net/1957/61571,"Background. Many studies addressing the reasons why minority students fail in higher education are based on what is defined as a deficit model. A deficit model documents that a significant number of minority students fail because their culture is distinct from that of the majority population. Numerous minority students do not possess the means or knowledge to navigate the US system of higher education. Increasingly, more Latino a students are enrolling in higher education and policymakers and accreditation agencies are requiring that colleges focus on retaining these students and ensuring they complete their degreeBased on critical race theory (CRT), Yosso (2005) proposed and later developed the community cultural wealth (CCW) theory, which indicates that Latino communities share acultural capital that consists of elements of “wealth” that a student possesses. Yosso (2005) identified six forms of capital: aspirational, familial, social, navigational, resistant, and linguistic.Purpose. The purpose of the study was to examine if it is possible to identify those cultural capitals influencing or empowering Latino student retention. This study sought to identify and analyze those factors known as cultural capitals associated with retaining Latino students. The study addressed the following research questions: (a) In terms of potential cultural influences, what do Latino students identify as a cultural component of their retention at community college? and (b) To what extent do the cultural factors that Latino students identify as important to their retention show similarities to the cultural capitals as defined by Yosso?Setting. Interviews took place at two rural community colleges in Oregon which contained the minority student demographic studied.Subjects. The study used a homogenous sampling of subjects who self-identified as Latino a and were required to meet three criteria outlined below. Subjects were full time students holding good academic standing as defined by the host institution, had completed at least three terms of continuous enrollment at the institution and be a member of a club that served minority populations.Research design. The study used semi-structured individual interviews with Latino a students at two rural community colleges in Oregon. The use of a qualitative interview was designed to examine the role of CCW in the retention of Latino a students at these colleges. A phenomenological study was selected to identify particular accounts and to analyze the phenomena, which in this instance was intrinsic in form, as the researcher sought to understand the role of CCW.Data collection and analysis. Using semi-structured interviews, interview data were subjected to a six-step analysis that used the theoretical framework of CCW as a lens to interpret the data. Comparing the literature with the findings provided a way to ensure the findings reliability, as well as search for potential new themes that might emerge. In addition, part of the individual interview process included member-checking using narrative accuracy to reflect and summarize the participants’ interviews. Triangulation was adopted through the use of interviews and field notes with both the test participants and the actual respondent participants.Findings and implications. The findings indicate that the cultural factors the participants identified are very similar, and in many cases, identical to the capitals Yosso identified. While the capitals found in CCW aid retention, they also included deficits within the capitals. These deficits exist as barriers to Latino a students’ success. These deficits are not to be confused with the deficit model, but rather constitute structural insufficiencies within the capitals that act as barriers to minority students.The findings of this study hold significance for community colleges that wish to increase their retention of Latino a students. In accessing and understanding the role of CCW in the retention of these students, colleges cannot only leverage the capitals that students bring with them, but also design better programs that use those capitals in the classroom and in college administration. In addition, colleges can increase Latino a students’ success by addressing specific structural barriers that impedes their success.Conclusions. The findings revealed that Latino culture is instrumental in retention at community college, in that all of Yosso’s (2005) cultural capitals were identified through this process. The findings did not identify additional cultural capitals or themes other than thoseYosso identified previously. However, it demonstrated that there are deficits in those capitals that potentially could reduce their efficacy."
http://hdl.handle.net/1957/61572,"During the Last Glacial Maximum (LGM, ∼ 21 ky before present) the atmospheric CO2 concentration was about 100 ppm lower than its pre-industrial (PI)value. The missing carbon from the atmosphere must have been stored in thedeep ocean during this period, but the mechanisms driving such re-distribution ofthe carbon cycle are still uncertain. LGM-PI changes in circulation, stratification,and or biogeochemistry have been suggested to enhance ocean carbon storage, butquantitative, three-dimensional, data-constrained estimates of these effects remainscarce.The most recent simulations from the Paleoclimate Model IntercomparisonProject 3 (PMIP3) predict an increase and deepening of the LGM Atlantic Meridional Overturning Circulation (AMOC) with respect to PI simulations, althoughthis is inconsistent with the interpretation of most sedimentary proxy data attributed to this period. The goal of this dissertation is to use an ocean model toconstrain the LGM global ocean circulation and biogeochemistry, and asses theireffects on the carbon cycle.We use a three dimensional global circulation model, coupled with a biogeochemical model that includes the interactive cycles of radiocarbon (14 C),15N and 13C. The inclusion of these three isotopes provides a powerful tool to constrainthe possible LGM scenarios, since model results can be directly compared to measurements of the same isotopes from the sediment records. Our physical LGMmodel set up includes changes in atmospheric CO2 , continental ice sheets, orbitalparameters and circulation.By varying meridional moisture transport of the model’s atmospheric component, we produce LGM circulations with different AMOC strengths and depths,from a collapsed state, to a strong state similar to PMIP3 models. We find that aweak (6 − 9 Sv) and shallow AMOC underlaid by a more voluminous and carbonrich Antarctic Bottom Water (AABW) best reproduces glacial δ 13 C and radiocarbon ages from sedimentary data. This configuration of water masses also maximizes the amount of remineralized organic carbon stored in deep waters. Wepropose that increased wind stress over the North Atlantic stabilizes the weakAMOC and prevents it from collapsing.We also evaluate effects of PI-to-LGM changes in atmospheric dust, sedimentary, and hydrothermal fluxes on the ocean’s iron and carbon cycles. We find thatiron fertilization caused by enhanced dust deposition in the LGM is strongly countered by a decrease in sedimentary flux due to 125 m lower sea level, which tendsto decrease primary productivity. In an upper-limit estimation of Southern Oceanatmospheric iron fertilization, assuming an increase in soluble iron deposition ofthe order of ∼ 10 − 20 times its PI value for this region, combined with changes insedimentary flux, we obtain higher export production and enhanced accumulationof remineralized organic carbon in deep waters, which would lead to atmosphericcarbon sequestration. This bigeochemical state also improves the agreement withδ 13 C and δ 15 N reconstructions from the LGM.The combined results suggest that a weak and shallow AMOC and enhancediron fertilization conspired to maximize carbon storage in the glacial ocean, andproduce part of the glacial-interglacial variations in atmospheric CO2 concentrations."
http://hdl.handle.net/1957/61573,"The perception that there exists a lack of leadership can be found throughout history. Currently, according to Robert Putnam, there does appear to be a decline is social capital. This research examines the connection between business leadership style and effects on social capital. Most research on corporate social responsibility focuses on the business entity. This research focuses servant leadership developed by Robert Greenleaf, and how that leadership style may affect social capital. Articulation, a method described by Stuart Hall, is utilized to analyze Greenleaf’s original essay to identify the speakers, the practices used to link the various speakers together and their overall effects. This research finds that there are multiple speakers in servant leadership, many of which are located outside of the business organization. There are four principle practices that link the speakers together: leadership style, service, community, and how power is exercised. The result is necessarily a business that builds social capital both internally and externally, serves the highest needs of its followers while also contemplating the impacts on speakers outside of the organization, including the least privileged among us. This research also argues that the measurement of a servant leader organization will be through elements of service and not purely economic dimensions."
http://hdl.handle.net/1957/61574,"This dissertation uses manipulative experiments to explore amphibian-Bd infection dynamics. Although there has been almost two decades research since the discovery of Bd, many questions still remain regarding what conditions mediate chytridiomycosis virulence. My research shows how certain host and pathogen factors can influence disease virulence. Identifying how host and pathogen factors mediate disease virulence is important in order to understand, predict, and mitigate this infectious amphibian disease. 	Worldwide biodiversity loss is occurring at unprecedented rates. Numerous factors are contributing to this loss, including infectious disease. Among vertebrate groups, amphibians are experiencing the highest rate of population declines and   extinctions and are vulnerable to numerous infectious pathogens that appear to be contributing to amphibian biodiversity loss. A widespread infectious chytrid fungus, Batrachochytrium dendrobatidis (Bd), causing the disease, chytridiomycosis, is implicated in numerous amphibian population declines and extinctions and can induce sublethal effects within individuals. My dissertation research examines host-pathogen factors that mediate infection outcomes in the amphibian-Bd system. 	The severity of an infectious disease is the result of specific host-pathogen interactions. Thus, there may be large variation in disease outcome depending on host and pathogen related factors. In Chapter 2, I conducted a comparative experimental   study in larval amphibians using multiple host species and Bd strains. I showed that host species varied in Bd susceptibility but that susceptibility was also contingent on Bd strain type. Thus, I showed chytridiomycosis virulence depended upon host and pathogen traits and that a sensitive host species could be robust to certain pathogen strains. 	In Chapter 3, I experimentally investigated multiple pathogen interactions with amphibian three amphibian host species to examine how Bd infection dynamics might change under simultaneous coinfection with a common water mold, Saprolegnia ferax (Sf). Coinfecting pathogens might interact within a host in a synergistic and antagonistic manner. In two host species, Bd infection intensity was slightly higher in hosts that were exposed to both Bd and Sf compared to just Bd alone indicating a small synergistic interaction with Sf. However, the differences were not significant in either host species. Survival differences were only detected in one host species; hosts exposed to Bd only experienced lower survival than those in the coinfected group. Additionally, I found host weight and days survived were predictive of Bd infection level for some hosts species showing species variation in infection response. 	Lastly, in Chapter 4, I experimentally examined age-dependent differences in Bd infection heterogeneity in two host species. I followed this with another experiment to test whether age-dependent differences in infection intensity of these hosts (‘donors’) influenced subsequent Bd transmission to a naïve conspecific host (‘recipients’). I found Bd infection intensity differences among juvenile and adult donors of both species. However, trend directions were not consistent; in one host species, adults had significantly higher infection levels than juveniles while the opposite was true in the second host species. Regardless of donor infection intensity, recipients had comparable infection levels within each host species. Survival also differed among host species and age groups suggesting Bd susceptibility may change with age and is species specific."
http://hdl.handle.net/1957/61575,"This research was aimed at providing the foundation for changing standards of care in a critical care setting using Catholic concepts of respect for human dignity, subsidiarity, common good, and solidarity as a matter of social justice. I first unpacked the nature of ICU care and the inevitability of the rationing of scarce medical resources. I presented data to support the theory that end-of-life care varies by region and that there is something unique in end-of-life care in the state of Oregon. I used the work of Margaret Mohrmann to detail the presence of social determinants in allocation decisions. To gain further insight into the literature regarding allocation of health care resources I examined the parable of The Good Samaritan as unpacked by Allen Verhey and “Who Shall Live When Not All Can Live” by James Childress. I also relied heavily upon the anthology Allocating Scarce Medical Resources: Roman Catholic Perspectives edited by H. Tristram Engelhrdt Jr. and Mark J. Cherry to reflect upon the issues of a purely secular debate of allocation of medical resources. I introduced the concept of moral luck as revealed through the work of Richard Miller and Thomas Nagel as an antecedent condition to allocation decisions. Finally I conclude with the work of John Coleman, Megan Clark and Pope Francis to re-imagine solidarity in contrast to the individualism that supports the ideology of the current healthcare system and state my case for regional change in end-of-life standards of care."
http://hdl.handle.net/1957/61576,"Automatic event extraction from natural text is an important and challenging task for natural language understanding. Traditional event detection methods heavily rely on manually engineered rich features. Recent deep learning approaches alleviate this problem by automatic feature engineering. But such efforts, like tradition methods, have so far only focused on single-token event mentions, whereas in practice events can also be described with a phrase. In this thesis, we introduce and apply forward-backward recurrent neural networks (FBRNNs) to detect events that can be either words or phrases. Experimental results demonstrate that FBRNN is competitive with the state-of-the-art methods on the ACE 2005 and the Rich ERE 2015 event detection tasks."
http://hdl.handle.net/1957/61577,"Due to a general reduction in pavement program funding levels over the past decade, the current budget is not sufficient to maintain roadways at a high level of service with acceptable roughness levels. Rough roadways with poor ride quality increase drivers’ vehicle operating costs (fuel consumption, vehicle maintenance, and tire-wear) and affect road-users’ safety. Therefore, current pavement program budget should be more efficiently allocated to road maintenance and rehabilitation. In addition, incorporating high reclaimed asphalt pavement (RAP) into pavement resurfacings reduces the pavement life cycle costs, preserves raw materials, benefits the environment, and provides more money for pavement maintenance programs.The goal of this study is to develop a network-level decision-making tool to select the most efficient pavement maintenance and rehabilitation strategies to minimize agency and user costs and maximize their benefits. This study also evaluates the effects of different trigger roughness levels, at which the maintenance should be applied, and different treatment methods (1. considering one value for trigger roughness value for all the sections regardless of the traffic levels, and 2. considering different trigger roughness values for sections based on their traffic levels) on user benefits and agency costs. Moreover, to increase RAP content in asphalt mixtures and preserve the long-term durability of the finished asphalt concrete containing RAP, methods of increasingRAP content (1. Using a softer binder and 2. using high binder content) in asphalt mixtures are investigated.Results show that available budget level controls the optimal trigger roughness values. Using a lower value for trigger roughness requires a higher budget level and increases user benefits. In addition, this study found that considering one value for trigger roughness for all the sections regardless of their traffic levels is more optimal than considering different values for trigger roughness based on the traffic levels. This study also shows that by using softer binders and higher binder contents, it is possible to increase RAP content in asphalt mixtures without sacrificing performance. In this study, possible combinations of RAP contents, binder contents, and binder grades to achieve acceptable cracking and rutting performance for asphalt mixtures are also suggested."
http://hdl.handle.net/1957/61578,"A common problem in energy allocation problems is managing the trade-off between selling surplus energy to maximize short term revenue, versus holding surplus energy to hedge against future shortfalls. For energy allocation problems, this surplus represents resource flexibility and is quantified as the surplus energy after meeting the demand. The decision maker has an option to sell or hold the flexibility for future use. As a decision in the current period can affect future decisions significantly, future risk evaluation of negative shocks (or uncertainties) is recommended for the current decision in which a traditional robust optimization is not efficient. Therefore, an approach to Flexible-Robust Optimization has been formulated by integrating a Real Options Model with the Robust Optimization framework. Real options analysis is an efficient economic model for risk evaluation in investment problems. In the energy problem, the real options model evaluates the future risk, and provides the value of holding flexibility, whereas the robust optimization quantifies uncertainty and provide a robust solution (i.e. a solution which is generally insensitive to uncertainties) of net revenue by selling flexibility. This integration or models has introduced compatibility issues which have been discussed extensively in the literature. However, the limitations have been overcome successfully by implementing bi-level programming in this work. Therefore, a complete general mathematical formulation of Bi-Level Flexible-Robust Optimization model is presented and results shown to provide an efficient decision making process in energy sectors."
http://hdl.handle.net/1957/61579,"The practice of green infrastructure is synonymous with collaborative partnerships. Expertise from engineers, land care professionals, planners, and natural resource consultants are often required for successful project implementation. Traditionally, these professionals perform their responsibilities in their disciplinary “silos,” but this evolving area of sustainable development is creating a demand for professionals who can think analytically and work across disciplinary boundaries. Interdisciplinary Continuing Professional Education (CPE) trainings provide opportunities for professionals to learn alongside one another, conversing and negotiating new knowledge about emerging practices. This study applies a qualitative approach to gain insight into the motivations, instructional design processes and evaluation mechanisms utilized for interdisciplinary green infrastructure CPE trainings. A variety of green infrastructure CPE providers in the Pacific Northwest United States participated in the study, offering perspectives from agencies, nonprofits, consulting firms and academic institutions. Qualitative software was used to code patterns and themes; and a content analysis on survey evaluation tools was completed. Findings suggest that provider organizations aim to increase worker competency and advance the field of green infrastructure by designing trainings that facilitate communication skills, enhance networking opportunities and exploit social learning activities. These three priorities are supported by the literature and appropriately foster communal environments shown to support the diffusion of innovative technologies. While training evaluation was found to lean heavily on standardized formal survey evaluation tools, several other informal evaluation approaches were found. A discussion of successful instructional design strategies for interdisciplinary audiences are presented for CPE provider organizations to adopt for future green infrastructure-related trainings."
http://hdl.handle.net/1957/61581,"Collaboration is tricky, but often beneficial in the context of numerous software related activities, from learning core concepts, to the design and implementation of large software products. The growth of online classes, from small structured seminars to massive open online courses (MOOCs), and the isolation and impoverished learning experience some students report in these, points to an urgent need for tools that support remote pair programming in a distributed educational setting. In “the real world” software developers and designers work together to solve common problems, and meaningful and effective designer-developer collaboration improves the user experience. Supporting these with today’s often distributed work model presents important challenges.Two key techniques which are believed to be effective in promoting better coordination and collaboration are collaborative coding and live programming. Collaborative coding allows all the team members to get involved in the development process, and live programming enables them to see what they are building effortlessly and in real time.In this work, we first describe Jimbo, an integrated development environment (IDE) based on collaborative and live programming techniques, and a set of user studies aimed at evaluating whether these techniques are effective in promoting better coordination and collaboration in two different settings; distance learning and design-focused software development. Our results show that these techniques can improve the learning experience through pair programming and a tight code-artifact feedback loop. We will show how collaborative coding and live programming can help designers and developers bridge their knowledge and language gaps and develop mutual understanding, allowing designers to join the development process as first-class citizens – not dependent on the coders to compile and share output – or being forced to become coders."
http://hdl.handle.net/1957/61582,"Cell-cell communication in bacteria is understood to facilitate the coordination of population-wide cooperative behavior in the form of concerted gene expression. The opportunistic pathogen Pseudomonas aeruginosa uses such a communication mechanism to regulate a large group of genes important to virulence strategies in this bacterium. This general mechanism of communication is termed quorum sensing (QS) and restricts activation of target genes to high cell density when cooperation is beneficial. QS in P. aeruginosa, like many Gram-negative Proteobacteria, is mediated through the synthesis of diffusible N-acyl-homoserine lactone (AHL) signals by LuxI-type synthases, and recognition by LuxR-type receptors that function as transcriptional regulators. P. aeruginosa harbors two complete AHL QS synthase receptor pairs termed LasI R and RhlI R. Here we use P. aeruginosa QS as a model system to investigate mechanisms that help maintain cooperative, QS-dependent secretion in the face of non-cooperating cheater mutants, and that define the cell density threshold that triggers the activation of QS target gene expression.We begin with analysis of an in vitro evolution system in which P. aeruginosa must express QS-controlled extracellular proteases in order to grow. In this system, QS-deficient cheater mutants evolve over time. They take advantage of protease production by the QS-proficient wild-type. Curiously, QS-deficient cheaters onlyreach a frequency of about 25% during the duration of the experiment. They do not enrich to levels that would cause a collapse of the population, generally referred to as a “tragedy of the commons”. Genomic sequence analysis revealed a previously unknown mutation in this system in the transcriptional regulator PsdR. Mutations in the gene coding for PsdR derepress growth rate limiting nutrient uptake and metabolism, a non-social adaptation. Combining mutational analysis with phenotypic assays and measurements of relative fitness, we show that rapid fixation of PsdR mutation in evolving populations serves to preserve cooperation and prevent a tragedy of the commons.Next, we focus on the mechanisms that determine the threshold of QS induction in P. aeruginosa. We constructed a set of isogenic mutant strains deficient in one, two, or three anti-activator proteins that serve to delay QS activation: QteE, QscR, and QslA. While these anti-activator proteins are understood to bind LasR and RhlR QS receptors, it is yet unclear why multiple anti-activators are needed, and how they work in concert to achieve the QS threshold. Using phenotypic assays, QS gene activation kinetics, and transcriptomic profiling, we found additive effects in the deletion of multiple anti-activator genes with largely overlapping sets of anti-activator-affected genes. Progressive deletion of anti-activators advances the induction threshold and increases expression levels. Our results suggest some anti-activators may even co-associate with R-proteins in exerting their effect.Together, these studies contribute new mechanistic understanding of how P. aeruginosa uses QS to coordinate cooperative behaviors to specific conditions, and how this cooperative communication system may be safeguarded against social exploitation."
http://hdl.handle.net/1957/61583,"Human alterations of landscapes take many forms, one of which is anthropogenic pollution. Mercury (Hg) is a complex contaminant because its uptake into the food web is not driven entirely by loading to the system; methylation is necessary to make Hg bioavailable and toxic to fish and wildlife. Because methylation takes place primarily in aquatic systems, research has historically focused on local Hg exposure in fish and fish-eating taxa (including the human health implications of eating exposed fish). As our understanding of Hg movement out of the aquatic and piscivorous food web advances, we must shift focus to other potential recipients and spatial scales. This dissertation seeks to understand how Hg moves through food webs with avian endmembers, both with traditionally-studied piscivores at novel spatial scales and novel endmembers (riparian songbirds in western North America) at more traditional spatial scales. Moving from broad to narrow, I consider Hg exposure across continental (Chapter 2), regional (Chapter 3), and local scales (Chapter 4). At the largest scale, in Chapter 2, I used fish Hg concentrations compiled across western North America at a 1 degree-by-1 degree grid cell resolution. Fish Hg concentrations were size corrected to reflect the primary prey base for a suite of five avian piscivores commonly used in Hg ecotoxicological studies: Bald Eagle, Osprey, Loons (Common and Yellow-billed), Grebes (Clark’s and Western) and Belted Kingfisher. At a continental scale, I identified taxa and regions of increased potential Hg risk to avian endmembers. Avian piscivores foraging on larger-sized fish generally were at higher relative risk to Hg. Habitats with relatively high risk included wetland complexes (e.g., prairie potholes in Saskatchewan), river deltas (e.g., San Francisco Bay, Puget Sound, Columbia River), and arid lands (Great Basin and central Arizona).  Chapter 3 focuses on one river basin in particular – the Willamette Valley in western Oregon. Mercury in fish and Osprey have been previously studied in this region; this study characterized differences in aquatic invertebrate and riparian songbird Hg exposure, starting at the headwater area which contains a point source of Hg from a historic Hg mine, moving downstream to a reservoir known to methylate Hg, and including all subsequent downstream reaches. While Hg exposure was highest in songbirds near the Black Butte Hg Mine, Hg concentrations were also elevated at the Cottage Grove Reservoir and several wetland complexes within the valley, reinforcing the importance of habitat on Hg methylation rates. Within the main stem Willamette River, birds in backwater areas had higher Hg concentrations than birds in main channel areas. Chapter 4 examines why individual songbirds and different species of songbirds can vary dramatically in their Hg exposure. I sampled 11 sites within the main stem Willamette River and found that both aquatic invertebrates and riparian songbird Hg concentrations were higher in backwater habitats than main channel habitats, even over relatively small distances. After sampling both aquatic and terrestrial invertebrates, I used a two end member mixing model for δ13C to determine the proportion of aquatic prey in the diet of composited riparian spiders and individual riparian songbirds. Birds sampled early in the season exhibited higher reliance on aquatic prey than those sampled later in the season and also had correspondingly higher blood Hg concentrations. Taken together, the findings of this dissertation show that, for many avian species, Hg exposure is mitigated by what, when, where, and how they eat. What birds eat is driven both by taxonomic and behavioral differences (piscivores versus insectivores vs omnivores) and source of diet (aquatic versus terrestrial prey). For riparian songbirds, those individuals foraging early in the season rely more heavily on the pulsed aquatic carbon subsidy of emergent aquatic insects. Birds foraging near habitats that efficiently methylate Hg, such as backwaters or wetlands, exhibit higher Hg levels."
http://hdl.handle.net/1957/61584,"This thesis considers the problem of training convolutional neural networks for online visual tracking. A major challenge for single object visual tracking is that most training sets with frame-level track annotations are quite small, due to the prohibitive cost of manual annotation. Current training approaches either supplement the annotations with other data sources (e.g.,  object-detection training data) or generate noisy variants of the track annotations. In either case, the data generation and training methods have ignored the fact that tracking involves sequences of decisions (one per frame) that are dependent on one another. Thus, the objectives optimized by these learning algorithms are not directly tied to the end goal of tracking performance. To further study this issue, we consider the state-of-the-art imitation learning algorithm, DAGGER, for training an online tracker. We observe that the DAGGER faces difficulty when applied to tracking, because online trackers typically experience unrecoverable failures, especially early in training.  To rectify this issue we introduce, analyze, and evaluate a variation of DAGGER, called DAGGER with Resets (DAGGER), a novel imitation learning framework which maintains the theoretical properties of DAGGER and is more appropriate for training deep trackers.  Our main contribution is to compare different training methods, including DAGGER and DAGGER, across a variety of datasets and multiple trackers. Our experimental results show this principled training approach and methodical random augmentation is able to outperform existing training approaches across multiple visual tracking datasets."
http://hdl.handle.net/1957/61585,"Aqueous hydroxo Hf nanoclusters enable studies to identify and codify steps in the deposition of Hf-based oxide thin films from solution precursors.  HfOCl2 reacts with combinations of H2O2(aq), acids, and TMAH to produce polymetal species at high pH and low pH.  X-ray scattering and spectroscopic methods reveal the nature of these species in solution, while temperature-programmed desorption coupled with a suite spectroscopic techniques detail their chemical changes as they transition to condensed thin films.  Three precursors were studied in this work:•	hafnium peroxide hydroxide nitrate Hf(O2)0.5(OH)1.8(NO3)1.2 (HafNOx) •	the photoresist Hf(O2)0.5(OH)1.6(SO4)0.7 (HafSOx)•	the hexameric cluster ((CH3)4N)6Hf6(O2)6(OH)18 (TMAHfOx)."
http://hdl.handle.net/1957/61586,"This dissertation investigates the structure and topological properties of cyclicallypresented groups. First, a family of groups called groups of type Z is considered. Withfew exceptions, the finiteness, asphericity, fixed point, and 3-manifold spine problemsare solved. Most groups of type Z have a central element of infinite order  fixed by theshift. Moreover, the shift extension decomposes as an amalgamated product, with factor acentrally extended triangle group. Consequently, most groups of type Z are SQ-universal.Heegaard diagrams are constructed to produce a class of Seifert  fibered 3-manifolds; eachis a cyclic branched cover of a lens space. Generalizing those in [16], this class includesthe Brieskorn [50] and Sieradski manifolds [64].The shift dynamics of the groups Gn(k,m) = Gn(x0xmxk^-1) of Fibonacci type [40]are investigated. These generalize the Fibonacci groups F(2, n) = Gn(1, 2) [20], Sieradskigroups S(2, n) = Gn(2, 1) [64], and Gilbert- Howie groups H(n,m) = Gn(m; 1) [28].Modulo two unresolved cases, the asphericity problem for groups of Fibonacci type wassolved in [71];  finiteness [72]; 3-manifold group [37]. Here the main  finding is the shiftaction is faithful for all n; m; k such that Gn(m; k) is nontrivial. The  fixed point andfreeness problems are also solved, except for a handful of groups including H(9; 4) andH(9; 7). The first known examples of infinite, non-aspherical groups with free shift actionare discovered.Finally, the situation is considered when a word w 2 F(x0,...,xn-1) in a cyclicpresentation Pn(w) is composite, i.e. w = v   u. We find the structure of Gn(v  o  u)depends on Gn(u) and Gn(v), with respect to the  finiteness, asphericity, shift dynamics,and 3-manifold spine problems. The idea of studying Gn(v o  u) via Gn(v) is introducedin [3], and arose in classifying  finiteness and shift dynamics [4]. The earliest example ofcomposite words we are aware of is [56], and [11] is the first of several papers ([55], [31])that discuss composing balanced presentations of the trivial group as it relates to theAndrews- Curtis conjecture. Only [31] specifically considers cyclically presented groups,and they show that if Gn(u) = Gn(v) = 1, then Gn(v o  u) = 1. This follows immediatelyfrom our results."
http://hdl.handle.net/1957/61587,"This dissertation focuses on extending the application scope of surface enhanced infrared absorption spectroscopy to gas sensing. The method we propose is incorporating plasmonic nanostructures with nano-composite material, metalorganic framework, which can selectively preconcentrate certain gas molecules into the nanopores. The preconcentrating property is first demonstrated by applyingmetal-organic framework to optical fiber based sensor. Then two different metalorganicframework integrated surface enhanced infrared absorption gas sensorsfabricated on bulk substrate and nano-membrane are investigated, and the highenhancement factors demonstrated for the first time. Lastly, an on-chip spectrometer using high resolution plasmonic filter array is proposed and experimentally demonstrated for resolving CO2 absorption spectrum at 2.0 μm with 10 ~ 12 nm resolution. This filter array spectrometer is simple and low-cost, which can be potentially used for portable gas spectroscopy system."
http://hdl.handle.net/1957/61588,"Gall-associated phytopathogens have unique evolutionary histories that haveshaped both their modes of infection and genomic structures. Pathogenicity of the gall-associated plant pathogens of the Rhodococcus, Agrobacterium, and Rathayibactergenera is mediated by horizontally acquired virulence loci. The relative ease of gainand loss of the virulence loci has confounded accurate characterization of thesebacteria, especially those characterizations made prior to the use of molecular markersfor genotyping. Work presented in this thesis uses whole genome guided approaches todiscern the intra- and inter- species genetic diversity in the three genera described.Rhodococcus fascians is the causal agent of leafy gall disease. We tested thehypothesis that R. fascians is comprised of a single species level group and show thattwo distinct clades with up to six species level groups are able to cause symptomsconsistent with leafy gall disease. These data reveal previously unknown chromosomaldiversity within this group of phytopathogenic bacteria. Four lines of evidence thatmake use of whole genome sequences indicate that the species are acted on by distinctselective pressures and have unique evolutionary histories. Further, a set of horizontallyacquired virulence loci is correlated with the pathogenic phenotype, regardless ofchromosomal lineage. These data suggest that delimitation of phytopathogenicRhodococcus isolates requires careful consideration with respect to both thechromosomal genotype as well as the presence of virulence loci.Rathayibacter spp. are vector mediated plant pathogens that infect nematodegalls in the seed heads of several grass species. Rathayibacter toxicus, a Select Agentin the U.S., has been shown to produce corynetoxins, nucleoside antibiotics that alsocause neurotoxic effects in mammals, when infected by a bacteriophage. As R. toxicusencodes a clustered regularly interspersed short palindromic repeats (CRISPR) systemthat acts as an adaptive immune system against foreign DNA in bacteria, we studiedthe CRISPR array evolution for insights into the ecology of bacteria-phage interactions.We predicted that over half of the spacers encoded in R. toxicus are functional intargeting the phage, while the bacteria still show susceptibility to the phage. These datasuggest a complex homeostatic interaction whereby neither bacteria nor phagepopulations are eliminated. Further, our results challenge past conclusions on theefficacy of CRISPR-mediated immunity.Lastly, we generated a set of tools to facilitate comparative genomics researchand accurate species and strain identification. Data are integrated into a website(http:  gall-id.cgrb.oregonstate.edu ) to facilitate their use by all researchers, regardlessof computational proclivity."
http://hdl.handle.net/1957/61589,"In 2014, W. Bogley identified a relation between the algebraic and geometric prop- erties of cyclically presented groups Gn (w) in the case where w = x0xkxl is a positive word of length three. Specifically, it was shown that the dynamics of the shift θG on the group G = Gn (x0xkxl) are connected to the finiteness of G and the combinatorial asphericity status of the corresponding cyclic presentation Pn (x0xkxl) that determines G. This dissertation provides an extension of those results to the case where w = x0xjxkxl is a positive word of length four. Additionally, this dissertation provides a complete clas- sification of the cyclically presented groups Gn (x0xjxkxl) that are finite and, except for two families of presentations where the status is unresolved, a complete classification of the cyclic presentations Pn (x0xjxkxl) that are combinatorially aspherical."
http://hdl.handle.net/1957/61590,"Organic semiconductors are used in a wide variety of applications including transistors,solar cells, and light emitting diodes. These materials are solution-processable,low cost, and tunable. Many successful organic optoelectronic materials utilizeblends of several types of molecules (such as donors and acceptors) in order topromote charge generation. As blends are an inherently heterogeneous system,nanoscale morphology plays a critical role to determine the optoelectronic propertiesof the blend. The work presented in this dissertation aims to develop novelmethods of probing the local nanoenvironment in organic semiconductors as wellas establish the relations between the nanoscale environment of the molecules andtheir photophysics.First, several experiments were performed via single molecule fluorescence microscopyto study energy transfer (FRET) and photo-oxidation in blends containingdonor and acceptor molecules. Donor molecules were imaged with increasingacceptor molecule concentration to determine the change in their photophysicalproperties due to acceptor-modified morphology and donor-acceptor energy transfer.As the concentration of acceptor molecules reaches a critical concentration suchthat the average donor-acceptor distance is below the FRET radius, fluorescenceof donor molecules is quenched. This enables single-molecule-level microscopy atrelatively high donor concentrations, thus creating a new super-resolution tool toimage donor molecules in a modified local environment. As the concentration of acceptorsincreased, the number of photons a donor emits over its lifetime decreased,and fluorescence intermittency increased. These observations were quantified usingstatistical analysis and complementary cumulative distribution functions. Thefindings were attributed to the acceptor-modified morphology which reduced thedonor molecule protection from photo-oxidation reactions; however, the presenceof the acceptors also enhanced the reversibility of the photo-oxidation process byquenching the highly reactive singlet oxygen. Such reversibility is important fororganic semiconductors as their photodegradation is one of the key drawbacks forapplications.Next, molecular packing and photostability changes are presented as a functionof different host matrices and different molecular side groups, again via singlemolecule fluorescence spectroscopy. Molecules embedded in a crystalline organicsemiconductor host matrix exhibited higher photostability than a polymer matrix.In addition, larger side groups lead to higher photostability, indicating thelarger side groups provide better protection from reactions with oxygen. Orientationalconstraints for guest molecules in a crystalline host were also observed andquantified.Lastly, a novel method to study photoinduced charge transfer between organicsemiconductors utilizing optical tweezers is presented. A silica microsphereis coated with an organic semiconductor (e.g. donor) film and suspended in aliquid with varying dielectric permittivity and containing other organic semiconductormolecules (e.g. acceptors). The time-resolved surface charge of this sphereis measured by trapping the sphere using optical tweezers and applying a sinusoidalelectric field across the sphere. (Dis)charging dynamics are measurable byphotoexciting the coating of the sphere and observing the dynamics of excitonsby monitoring the photoluminescence of the trapped sphere while simultaneouslymeasuring surface charge with optical tweezers."
http://hdl.handle.net/1957/61591,"Natural selection, in its most basic form, is described as a process in which traitsincrease or decrease in frequency depending on their fitness, and only the trait withthe highest fitness will remain in the population. Yet, populations rarely have asingle `optimal' trait. The way natural selection maintains this observed variationwithin populations has been a keen focus of evolutionary biologists. In the followingchapters, I focus on how natural selection maintains a form of phenotypicvariation referred to as `partial migration'. Partial migration is the coexistence ofmigratory and non-migratory phenotypes, and is found in a wide variety of taxa. Ifound that some, but not all forms of density-dependent competition can lead to theevolution and maintenance of partial migration (i.e., partial migration as an evolutionarilystable strategy (ESS) and convergent stable strategy (CSS)). Whetherdensity-dependent competition allows for partial migration as an ESS and a CSSdepends on how it influences the relative fitnesses of the phenotypes. If competitionchanges the relative fitnesses in opposing directions, then it will allow forpartial migration. If it affects the relative fitnesses in the same direction, it willnot. I then apply these results to a fish species of conservation and commercialconcern: Oncorhynchus mykiss, or steelhead and rainbow trout. I demonstratehow female steelhead and rainbow trout competing separately for spawning habitatcan still be subject to frequency-dependent selection and how this allows forpartial migration. The frequency-dependent selection also results in strong feedbacksbetween survival and reproduction, which produces a non-linear response inthe migration propensity ESS and CSS. In practical terms, this means that conservationor management actions may not affect the population as expected, andmeasuring the propensity for migration in wild populations is notoriously difficult.To address this difficulty, I develop a method to measure the propensity for migrationin wild populations that can be used to test the predicts I generated in thetwo previous chapters. The method is called sex-ratio balancing and it relies on afundamental relationship between sex ratios and the propensity for migration. Sexratios are much easier to measure than the propensity for migration and the easeof measurement makes this method valuable for studying many different partiallymigratory taxa."
http://hdl.handle.net/1957/61592,"School forests in South Korea are trees and vegetation areas within schoolyards, and they provide natural environments for schools and neighborhoods. After the Korea Forest Service (KFS) and local governments create these school forests, the management of school forests transfers to the host schools. Some studies suggest that experiences with school forests positively affect student temperament. However, little is known about how schoolteachers use school forests or how school forests are managed. This study addresses these knowledge gaps by exploring schoolteachers’ opinions on school forests. Data were obtained from an online survey of schoolteachers in South Korea (N = 149). This survey found that schoolteachers frequently visit school forests, but their most significant problem is a lack of time for planning their use of school forests. Furthermore, schoolteachers are satisfied with school forest management. However, this survey showed that schools experience a lack of maintenance funding and a lack of expert advice in management. The KFS and local governments can use these results to support the management of school forests."
http://hdl.handle.net/1957/61593,"River impoundment by dams, along with other human driven changes, has threatened the health of riparian forests in the northern Great Plains for much of the last century. Two major concerns in the region are the impediment of natural recruitment of plains cottonwood (Populus deltoides Marsh. subsp. monilifera (Ait.) Eckenw.) following dam construction on the Missouri River, and the impact of pathogens on stressed or weakened trees. Two independent studies were performed to look at these forest health issues. In one study, methods of establishing plains cottonwood were compared along the Missouri River in North Dakota. Three treatments: tree planting, planting with five-foot tree shelters, and planting with five-foot tree shelters and weed barrier fabric, all proved to be effective after two years. As a general trend, height, height to live crown, and caliper increased with treatment complexity, suggesting improved vigor and growth rate with more intensive treatments. In the second study, riparian woodlands in North Dakota, South Dakota, and Nebraska were surveyed to determine the ecological role of a prevalent root disease-causing fungus, Armillaria. The fungus was present in 78 of 101 surveyed stands, and was observed in a pathogenic role (i.e. caused root disease) 71% of the time. Results of logistic regression suggested that the odds of observing a pathogenic interaction were greater at sites that had clearly flooded; the same was true with increases in percent clay and basal area ha-1. Host DBH, the presence of competitive grasses, and stumps and snags hectare-1 had no significant effect on the ecological role of Armillaria in surveyed stands."
http://hdl.handle.net/1957/61594,"Ground failures, in particular landsliding, liquefaction and lateral spreading can be triggered by seismic sources. The frequency, magnitude, and impact of these ground failures are highly dependent on the topography and geology of the site including its slope, depositional environment, and geotechnical properties as well as the proximity of the site to seismic sources. Many available models for estimating these variables have high epistemic uncertainty given the extreme challenge to fully characterize seismic sources and subsurface conditions. Nevertheless, this high uncertainty must be considered when mapping ground failure hazards for a large area using geologic, geotechnical, topographical, and seismic hazard data of limited availability.Many hazard maps do not fully consider uncertainty from the seismic sources, subsurface testing, and empirical models developed for estimating ground failures. Often, previously developed maps are qualitative based on judgment due to the lack of detailed subsurface geotechnical investigations.This research presents new mapping methods to address these challenges, resulting in ground failure hazard maps for evaluation and risk assessment. It explores both deterministic and probabilistic methods of mapping ground failure hazards for large study areas. Available geospatial data are incorporated in this research including digital elevation models (DEMs) acquired from lidar and photogrammetric data, DEM derivatives such as slope, geologic mapping, shear wave velocity tests and other geotechnical subsurface investigations, and seismic hazard curves.First, efficient algorithms were developed to map estimates of the peak ground acceleration, landslide and liquefaction triggering probability, and horizontal displacement as a result of landslides or lateral spreading across the state of Oregon for several earthquake scenarios associated with the Cascadia Subduction Zone (CSZ).  These algorithms utilize site classification and site geology maps provided by the Oregon Department of Geology and Mineral Industries (DOGAMI).Second, a performance-based, landslide-induced, displacement hazard mapping technique is proposed and implemented for Western Oregon.  This approach computes landslide displacement hazard curves across the regional area.  The approach utilizes a detailed landslide inventory database and high-resolution topographical data to estimate the soil strength and associated uncertainty in the general geologic units. Third, in an effort to characterize the uncertainty of the geotechnical properties of geologic units, a geospatial geotechnical database was developed and evaluated.  In this evaluation, available geologic maps and geotechnical subsurface databases from three counties in the State of Utah were compiled. Then, several distributions of geotechnical properties for the general geologic units were developed, and these distributions enabled the determination of which geologic units were most susceptible to liquefaction and lateral spreading.  A statistical approach was also developed to provide a framework for simplifying geologic units based on soil properties.Lastly, a new and fully probabilistic framework is developed for mapping the liquefaction-induced lateral spread displacement hazard at a regional scale. This framework is demonstrated by producing lateral spread hazard maps for Utah County, Utah. By performing numerous Monte Carlo simulations, the method accounts for uncertainties in the soil properties, seismic loading, and the empirical models for predicting horizontal displacements due to lateral spreading."
http://hdl.handle.net/1957/61595,"The present research sought to investigate individual differences in the way individuals process intuitive risk judgments. The present investigation is centered on Fuzzy Trace Theory (Brainerd & Reyna, 1991), a developmental dual process theory of cognition which posits two ways in which individuals process information, gist and verbatim processing. 228 participants completed a battery of self-report personality measures as well as an intuitive risk judgment task that required participants to judge a particular situation as either a “good” or “bad” idea to engage in. Response times to the risk judgments were recorded and used in conjunction with actual responses and used to operationalize gist and verbatim processing. This operationalization was then correlated with other theoretically relevant measures of personality in order to demonstrate convergent validity. Results indicated differential support for the convergent validity of our gist and verbatim operationalization. Response times were related to risk-taking propensity, and personality traits such as honesty humility, and impulsivity. These findings provide some clarity to theoretical presumptions made by Fuzzy Trace Theory while providing a potentially useful operationalization of gist and verbatim processing."
http://hdl.handle.net/1957/61596,"On January 2, 2016 a militia occupied the Malheur National Wildlife Refuge in Oregon and captured national attention.  The militia vowed to occupy until certain demands were met, and among these demands was a call for less federal control of land.  While the occupation lasted 41 days, the militia remained unable to negotiate any of their demands with the federal government. Thus, the occupation and this iteration of a modern militia movement were unsuccessful.  There is extensive research addressing the evolution of the militia movement.  However, there is a glaring absence of literature addressing rhetoric created by militia groups.  Therefore, this research serves to address this gap by comparing rhetoric cultivated by the Malheur militia and Governor Kate Brown to determine why the Malheur militia’s movement was unsuccessful.  This research focuses primarily on metaphor usage and the messages they derive within three discourses created by the parties mentioned above.  As a stylistic token, metaphor is able to suggest various audiences most receptive to the messages and understanding cultivated by the metaphor. By comparing Governor Brown’s rhetoric with the militia’s, this research revealed several interesting conclusions.  First, that the militia used significantly more metaphor in their discourse to justify their actions amongst a wider audience.  Secondly, Governor Brown’s subdued use of metaphor only served to reinforce society’s expectations of the occupation and militia.  Lastly, the Malheur militia’s movement was unsuccessful because the metaphors in their discourse didn’t appeal to a larger public.  Through metaphor, the militia remained unable to connect and identify with the larger public."
http://hdl.handle.net/1957/61597,"Sintering of nanoparticles to create films and patterns of functional materials is emerging as a key manufacturing process in applications like flexible electronics, solar cells and thin-film devices. Further, there is the emerging potential to use nanoparticle sintering to perform additive manufacturing as well. While the effect of nanoparticle size on sintering has been well studied, very little attention has been paid to the effect of nanoparticle shape on the evolution of sintering. This thesis uses Molecular dynamics (MD) simulations to determine the influence of particle shape on shrinkage, neck growth, and atomic diffusion for three common nanoparticle shape combinations, i.e., sphere-sphere, sphere-cylinder, and sphere-flake nanoparticles of different sizes. The results from this work show that depending on their relative sizes, both the degree of neck growth and shrinkage are affected by the nanoparticle shape. The possibility of using this phenomenon to control density, neck growth and stresses during nanoparticle sintering are discussed."
http://hdl.handle.net/1957/61598,"Douglas-fir (Pseudotsuga menziesii) is a widely distributed, ecologically important, and commercially valuable tree species in North America. However, climate change is expected to adversely impact Douglas-fir trees, and assisted migration may become necessary to lessen the effects of climate change. Because drought stress is one of the projected effects of climate change in the western U.S., it is increasingly important to include drought adaptation traits in breeding programs and in reforestation decisions.This study assesses genetic variation in drought adaptation traits in Douglas-fir as part of the Drought Hardiness Study that was initiated by the Bureau of Land Management (BLM). Currently, it is being managed as collaboration among the BLM, Pacific Northwest Tree Improvement Research Cooperative (PNWTIRC), Northwest Tree Improvement Cooperative (NWTIC), Weyerhaeuser, Silver Butte Timber Company, and Washington Department of Natural Resources.In this study, I addressed the following objectives: (1) obtain baseline measurements and climate data to help in the analysis and interpretation of future measurements in theDrought Hardiness Study; (2) characterize the quantitative genetics of drought adaptation traits; and (3) determine whether drought adaptation traits are associated with the climatic origin of Douglas-fir seedlings.To achieve these objectives, data were collected from about 10,000 Douglas-fir seedlings from 429 families from western Oregon and Washington that were planted at two sites (Sprague and Lost Creek) in southern Oregon. Measured variables, which I refer to as drought adaptation traits, included height, second flushing, spring bud flush, damage (foliage, stems, and leaders), and survival.Each drought adaptation trait was subjected to an analysis of variance (ANOVA) to obtain variance components. Then, these components were used to estimate quantitative genetic parameters, including genetic variances, heritabilities, family-level breeding values (BLUPs), and genetic correlations. Climate variables (1961-1990 normals) from the female parent source locations were estimated using the ClimateNA software program. Simple correlations and lasso regressions were calculated between drought adaptation traits (family BLUPs) and climate variables.Based on ClimateNA models and weather station data collected in the year of the study (2015-2016), the Sprague site is typically hotter and drier than Lost Creek. Results also indicate that the trees at the Sprague site grew less, were more damaged, and had greater mortality than the trees at Lost Creek. Therefore, differences in climate and seedling growth between the two sites indicate that this experiment should be effective forscreening families for drought adaptation. In later analyses of the Drought Hardiness Study, early height measurements will be helpful for the analysis and interpretation of later measurements. For instance, either height in the greenhouse or height in the field can be used as an “initial height” for comparison with later height measurements to remove the confounding effects of family height variation resulting from early seedling growth in the greenhouse.In the first growing season, heritabilities and genetic variances differed widely among traits. I also found that estimated genetic gains were large for drought adaptation traits, primarily because of the large number of families tested (i.e., high selection differentials). For example, large potential genetic gains were observed for flushing (Flush), second flushing (SFlush), and height increment (Htinc). Although genetic correlations were found among drought adaptation traits, low correlations were found between growth in the greenhouse and other drought adaptation traits, flushing versus height growth, and flushing versus mortality. Additionally, genotype-by-environment interactions at the family level are reported.Drought adaptation traits were significantly correlated with some parental climate variables. Large and significant correlations were found between growth in the greenhouse and parent source climates. However, I did not find any correlations with growth in the field. I found moderate correlations for spring bud flush, and low correlations between other drought adaptation traits and climate. For instance, I foundearly bud flush was associated with warmer and drier climates, suggesting that early bud flush is a drought avoidance strategy.Selection of climate variables associated with drought adaptation traits was investigated using genecological-modeling techniques. I found that the end of the frost-free period (eFFP) was the most relevant variable, based on the data from the Sprague site. However, eFFP only explained a low amount of variation in second flushing (SFlush). The same procedure identified growing degree-days below 18°C (DD_18) as the most relevant variable based on the Lost Creek data.My results help increase the understanding about the importance of climatic-driven genetic differences for drought adaptation traits in Douglas-fir. The results of this study and later analyses of the Drought Hardiness Study will provide useful information for understanding drought, enhancing breeding programs, and potentially adjusting forest management to climate change impacts."
http://hdl.handle.net/1957/61600,"Mary Collins composed the award-winning book American Idle in 2009 after her recovery from an awful bicycle accident. This bicycle accident inspired Mary Collins to take a trip of discovery. Mary Collins visited historical locations to see changes in peoples’ physical activity over time. Collins interviewed individuals whose professions varied from archaeology, brain surgery, fitness, non-profits, etc. These professionals provided additional experiences to the large narrative of sedentary living in the United States. Bitzer’s Rhetorical Situation, Fisher’s Narrative Paradigm and The Social Ecological Model acted as lenses to observe Mary Collins’ personal research, narratives and interviews. These perspectives drew attention to some reasons why Americans often embrace a sedentary lifestyle. This paper supported how American Idle is a piece of rhetoric that incited a response from the audience. The narratives in American Idle satisfied Fisher’s Narrative Paradigms’ aspects of narrative fidelity and coherence."
http://hdl.handle.net/1957/61601,"Monoterpenes are important volatile compounds to the aroma of many white wines. Many monoterpenes are chiral and found in wine as different isomers. These isomers (also known as enantiomers) are non-superimposable mirror images of each other, maintain the same molecular structure and in many instances possess different sensory characteristics. Much research in wine has investigated the contents of monoterpenes, but has largely overlooked the monoterpene enantiomer profiles and important roles of the different monoterpene enantiomers in wine.Monoterpene enantiomer profiles in grapes and final wine are due to many factors, including genotype (grape variety), climate, temperature, soil type and winemaking technique. These compounds are of great interest to wine as they are related to the unique sensory identity of varietal wine. The aim of the project was to: firstly develop a robust and valid method for monoterpene enantiomer identification and quantitation, secondly investigate the effect of grape variety, growing region and wine style on the profiles of monoterpene enantiomers, thirdly determine the important role of monoterpene isomer profiles in wine matrix and evaluate the effect of interactions between monoterpenes and other wine components on odor perception of wine.The study presented the comprehensive exploration of monoterpene enantiomers (S-(-)-limonene, R-(+)-limonene, (2R,4S)-(+)-cis-rose oxide, (2S,4R)-(-)-cis-rose oxide, (2R,4R)-(-)-trans-rose oxide, (2S,4S)-(+)-trans-rose oxide, (2R,5R)-(+)-trans-linalool oxide, (2R,5S)-(-)-cis-linalool oxide, (2S,5S)-(-)-trans-linalool oxide, (2S,5R)-(+)-cis-linalool oxide, R-(-)-linalool, S-(+)-linalool, S-(-)-α-terpineol, R-(+)-α-terpineol, and R-(+)-β-citronellol) in white wines from different grape varieties using head-space solid phase micro-extraction-multidimensional GC-MS (HS-SPME-MDGC-MS). In addition, it presented for the first time the varietal differences from monoterpene enantiomers and enantiomer fractions which were calculated by dividing the first eluting enantiomer by the total enantiomers of each compound (enantiomer pairs). Despite heterogeneity in vintages, regions, and styles, varietal wines could be clearly differentiated. Results have expanded upon the current knowledge of varietal distinctiveness based on isomer profiles and enantiomeric fraction.Riesling wines possess very diverse flavors as the composition of grapes, can be altered by environmental characteristics and viticultural practices. Moreover, Riesling wines carry more stylistic variability in terms of residual sugar content, than any other major international white grape variety. Our study found that chiral monoterpene profiles and enantiomer fractions could be important factors to classify Riesling wines according to their geographical origin and style.Sensory discrimination tests were performed to elucidate the interactions between monoterpene isomers at low concentrations and other wine components. The results imply that a combination of enhancing and suppression effects occur and impact the perception of monoterpene isomer profiles in Pinot gris wines. Furthermore, the effects of same monoterpene profiles differed according to the matrices, displaying the many interactions that occur and affect sensory perception.The study on chiral monoterpenes in white wine not only expands our knowledge on monoterpene isomer analysis and distribution, but it provides information for varietal quality, by offering an objective measure of flavor quality. Additionally we have shown that when investigating sensory perception it is important to use a matrix as close to the original product and we further support that aroma compounds found at concentrations below their known perception thresholds can effect aroma perception."
http://hdl.handle.net/1957/61602,"The increasing human demands on natural resources, in combination with uncertainties about ecosystem dynamics due to global change, has led the scientific community to conclude that new approaches in understanding of ecological systems are needed to tackle environmental issues in an efficient manner. One development that has received more attention globally is high-grading forests by removing only valuable trees with little attention paid to tree regeneration. In several forest regions, this practice has become widespread and can trigger the development of aggressive and recalcitrant understory vegetation. In these cases, successional progression stagnates or is “arrested” and many ecosystem processes typically associated with successional development stall as well or only act at reduced levels, leading to lower provision of desired ecosystem services. In this dissertation, I present the results of three research studies based in high-graded Nothofagus forests in south-central Chile. In chapter 1, I developed a conceptual framework by integrating ecological theories to provide a comprehensive understanding of ecosystem dynamics after disturbances and therefore for restoration practices focused on forests with arrested succession. Second, I evaluated the effectiveness of restoration activities (i.e., topsoil removal through scarification) to overcome and move the forest from the arrested succession condition toward a more standard or desirable (in terms of higher provision of ecosystem services) successional development. The last chapter evaluates how this restoration practice influences the seedling growth of different species, and thereby the potential successional development of these regenerating forests. The integration of successional theory and properties of adaptive cycle phases and traps (i.e., potential, connectedness and resilience) with multiple equilibrium models offers an understanding of why ecosystems may remain in one basin of attraction or move into another basin. This knowledge provides a theoretical foundation for management practices aimed at pushing ecosystems over a threshold from an undesirable basin of attraction (i.e., arrested succession) to a more desirable basin, in which ecosystems transition to more diverse and productive forest ecosystems. The field studies showed that ground disturbance was an effective management approach to overcome arrested succession, i.e., manipulating understory vegetation and to encourage tree regeneration, that is expected to facilitate the successional development of these forest ecosystems. This study provided insights into the relative importance of different biotic and abiotic environmental conditions that lead to arrested succession after high-grading, and how ground disturbance alters these conditions and leads to successional development.Growth of species established in the understory after ground disturbance were strongly related to light and nitrogen levels, suggesting that the interaction of these factors may influence successional trajectories. Thus, understanding the traits of undesirable and desirable vegetation in terms of their resources needs is key to designing restoration treatments. Such treatments can be specifically designed to alter resource levels to favor desirable species. Collectively, these chapters contribute to the understanding of factors responsible for temperate rainforest ecosystems exhibiting arrested succession and how to overcome such conditions. Furthermore, the chapters provide more general insights into ecosystem dynamics that can be used to promote ecologically based management practices that are grounded in ecological theories in general."
http://hdl.handle.net/1957/61603,"Abstract	C. perfringens type A isolates are the causative agents of C. perfringens type A food poisoning (FP) and non-food-borne (NFB) human gastrointestinal diseases. In this study, we evaluated the antimicrobial effect of essential oil constituents (cinnamaldehyde, eugenol, allyl isothiocyanate (AITC), and carvacrol) against C. perfringens FP and NFB isolates grown in laboratory medium and chicken meat. Lower concentration (0.05%) of cinnamaldehyde, eugenol, carvacrol, but not AITC showed noticeable inhibition in spore germination. Furthermore, all tested essential oil constituents at 0.05-0.1% illustrated significant inhibitions in spore outgrowth and vegetative growth of C. perfringens. However, most significant inhibition was detected in the presence of AITC or carvacrol at 0.05% concentration. In meat model system, AITC at various concentrations (0.5%, 1%, 1.5%, and 2%) were able to inhibit the growth of C. pefringens FP and NFB isolates, but no inhibitory activity of cinnamaldehyde, eugenol, and carvacrol was found at the same concentrations. Even at higher concentration (5%), carvacrol showed no antimicrobial activity against C. pefringens FP and NFB isolates in chicken meat model. Collectively, although all constituents observed inhibitory effects against spore outgrowth and vegetative cells of C. perfringens FP and NFB isolates in laboratory condition, only AITC was able to control C. perfringens spores into meat model system."
http://hdl.handle.net/1957/61604,"Understanding which factors motivate farmers to adopt certain practices is animportant part of helping to solve many agri-environmental issues. This study uses 19interviews with farmers along Oregon’s Willamette River, a statewide producer survey, andselect interviews with organizations and agencies active in the farming community toexamine the extent to which farmers’ environmental ethics and worldviews influence theirpraxis. Results indicate that while conventional- and alternative-style farmers’ ethics andworldviews exist on a spectrum, general differences can be identified between the twogroups who oftentimes have differing ideas about what practices are beneficial for theenvironment. Although these values and beliefs play a role in shaping their praxis, theirinteractions with distinct formal and informal institutions and the social and economicchallenges they face are equally as influential and are potentially shaping and reinforcingbeliefs and practices."
http://hdl.handle.net/1957/61605,"In this dissertation, we introduce a family of fully discrete finite difference time-domain (FDTD) methods for Maxwell’s equations in linear and nonlinear materials. Onecategory of methods is constructed using multiscale techniques involving operator splittings. We present the sequential splitting scheme, the Strang Marchuk splitting scheme,the weighted sequential splitting scheme including the symmetrical weighted sequentialsplitting scheme for the discretization of the time domain Maxwell’s equations in twoand three dimensions. We construct and analyze these operator splitting schemes basedon energy techniques for Maxwell’s equations in linear non-dispersive and non-dissipativematerials, and in nonlinear ferromagnetic materials. The fully discrete methods use theCrank-Nicolson scheme in time to enhance and improve stability and use staggering of electric and magnetic variables in space. As a consequence, we obtain fully discrete schemesthat are unconditionally stable. Moreover, we prove the convergence of solutions of ournew numerical techniques and provide comparisons with other relevant numerical methods, such as the Yee-FDTD scheme.The second category of methods involves efficient, accurate, and stable computational techniques, based on high order finite difference time domain (FDTD) methods inspace for Maxwell’s equations in a nonlinear optical medium. The nonlinearity comes from the instantaneous electronic Kerr response and the residual Raman molecular vibrational response, together with the single resonance linear Lorentz dispersion. We constructfully discrete modified second-order leap-frog and implicit trapezoidal temporal schemesto discretize the nonlinear terms in our Maxwell model. Under stability restrictions, thefully discrete modified leap-frog FDTD methods are proved to be stable under appropriate stability conditions, while the fully discrete trapezoidal FDTD methods are provedto be unconditionally stable. Finally, numerical experiments and examples are given thatillustrate and confirm our theoretical results."
http://hdl.handle.net/1957/61606,"In this project, I explore the use of monomania as a literary and rhetorical device that pathologizes deviance from certain norms—in this case, sexual and political norms— and allows for contradiction, dissonance, and reform. Using Nathaniel Hawthorne’s short story “The Birthmark” and Edmund Clarence Stedman’s poem “How Old Brown Took Harpers Ferry,” I explore monomania’s role as a literary and rhetorical device and argue that the diagnosis was a way to target aberrant behavior for a “return to the senses”: altering behavior to fit socially acceptable norms."
http://hdl.handle.net/1957/61607,"Private forest landowners can adapt to climate change by altering their timing and intensity of harvests, by changing thinning or fertilizing activities, and by altering the tree species growing on their land. The well-being of humans is closely tied to the ecosystem services that forests provide as both market and non-market goods and services, including timber, recreation and tourism, carbon sequestration, wildlife species habitat, erosion control, and water purification. Adaptation by forest landowners to climate change can result in changes in a number of ecosystem service provisions. For example, a change in tree species composition and age class structure of forests could lead to degradation and loss of habitat for existing wildlife species; switching to different tree species could change the carbon sequestration rates; and market timber prices could adjust as a dominant tree species is replaced by other species and its market supply declines.There are many who advocate for a policy intervention in forestry in response to climate change, as forests mitigate greenhouse gas emissions as a major carbon sink. The climate mitigation policy of carbon pricing uses a forest’s capacity as a carbon sink to help internalize the negative externalities resulting from climate change. Since different tree species sequester different amounts of carbon at different rates, carbon prices alter incentives for private forest management, potentially resulting in either accelerating adaptation or pushing back. Despite the potential consequences of adaptation behaviors on ecosystem services, there has been little empirical analysis on how climate change and mitigation policy can affect adaptation behavior. Examining how mitigation policies affect adaptation behavior has important policy implications when the mitigation policy has the potential to create other externalities such as endangering existing wildlife species whose habitat may be altered by changes in forest management resulting from both climate change and mitigation policy.My dissertation conducts an empirical micro-econometric analysis of private landowners’ forest management decisions under climate change in California, Oregon, and Washington. The study area consists of diverse climate conditions and some of the most productive forests in the world. I address the following primary research questions: (1) How will the forested landscape evolve over time as humans adapt to a changing climate?; (2) How will climate mitigation policy affect adaptation behaviors?; (3) What is the impact of adaptation on existing wildlife species habitat?; and (4) What is the impact of adaptation on natural disturbances such as fire? Chapter 2 provides the conceptual framework for my approach with an emphasis on commonly used forest management practices, followed by an empirical econometric approach grounded in natural resource economic theory regarding forest management. In Chapter 3, I estimate a nested-logit econometric model for forest management practices while accounting for the simultaneous nature of harvest and replanting decisions, as well as the impact of natural disturbance occurrence on management decisions. In Chapter 4, the estimated discrete-choice econometric model is used as the basis for a dynamic simulation of the time-path of landscape change underboth climate change and carbon price scenarios. In the western portion of the Pacific Northwest, I find that landowners shift out of their current dominant tree species choice of Douglas-fir to other tree species more suitable for the future climate, notably hardwood and ponderosa pine. For example, climate change discourages a harvested plot being replanted with Douglas-fir in western Oregon and Washington by 20-65 percentage points relative to a no-climate-change baseline, resulting in the landscape shifting away from the current Douglas-fir forests towards other forest types. My results also indicate that the discrete effect of climate change on the probability of that the stock of forest types changes is 6 percentage points for current Douglas-fir forests in western Oregon, which indicates that the climate path in the next 90 years will add 6 percentage points to the probability of the current Douglas-fir forests switching to different forest types. The discrete effect on the current stock of hardwood forestland is to reduce the probability of switching out of hardwoods by 13 percentage points.The results also imply that a carbon price policy would further accelerate such adaptation behaviors, where carbon pricing has a larger effect on the adaptation away from Douglas-fir than the effects of climate change. For example, the discrete effect of carbon pricing on the probability of switching the current Douglas-fir forest to other forest types is an additional 10 percentage points. The effect of a carbon price on landscape change could necessitate an additional policy intervention to counteract the impact on wildlife species from the landscape’s more rapidly changing habitat. Chapter 6 discusses the impact on wildlife species that have been listed as concerned species by state agencies, with a particular focus on seven “habitat specialists” who have narrow habitat preferences associated with particular forest types. I present changes in their habitat across ecoregions, as well as across the entire habitat range and by states. The direction and magnitude of change vary considerably across regions. The effect of climate change shows that some species gain from climate change (e.g., ringtail), while many others lose. The direction and degree of impact of climate change also vary considerably across regions. The carbon price intensifies the change by inducing additional habitat change through forest management. In Chapter 7, I focus on the effects of climate adaptation on natural disturbance with a distinction between the impact of climate change and the impact of the carbon price scheme. My finding illustrates the mechanism as to why natural disturbance increases in some regions while decreasing in others. I also discuss how the burn severity of wildfires can increase under climate change.My empirical approach combines fine-scale econometric and simulation methods that use recently observed forest management behaviors to estimate a model that serves as the basis for projecting changes in forest management. My framework is developed to reflect forest landowners’ decision-making as observed in recent years. The econometric estimation accounts for the simultaneous nature of various forest management choices and different channels with which climate affects the forest landscape both directly through changes in growing conditions and indirectly through deliberate modifications of forests. The simulation framework treats natural disturbance events as endogenous as landowners’ harvest and replanting decisions affect disturbance outcomes, and the possibility of natural disturbance affects management. The simulation tracks forest attributes such as stand volume and incremental growth, depending on the landowners’ decisions as to the timing and intensity of harvest, as well as replanting choice.The simulated growth of the forest stock is a key determinant that affects the landowner’s decision as the simulation progresses through time. Another novel feature of the simulation is that it allows me to model different policy scenarios because management decisions are explicit functions of forest rents. This allows me to differentiate landscape outcomes into separate components, such as the impact of climate change and the impact from carbon price policy. Private forestland today is formed by deliberate landowners’ decisions in addition to natural processes that affect tree species. Management decisions are affected by site conditions, climate, market conditions, and policy factors. My simulation approach contributes by incorporating interactions between these intertwining factors in a manner that enhances understanding about the impact of climate change on forested landscapes. By providing the time paths of landscape change with a focus on the policy of carbon pricing (Chapter 5), wildlife species conservation (Chapter 6), or natural disturbance occurrence (Chapter 7), my dissertation will offer foundational information to policy makers and natural resource managers about the state of forest landscape change under climate change and climate mitigation policy.In a broad sense, this dissertation uses empirically-driven models to highlight the interplay between climate change, landowner adaptation, carbon prices, natural disturbance, and the spatially heterogeneous biophysical climate conditions in the study area. Although previous studies have examined each component separately, the role of adaptation behavior as the intermediate link that connects climate change and landscape change needs more attention in the literature. The methodology developed in this dissertation could also apply to other economic analyses of policy outcomes at the intersection of land use, land-use change, ecosystem services, climate change, and human well-being to help us better understand the feedback between humanbehavior, the environment, and long-term sustainability of natural resources. This dissertation research contributes by improving our understanding of the consequences of climate change and climate policies on adaptation behavior in a manner that provides a foundation for improved policy design that balances the needs of people and environmental values."
http://hdl.handle.net/1957/61608,"limate change and the increase in meteorological drought have generated global concern over the persistence of ecosystems already in decline from decreased moisture. Evidence suggests dryland ecosystems have been more impacted by drought because of their tightly coupled growth-water relationships and high sensitivity to environmental shift. Removal of competing vegetation to free available moisture can allow remaining trees to both persist and increase in vigor during periods of drought. However, in the dry forests of the western North America, the magnitude and duration of the growth response of angiosperms to such releases are not well understood. I selected quaking aspen (Populus tremuloides) stands within the dry forests of the Inland Pacific Northwest (PNW), experimentally treated them with conifer removal from within and around the aspen, and assessed them together with historically treated aspen stands. To test aspen vulnerability to future climate change, I used an adapted version of the forest growth model Physiological Principles for Predicting Growth (3-PGmix) with specific parameters for aspen in my region.My objectives were to examine the response of aspen suckers and overstory stems to removal of competing vegetation and the vulnerability of aspen stems to the stressors of future climate change. I found aspen sucker growth and density both increased in the three years following conifer removal. Plant water potential (PWP) was the strongest predictor of the observed increase. Aspen stem radial growth, as measured by basal area increment (BAI), was also greater after conifer removal. The increase over pretreatment growth in average annual BAI continued from post-treatment year 1 to year 11. PWP was the strongest predictor of the increased BAI. The modeling under 3-PGmix found most 40-year old stems are at risk of mortality while 70- and 100-year old stems in medium and high soil moisture sites are not at risk under future climate change effects. My results highlight moisture as the driver of aspen sucker growth, sucker density, and radial growth in the Inland PNW where aspen occurs in small, localized drainage catchments, and differ from Rocky Mountain studies where precipitation and site index are the key drivers. Further, I suggest that release of competition in dry conifer forests increases soil moisture availability allowing successful regeneration and growth of moisture-demanding plants. The rapid aspen mortality that occurred under drought conditions in the Rocky Mountain Region has not yet been documented in the Inland PNW. My study highlights that some climate-induced aspen mortality could be expected by 2025 with older stems and those growing in higher moisture sites not being at risk of mortality while younger stems could be vulnerable to die-off under even modest future climate conditions."
http://hdl.handle.net/1957/61609,"Time-dependent crack growth mechanisms in Alloy 617 at 800°C in air were studied using compact tension samples machined in the L-T direction, cracked at temperature using an induction furnace and servo-hydraulic load frame. The application of different loading waveforms, including triangular, hold time, and sustained loading, were studied with relation to relevant crack tip parameters in order to better understand the material’s viscoplastic response to crack growth mechanisms. Fracture surfaces and crack tip profiles were examined to discover relevant relationships between transgranular cracking, void growth and coalescence, and the role of oxygen embrittlement. A transition from transgranular cracking to void coalescence was noted, and the mechanism mapped, both onto the results obtained in this work and the existing literature. Additionally, overload experiments aided in describing stress relaxation as the dominant transgranular mechanism governing crack growth below Kth, the sustained load crack growth threshold stress intensity factor, which is also reported herein."
http://hdl.handle.net/1957/61610,"Strong self-regulation skills can predict academic success in early childhood contexts, specifically for math and literacy skills, thus laying the foundation for future success (McClelland & Cameron, 2012; McClelland & Ponitz, 2011). Children’s exposure to increased instructional time in school through programs such as full day kindergarten (FDK) has also shown a myriad of benefits to children’s academic achievement (Cannon, Jacknowitz, & Painter, 2006; Cooper et al., 2010; Gibbs, 2014). Research has not yet examined the relationship between FDK and self-regulation or children’s self-regulation skills as a mediating or moderating factor for the association between FDK and academic achievement in math, literacy, and vocabulary.This study used multiple regression, mediation with bootstrapping, and moderation models to examine (1) how FDK is related to gains in self-regulation and academic achievement at the end of the kindergarten year when controlling for fall scores, and (2) if spring self- regulation scores in kindergarten mediate the association between FDK and academic achievement and (3) if fall self-regulation scores moderate the relationship between FDK and academic achievement. It was expected that FDK would be related to stronger self-regulation and stronger academic achievement in the spring of kindergarten. Self-regulation in spring was￼￼￼￼￼￼￼also expected to be a mediator of the relationship between FDK in the fall and academic achievement in the spring. Last, it was expected self-regulation in the fall to moderate the relationship between FDK and academic achievement. Results from research question one indicated that FDK was significantly related to both literacy and vocabulary achievement in the spring of kindergarten but FDK was not significantly related to spring math achievement or spring self-regulation scores. For the second research question, no significant indirect mediation effects were found but several direct significant pathways within the mediation models were present. Specifically, spring self-regulation was significantly related to spring math achievement and spring vocabulary achievement. For the third research question, there was only one significant interaction indicating self-regulation as a moderator for the relationship between FDK and math achievement. When further probed, this interaction was proved to be not a meaningful moderator of the relationship between FDK and math achievement. No other significant interactions were found during the moderation analysis. The results from this study add to the knowledge regarding FDK, self-regulation, and academic achievement across the kindergarten year."
http://hdl.handle.net/1957/61611,"Commercial fishing is a culturally and economically significant industry on the Oregon coast. The importance of this industry to human communities is often neglected in fisheries research, with economic and ecological data being favored by managers and decision makers.  Recent observations in many coastal communities have indicated aging of fishermen and a lack of young people entering the industry, causing a “graying effect” in commercial fishing fleets.  This phenomenon could have significant implications for commercial fishing participants as well as the larger communities this industry supports. This qualitative study uses oral history data to examine the graying phenomenon and implications for the resilience of the commercial fishing industry in two coastal communities in Oregon.  Extensive research has been conducted on the graying of the fleet in Alaska but research on the phenomenon in the Pacific Northwest is lacking. Results reveal that commercial fishermen, fishing family members, and fishing support industry representatives perceive graying as a threat. This threat was specifically referenced in relation to changing fisheries management such as catch share implementation, as well as shifting motivations to fish and dynamic social influences.  Such changes may impact resilience through lost local ecological knowledge, diminished connection to place, and a loss of financial capital that has historically been brought into coastal communities through commercial fishing.  This research offers insight into the relationship between fisheries management and community perception, and provides potential strategies that can be used to combat current regulations favoring larger corporate fishing enterprises.  The results of this study also add to the literature on the graying of the fleet phenomenon providing much needed background and context for more extensive graying projects into the future."
http://hdl.handle.net/1957/61612,"Celebrity culture is part of a long history of fame, but the modern celebrity individual came into focus in the nineteenth century. The first part of this thesis distinguishes modern celebrity – including its morality – from other types of fame, explores the intersection of celebrity and gender through the figure of the female literary celebrity, and discusses George Eliot’s desire to control her public persona in Victorian celebrity culture. Previous scholarship has paid little attention to celebrity in Eliot’s fiction, so the second part of this thesis provides a close reading of Eliot’s last novel, Daniel Deronda (1876), as a means of attending to the connections between fame, artistic endeavor, and morality. I use Tom Mole’s three pillars of the celebrity apparatus (individual, industry, and audience) as a framework and reveal how the novel consistently relies on historically famed performers to help orient the reader. I read Daniel Deronda’s negative representation of pursuing art for the sake of celebrity as a reassertion of the same attitude that Eliot first established in her essay “Silly Novels by Lady Novelists” twenty years prior. However, those twenty years cover Eliot’s increasing popularity as an author, thus necessitating her need to defend her motivation for continuing to write and publish. Therefore, Daniel Deronda also offers the additional assertion that renown is morally acceptable, a qualification that legitimizes Eliot’s fame while allowing her to still critique celebrity."
http://hdl.handle.net/1957/61613,"Evacuation strategies have been established for most user groups in tsunami inundation zones; however, surprisingly little information is available for a growing visitor group - surfers. For near-shore tsunami events, Oregon surfers, who recreate in the nearshore region, must make life or death choices when deciding what to do in the case of a Cascadia Subduction Zone Earthquake. First hand accounts from recent global tsunamis indicate that surfers may improve their opportunities for self-rescue, if they identify early warning signs. Site specific characteristics also matter. At some surf spots, the wave breaks close to shore and there is high ground nearby. At other sites, surfers are not able to exit the water and reach high ground prior to the arrival of the first wave. In order to reach out to surfers and share potentially life-saving information, more research is needed regarding surfers’ perceptions of the risks involved in surfing and the tsunami hazard, and how their perceptions compare to other risks in everyday life. This study attempts to better understand how Oregon surfers perceive risk in general, and specifically tsunami risks. Furthermore, do surfers’ risk perceptions also lead to positive intent to change behavior? To address these questions, survey data is used to examine the relationships between perceptions of surfing, tsunami, and every day risks, as well as interactions with demographic information, perceptions of locus-of-control, and risk mitigation behaviors.  Results from this study will have important Implications for outreach and education within this community, as well as contribute to our scientific understanding of this understudied population.	Descriptive statistics, Mann-Whitney U tests, non-parametric correlations, and a path analysis are used to address these issues. Surfers in the study correctly identified their own board as the greatest surfing hazard. Participants tended to over estimate surfing hazards when compared to general hazards. Locus of control did not have statistically significant relationships with any of the other variables. A path model including demographic traits, general risk perceptions, surfing risk perceptions, and surfing mitigation behaviors was supported by the path analysis. Qualitative insights from conversations with surfers indicate that they are able to understand technical information about tsunamis and are hungry for more knowledge."
http://hdl.handle.net/1957/61615,"Childhood cancers are rare diseases that affect 188 children in Texas for every million born. Leukemia is the most common childhood cancer and accounts for roughly one third of childhood cancer cases. However, it is estimated that only 10% of childhood cancer cases can be explained by known risk factors. Although environmental pollutants (e.g., pesticides, groundwater, air pollutants) have been suspected as causes of childhood cancers their relationship with childhood leukemia have not been clearly established. Previous epidemiological studies that examined benzene and childhood cancers have used a variety of exposure metrics to estimate benzene exposure, including proximity to major roads, road density, proximity to industrial facilities and natural gas wells, and estimates from emission models. Despite the number of studies, no single metric of exposure to benzene has been consistently linked to childhood cancers.  We performed three analyses using spatially-derived metrics to assess the relationship between benzene exposure and childhood cancers, including acute lymphocytic leukemia (ALL), acute myeloid leukemia (AML), and central nervous system tumors (CNS) among a study population of 24,164 children in Texas born 1996 to 2009. First, we conducted an exploratory analysis to assess agreement among six spatially-derived metrics as a basis for determining exposure to benzene. Second, we conducted a case-control study to calculate the risk of childhood cancers based on exposure to benzene in utero. Finally, we used a spatial scanning method to identify clustering among children with ALL in five metropolitan areas in Texas.  Results indicate that aside from proximity to major road and major road density, few metrics of exposure to benzene agree, because the distribution and density of benzene-producing sources such as roads, industrial facilities, and gas wells differ among the major metropolitan areas in Texas. Childhood ALL was most consistently associated with natural gas wells, road density, and National Air Toxics Assessment benzene estimates (NATA), with an upper range of estimated effect at 1.30, a 30% increased risk. AML was less clearly associated with metrics of exposure to benzene. Central nervous system tumors showed a similar magnitude of risk as ALL with the NATA estimates of benzene exposure. The cluster analysis using spatial scan statistics identified four statistically significant clusters in the Houston metropolitan area and one space-time cluster in the Dallas-Ft. Worth metropolitan area. These findings indicate that spatial scan statistical methods can be used to detect and infer significance of clustering of higher than expected levels of adverse health outcomes. Collectively, the results of this research highlight the need for future studies to use multiple metrics to assess exposure to carcinogenic chemicals such as benzene, and to utilize novel methods to identify locations with elevated cancer rates. Further spatial epidemiological research and analysis using a variety of exposure sources and innovative methods will help pinpoint the causes of childhood cancers and potential measures to counteract this disease."
http://hdl.handle.net/1957/61616,"We generalize  overpartition rank and crank generating functions to obtain k-fold variants, and give a combinatorial interpretation for each. The k-fold crank generating function is interpreted by extending the first and second residual cranks to a natural infinite family. The k-fold rank generating functions generate two families of buffered Frobenius representations, which generalize the first and second Frobenius representations studied by  Lovejoy."
http://hdl.handle.net/1957/61617,"This phenomenological study explores the effects that an interdisciplinary program of study at a community college has on students once they transfer to a four-year institution. Interdisciplinary approaches have been proposed as a way of meeting the complex thinking skills needed for 21st Century learning. Because interdisciplinary learning is complex, it is difficult to assess; the literature on interdisciplinary learning has identified assessment as a key area where few empirical studies have been done. Complex learning requires complex and various approaches to assessment; thus, exploring student perceptions of their learning as the result of an interdisciplinary program is one way of beginning to assess the experience of interdisciplinary learning and to identify themes worthy of further study. In addition, interdisciplinary learning has been proposed as an approach for contextualizing and revitalizing general education requirements, but few studies have been done on the effectiveness of doing so. Because the primary focus of community college transfer degree programs is general education, a community college interdisciplinary program offers an opportunity to explore the effectiveness of interdisciplinary learning as a vehicle for￼￼￼￼￼enhancing the experience of general education requirements and for developing complex thinking skills. The literature on interdisciplinary learning also engages the question of whether interdisciplinary approaches are appropriate for first- and second- year students or should be reserved for upper division work. Since one of the primary goals of community college transfer degrees is adequate preparation for a four-year degree program, exploring the experiences of students from a community college interdisciplinary program once they are engaged in a four-year program can begin to answer the tricky question of assessment when it comes to interdisciplinary learning and its efficacy in delivering and contextualizing general education requirements and outcomes to first- and second-year students. This research was guided by the question: How do students who graduate from a community college interdisciplinary program use and experience that learning when they transfer to a four-year school? The framework for this study is Boix Mansilla and Dawes Duraisingh's (2007) empirically grounded framework for the assessment of interdisciplinary learning, which defines three domains of interdisciplinary understanding: disciplinary grounding, integration, and critical awareness. Interview questions were designed to have students reflect on their learning in these areas and on their ability to apply interdisciplinary learning to their four-year program course work and to complex real world situations. The study conducted interviews with students who graduated with an interdisciplinary Associate of Arts degree from Skagit Valley College, transferred to a four-year program within Washington State, and completed at least 30 credits. Qualitative, semi-structured interviews were conducted until a point of saturation was reached. Subjects were coded for anonymity and analyzed according to themes thatemerged around the framework that guided the interview questions. While Students perceived that interdisciplinary approaches at community college benefited their learning at the college and at the four-year program, especially in the areas of critical thinking, writing, research, and making general connections among classes, student perceptions of disciplinary grounding, integration, and critical awareness varied and seemed to be affected by the type of major the student was pursuing. Student interviews indicated that disciplinary grounding achieved through interdisciplinary courses at the community college might be limited and might need more development through stand-alone disciplinary courses or interdisciplinary courses that offer more than introductory level disciplinary content. While students reflected that they developed strong interdisciplinary habits of mind through their coursework at the community college, their abilities to describe integrative understandings that they achieved at the four-year institution varied. While all students found themselves applying interdisciplinary perspectives to complex problems at school and outside school, their articulations of their critical awareness in applying such approaches tended toward descriptions of general approaches rather than rich discussions of the strengths and weaknesses of the disciplines and of the logic they used in bringing those disciplines to bear on complex problems. Overall, student responses indicated that interdisciplinary approaches at the community college have potential to be used effectively to engage students in general education requirements and that such approaches have real world, as well as academic, applications. However, it appears that sustained support through programmatic, integrated, and incremental interdisciplinary learning approaches at both the community college and four-yearprogram might be needed in order for higher-level interdisciplinary outcomes to be achieved."
http://hdl.handle.net/1957/61618,"In this thesis, I deconstruct strategies of support for the LGBTQ youth of my home community,the Inland Empire. I call on Foucauldian understandings of discourse, knowledge, and power to analyze the existing support networks for LGBTQ youth in the Inland Empire. Gloria Anzaldúa’s theories of Nepantla and Nepantlera, and AnaLouise Keating’s theories of Threshold Theorizing and Post-Oppositional Resistance create openings and opportunities to construct strategies of support that center the LGBTQ youth of the Inland Empire. I interviewed GSA Advisors from the Inland Empire and Community Organizers who embody praxis and work with LGBTQ populations to build a network of collaboration and knowledge to inform the strategies of support I develop in this thesis. Through a systematic analysis of my interviews, I develop the concepts of nepantla discourses and nepantla pedagogies. I use grounded theory as my methodology to deconstruct and theorize about the roles of GSA Advisors, students, the educational system, safe space discourses, educational discourses, local knowledge, and power. The use of Keating, Anzaldúa, Foucault, and Geertz’s theories reveal the untapped potential of GSAs. The research of my thesis provides both theoretical and practical insights for developing community-informed strategies to serve the LGBTQ youth of the Inland Empire.      Questions this thesis will answer:How can community-informed strategies better serve the LGBTQ youth of the InlandEmpire?What roles do knowledge, discourse, and power play in creating LGBTQ inclusiveclassrooms, schools, and communities?"
http://hdl.handle.net/1957/61619,"Three analytical methods for determination of aroma compounds in alcoholic beverages were developed and validated. These methods are sensitive and reliable that can be applied to analyze volatile phenols, stale aldehydes as well as some highly volatile aromas in alcoholic beverages.  In the first study, an ethylene glycol (EG) polydimethylsiloxane (PDMS) copolymer based stir bar sorptive extraction (SBSE)-GC–MS method was developed for the analysis of volatile phenols in alcoholic beverages. Parameters affecting extraction efficiency were studied including ionic strength, pH, extraction time, ethanol content and nonvolatile matrix. Good correlation coefficients with R2 in the range of 0.994–0.999 were obtained for volatile phenol concentration of 5–500 µg L. Recovery for all phenols were from 95.7% to 104.4% in a beer matrix and 81.4% to 97.6% in a wine matrix. The method had a standard deviation less than 5.8% for all volatile phenols. The limit of quantification (LOQs) in beer samples was lower than 3μg L. In the second study, a simple, fast and reliable method was validated, in which headspace sampling was used in combination with gas chromatography-flame ionization detector (GC-FID) for quantifying the most abundant and highly volatile compounds in alcoholic beverages. The linearity for all the compounds covered 2 orders of magnitude with correlation coefficients (R2) between 0.9993-0.9996. The recovery ranged from 92.7%-99.9% in beer samples and 90.9%-117% in wine samples. The repeatability of this method was satisfactory with relative standard deviation of 2.9%-4.7%. The LOQ and LOD were much lower than the reported concentrations in alcoholic beverage including beer and wine.In the third study, a sensitive method for the determination of stale aldehydes in alcoholic beverages has been developed. Aldehydes were derivatized with O-(2, 3, 4, 5, 6-pentafluorobenzyl) hydroxylamine (PFBHA) in solution and the corresponding oximes were extracted using a DVB PDMS SPME fiber and quantified by GC-MS-SIM mode. It is shown that acidic pH and lower temperature would favor the sensitivity of aldehyde derivatives. Meanwhile by using SIM mode, the background can be eliminated a lot and the limit of quantification reached as low as 0.01μg L (0.1ppb) for most compounds, and the linearity is up to 100μg L with R2 in the range 0.993–0.999.In the fourth study, 5 out of 12 yeasts that isolated from a pre-fermentation cold maceration (9°C) of Pinot noir grapes, were confirmed with β-glucosidase activity, namely Metschnikowia pulcherrima, Hanseniaspora uvarum, Lachancea thermotolerans, and two isolates of Saccharomyces cerevisiae. These yeasts were inoculated in Pinot noir grapes sterilized by high hydrostatic pressure, individually or mixed. Pre-fermentation cold maceration (9°C) was performed followed by alcoholic fermentation conducted by Saccharomyces cerevisiae RC212 at 27°C. Aroma analysis of wine by solid-phase microextraction-GC-MS demonstrated that the presence of the different yeast species during the pre-fermentation cold maceration could alter the volatile aroma composition of wine. The yeasts in pre-fermentation cold maceration altered the concentrations of ethyl esters, branch-chained esters, higher alcohols and monoterpenes. In the fifth study, one of the two Saccharomyces cerevisiae isolates with high β-glucosidase activity from previous work was used to further investigate the impact of pre-fermentation cold maceration on Gewürztraminer wine aroma. A commercial yeast was used in comparison where no cold maceration treatment was performed. The quantification results of aroma compounds showed that pre-fermentation cold-maceration did not significantly affect aroma profile of Gewürztraminer wine. OSU yeast isolate produced comparable amount of terpene alcohols as yeast Vin13, a commercial yeast strain known to produce good aromatic white wine. However, OSU yeast isolate produced dramatically higher concentration of 4-vinylphenol and 4-vinylguaiacol, which give spicy, clove-like aroma, a major character of Gewürztraminer wines. The results were highly correlated to the sensory evaluation. OSU yeast isolate is a good candidate in fermenting aromatic white wine. Pre-fermentation cold maceration is not essential in making white wines.In the sixth study, glycosides precursors extracted from pinot noir grape have been reconstituted with a synthetic must. The must is fermented by yeasts belonging to previously isolated different genera.  Fermentation was allowed to take place for 48 hours. The fermented solutions were analyzed by headspace solid phase microextraction gas chromatography–mass spectrometry (HS-SPME-GC-MS) to determine the aroma composition. The results shows that the yeast genus exerts a critical influence on the levels of most varietal aroma compounds. The aroma produced from precursors such as norisoprenoids and terpenols has been affected."
http://hdl.handle.net/1957/61620,"The blast technique has been used as an effective soil improvement method to compact loose coarse-granular soils since 1930s, and the use of the blast technique is extended as an application of in-situ liquefaction testing to investigate the performance of full scale foundations and countermeasures against liquefaction in recent decades. Several guidelines have been provided to determine optimum blast specification; however “Trial and Error” is mostly used in designing blast-induced liquefaction. Then, the mechanism of blast-induced liquefaction is still poorly understood. Accordingly, not consistent design procedures for blast-induced liquefaction has effectively been used in various types of soils. The objective of this work is to improve the relationship between explosive energy and ground vibration, ground surface settlement, and residual pore water pressure resulting from blast-induced liquefaction. In order to achieve this objective, the data from USA, Japan, Canada, and New Zealand, including blast densification and in-situ liquefaction testing in terms of explosive, are collected and screened for quality. The new energy put accounting for multiple blasts is proposed, and the new empirical models are developed. Explosive is only a source relating to phenomena from blast-induced liquefaction. Vibration, settlement, and residual pore water pressure can be predicted based on the contribution of explosive energy. The developed models are useful as a preliminary tool for engineers to design blast-induced liquefaction testing safely."
http://hdl.handle.net/1957/61621,"Humpback whale populations in Antarctica are recovering after intensecommercial whaling in the 20th century. Along the Western Antarctic Peninsula (WAP)this recovery is occurring in an environment that is experiencing the fastest warming ofany region on the planet. To begin to understand the dynamics of this recovery undersuch dramatic climate change, we are studying the demography of these whales. To date,we have collected 583 biopsy samples from 239 individual males and 268 individualfemales during the austral feeding season from 2010, 2013-2016. The overall sex ratio ofour sample population is 0.89 M:F, supporting early observations that sexes mixrandomly on the feeding grounds. Additionally, we did document a significant seasonalincrease in the proportion of females along the WAP into the fall. We believe that thisshift represents a tendency for pregnant female humpback whales to depart last from thefeeding grounds. Furthermore, we examined progesterone levels of females to assign apregnancy status; providing to our knowledge, the first non-lethal estimation ofpregnancy rates in Antarctic whales. A series of female humpback whales of knownpregnancy status (n=29) from the Northwestern Atlantic, verified from field observations,were used as control samples to develop a logistic regression model, modelling theprobability of pregnancy relative to blubber progesterone concentrations. A pregnancystate was then assigned to females biopsied along the WAP by modelling theirprobability of being pregnant across the control model. Based on our assignment offemales as pregnant not-pregnant, mean progesterone levels for pregnant assignedhumpback whales from the WAP was 250 ng progesterone g blubber (n = 155). Themean value for not-pregnant assigned females was 2.10 ng progesterone g blubber (n =89). Pregnancy rates varied significantly across all years, from 36% in 2010 to 86% in2014.We detected a significant increase in the proportion of pregnant females (58% to72%) from summer to autumn across all years. Some female whales in this populationappear to experience a post-partum ovulation followed by conception (annualpregnancy); on average, more than half (52%) of female whales accompanied by calveswere pregnant. These are some of the first quantitative observations of the demographyof recovering humpback whale populations in the Antarctic and provides a criticalreference point as the Antarctic climate continues to change and populations recover fromwhaling."
http://hdl.handle.net/1957/61623,"Over the past several decades, American families have adopted thousands of children from outside of the United States. A large percentage of international adoptions come from South Korea (Selman, 2012). Transracial Korean-American adoptees must navigate circumstances unique to their situations as individuals with a birth culture and an adoptive culture that differ (Lee, 2003). Previous research has investigated outcomes related to psychological adjustment for this population (e.g. Benson, Sharma & Roehlkepartain, 1994; Juffer & van IJzendoorn, 2007), or considered the role that constructive exposure to racial and ethnic experiences serves in the positive psychological development of transracial adoptees (Yoon, 2000). No prior study, however, has evaluated the impact that cultural resources provided by adoption agencies may have on substance usage in adulthood for this population. The present study analyzed self-report responses from adult adoptees to examine an association between adoptee cultural post-adoption service utilization and substance usage represented by smoking in adulthood. In the data utilized for this study, cultural post-adoption resources included accessing cultural and historical information, networking with other adoptees, attending heritage camps, and traveling on heritage tours (Sacerdote, 2007). It was expected that transracial Korean-American adoptees whose families accessed cultural post- adoption services at higher rates would have lower reports of cigarette smoking behavior. A logistic regression model was used to consider the connection between use of cultural services and cigarette smoking. This study points to the potential beneficial effect that cultural post-adoption services may have on reducing activities detrimental to health in transracial Korean-American adoptees, and therefore warrants future consideration and research."
http://hdl.handle.net/1957/61624,"The Endangered Species Act is hailed as the “gold standard” of species conservation legislationboth in the U.S. and globally. There are scarce conservation funds that we as a society can spendon the recovery of endangered species, so it is important to understand how the parties involvedwith this legislation choose which species to prioritize. There is literature that shows thegovernment allocates funds to individual species mainly based on visceral characteristics such asbody length, and allocates funds in response to short term political pressure. However, there islittle literature on the motivations behind why private organizations target specific species inlawsuits against the Fish and Wildlife Service (FWS). In this paper, I conducted an empiricalstudy to find evidence for these motivations. I find that body length and the taxonomicclassification of the species (mammal, fish, etc.) is significant to how environmental non-profitsmake these decisions, and economic conflict is significant to how corporate groups decide whichspecies to target."
http://hdl.handle.net/1957/61625,"The purpose of this study is to critically analyze whether India’s National Population Policy of 2000 represents a paradigm shift in terms of how the nation-state conceptualizes and address population growth through formal population policy. Analyzed through transnational feminist theory, this study employed political discourse analysis as the research method. Composed of the three levels of analysis, PDA focuses on the political and historical contexts in which political discourse is constructed, how these contexts impact the formal linguistic and discursive features of policy, and the impact of political discourse on social practice. The findings from this study found that the NPP does represent a paradigm shift, specifically in terms of the policy framework upon which India’s National Population Policy is premised. However, discourse and social analysis demonstrate that the focus of this policy continues to be economic development, meaning that while a paradigm shift has occurred, this shift has not necessary been for the betterment of India’s women and marginalized populations."
http://hdl.handle.net/1957/61626,"Despite the now common usage of the term “girl”, there has been little call for pause and deeper analysis into what we actually mean when we use this term. In particular, animated film provides a wide scope of media texts that claim to focus on girlhood; but how do we in fact know girlhood? How is girlhood constructed? With these questions in mind, I use feminist textual analysis to examine three films—Nausicaä of the Valley of the Wind (1984), Kiki’s Delivery Service (1989), and Princess Mononoke (1997)—by acclaimed Japanese animator Hayao Miyazaki in which girl characters and girlhood play prominently into the film's construction as a whole. In particular, I examine how Miyazaki constructs girlhood through his storylines and characters and how these characters (i.e. girls) are then positioned in relation to three specific aspects of their representation: their use of clothing, their relationships to other characters, and their freedom of movement relative to other characters. In doing so, I deconstruct more traditionally held notions of girlhood in which girls are seen as dependent and lacking autonomy. Through Miyazaki’s work, I instead offer up a counternarrative of girlhood in which the very category of gender, and indeed “girls”, are destabilized. In doing so, I hope to provide a wider breadth of individuals the chance to see themselves represented in animated film in both significant and meaningful ways."
http://hdl.handle.net/1957/61627,"Increasing numbers of individuals aspire to, seek out, and need a college degree in order to be competitive in the job market (Goyette, 2008; U.S. Department of Education, 2013). College degrees provide access to economic, social, and health benefits (Abel & Deitz, 2014; Autor, 2014). The United States also needs more college educated citizens to fill employment demands (Lumina Foundation for Education, 2010). Despite the increased amount of college-seeking students and the country’s need for more college graduates, post-secondary institutions also face stress in meeting enrollment goals (Bidwell, 2013; Burd, 2015). These realities make the college planning process an important area of investigation.One aspect of this process is the role of parents in their children’s development of college-going expectations and college planning. Both within popular press and scholarly research, parents are lauded as a key mechanism for leveraging college opportunities for their children (Cohen, 2012; Mullen, 2010). Children of parents who have the time and means to be more involved in their education and college planning are more likely to enter college (Perna & Titus, 2005). For example, enrollment rates are higher for children of parents with knowledge of the financial aid system, admissions criteria, and other mechanisms of the process (Charles, Roscigno, & Torres, 2007; Hossler, Schmit, & Vesper, 1999; D. H. Kim & Schneider, 2005; Tierney, 2002). Parents experiencing financial strain and competing financial demands, such as retirement savings, may be less likely to provide support to their children (Napolitano, Pacholok, & Furstenberg, 2014). Despite evidence of their importance, it is less clear why and how parents develop college-going expectations and provide support. Further investigation of the influence of parents’ contexts on their role in this process and the support they can provide is warranted. The dissertation asked the following research questions: Manuscript 1: What do parents see college and a college degree providing for their children? How do parents’ own life experiences influence those thoughts and expectations? Manuscript 2: How do parents view, and support children in, college preparation and planning? How do these views and supports differ by parent and family characteristics? To answer these research questions, the study conducted 35 semi-structured interviews with parents of 35 college-bound high school seniors. Parents of high school seniors were at the end of the college planning process. This allowed for reflection on the role parents played. The sample came from two high schools within a Northwestern city of approximately 55,000 people.The results from the first manuscript report parents’ own school, work, and life experiences were important factors in shaping their college-going expectations for their children. For parents without a four-year degree, or did not earn one until later in life, a degree provides the means towards a stable, middle-class lifestyle. Parents recalled struggles because of limited prospects they do not wish their children to experience. Parents with two- and four-year degrees that experienced relative stability and sometimes success in work and home want the same for their children. Some parents emphasized the importance of gaining a specific credential for job placement, while others emphasized the general importance that furthering one’s education provides within any area of the job market. College-educated parents specifically mentioned the role college could provide in allowing for personal growth and perspective taking for their children.The second manuscript found parents felt supports provided very early in their children’s lives were critical to ensuring college access. Many academically socialized their children by stressing the importance of education. They made efforts to align their expectations with a positive environment for their children to grow. In high school, parents often discussed the selection of courses and ways to be competitive on their college application. For many of these families, this process was one of trial and error. They often learned from mistakes made from their older children’s transitions, which helped provide better support to their younger ones. Families with greater resources were able to provide more opportunities for their children, including the ability to visit colleges and the option to explore private and out-of-state institutions. For low- and middle-income families, particularly when the child was immature and lacked clarity on their desired career field, community college was often suggested and ultimately selected. All families were cost-conscious, making opportunities for aid important in perceived options and final selections. Together the two manuscripts highlight important ways parents provide support to their children to encourage college enrollment. Parents’ expectations, and the shape those expectations take, guided their parenting practices. The results suggest all parents, regardless of socio-economic position, can invest in their children’s education and set high expectations they hope for them to meet. However, more resourced families are better able to align expectations to environment. They are also more likely to be able to provide additional options to their children, both in college preparation and decisions. It is important for high schools, postsecondary educational institutions, and policy makers to understand that all families struggled at one point in the college planning process, and assuming more resourced families do not need much support is misguided. For all families, clearer policies on what parents and their children should be doing to prepare for college, as well as obtainable options for those families, given financial, personal, and academic factors, is needed."
http://hdl.handle.net/1957/61628,"Recent studies have shown that queer, trans, and non-binary students alike are experiencing sexual assault at higher rates than their heterosexual, cisgender counterparts (Cantor et al. IV). While conversations surrounding university sexual assault education and prevention have increased in recent years, this disparity suggests that not enough is being done to combat sexual assault. Drawing upon community-based research methods, this thesis utilizes an interview series conducted by the researcher to explore the current relationship between queer, trans, and non-binary survivors of sexual assault at Oregon State University and the University of Oregon and their access to university-provided resources. Through constructing an analysis of administrative violence, institutional betrayal, and trauma healing, this thesis explores shortcomings in university survivor resources, and identifies institutionally-specific needs for improvement to services."
http://hdl.handle.net/1957/61639,"To address several challenges faced in healthcare, the Triple Aim (3A) was targeted by institutions to improve health outcomes and patient experience while reducing the costs of health. Process improvement techniques in manufacturing, such as Lean systems, were applied as tools to achieve the 3A framework.  Unfortunately, the high level of employee burnout in healthcare, and the incorrect application of process improvement tools inhibited the good performance of the 3A. Accordingly, only ten percent or fewer of companies attempting to implement Lean achieved their goals. Most of these attempts failed because the organizations were unable to change their organizational culture. Companies have focused on macro level tools to implement Lean culture, forgetting the individual perceptions often required to instill a continuous improvement mindset. Satisfied employees have a positive perception of their work environment, which ensures their commitment, innovation, and performance. Likewise, employees are satisfied when they share values and beliefs with the organizational culture. Mirdad, Hille and Melamed (2015) proposed conceptual change model as a framework to improve successful employee transition to a Lean mindset. However, there are insufficient tools to prepare and monitor the effect of the conceptual change process on employee expectations at work. The objective of the study was to help healthcare organizations sustain improvements once made, by providing tools to assess employee perceptions along the conceptual change process. A customer relationship tool and an organizational survey were adapted to assess the Lean environment from employee perspectives.  Pilot studies were used to validate both surveys. Furthermore, this work provided tools to identify the specific aspects of organizational culture and work environments that affect employee satisfaction. The two surveys are recommended as tools to support different stages of the conceptual change model proposed by Mirdad, Hille and Melamed (2015). These tools could help trainers adapt the conceptual change process to the organization characteristics."
http://hdl.handle.net/1957/61640,"Cognitive impairment, or cognitive decline, a noticeable and measurable decline in cognitive abilities (e.g. memory and learning) that exceeds those attributed to normal aging, represents an early symptom of neurodegeneration and increased risk for progression to more severe dementias, such as Alzheimer's disease (AD). While the complex etiology of these conditions remains an area of active investigation, oxidative stress has been implicated as a primary factor in neurodegenerative disease pathogenesis. Zebrafish (Danio rerio) are a recognized model for studying the pathogenesis of cognitive deficits and the mechanisms underlying behavioral impairments, including the consequences of increased oxidative stress within the brain. The vertebrate brain is especially enriched in long-chain polyunsaturated lipids, such as ω-3 docosahexaenoic acid (DHA; 22:6 ω-3); therefore, lipid peroxidation is a likely contributor to neuropathology. Vitamin E (α-tocopherol; VitE), the body’s most potent lipophilic antioxidant, was first discovered in 1922 as an essential nutrient for preventing fetal resorption in rodents, and has since been linked with embryonic and neurological health in both numerous animal (including my own work with zebrafish) and human studies. VitE deficiency increases early miscarriage risk in humans, which poses public health concerns since estimates of inadequate dietary VitE intakes exceed 80% of the global adult population. However, nearly a century after its initial discovery, the underlying biological rationale explaining VitE’s essentiality for (neuro)development and brain function remains unknown.The purpose of this project was to provide for an evidence-based assessment of metabolic interactions between VitE and specific membrane lipids to elucidate the biochemical basis underlying VitE’s neurological function in vivo during neurodevelopmentand into adulthood. To accomplish this overall aim, I exploited a zebrafish model in which my lab group has pioneered the study of nutrition and dietary manipulation and the use of novel “omics” methodologies. I used both embryonic and adult conditions of VitE deficiency to publish compelling evidence that demonstrates the major role for VitE in the brain is to protect DHA and DHA-containing phospholipids (DHA-PLs) against oxidative stress, and without this antioxidant protection, ensuing secondary deficiencies in both DHA and choline coincide with increased morbidity, mortality, and or cognitive impairments. Further, my work shows that VitE’s antioxidant activity is vital for maintaining the cellular antioxidant network, and dysregulation of such aberrantly alters energy metabolism by severely compromising mitochondrial function. The studies included in this work, when considered together, provide insight as to how inadequate VitE perturbs DHA, phospholipid, and choline metabolism, resulting in dysregulation of other metabolic pathways as well as epigenetic methylation reactions, and how disruption of these processes compromises neurological and cognitive outcomes during neurodevelopment as well as in later life.My primary research goal was to help elucidate the mechanism(s) through which VitE contributes to lifetime brain health. To achieve this, I evaluated the consequences of inadequate VitE from the earliest stages of brain development through middle-age. My central hypothesis was that VitE protects DHA, a vital substrate for brain membrane phospholipid maintenance, and that dysregulation of DHA-PL status due to restricted dietary VitE severely perturbs critical events necessary for embryonic neurodevelopment that, ultimately, increase susceptibility for consequent, persistent cognitive impairments.First, I performed phenotypic assessments and lipidomics analyses, as well as developed a method to measure PL turnover in zebrafish embryos using H218O labeling, to gain mechanistic insight on the organism-level effects of developmental α-tocopherol deficiency. I hypothesized that VitE is required by the developing embryonic brain to prevent depletion of highly polyunsaturated fatty acids, especially DHA, the loss of which I predicted would underlie abnormal morphological and behavioral outcomes. Therefore, I fed adult 5D zebrafish defined diets without (E-) or with added VitE (E+, 500 mg RRR-α-tocopheryl acetate kg diet) for a minimum of 80 days, and then spawned them to obtain E- and E+ embryos. The E- compared with E+ embryos were behaviorally impaired at 96 hours post-fertilization (hpf), even in the absence of gross morphological defects. Evaluation of phospholipid (PL) and lysophospholipid (lyso-PL) composition using untargeted lipidomics in E- compared with E+ embryos at 24, 48, 72, and 120 hpf showedthat four PLs and three lyso-PLs containing DHA, including lysophosphatidylcholine (LPC 22:6, required for transport of DHA into the brain), were at lower concentrations in E- at all time-points. Additionally, H218O labeling experiments revealed enhanced turnover of LPC 22:6 and three other DHA-containing PLs in the E- compared with the E+ embryos, suggesting that increased membrane remodeling is a result of PL depletion. Overall, these data indicate that VitE deficiency in the zebrafish embryo causes the specific depletion and increased turnover of DHA-containing PL and lyso-PLs, which may compromise DHA delivery to the brain and thereby contribute to the functional impairments observed in E- embryos.Next, I investigated the underlying mechanisms causing developmental VitE deficiency-induced mortality in E- embryos using targeted metabolomics analyses embryos over five days of development, which coincided with their increased morbidity and death. VitE deficiency resulted in peroxidation of DHA, depleting DHA-PLs, especially phosphatidylcholine, which also caused choline depletion. This increased lipid peroxidation increased NADPH oxidation as well, which depleted glucose by shunting it to the pentose phosphate pathway. Using bioenergetic profiling analyses, I also found that VitE deficiency was associated with mitochondrial dysfunction with concomitant impairment of energy homeostasis. The observed morbidity and mortality outcomes could be attenuated, but not fully reversed, by glucose injection into VitE-deficient embryos at developmental day one. These studies together suggest that embryonic VitE deficiency in vertebrates leads to a metabolic reprogramming that adversely affects methyl donor status and cellular energy homeostasis, with ultimately lethal outcomes.I then shifted my focus to address outcomes of chronic VitE deficiency and to probe more thoroughly brain-specific consequences. I investigated behavioral perturbations due to isolated, chronic VitE deficiency in adult zebrafish fed diets that were either VitE-deficient (E- group) or sufficient (E+ group) for up to 18-months of age. I hypothesized that E- adult zebrafish would display significant cognitive impairments associated with elevated lipid peroxidation and additional metabolic disruptions in the brain. Using assays of both associative (avoidance conditioning) and non-associative (habituation) learning, I found E- adults were learning impaired compared with E+ fish, and that these functional deficits occurred concomitantly with the following observations in adult E- brains: decreased concentrations and increased peroxidation of polyunsaturated fatty acids (e.g. DHA), altered brain phospholipid and lysophospholipid composition, dysregulation of the cellular antioxidant network, and perturbed energy (glucose ketone), phosphatidylcholine, andcholine methyl-donor metabolism. Collectively, these data show that chronic VitE deficiency could lead to cognitive dysfunction through multiple potential mechanisms, including decreases in DHA, antioxidants, glucose, and choline, as well as corresponding dysfunction in related metabolic pathways (e.g. energy NAD(P)H and methyl-donor metabolism) within the brain.Finally, given the outcomes of my embryo studies demonstrating that increased lipid peroxidation in E– embryos perturbs their cellular antioxidant network, which ultimately disrupts aerobic energy metabolism, causing a significant decrease in whole-body (and, presumably, brain) glucose levels, and thus adversely impacts neurobehavioral outcomes, I investigated whether these consequences could be reversed via dietary remediation. Previous pilot studies showed that mortality and behavioral impairments are avoided with proactive VitE repletion, as an α-tocopherol emulsion administered into the yolk of 0 hpf E– embryos entirely prevented mortality and morbidity outcomes. However, remediation of VitE deficiency-induced (i.e. secondary) nutrient deficiencies only partially rescues E– embryos, as observed following glucose supplementation into the yolk at one day of age (24 hpf; after established VitE deficiency but prior to glucose depletion). Together, this data suggests the effects of developmental VitE deficiency may be prevented, but not necessarily reversed. I hypothesized, therefore, that deleterious outcomes of embryonic VitE deficiency cannot be ameliorated fully though later supplementation with VitE and other depleted nutrients (e.g. DHA and choline), and that long-term cognitive defects will persist in E– compared with E+ embryos despite dietary intervention.To test this hypothesis, I selected normal appearing E– or E+ embryos, then fed them a complete diet for 7 days and analyzed them for behavioral, biochemical, and morphological changes. I evaluated the embryo groups for up to 12 days post-fertilization (dpf). The E– group suffered significantly increased morbidity and mortality as well as altered DNA methylation status through 5 dpf when compared to E+ larvae, but upon feeding with a VitE-adequate diet from 5-12 dpf both the E– and E+ groups survived and grew normally; the DNA methylation profile also was similar between groups by 12 dpf. However, 12 dpf E– larvae still had behavioral defects. These observations coincided with sustained VitE deficiency in the E– vs. E+ larvae, despite adequate dietary supplementation. I also found continued DHA depletion and significantly increased lipid peroxidation in E– vs. E+ larvae. Further, targeted metabolomics analyses revealed persistent dysregulation of the cellular antioxidant network, the CDP-choline pathway, andglucose metabolism. While anaerobic processes were increased, aerobic metabolism was decreased in the E– vs. E+ larvae, potentially indicating mitochondrial damage and aberrant reliance on aerobic glycolysis (“Warburg effect”) in the E- group. Taken together, these outcomes indicate embryonic VitE deficiency causes lasting behavioral impairments due to persistent lipid peroxidation and metabolic perturbations that are not resolved via later dietary VitE supplementation.Collectively, the findings from these completed studies provide mechanistic evidence to explain VitE’s essentiality for human neurodevelopment and adult brain function, and yield new insights regarding the impact early-life VitE deficiency has on embryonic (neuro)development as well as on the inception of cognitive decline and ensuing neurological disorders. These outcomes may be used to support continued research investigating and promoting the importance of adequate VitE for optimal brain health throughout life."
http://hdl.handle.net/1957/61641,"Work-related musculoskeletal disorders (WMSDs) are prevalent amongsurgeons due to a variety of risk factors. Various subjective tools have beenused to investigate the associations between these risk factors and theircontributions to the development of WMSDs. This study aimed to provide asummary of a collection of popular subjective tools, including their applicationsand risk factors investigated using these tools, and to develop a comprehensivequestion pool and general guidelines to assist researchers to select tools basedon their research interests. Furthermore, the developed comprehensive questionpool was used to create a questionnaire and investigate the risk factorsassociated with developing WMSDs among surgeons with experience ofperforming a variety of surgical procedures.A systematic literature review was performed using six electronicdatabases. Articles that met inclusion criteria were investigated thoroughly.Questions were categorized based on the categories of risk factors and outcomemeasurements to create the comprehensive question pool. The results of the systematic review indicated that among 60 articles meeting inclusion criteria, 10 standard, 5 modified version, and 18 self-developed tools were recognized. The NASA-TLX and Nordic Musculoskeletal questionnaires were the most popular tools. Four groups of risk factors were identified: physical, cognitive, psychosocial, and individual factors. Physical and individual risk factors have received more attention compared with the psychosocial and cognitive risk factors. It was also found that investigating the short-term outcome measurements, such as discomfort, got more attention comparing the long-term ones.The second objective of this study was to use the developed comprehensive question pool to create a questionnaire and investigate the risk factors associated with developing WMSDs among surgeons. Seven surgeons from local hospitals participated in the pilot study. They answered to the questions about each of the categories of risk factors. The results of the questionnaire indicated that the levels of risk factors are different while performing different surgical procedures of open, laparoscopic, and robotic. The results also showed that surgeons who are aware of ergonomic guidelines experience discomfort in fewer regions of their bodies after performing surgeries.The results of this study indicated that only few tools can be used to investigate the risk factors from all four categories of risk factors. Moreover, risk factors from different groups got different levels of attention. Using the developed comprehensive question pool helped us to create a questionnaire more efficiently to investigate the risk factors associated with developing WMSDs thoroughly. The results of the survey itself showed the association between the risk factors and prevalence of discomfort among surgeons and different levels of risk of performing different surgical procedures. The results also indicated the importance of ergonomic guidelines awareness in reducing the risk of developing WMSDs among surgeons. Since most of the risk factors included in these tools are very common among various occupations, the general guidelines developed in this paper can be used by researchers who are interested in reducing the risk of the development of WMSDs among surgeons and workers in other occupations."
http://hdl.handle.net/1957/61643,"During the first decades of the twentieth century different attempts were made to unify the diversifying and specializing sciences. One of these attempts manifested as the History of Science. Established in 1913 with the academic journal Isis, its first article written by George Sarton clarified that the field was created to keep connected and synthesize the sciences, which had become highly stratified over the previous century. The primary concern was that scientists would lose the ability to communicate across disciplines, that the many branches would disintegrate into ever-increasing specializations, and that science itself would lose its meaning. This thesis looks at another attempt to unify the sciences that emerged at this time in Germany: phenomenology.Edmund Husserl created phenomenology to provide the unified foundation of the sciences. The phenomenologist who accomplished this was one of his students, Edith Stein. This thesis looks at Stein’s historical context: the intellectual influences and the European cultural crisis that conditioned phenomenology’s first decades. This thesis then examines Stein’s phenomenology and its consequences. My analysis found that as a result of her phenomenological investigation of empathy, Stein asserted the foundation of the sciences is the unfolded person."
http://hdl.handle.net/1957/61644,"Scalable array transceivers with wide frequency tuning range are attractive for next-generationradios. Key challenges for such radios include generation of LO signals with widefrequency tuning range, scalable synchronization between multiple array unit cells andtolerance to in-band and out-of-band interferers. This thesis presents approaches toaddress these challenges in commercial CMOS technologies.The first part focuses on a series resonant mode-switching VCO architecture thatachieves both state-of-art area and power efficiency with an octave frequency tuningrange from 6.4-14 GHz achieved 186-dB-188-dB Figure-of-Merit (FoM) in 65 nm CMOStechnology. The scalability of this approach towards achieving even larger FTR is alsodemonstrated by a triple-mode 2.2 GHz to 8.7 GHz (119% FTR) CMOS VCO.In the second part a scalable, single-wire coupled-PLL architecture for RF mm-wavearrays is presented. The proposed architecture preserves the simplicity of a daisy-chained LO distribution, compensates for phase offset due to interconnect, and provides phasenoise improvement commensurate to the number of coupled PLLs. Measurements on a28 GHz CMOS prototype demonstrate the feasibility of this scheme.The third part of this thesis presents filtering techniques for in-band blocker suppression.A spatial spectral notch filter design for MIMO digital beam forming arrays is proposedto relax the ADC dynamic range requirement. Orthogonal properties of Walsh functionsincorporated into passive N-path approach enables reconfigurable notches at multiplefrequencies and angles-of-incidence. A 0.3 GHz-1.4 GHz four-element array prototypeimplemented in 65 nm CMOS achieves > 15-dB notch filtering at RF input for twoblockers while causing < 3-dB NF degradation.Finally, a code-domain N-path receiver (RX) is proposed based on pseudo-random(PN) code-modulated LO pulses for simultaneous transmission and reception (STAR)applications. A combination of Walsh-Function and PN sequence is proposed to createcode-domain matched filter at the RF frontend which reflects unknown in-band blockersand rejects known in-band TX self-interference (SI) by using orthogonal codes at RXinput thereby maximizing the SNR of the received signals. The resulting prototype in65 nm is functional from 0.3 GHz-1.4 GHz with 35 dB gain and concurrently receivestwo code-modulated signals. Proposed transmitter (TX) SI mitigation approach resultsin 38.5 dB rejection for -11.8 dBm 1.46 Mb s QPSK modulated SI at RX input. TheRX achieves 23.7 dBm OP1dB for in-band SI, while consuming ∼35 mW and occupies0.31 mm2"
http://hdl.handle.net/1957/61646,"Across the U.S. social activism is on the upsurge, offering possibilities for a revolution against capitalism. However, these possibilities are potentially undermined by entrenched factionalism amongst the left. At root, such in-fighting is fostered by the creation of false dualistic frameworks on the transition out of capitalism and into the next social system. These frameworks are categorized into two typologies labelled the “strategic” and “prefigurative” camps. Blasting open these dualisms can bridge the left and allow for fresher views on revolution and the role of the state, leadership and vanguardism, the significance of democracy, and the value of utopian dreaming. Replacing these frameworks is a methodology called the radical imagination, which poses that within everyday life exist creative opportunities for rebellion. The radical imagination enables the process of seizing spaces for revolutionary (re)production. By viewing daily life as the struggle against alienation, possibilities abound in capturing previously mundane spaces and injecting them with revolutionary activity."
http://hdl.handle.net/1957/61647,"This study explores the narratives of male undergraduate students and their experiences with body dissatisfaction. The inquiry utilizes a constructivist epistemology and a qualitative design in order to best understand previous and current experiences of individuals who have reflected upon their body image as part of their identity. To gather data, this study utilizes narrative inquiry through in-depth interviews and asks participants to share stories in their lives that have shaped the way they view their bodies. Additionally, this research attempts to learn more about their coping strategies, including self-care, help-seeking, and risk-taking practices connected to body dissatisfaction. Participant responses were used to create themes that best represented the coping strategies of the sample of male undergraduates. The results of the study could be utilized by universities to provide direction to counselors and university practitioners in their support of body dissatisfied male students as well as in their promotion and programming efforts in body image."
http://hdl.handle.net/1957/61648,"Over the course of the last century, a successful history of fire suppression has contributed to unsuccessful present day control over wildfire. In the absence of fire and the janitorial and ecological services it provides, drier inland forests are shifting in species composition and exceeding densities that cannot survive and persist in current fire patterns occurring on the landscape. In the past two decades, managers have introduced restoration use of fire and thinning for their ecological benefits and to convert fuel-heavy forests to fuel-lean landscapes to lessen the threat of stand-replacing wildfire. In this study, we evaluated the long-term impact of forest restoration practices on soil biochemistry and the mycorrhizal fungi associated with ponderosa pine (Pinus ponderosa). Study sites were located in the Blue Mountains of northeastern Oregon where treatments implemented in 1998 and 2000 included mechanical thinning of forested areas, prescribed fire, a combination of thinning followed by fire, and an untreated control. Soil sampling for this study occurred in 2014 and included four replications of each treatment for a total of 16 experimental units. Fungal-specific sequence analysis of morphotyped root-tips from ponderosa pine was used to assess the species diversity and root-tip density abundance of each fungal taxon within each sample unit. Additionally, litter depth, pH, and soil carbon (C), nitrogen (N), and Bray phosphorus (P) were measured from soil cores that were stratified into depths of 0-5cm and 5-10cm. Bray-P, pH, and percent C differed among treatments. Bray-P and percent C and N differed between soil depths. The results indicated that given a decade-plus period of recovery, mycorrhizal fungi in dry inland forests dominated by ponderosa pine returned to levels similar to the untreated controls. Similar litter depths across treatments suggest that litter depth stabilizes over time in these forests. Soil C and nutrient differences may have been driven by the thinning treatments and the resultant deposition of residual slash following harvesting or the consumption of slash by prescribed fire. Elevated ectomycorrhiza biomass in the thinning and burning treatment may be a response of the host trees that creates a larger nutrient acquisition network in a less fertile environment. The results of this study demonstrate the resiliency of these forests to disturbances associated with restoration treatments, providing managers increased flexibility of options if maintaining abundant and persistent fungal communities is a concern. Given that the mean fire return interval for these forests is 15 years, a second reintroduction of prescribed fire may be timely."
http://hdl.handle.net/1957/61649,"Species distribution models (SDM), which  quantify  the correlation between the distribution of a species and environmental factors, are increasingly used to map and monitor animal and plant distributions in the context of awareness of environmental change and its ecological consequence. For perfect data, this is a straightforward classification problem from environmental features to presence or absence labels. But for imperfect data, such as the citizen science data from eBird, in which volunteers report locations where they observed or failed to observe sets of species, mistakes will cause label noise. In this case,  both  the class features and the observation features would be  sources of  false positive noise and false negative noise. However, few common modeling approaches for this task  address these sources of noise explicitly. In this work, I explore the idea of treating this problem as a classification problem with class-conditional label noise.  By leveraging additional information about observation features, this model outperforms other candidates significantly when sufficient data is available. I describe the conditions under which the parameters of my proposed model are identifiable, explore the impact of model misspecification,  and apply this model to simulated data and real data from the eBird citizen science project."
http://hdl.handle.net/1957/61650,"School is a hostile environment for many LGBTQ youth. Teachers participate, consciously or unconsciously, in perpetuating oppressive heteronormative expectations in the classroom both through the overt and covert curriculum. Yet, pre-service teachers are under-trained about questions related to gender and sexuality during their teacher preparation. This qualitative study explores the reasons behind this lack of widespread training by focusing on the experiences of eight teacher educators in a public university located in the Northwest of the United States. Data was collected over the course of nine months through the recording of interviews with teacher educators, the analysis of syllabi, class observations, and an online survey answered by eighteen pre-service teachers. Data was then analyzed through an intersectional theoretical framework relying on queer theory, Queer of Color and Queer Indigenous Critiques, and critical pedagogy. Four themes emerged from this analysis, pointing to the limits of certain practices, and to the obstacles faced by teacher educators who were generally hesitant to include non-normative genders and sexualities in their curriculum: Practices, Self, Others, and Institution. Discourses at work around gender and sexuality in education, and the impact that neoliberalism’s stranglehold on higher education exerts on faculty’s practices highlight the structural factors that also come into play in the absence of preparation for future teachers to challenge heteronormativity."
http://hdl.handle.net/1957/61651,"Animals can be naturally exposed simultaneously to multiple stressors. These include habitat changes, contaminants, diseases, invasive species, parasitism, and predation. Exposure to various combinations of biotic and abiotic stressors may induce behavioral changes that affect the way an individual interacts within its environment.Like other groups of organisms, amphibians are exposed to a wide array of both natural and introduced stressors. However, due to their life history and utility in experimental studies, amphibians can serve as useful models to examine how an animal behaves when encountering various stressors. Unlike other vertebrates, amphibians have a biphasic life cycle and are aquatic or terrestrial during different times of their life cycle. In their aquatic phase, amphibians may use chemical cues to detect the presence of stressors. For example, predators may emit chemical cues that an amphibian could detect, or another amphibian that has been captured may emit chemical cues that alert nearby       conspecifics of a threat. Moreover, amphibians may use chemical cues to detect parasites when parasites are at certain life stages.In this thesis, I experimentally tested the behavioral reactions of the larvae of a model amphibian species to the presence of alarm cues emitted by amphibian larvae, a pathogen, and a parasite. The pathogen and parasite were an emerging infectious chytrid fungus and a trematode, respectively. Although the interaction between anti-pathogen, anti-parasite and anti-predator responses in larval amphibians has received some attention, results have shown strong interspecific variation in behavioral responses by amphibians to pathogens, parasites, and predators. Moreover, there is less information about the response of amphibians to simultaneous stressors. To examine the behavioral responses of an amphibian to predation cues, pathogens, and parasites I exposed western toad larvae to combinations of the chytrid fungus, Batrachochytrium dendrobatidis (Bd), a trematode parasite, and conspecific alarm cues in a fully factorial experiment. Based on the findings of Han et al. (2011), I predicted that prior exposure to Bd would result in tadpoles having increased activity levels when in the presence of echinostome trematode ocercariae and conspecific alarm cues. Based on the findings of Hews and Blaustein (1985), I also predicted that tadpoles exposed to echinostome cercariae and conspecific alarm cues would avoid the conspecific alarm cues. I found that prior Bd exposure did not influence activity levels of tadpoles exposed to echinostome cercariae and conspecific alarm cues but it did influence avoidance behaviors. Tadpoles that had been previously exposed to Bd displayed increased avoidance behaviors when in the presence of echinostome cercariae and conspecific alarm cues when compared to tadpoles that had only been exposed to echinostome cercariae and conspecific alarm cues. The results fromthis research provide more information about the interactions of commonly co-occurring stressors and an emerging pathogen and their effects on amphibian behavior."
http://hdl.handle.net/1957/61652,"Phytophthora ramorum continues to cause extensive mortality of tanoaks in southwestern Oregon. Rain readily washes inoculum down through the canopy, causing new infections on the lower parts of the tree and neighboring host plants. Although this aspect of dispersal is well understood, the relative importance of infested soil and leaf litter as factors contributing to the spread of disease remain unclear. The primary objectives of this study were: (i) to compare the amount of inoculum washed down through the canopy to that splashed up from soil and litter, and (ii) to detect and quantify inoculum in relation to soil depth. Over the course of the 2014-2015 rainy season, rainwater was collected 8 times and soil sampled 3 times from within the Generally Infested Area in Brookings, Oregon. Rainwater, soil, and litter were subject to both qPCR and traditional baiting methods. P. ramorum was detected by qPCR more frequently in splash-up from the ground surface than from canopy throughfall. P. ramorum was only detected in soil twice via qPCR and was never recovered by baiting. In canopy throughfall water, qPCR also proved to be a more sensitive way to detect the pathogen than baiting with whole rhododendron leaf baits. In the Oregon tanoak forest studied, quantification of Phytophthora ramorum was not possible because inoculum      levels were too low and distribution was too uneven for reliable detection with the methods employed."
http://hdl.handle.net/1957/61653,"Communities across the American West face new challenges in water management: historical management structures devised to prioritize economic uses, predominantly agriculture, are being tasked with adapting to address growing and changing populations, unaddressed species and ecosystem needs, and climatic changes. Scholars in the field of collaborative governance posit that collaborative processes may generate more innovative and flexible solutions better suited to resolving modern environmental problems, such as water management, than traditional regulatory approaches. However, there is a debate within this field about how collaboration and regulatory enforcement in the form of litigation may interact: does litigation destroy collaborative governance efforts or does litigation serve as a mechanism to facilitate collaboration? This thesis explores this question through a qualitative case study of the Upper Deschutes River Basin in Oregon, which provides an example of a community wrestling with the changing context of water management in the American West. Stakeholders, representing the diverse water interests in the basin, began two collaborative processes, the Upper Deschutes River Basin Study and the Deschutes Basin Habitat Conservation Plan, to lay the foundation for a new water management regime to address this changing context. However, a participant in these processes was concerned that they were not progressing and filed a lawsuit under the citizen suit provision of the Endangered Species Act seeking to mandate immediate flow changes in the Upper Deschutes River to protect the federally threated Oregon spotted frog. The results of this research, derived from semi-structured interviews with participants in the processes and observation and document analysis techniques, reveal that in this case the litigation, while having negative effects, did not destroy the collaborative processes; rather the litigation served as a mechanism to facilitate the collaborative processes by increasing incentives for the powerful to commit to making change within the collaborative processes and creating an assurance mechanism for the weak that their interests will be met in the collaboratives. The results of this research also illustrate that while the litigation was seen to help facilitate the collaborative processes, ultimately collaboration is perceived as the best method for developing a new water management regime in the basin."
http://hdl.handle.net/1957/61654,"Two parties, Alice and Bob, hold inputs x and y respectively. They wish to compute a function f of their inputs. In an ideal world, f (x, y) could be calculated by sending the inputs to a trusted third party. In the absence of such a third party, Alice and Bob are required to communicate directly. Alice would like the real-world computation of f to reveal no more about her input x to Bob than he could have deduced from the ideal-world interaction. In addition, Alice would like this guarantee to hold even if Bob cheats at the protocol. Bob would like the computation to have the same properties with regards to security against malicious Alice.If both parties have unlimited computation power, such a feat is impossible for all but the simplest f . We introduce a trusted third party that can compute for Alice and Bob a different function g. If f can be computed in this modified model, we say that f reduces to g. Some g, which we call complete, have a special structural property that allows all f to reduce to g. These reductions are well-studied. Unfortunately, if g does not have this structural property, we do not fully understand reductions to g. This thesis describes our work in characterizing this landscape.In particular, we show that if f reduces to g by some deterministic protocol or by a randomized protocol with a strict sub-logarithmic bound in the number of communication rounds, then we can shorten these protocols to use only a single call to g. In addition, we give a combinatorial property of f and g that is present if and only if this single-call protocol is possible. We also show an example of f and g where a randomized and potentially super-logarithmic protocol is required for f to reduce to g. This example hints at a direction for future investigation towards the complete characterization of these reductions."
http://hdl.handle.net/1957/61655,"Following a history of tensions surrounding concubinage in medieval and early modern Spain, the Church sought greater control of religious life, particularly over the sacrament of marriage, via the Holy Office of the Inquisition. The Church exercised its strengthened restrictions and prosecuted these relationships with more frequency, as did civil courts. Still, concubinage [termed 'amancebamiento' within the archive] took place in many forms and with frequency throughout the viceregal period in New Spain. This calls into question whether public perceptions of sex and sexuality reflected those imposed by the Church. Using the lenses of colonialism, gossip, and narrative, this thesis will address the following concerns: Why did these relationships persist at the risk of prosecution? Who engaged in these types of relationships? How did the courts, including the Holy Office, prosecute these offenses? What social implications did amancebados face for their relationships? Did the Church seek to control viceregal sexuality or the propagation of dissident beliefs? Based on archival research conducted at the Archivo General de la Nación in Mexico City, this thesis argues that in spite of attempts to regulate sexuality throughout the viceroyalties, ecclesiastical rhetoric did not sexually suppress the viceregal populace, nor did it prevent lay interpretation of Catholic doctrine."
http://hdl.handle.net/1957/61656,"The first goal of this master’s thesis was to investigate the linkage between a non-destructive testing method, surface resistivity, and premature concrete deterioration brought on by chloride ingress and or freeze-thaw cycling. The experimental method for this project consists of taking surface resistivity measurements of reinforced concrete slabs after they were ponded with a magnesium chloride de-icing solution, containing a corrosion inhibitor. Reinforced concrete slabs and companion concrete cylinders also underwent freeze thaw cycling to observe its effect on surface resistivity in conjunction with exposure to chlorides. Many factors such as internal and ambient temperature and relative humidity affect surface resistivity measurements so this data was also collected.  To compare the surface resistivity to the rate of chloride ingress, cores were taken from the slabs. As expected, the surface resistivity of the concrete slabs initially increased while the concrete cured and lost moisture due to the hydration process and to the environment. Once ponding of the chloride solution started, however, there began to be a decrease in surface resistivity. This decrease in surface resistivity is believed to be caused by the increase of free chlorides present in the slabs after being saturated with the de-icing solution. The surface resistivity of the corresponding slabs that were ponded with tap water remained constant. These results show that surface resistivity measurements are a potential indicator of chloride ingress and, therefore, may correlate to risk of corrosion in reinforced concrete. The effect of freeze thaw cycling on surface resistivity, according to this study, is that it increases the surface resistivity. This is due to the micro-cracking in the concrete matrix, caused by the freeze-thaw damage. In the second part of this master’s thesis the corrosion susceptibility of ductile iron pipe (DIP) was investigated. Ductile iron pipe has been used mostly in the water transmission field since the 1950s. At that time, ductile iron pipe replaced traditional cast iron pipe, due to ductile iron’s superior strength properties. More recently, ductile iron pipe has been considered as a replacement for traditional timber poles for power transmission.  While there are benefits to using ductile iron such as its strength and sustainability, ductile iron suffers from pitting corrosion due to the nodular structure of its free graphite. This type of corrosion can lead to severe deterioration of the pipe in localized areas. Due to this, researchers have been studying ductile iron durability and developing solutions for its durability issues. In this research study ductile iron was tested for its susceptibility to corrosion. Samples were subjected to an accelerated corrosion process inside a salt fog chamber. After the samples had corroded, mass loss measurements were taken. Tensile strength tests were also done before and after corrosion. Stainless steel samples were tested alongside the ductile iron for comparison. In addition to the corrosion chamber and strength tests, electrochemical tests were done to characterize the corrosion kinetics of ductile iron. Stainless steel samples showed almost no change in mass loss and tensile strength after corrosion. Ductile iron samples, on the other hand, had a corrosion rate of approximately 52.6 mpy (1.3 mmy), and a 10 ksi (69 MPa) decrease in ultimate tensile strength after corrosion. Open circuit potential results showed that the ductile iron samples had a higher potential, and thus, lower corrosion resistance than the stainless steel samples. Similarly, electrochemical impedance spectroscopy showed that stainless steel had a greater impedance than ductile iron, which correlates to increased corrosion resistance. Analysis of cyclic polarization curves showed that the ductile iron samples had much higher corrosion rates than stainless steel samples. However, the corrosion products which formed on the ductile iron samples appeared to be protective in nature. This indicates that ductile iron may have good field performance."
http://hdl.handle.net/1957/61657,"Decisions about college are significant in the lives of students and their families, especially since these are often the first major life-decisions that adolescents are able to make largely on their own (Galotti, 1995; Galotti & Mark, 1994). It is widely recognized that family history plays a role in whether a person chooses to pursue post-secondary education, with children of parents that hold college degrees far more likely to follow in their footsteps. Little is known, though, of other family relationships and their impacts on educational decisions. Sibling relationships have been identified as playing a large role in development during childhood and adolescence, with siblings acting as role models, supporters, collaborators, and competitors, among other things (Cicirelli, 1995; Milevsky, 2005; Seginer, 1998; Weaver, Coleman, & Ganong, 2003). Positive sibling relationships have been associated with child adjustment (Pike, Coldwell, & Dunn, 2005), while conflictual relationships between siblings can help adolescents learn about social rules and boundaries (Raffaelli, 1992). In young adulthood, siblings spend less time with one another but are more likely to report emotional and warm relationships along with a decrease in conflict (Buhrmester & Furman, 1990; Scharf, Shulman, & Avigad-Spitz, 2005). The quality of the relationship between siblings has also been found to be critical since these relationships play a role in individuals’ psychosocial and emotional development. Positive sibling relationships are related to positive sibling adjustment, and positive and affectionate relationships can be protective in the face of stressful situations (Branje, van Lieshout, van Aken, & Haselager, 2004; Gass, Jenkins, & Dunn, 2007; Pike et al., 2005; Senginer, 1998). This thesis is grounded in the life course theoretical perspective. The life course perspective provides many conceptual ideas that are promising for understanding the role siblings may play in first-generation students’ decision-making process around college. Specifically, the main life course principles of historical time and place, linked lives, timing in the life, and agency are considered, along with institutionalization of the life course and cumulative advantage and disadvantage.This exploratory study examines sibling and parent relationships as they relate to college decision-making for first-generation college students. First-generation college students are defined as those whose parents never enrolled in college or those whose parents never graduated from college (Cabrera, 2014; Nunez & Cuccaro-Alamin, 1998; TRIO History; TRiO Student Support Services, 2016). Of particular interest for this study is whether the quality of sibling relationships impacts first-generation students, and if their influence is greater than the influence of their parents. Measures used in the study include a variation of the Warmth scale from the Adult Sibling Relationship Questionnaire-Short (Stocker, Lanthier, & Furman, 1997; Lanthier, Stocker, & Furman, 2000), parent and sibling college decision-making matrices, and open-ended questions pertaining to whether and how siblings and parents impacted college decisions. Research questions posed for this study are as follows: 1. Who contributes more in the college decision-making process, parents or siblings? 2. Is sibling warmth associated with college decision-making above and beyond demographic factors, first-generation status, and whether or not siblings have attended college? 3. Do siblings provide more assistance in the college decision-making process among first-generation students than among non-first-generation students? 4. Among first-gen students, are the roles of siblings and parents less differentiated in the college decision-making process?Results from this study indicated that siblings and parents contribute a significantly different level of assistance in the college decision-making process of students, with parents contributing a significantly larger amount (as indicated by the number of pre-college activities that parents participated in compared to siblings). Sibling warmth was found to be significantly associated with college decision-making, above and beyond demographics, first-generation status, and siblings’ college attendance. For first-generation students, siblings did not contribute a higher level of assistance in the college decision-making process when compared to their non-first-generation counterparts. Finally, it was found that while parents play a larger role than siblings in the college decision-making process of students, the difference in support between parents and siblings is far less distinct when the student is first-generation.This research provides insight into how sibling warmth and college attendance of siblings can play a role in the college aspirations of others in the family. It also highlights the importance of siblings specifically for first-generation students, indicating that while parents remain a significant source of support, siblings in these situations can be a critical supplementary resource."
http://hdl.handle.net/1957/61658,"Reasoning about 3D shape of objects is important for successful computer visionapplications in robotics, 3D rendering and modeling. In this thesis, we address twoproblems { First, given an image, we generate 3D shape of the foreground object thatappears in the image. Second, we predict the class label of the input 3D object shape.Recent work uses convolutional neural networks (CNNs) for these problems. However,their training is difficult, since it requires a large amount of training data. Also, in 3Dshape generation, existing approaches can not generate realistic 3D shapes and havelimited variations in generated 3D shapes.This thesis addresses these issues. We present two novel approaches, one for eachproblem. First, for 3D classification, we formulate CNN learning as a beam searchaimed at identifying an optimal CNN architecture as well as estimating parametersof such an optimal CNN. This model pursuit approach is evaluated on 3D ShapeNetdataset. Second, we introduce a 3D-VAE-GAN (3D Variational AutoEncoder - Generative Adversarial Network) model to synthesize high-quality 3D objects from 2D imagesin ObjectNet3D dataset. Our experimental evaluation shows that our new CNN learningachieves the state-of-the-art results with better modeling efficiency, i.e., with fewer parameters which are much easier to train. Also, in 3D shape synthesis, we achieve largervariability in shapes."
http://hdl.handle.net/1957/61659,"Renewable energy sources are becoming increasingly important due to their low environmental impact and limitless nature. This thesis explores the design of a 250 mW permanent magnet linear generator wave energy converter to power ocean sensors. While many wave energy converters exist, this is a unique application because the wave energy device is neither at the surface nor at the seafloor and is a low power application. The permanent magnet linear generator detailed in this thesis would enable the continuous operation of ocean mixing sensors with minimal maintenance and intervention."
http://hdl.handle.net/1957/61660,"Bicyclists are one of the highest and most vulnerable road users. This is due to the higher likelihood of being seriously injured when involved in a crash. This research seeks to understand two different behavioral interactions of an implemented facility user: the motorist (secondary user) and bicyclist (primary user). The resulting model is for road segments only and does not include intersections. For the bicyclists behavior this research attempts to understand the use of available buffered bicycle lane; a bicyclists’ sway (or side to side movement) within a buffered bicycle lane; the passing of another bicyclist; and the behavior of vehicles adjacent to the travel lanes under different operating conditions of traffic densities, speeds, and facility design. For the motorist behavior, the research is seeks to understand the motorist and bicyclist behavior during a high-risk vehicle bicyclist conflict point to define near miss collisions. The data that is to be evaluated by an ANOVA are the non-truncated and truncated data sets for each buffered bicycle lane facility. A binary logistic regression (logit) model was used to evaluate the behavior of near miss collisions between a bicyclist and motorized vehicles."
http://hdl.handle.net/1957/61661,"Untreated wood is inherently hygroscopic and moisture content variations can have substantial effects on dimensional stability leading to the development of deep surface checks that further enhance moisture uptake and ultimately encourage deterioration. The horizontal exposure of wood crossties makes water repellency and dimensional stability particularly important in railroad applications. Ties are typically preservative treated to prolong service life. Preservatives primarily protect against insect and fungal attack, but many also alter hygroscopicity and enhance dimensional stability. Currently, there is no standard method for assessing the water repellency and its interaction with dimensional stability in large wooden members such as railroad ties.Potential methods for assessing moisture behavior were investigated on four wood species. Untreated or materials treated with creosote, pentachlorophenol or ammoniacalcopper zinc arsenate were assessed. Samples were subjected to eight accelerated wetting and drying cycles. Dimensional stability and water repellency were evaluated after each cycle using digital image analysis techniques to quantify checking and observing water droplet contact angle over time, respectively. Water repellency varied widely with cycles, but creosote and pentachlorophenol treated samples provided the best resistance to moisture uptake. Dimensional stability was more variable and more dependent on treatment in terms of check development. The results of this work will be used to develop a rapid, reproducible and cost-effective method for assessing the water repellency and dimensional stability of preservative treated wood used in railroad and other applications."
http://hdl.handle.net/1957/61662,"Load modeling that can accurately represent the dynamic behavior of generators and loads is important in the operation and planning of transmission and distribution systems. Yet, it is a complex subject in power system research communities and electric utilities. The composition of the end-use loads is changing continually based on climate zone, season, and time. The WECC composite load model has been developed recently to better represent Fault Induced Delayed Voltage Recovery (FIDVR) events, which is caused by air-conditioning stalling phenomena. The approach is based on using the information of the load class at the substation level and composition of air-conditioning, induction machines, power electronics, and static loads associated with the load class. Therefore, it is important to be able to identify and classify the load class. This can be accomplished by using machine learning based signature detection since each load class has a unique signature response due to a particular disturbance in the system.         The objective of this project is to implement a supervised learning, Artificial Neural Network (ANN), algorithm to detect and classify the composite load signatures in terms of residential, commercial, agriculture, and mixed load class. Furthermore, the process of creating WECC composite load model data, using the Load Model Data Tool (LMDT), to be used in time-domain dynamic simulation (PSS E) is demonstrated. The One-Area Reliability Test System is used for the purpose of demonstration and validation of our proposed methodology.         In term of classification accuracy, the classifier gives about 87 percent using standardization for data normalization and Principle Component Analysis (PCA) for feature reduction."
http://hdl.handle.net/1957/61663,"One of the biggest hurdles for a juvenile salmonid (Oncorhynchus mykiss) is migrating downstream from freshwater spawning grounds to the ocean. Juveniles from wild broodstock were reared from the South Santiam River for more than 1 year at the Oregon Hatchery Research Center (OHRC) in Alsea, OR. The fish were reared for 9 months on two treatments: conventional tanks and tanks with a scalable complex structure that was easy for hatchery staff to implement and clean. Both groups were reared at densities below conservation hatchery standards and fed low-lipid experimental diets. Assessment of fish quality included morphometric measurements, behavioral assessments, and growth rate analyses. Fin morphometrics showed the dorsal and caudal fins of fish reared in tanks with structure had less fin degradation than fish reared in conventional hatchery tanks. The two treatments also provided fish for behavioral assessments, including predator-avoidance and foraging behavior patterns. A separate third component tested fish growth rate related to the egg size of individual at spawning. It was shown that fish originating from smaller eggs (within a single female) grow at a faster rate than larger eggs. The goal of this project is to improve on current hatchery practices to produce a wild “surrogate” fish for tagging studies when a wild run is not large enough to provide experimental animals."
http://hdl.handle.net/1957/61664,"Humans have a desire for a connection among others, and they also have a desire for both giving and receiving affection, regardless of class, age, gender, cultural or religious backgrounds. There is a plethora of research on the health benefits for both giving and receiving affection in romantic and family relationships. However, there is a lack of research about the benefits of receiving affection in the workplace. The general discourse surrounding workplace affection is negative because it is viewed as inappropriate in a workplace setting. However, affection is innate and humans are adept at giving and receiving affection. In fact, there are consequences on a person’s mental and physical health when this desire is not met. Therefore, the objective of this study was to understand if affection in the workplace could be beneficial on an employee’s perception of stress, depression, and job satisfaction. Also, to learn if the personality characteristics self-esteem, introversion and trait affection impact perceptions of affection in the workplace. The study found that personality characteristics do play a role in perceptions of received coworker affection. The study also found that affection does have an impact on stress, depression and job satisfaction."
http://hdl.handle.net/1957/61673,"The internet-of-things is a growing market segment which is based on an arrayof portable communication devices with high power efficiency. Advanced semiconductortechnology can easily improve their digital performance, but the samecannot be said for the analog blocks which are vital to their operation. Highperformance analog circuits continue to use conventional design techniques andarchitectures at the expense of power efficiency. Deeply scaled CMOS exaggeratesthis trade-off, opening the door for novel system techniques that take advantage ofthe digital nature of sub-micron transistors. This research focuses on two highlydigital ADCs which can mitigate the short channel effects of limited output swingand low intrinsic gain while also benefiting from process scaling.First, a multi-domain ADC is used to perform quantization on both voltageand time domain signals, relaxing the power-performance trade-off. This hybridapproach can lead to a high resolution, high efficiency data converter in scaledprocess. A prototype ADC was fabricated in 180nm CMOS, showing an SNDRof 73 dB, operating at 20 MHz sampling frequency, with a power consumption of1.28 mW.Next, an automated synthesis process is used to automatically generate a highspeed VCO-based quantizer from verilog code. Stochastic spatial averaging iscombined with a high speed open-loop noise-shaping quantizer to provide enhancedresolution in the presence of device mismatch. Simulation results of a prototypeADC in 180nm CMOS shows an SNDR of 49 dB, operating at 800 MHz samplingfrequency and 50 MHz signal bandwidth."
http://hdl.handle.net/1957/61674,"In this note, we generalize recent work of Mizuhara, Sellers, and Swisher that gives a method for establishing restricted plane partition congruences based on a bounded number of calculations. Using periodicity for partition functions, our extended technique could be a useful tool to prove congruences for certain types of combinatorial functions based on a bounded number of calculations. As applications of our result, we establish new and existing restricted plane partition congruences and several examples of restricted partition congruences. Also, we deﬁne a restricted form of plane overpartitions called k rowed plane overpartitions as plane overpartitions with at most k rows. We derive the generating function for this type of partition and obtain a congruence modulo 4. Next, we engage a combinatorial technique to establish plane and restricted plane overpartition congruences modulo small powers of 2. For each even integer k, we prove a set of k-rowed plane overpartition congruences modulo 4. For odd integer k, we prove an equivalence relation modulo 4 between k-rowed plane overpartitions and unrestricted overpartitions. As a consequence, using a result of Hirschhorn and Sellers, we obtain an inﬁnite family of k rowed plane overpartition congruences modulo 4 for each odd integer k ≥ 1. Also, we obtain a few unrestricted plane overpartition congruences modulo 4. We establish and prove several restricted plane overpartition congruences modulo 8. Some examples of equivalences modulo 4 and 8 between plane overpartitions and overpartitions are obtained. In addition, we ﬁnd and prove an inﬁnite family of 5-rowed plane overpartition congruences modulo 8."
http://hdl.handle.net/1957/61675,"In the face of a disruptive event or prolonged period of stress, resilient performance ischaracterized by preventative measures, effective response, and the integration of lessonslearned. In healthcare, resilience significantly affects patient safety. However, currentguidelines for healthcare performance assessment, such as the Triple Aim, do notconsider physician satisfaction and preventative measures against burnout. Consequently,burnout significantly affects healthcare providers' cognitive and emotional capacity. Inaddition, process improvement projects in healthcare often have a negative impact onresilience by over-standardizing processes.This research utilizes Resilience Engineering approaches to evaluate organizational resilience in one emergency department and two primary care case study examples. A qualitative method is applied to gain understanding of characteristics of resilient employees and learning behaviors that impact overall resilience. Frequency of single and double loop learning behaviors are observed and a resilient healthcare system is defined as one in which all organizational actors exhibit double loop learningbehaviors. Results give insights into the relationship between individual and organizationalresilience by adapting resilient systems attributes and capabilities to healthcare settings.A typology based on the dimensions of organizational and individual resilience ispresented, providing a mode for healthcare managers and academic professionals tocharacterize resilience in specific organizations."
http://hdl.handle.net/1957/61676,"In this thesis I will look at a definition of computable randomness from Algorithmic Information Theory as defined by Andre Nies through the lens of Computable Analaysis asdefined by Klaus Weihrauch. I will show that despite the fact that these two paradigmsgenerate distinct classes of computable supermartingales, the class of sets on which nocomputable supermartingale succeeds of either type is identical. Therefore, both theoriesgenerate the same collection of computably random sets. I will then consider how onemight apply some of the techniques in Algorithmic Information Theory, including prefixfree codes and the Kraft Inequality, to the study of the Collatz Conjecture."
http://hdl.handle.net/1957/61677,"Predicting condensation flow regimes and the associated heat transfer and pressure drop in microchannels is critical for designing terrestrial and space systems for heating, cooling, power generation, and advanced manufacturing. It is well established that in flows approaching the microscale (Dh < 1 mm) gravity-dominated flow regimes become less relevant, with stratified and wavy flows being replaced by the intermittent and annular regimes. While a large body of work has been developed to investigate fluid behavior in microscale channels, past research has focused primarily on adiabatic air-water studies at relatively high superficial velocities or condensing refrigerants at large mass fluxes (G > 100 kg-m-2-s-1). Fluid visualization results from these studies have been used to develop many of the flow regime maps currently available for estimating heat transfer and pressure drop. Review of these flow maps shows that at microscale channel diameters and low mass fluxes, common flow regime predictions begin to break down.In the current research, two-phase flow regime data is obtained via high-speed visualization of condensing flows of R-134a at mass fluxes from 80 to 150 kg-m-2-s-1 in square microchannels (Dh = 840 μm) at quality ranging from 0.01 to 0.60. A relatively small experimental uncertainty in thermodynamic quality (Uavg ≈ 3%) was maintained by enforcing a large temperature difference across the water-side (ΔT > 10°C). To mitigate maldistribution in the channels, vapor enters the test section superheated and is condensed to the desired quality before entering the viewing section. All data points were found to be either wavy or wavy-annular flow, and did not compare well to predictions made by commonly used flow regime maps for both micro and macro channel flow. Additional research is required to better understand the characteristics of low mass-flux two phase flows in microchannel geometries."
http://hdl.handle.net/1957/61678,"Forest management in the face of fire risk is a challenging problem because fire spreads across a landscape and because its occurrence is unpredictable. Additionally, management must be adjusted over time as unpredictable fire events are realized. Land managers have some control over the vegetation conditions that facilitate fire spread, and they can engage in activity that reduces fire arrival probability and decreases the likelihood of damage. This management activity will have consequences for fire risk in multiple locations on a landscape over a long time-horizon. The first manuscript in this dissertation demonstrates a method for incorporating spatial information and interactions into a dynamic model for management decisions. Approximate dynamic programming is applied to determine the optimal timing and location of fuel treatments and timber harvests for a fire-threatened landscape. This method allows a value function and an optimal policy to be found for a problem with high dimension state and action spaces. Larger net present values can be achieved using policies that explicitly consider evolving spatial interactions created by fire spread, compared to policies that are optimal in a non-spatial or non-dynamic setting. The second manuscript explores the interaction of multiple landowners on a single landscape. Fuel conditions that allow fire to cross property boundaries creates externalities, and must be accounted for when making management decisions. In the second manuscript, the problem of determining optimal management is formulated as a dynamic game where each agent affects the fire risk for other agents on the landscape. Value functions and optimal policies that account for fire-spread externalities are determined for each agent.  This method is applied to analyze the effect of ownership fragmentation on landowner welfare and ecological outcomes.The third manuscript explores policies designed to make landowners accountable for externalities generated by their management. Damage caused by spreading fires has prompted the creation of laws such as liability and negligence standards for landowners. Large damaging fires that resulted in expensive litigation have prompted changes to wildfire liability laws in several states. These regulations change the incentives that managers face. In this manuscript, the multi-agent framework developed in the second part of this dissertation is expanded and applied to analyze the effect of different types of liability regulations."
http://hdl.handle.net/1957/61679,"The Earth’s surface is experiencing unprecedented change. Humanity’s growing population, expanding land-use footprint, and increasing global emissions of atmospheric greenhouse gases affect a vast number of species on Earth and the functioning of virtually all ecosystems. Given the vital interactions and feedbacks between the Earth’s land surface and climate, measurements that link surface conditions and climate can provide crucial information on biospheric change. Land surface temperature (LST) is one of the most important parameters in the physical processes of surface energy and water balances at local through global scales. Interactions between the land surface and the atmosphere and the resulting exchanges of energy and water have a substantial impact on climate. This dissertation presents new methodologies developed using satellite-derived LST in conjunction with other biophysical datasets to monitor, quantify, map and understand critical Earth system changes from global to ecoregional scales.It has long been known that temperature is one of the key environmental controls and stressors to which an organism may be subjected. Its influence is fundamental, ranging from controls on chemical reactions that drive key processes on Earth, such as photosynthesis and respiration, to its role in defining large-scale species distributions and biome patterns. Climatological data can be developed for two kinds of surface temperatures: near-surface air temperature and the skin temperature, or LST. Although correlated with air temperature, LST differs from air temperature in its physical meaning, magnitude, and measurement techniques. LST can be estimated from measurements of thermal radiance coming from the land surface, retrieved from satellite, and mapped globally. In vegetated areas, satellite-derived LST measures the canopy surface temperature, and is more closely connected to the biophysical characteristics of the land surface, such as the land cover type, vegetation density, and water and energy fluxes of a specific area. LST provides important insights into high temperature extremes associated with droughts and heat waves, and the thermal tolerances and exposures for species and ecosystems. The Moderate Resolution Imaging Spectroradiometer (MODIS) LST product is measured across every 1-km2 pixel of the Earth’s surface. This is an important distinction from air temperature measurements from weather stations that have an inequitable global distribution including few stations across remote areas of the Earth’s surface, and cannot give detailed spatial patterns.We describe a new global change indicator based on an annual global measure of the Earth’s maximum land surface temperature (LSTmax) and demonstrate its value to examine critical Earth system functions (Chapter 2). LSTmax provides a unique integrated measure of the ecosystems thermal condition that is especially powerful at minimizing synoptic and seasonal variability and highlighting changes associated with extreme climatic events and significant land cover changes. We questioned whether maximum thermal anomalies could be indicative of heat waves and droughts, a melting cryosphere, and tropical forest disturbance from 2003 to 2014. The 1-km2 LSTmax anomalies detected complex spatial patterns associated with heat waves and droughts across the Earth’s surface, peaking in 2010 and 2012 with 5% (16%) of the Earth’s surface experiencing anomalies greater than 4°C (2°C). Our findings show that entire biomes are experiencing shifts in their maximum surface temperature distributions in association with extreme climatic events and large-scale land surface changes. These directional shifts in components of the Earth’s integrated LSTmax histograms are associated with melting of ice sheets, severe droughts in tropical rainforests, and with the incremental effects of forest loss in tropical forests. We conclude that with continued warming, the Earth’s integrated maximum temperatures will experience greater and more frequent directional shifts, increasing the likelihood that critical thresholds will be surpassed resulting in regional scale transitions that are tipping points in the global climate system.In a regional assessment responding to the acute concern about increasing forest stress and tree mortality and its direct link to combinations of drought and high temperatures (Chapter 3), we developed and applied a new forest vulnerability index (FVI) that identifies when and where forests have been experiencing increasingly high surface temperatures and greater growing season water deficits across the Pacific Northwest region (PNW: Oregon and Washington) of the USA during the MODIS Aqua era (since 2003). Our technique incorporates the alterations to canopy water and energy exchange processes caused by drought and high temperatures with MODIS LST and evapotranspiration (ET) data, and with Parameter-elevation Relationships on Independent Slopes Model (PRISM) precipitation (P) data. The FVI’s monthly assessment over the growing season revealed a possible trajectory toward more extreme conditions indicated by a trend toward cooler and wetter conditions in the spring, followed by a rapid transition to widespread warmer and drier trends in August and September. Area of increased vulnerability was concentrated in the months of August and September, with peak vulnerability occurring at separate times for different forest types. Overall, increased vulnerability rates were highest in drier forest type groups, such as Ponderosa Pine, Juniper, and Lodgepole Pine. Western Larch and Fir Spruce Mountain Hemlock groups occupy moister sites but also had relatively high proportion of increased vulnerability. The Douglas-fir group had the second largest total area of increased vulnerability due to its large areal extent in the study area. Based on an analysis using imagery viewed in Google Earth, we found that areas with increased vulnerability are associated with greater amounts of visible health decline and mortality. The FVI is a new way to conceptualize and monitor forest vulnerability based on first-order principles and has the potential to be generalized to other geographical areas.In Chapter 4 we utilize the FVI and its intermediary datasets on canopy energy and water exchange trends to investigate the Swiss needle cast (SNC) epidemic in the Oregon Coast Range. SNC is caused by an ascomycete fungus endemic to the PNW, and is having important consequences on the region’s coastal Douglas-fir forests. Seasonal changes in temperature and or precipitation regimes, such as we detected in Chapter 3 of this dissertation, have the potential to shift conditions in favor of pathogens, resulting in widespread epidemics. Foliar fungi diseases such as SNC are thought to be especially responsive to climate changes. Previous research has verified that spring and early summer leaf wetness is a key factor in SNC disease epidemiology. In this study, we investigate the relationship between climatic trends detected during the spring and early summer months (May – August) along the Pacific Coast of Oregon from 2003 to 2012, and the distribution of forests with visible symptoms of SNC in 2012. Our objectives were to: 1) Calculate the relationship between LST and water balance (WB) trends and pixel-level presence absence of SNC symptoms. 2) Compare the relationship between private and public forest lands to make inferences about the effects of forestry practices on forest vulnerability to SNC intensification. We find evidence that recent short-term directional climate changes may have contributed to the recent increases in SNC symptoms in Douglas-fir forests, and that this influence was stronger on private lands. The LST trends had greater explanatory power than WB trends, and the interactions between monthly LST trends increased the explanatory power of LST, whereas this effect was minimal for WB. The trends of the May and August LST together explained 7% of the deviance in SNC symptom distribution on private land, and 2% on public land. When combined with proximity to coast (strongest explanatory variable), May and August LST explained 14% of the deviance in SNC symptom expression on private land, and 8.7% on public land. Adding the WB factor did not improve the deviance explained in presence of SNC symptoms. This study indicates that early spring and mid-summer LST contains valuable information on leaf wetness, possibly contrasting both early season wetness and late season dryness, both of which are important to the epidemiology of SNC.The results from this dissertation highlight the immense value of the LST measurement in tracking critical changes in the Earth system. While questions remain regarding upper temperature thresholds that may trigger biome shifts or widespread forest die-offs, our results help to fill the knowledge gap about how these temperature changes are impacting the Earth’s ecosystems. The methodologies and tools developed here offer new and important opportunities for long-term monitoring that will continue to increase our understanding of these key land surface-climate interactions."
http://hdl.handle.net/1957/61680,"The desire to understand the spatial and temporal drivers of animal behavior and distribution relative to scale is central to movement ecology. Optimal foraging theory states that a predator should continue exploiting a patch until it is no longer profitable to do so. As human developments increasingly encroach on the marine environment, understanding how anthropogenic interactions affect predator searching and foraging behaviors is key to minimizing disturbance. In 2015 and 2016, two studies were conducted to assess how gray whale behavior state changes (1) relative to static and dynamic environmental cues, and (2) relative to vessel interactions. The first study was addressed through the non-invasive documentation of gray whale movements (n = 76 tracks) using shore-based theodolites for eight weeks from July-August 2016, in Port Orford, Oregon, USA. When conditions allowed, a research kayak was concurrently navigated to 18 sampling stations in two comparative study sites (Mill Rocks and Tichenor Cove) within the study area. Go-Pro cameras were used to record zooplankton relative density in the water column (n=198 casts), and zooplankton net tows (n=107) were used to assess community structure. Video stills were scored for quality and relative density of zooplankton, and averaged through the water column to provide a daily density estimate of zooplankton density for each station.  Whale behaviors were categorized into search, forage, and transit using the Residence in Space and Time (RST) method; behavior state was then assessed relative to static and dynamic variables at multiple scales. Despite being only one kilometer apart, there were significant spatio-temporal differences in the community assemblages of zooplankton between the two study areas, and whales demonstrated scale-dependent habitat selection relative to predictable static features (kelp) and dynamic prey availability. In Tichenor Cove, mysids (Holmesimysis sculpta), a known regional gray whale prey item, dominated the community, yet whales spent little time foraging here. Whales preferentially foraged in Mill Rocks where a combination of mysids and gammarid amphipods, previously undocumented as gray whale prey in Oregon, were prevalent. The second study occurred in the summer of 2015, and tracked whales and vessels using non-invasive, shore based theodolite and photo ID techniques. Two sites with differing levels of vessel traffic, Boiler Bay and Port Orford, were monitored for 4 weeks each. Whale focal follows were again analyzed with RST to assess behavior state changes relative to location, individual, and vessel presence, type, and distance to whale. There were significant differences in population level gray whale activity budgets between control and impact conditions, and between study sites. No significant difference in individual response to vessels disturbance was found. Taken together, the results of these two studies show that gray whales maximize energy gain through predictable, successful foraging. In the absence of vessels, foraging gray whales use information from a static feature and prey availability at a fine scale (<0.5 km) and larger regional scale (1-2 km), but searching behavior may be influenced by these features in a scale-dependent manner. When a vessel is present, disturbance appears to be tolerated as long as the foraging is profitable. Multi-faceted studies such as these advance the knowledge of which factors inform fine scale predator decision making in an increasingly anthropogenically impacted environment and have the potential to inform local management and conservation efforts."
http://hdl.handle.net/1957/61681,"Over the past century, life expectancy in the United States has dramatically increased leading to an increasingly aging population with people reaching, and spending more years in ‘old age’. While this unprecedented shift in population demographics represents great strides for humanity, it is not without cost. One consequence of longer life is the increased accrual of age-associated diseases and chronic pathophysiological conditions. This is evident in the fact that over 80% of Americans over the age of 65 have at least one chronic medical condition [275]. Thus, lifespan has outpaced ‘healthspan’, or the time of one’s life spent free from disease and disuse syndromes. The work in this dissertation is defined by the investigation of “health assurance” biochemical pathways, the failure of which lead to heightened risk for age-related diseases. In particular, I have focused on why resiliency to oxidative stresses decline significantly with age. This focus has led to a research project that ultimately pinpoints a loss in glutathione-dependent defenses as an underlying aging factor, which could enhance risk for a variety of age-related diseases. Nuclear factor (erythroid-derived 2)-like 2 (Nrf2) is a major transcriptional regulator of numerous anti-oxidant, anti-inflammatory, and metabolic genes. We observed that, paradoxically, Nrf2 protein levels decline in the livers of aged rats despite the inflammatory environment evident in that organ. To examine the cause(s) of this loss, we investigated the age-related changes in Nrf2 protein homeostasis and activation in cultured hepatocytes from young (4–6 months) and old (24–28 months) Fischer 344 rats. While no significant age-dependent change in Nrf2 mRNA levels was observed, Nrf2 protein content was attenuated by ~40% with age (p<0.05 , N=4). Treatment with anethole trithione (A3T), along with bortezomib to inhibit degradation of existing protein, caused Nrf2 to accumulate significantly in cells from young animals (p < 0.05), but not old, indicating a lack of new Nrf2 synthesis. We hypothesized that the loss of Nrf2 protein synthesis with age may partly stem from an age-related increase in microRNA inhibition of Nrf2 translation. miRNA-146a, increases by > 2-fold with age and is predicted to bind Nrf2 mRNA. Transfection of hepatocytes from young rats with a miRNA-146a mimic caused a 55% attenuation of Nrf2 translation that paralleled the age-related loss of Nrf2. Overall, these results provide novel insights for the age-related decline in Nrf2 and identify new targets to maintain Nrf2-dependent detoxification with age. Having established that this major transcriptional regulator is attenuated with age, we next examined what effects this would have on toxicological resilience.Isolated hepatocytes from young and old rats were exposed to increasing concentrations of menadione, a vitamin K derivative and redox cycling agent, an LC50 for each age group was established, and results showed a nearly 2-fold increase in susceptibility to menadione (LC50 for young: 405 μM; LC50 for old: 275 μM) with age. Examination of the known Nrf2-regulated pathways associated with menadione detoxification revealed, surprisingly, that NAD(P)H:quinone oxido-reductase 1 (NQO1) protein levels and activity were induced 9-fold and 4-fold with age, respectively (p=0.0019 and p=0.018; N=3), but glutathione peroxidase 4 (GPX4) declined by 70% (p=0.0043; N=3). These results indicate toxicity may stem from vulnerability to lipid peroxidation instead of inadequate reduction of menadione semi-quinone. GSH declined by a 3-fold greater margin in old versus young rat cells given 300 µM menadione (p<0.05 and p≤0.01 respectively; N=3), and providing GSH synthesis substrates (400 µM N-acetyl-cysteine ) to hepatocytes from old before menadione resulted in a >2-fold reduction in cell death, suggesting that the age-related increase in menadione susceptibility likely stems from attenuated GSH-dependent defenses. Additionally, young rat hepatocytes maintained ~30% of their GSH content which suggested the possibility that mitochondrial GSH preservation may be critical for cell survival. In order to determine the role of mitochondrial GSH (mGSH) loss in increased susceptibility to xenobiotic insult with age, markers of mitochondrial function were measured in intact and digitonin permeabilized isolated hepatocytes from young and old rats under a redox cycling challenge (300 μM menadione; ~LC50 for old). Preliminary results show that, while the rate of mGSH loss under menadione challenge was similar in both age groups, the difference in basal mGSH with age (68 vs 36 nmol GSH mg protein, N=1) ultimately resulted in a 50% loss of mGSH in old rat hepatoctyes versus only 28% in young within 10 minutes of exposure. Examination of mitochondrial membrane potential (Δψm), which is acutely regulated by mGSH content, showed a distinct loss in basal mitochondrial membrane potential (Δψm) (~21%). Additionally, within five minutes of menadione treatment, Δψm was not markedly reduced in young but had collapsed and passed the threshold for mitochondrial permeability transition pore opening (~100 mV) in old rat hepatocytes. Further characterization demonstrated that basal respiration and respiratory reserve capacity, indicators of cellular bioenergetic capacity, were both significantly reduced upon menadione treatment in old rat hepatocytes (34% and 72% respectively, N=4, p<0.05) but not in young. These results suggested that the age-related difference in mitochondrial function under menadione challenge might stem from mGSH regulated electron transport chain (ETC) components. We therefore examined proton leak, complex I, and complex II contributions to mitochondrial oxygen consumption rates under menadione challenge in both age groups. Results showed no marked effect in young rat hepatocytes, while old rat hepatocytes demonstrated significant increases in proton leak and complex II contributions to oxygen consumption rate (4.2 and 3.6-fold respectively, N=4, p<0.05), along with a significant decline in complex I contribution (4.8-fold, N=4, p<0.05). This data clearly demonstrates an age-related increase in mitochondrial susceptibility to menadione challenge, particularly in complex I, and provide a plausible mechanism that links this vulnerability to age-related mGSH perturbations."
http://hdl.handle.net/1957/61682,"The complex, dynamic nature of microbial communities in both natural and engineered environments complicates the work of scientists and engineers who wish to channel microbial interactions for societal good. The successful management of these communities towards engineering goals is dependent on developing predictive linkages between community structure and functional outputs. The performance of microbial fuel cells (MFCs), an emerging environmental biotechnology, is driven by a diverse microbial community capable of converting the chemical potential energy contained in waste streams to electrical energy. This technology stands to benefit greatly from an increased understanding of the microorganisms contained within as it transitions from the laboratory to practical application. MFCs also offer a controlled environment in which new approaches to developing predictive understandings of microbial communities can be developed.Revolutions in molecular science over the past decade paved the way for the rapid increase in genomic data available for microbial communities from a wide range of environments. Increases in computing power and accessibility over the same period provide a means in which the amassed community data can be mined for potential interactions and linked to functional outcomes. One of the methods through which this can be done is the use of artificial neural networks (ANNs). ANN-based models can be used to generate accurate microbial assemblage predictions across a variety of environments, but have never been applied to the microbial communities of environmental biotechnologies.In the present dissertation, MFC biofilms are analyzed over time, across reactor designs, under varying environmental conditions, and following pH disruption to identify core community membership. Results demonstrated that deterministic interactions shaped consistent community structures characterized by the formation of highly conductive anodic biofilms. The core MFC community is defined by a high abundance of anode-respiring Geobacter sulfurreducens. and biomass fermenting Aminiphilus circumscriptus along with other syntrophic bacteria. Community structure shifted into repeatable formations following the introduction of various substrates and wastewaters. Under changing conditions reactor performance in terms of power generation, treatment rates, and coulombic efficiencies was repeatable and linked to community composition using ANN models. ANN models that incorporated community predictions performed significantly better than those solely based on environmental parameters and predicted all performance metrics within 6% providing the first evidence for the value of including community data into ANN-based MFC models. Community composition could also be linked to biofilm stability following exposure to low pH solutions. Through the first quantitative evaluations of biofilmresilience in MFCs a correlation between the relative abundance of Geobacteraceae and process stability was observed, however, ANN models that considered relative abundance of other bacteria predicted stability more accurately. Further development of these models can be used in practical settings to determine and avoid risk of deactivation during operation.This dissertation characterizes a single MFC community over a variety of conditions and represents the first attempt to use machine-learning based approaches to connect community structure to performance in environmental biotechnology applications. The further development of these and other similar artificial intelligence data-mining tools will improve the management of microbial communities that drive environmental biotechnologies like MFCs and spur them towards practical application. Strengthening linkages between community, structure, interactions, and function in these technologies may be applied across industries, inspiring new applications and innovations involving microbial communities."
http://hdl.handle.net/1957/61683,"Wave energy converters (WECs) are a broad class of emerging technology that converts hydrokinetic energy into some other useful form, such as electricity. The last stage in this transformation, the power take-off (PTO) subsystem, is often not experimentally evaluated until half-way through the recommended development process. This delay in evaluation is rooted in history, technology and practicality. It also results in full-scale PTO systems that are not well integrated into the device architectures. In effect, the PTO becomes a design retro-fit.The development approach supported by public funding agencies follows a stage-gate process that has been proven to reduce risk when the project goals are well defined. However, the early-stage goals do not adequately incorporate the main goal of the project: The development of a commercially-viable device that converts ocean wave energy to electricity.In addition, the existing development paradigm lacks defined methodologies for evaluating the captured mechanical power. This has led to a situation where there is no consistency across development efforts. The situation can be changed through the adoption of evaluation methodologies, such as the one presented here. The use of the methodology has the additional advantage of focusing the developmentefforts on the single most important goal of the project – commercially-viable energy conversion.The methodology presented here has been developed and validated with a unique set of experimental data captured during the WEC-Sim Experimental Validation project. Methodology process steps are explained in detail and rooted in proven development approaches. Application examples for each step are also provided. All the source data will be made publicly available this year by the WEC-Sim project team. Mechanical power results obtained from the use of this methodology can affect device development early in the design cycle, when architectural changes to the device are still easy to make.Finally, the methodology is designed to be a living process. Developers using it will encounter issues whose resolutions cause methodology changes, to the benefit of the entire wave energy industry."
http://hdl.handle.net/1957/61686,"The Toba Caldera Complex is the youngest resurgent caldera in the last 100 kyrs, formed from four overlapping eruptions starting 1.2 Myrs ago. The last caldera-forming eruption, the Youngest Toba Tuff eruption, occurred ~74 kyrs ago, emitting 2800 km3 of ash and pumice into the atmosphere and forming the caldera outline seen today. The amount of ejecta released into the atmosphere potentially affected the global climate and regional human evolution.  The youth of this caldera system has made it the perfect natural laboratory for investigating resurgence, the last stage in the caldera cycle, associated with volcanic effusions and structural deformation and uplift. Organic-rich sediments found on the uplifted caldera floor provide a well-preserved and detailed history of the resurgent uplift, while lava extrusions along faults running through and around the caldera provide geological context for the initiation of resurgent activity at Toba Caldera. New data reveal details of the post-caldera history at the Earth’s youngest resurgent supervolcano, Toba caldera in Sumatra. Resurgence after the caldera-forming ∼74 kyrs ago Youngest Toba Tuff eruption uplifted the caldera floor as a resurgent dome, Samosir Island, capped with 100 m of lake sediments. 14C age data from the uppermost datable sediments reveal that Samosir Island was submerged beneath lake level (∼900 m a.s.l) at 33 kyrs ago. Since then, Samosir experienced 700 m of uplift as a tilted block dipping to the west. 14C ages and elevations of sediment along a transect of Samosir reveal that minimum uplift rates were ∼5.6 cm year from ∼33.7 to 22.5 kyrs ago, but diminished to ∼0.7 cm year after 22.5 kyrs ago.  Localised uplift activity continued along the eastern coast of Samosir associated with volcanic effusions, with 14C ages of sediments found blanketing lava domes as young as ~2.7 kyrs ago, producing localized uplift rates of ~1.9 cm yr. Zircon U-Th crystallization and (U-Th) He ages reveal resurgence commenced at 69.7 ± 4.5 kyrs ago progressing westward across the caldera, as reflected by post-caldera effusive lava eruptions and uplifted lake sediment. Previous geochronology for four of these lava dome localities (North Samosir, Tuk Tuk Samosir, North Pardepur, South Pardepur) by combined U-Th-disequilibrium (U-Th) He zircon geochronology yielded eruption ages ranging from 69.7 ± 4.5 kyrs ago to 56.9 ± 3.9 kyrs ago, implying resurgent volcanic activity started almost immediately after the climactic eruption and continued for ~20,000 years. 40Ar 39Ar ages from sanidine and plagioclase feldspar crystals from the same lava domes have returned ages that are contemporaneous with the climactic eruption, between 74.3 ± 0.4 and 71.4 ± 8.2 kyrs ago for North Samosir, Tuk Tuk Samosir, and South Pardepur, with only North Pardepur showing a substantially younger 40Ar 39Ar crystallization age of 23.6 ± 9.8 kyrs ago. These ages overlap with the (U-Th) He ages, but the younger error weighted average (U-Th) He eruption ages imply that the process of resurgence is more complex. Using eruption temperatures and a simple argon diffusion model, the difference between the weighted mean (U-Th) He age and stacked plateau 40Ar 39Ar ages can be explained by a difference in closure temperatures between argon and helium. Sanidine and plagioclase feldspar crystals from three lava domes record the YTT eruption age and are interpreted to be antecrysts that remained in the remnant magma system below argon closure temperature (Tc) in sanidine plagioclase (350°C). In contrast, the younger North Pardepur lava dome 40Ar 39Ar inverse isochron plagioclase age of 47.9 ± 11.1 kyrs ago overlaps with the (U-Th) He age, implying that plagioclase crystals are either autocrysts, formed during the eruption of the North Pardepur dome, or YTT antecrysts that have been reset due to their host magma remaining above argon Tc for >700 yrs. Matrix glass analyses represented on the quartz-albite-orthoclase (Qz-Ab-Or) ternary plot indicate that the Samosir dome magmas equilibrated over a deeper range of pressures (200-50 MPa) than the YTT (100-50 MPa), while the Pardepur dome magmas record the lowest pressures (50-0.1 MPa). Fault and drainage analysis of the resurgent dome shows that the southern half of Samosir Island is much more dissected than the northern half of the island. Drainage basins in the south are much more developed, with very little sediment cover left and basement rock observed to be exposed in some areas. Using drainage basin analysis tools in ArcGIS and the Geomorph Tools program in Matlab, the stream networks were analysed and channel profiles were created. Combining the identified locations of knickpoints along these channel profiles with assumed erodibility paramters, the minimum amount of time needed for the drainage basins to develop was calculated. Based on these calculations, drainage basins in the north and south took the same amount of time to develop. This means that the difference in drainage development is a result of another factor. One possible explanation is that pre-existing faults may underlie the thick intracaldera YTT deposit on the southern half of Samosir. These faults may have been from the previous half of the OTT resurgent dome, Uluan, which Samosir has appeared to take the place of. Pre-existing faults could have resulted in areas of weakness that were exploited during drainage basin development, thus making the southern drainage basins develop faster than the northern drainage basins. A more detailed study is required, however, to fully develop this potential hypothesis. A major active stratovolcano north of Toba, Sinabung, shows strong geochemical kinship with Toba, through 87Sr 86Sr isotopes, whole rock chemistry, and 238U-230Th disequilibrium ages of zircons from recent eruption products. This suggests that Toba’s climactic magma reservoir, which was tapped during resurgence, may extend beneath Sinabung and is being tapped during current Sinabung eruptions. This implies that resurgence at the Toba Caldera system may have continued as eruptions at Sinabung."
http://hdl.handle.net/1957/61687,"CNTs also offer new opportunities to study new science and develop new technology enabled by their strong electron-electron (e-e) interactions. The lack of dielectric screening inherent in nanoscale structures like CNTs leads to strong e-e interactions, which produce unique physical phenomena. In this thesis, we study the effects of strong e-e interactions in CNTs through the experimental system of suspended CNT devices fabricated with two gate electrodes. The work presented here includes the development of a theoretical framework to understand of the behavior of these ‘split-gate’ devices. Using this framework, we are able observe signatures of the strong e-e interactions in CNTs.The purpose of using split-gates (two gate electrodes) is to electrostatically dope the CNT into a pn junction. These suspended CNT pn junctions have been used by several groups to investigate the optoelectronic properties of CNTs. However, the device transport models proposed by previous authors have been unable to explain the disparities in experimental observations. In particular, different authors have seen different responses of the source-drain current vs source-drain bias (Isd-Vsd characteristic) of similar devices. To explore the reason for this variability, we investigate the Isd-Vsdcharacteristic while varying the metal contact work function. The results allow us to develop a model that explains the variation in the literature in terms of variations in the metal work functions and or CNT diameter. The device is modeled with a pn junction diode in the center of the CNT and Schottky diodes at the contacts. We are also able to use this model and temperature dependent measurements to extract the n-type and p-type Schottky barrier heights.Carbon nanotubes (CNTs) are a promising material for high-performance electronics beyond silicon. Unlike silicon, the nature of the transport band gap in CNTs is not fully understood. The transport gap in CNTs is predicted to be strongly driven by e-e interactions and correlations, even at room temperature. The effects a dielectric material, like a SiO2 substrate, on the transport gap is important for implementation of this technology. Here, we use dielectric liquids to screen e-e interactions in individual suspended ultra-clean CNTs. Using multiple techniques, the transport gap is measured as dielectric screening is increased. Changing the dielectric environment from air to isopropanol, we observe a 25% reduction in the transport gap of semiconducting CNTs, and a 32% reduction in the band gap of narrow-gap CNTs. Additional measurements are reported in dielectric oils. Our results elucidate the nature of the transport gap in CNTs, and show that dielectric environment offers a mechanism for significant control over the transport band gap.CNTs are candidates for next-generation photovoltaic technology, because they have the potential to break the Shockley-Queisser limit. Because of the strong e-e interactions, photogenerated carriers in CNTs can undergo carrier multiplication, where more than one electron-hole pair is created per absorbed photon. The photocurrent quantum yield(PCQY), defined as the number of electron-hole pairs extracted from a device per absorbed photon should therefore be able to exceed unity. However, a previous measurement on a similar split-gate device only achieved PCQY of 1-5%. To address this discrepancy we study photocurrent generation in individual suspended carbon nanotube pn junctions using spectrally resolved scanning photocurrent microscopy. Spatial maps of the photocurrent allow us to determine the length of the p–n junction intrinsic region, as well as the role of the n-type Schottky barrier. We show that reverse-bias operation eliminates complications caused by the n-type Schottky barrier and increases the length of the intrinsic region. We develop a method of determining the PCQY that takes into account the beam waist, length of the intrinsic region, CNT diameter, resonant absorption cross section of CNTs, and intensity enhancement from reflection off the substrate. We find that the room temperature PCQY is approximately 30% when exciting the carbon nanotube at the S44 and S55 excitonic transitions. The PCQY value is an order of magnitude larger than previous estimates."
http://hdl.handle.net/1957/61688,"There is increasing evidence that the type of land cover surrounding remnant patches of native habitats (the ‘matrix’) can modify effects of landscape change on biodiversity; thus the traditional idea of dichotomous habitat and non-habitat following island biogeography theory is insufficient in complex landscapes.  Matrix type can have dramatic influences on the amount of functional connectivity in a landscape, and some types of land use may conserve connectivity better than others. Evidence is accumulating across multiple systems that pollinator communities and the plants they pollinate and depend upon respond negatively to habitat loss and fragmentation.  However, relatively little effort has been devoted to examining the effects of matrix type on pollinator movements. Tropical forest conversion often results in matrix areas of agricultural use, predominantly animal pasture and crop growth.  Areas of pasture are vastly different than native forest, both in terms of physical structure and the resources they might provide to native pollinators.  Our research compared responses of four mature-forest associated tropical hummingbird species to varying matrix type.  We conducted a titration experiment where unlimited food was provided along transects through two matrix types (pasture and regenerating forest (hereafter “scrub”) to test whether functional connectivity differed, independent of resource availability.  We used radio frequency identification (RFID) systems to empirically test differences in the use of matrix types by species, as well as the distance each species ventured into each matrix type.  The number of feeder visits for one specialist species, the green hermit (Phaethornis guy), was strongly influenced by matrix type; scrub was >1.4 times (95% CI = 1.24 – 1.57) more permeable than pasture, and forest was >4 times (95% confidence interval [CI] = 3.66 – 4.65) more permeable than scrub.  However, we did not detect an effect of matrix type on the number of rufous-tailed hummingbird (Amazilia tzacatl) visits. The other two species (violet sabrewing [Campylopterus hemileucurus] and stripe-throated hermit [Phaethornis striigularis]) were never detected in pasture, and only rarely in scrub, although sample sizes for these species were low. Interestingly, two of our species – violet sabrewing and green hermit – also showed a strong affinity for forest interior, which may explain greater observed rates of pollination in large patches. Overall, our results suggest that the presence regenerating tropical forest scrub boosts functional connectivity by a ‘forest interior’ species (the green hermit), and therefore has the potential to restore hummingbird pollination networks in fragmented tropical landscapes."
http://hdl.handle.net/1957/61689,"Student engagement is key for learning in the classroom, and different levels of engagement have led to greater learning. The ICAP framework distinguishes these different levels of engagement by different overt behaviors, but little is known about how to measure different forms of engagement in the classroom. This article will assess the self-reported engagement of students compared to their observed engagement based on the ICAP framework. In this study, we observed 13 students in an upper level engineering thermodynamics classroom across a 10 week term, and then asked the students to take a survey based on the ICAP framework at the end of the term. We compared the overt behaviors of the students to how the students answered the survey. For different questions in the survey, the overt behaviors contributed to different expected responses. The expected responses compared to the actual responses of the students yielded correlations and discrepancies. Interviews with the students at the end of the study assisted in understanding these differences. The observed responses of the students, based on the observation of student overt behavior, typically were not consistent with the actual student responses to the survey. The behavior of the students is related to the opportunities given by the instructor to engage. Additionally, the observed students generally did what the instructor expected of them. Overall, students in the study did not have a consistent understanding of the survey questions. These questions need reassessment and their intended purpose made clearer to have a more effective survey."
http://hdl.handle.net/1957/61690,"Bioenergy is a rapidly growing subsector of the emerging global bioeconomy, with the potential to create a substantial number of jobs and mitigate climate change. In order to develop bioenergy into a viable industry, capable of providing valuable energy and employment, there is an immediate need for a skilled workforce prepared for the impending challenges of this interdisciplinary field.  However, programs providing training for these positions are limited, and there is currently a lack of research-based guidance for the creation of new educational programs. To meet this need, it is necessary to identify and prioritize the topics that should be included in a college-level bioenergy curriculum and determine best practices for bioenergy education.  In order to gain insight into expert and academia priorities and how they can be applied in an academic program, two Delphi studies, combined with a case study of an existing minor degree program at Oregon State University, were implemented. During the first Delphi study, an iterative, mixed-methods approach used to reach group consensus, 12 bioenergy experts in both educational and employment sectors provided open-ended responses to the following question:  Keeping in mind the future of a commercial bioenergy industry, what content knowledge should a student have upon completion of a college-level bioenergy curriculum?  Responses were qualitatively coded into themes, and experts were asked to rate the importance of each theme using a five-point Likert-type scale during two subsequent rounds.  The final round resulted in the following 13 themes, listed in order of importance: Energy Basics, Types of Bioenergy, Environmental Impacts (including Life Cycle Analysis), Current Technologies, Societal Issues, Logistics, Policy, Biomass Composition, Non-Bioenergy-Specific Fundamentals, Biomass Production, Conversions, Bioenergy Market, and Business-Related Knowledge.  The second, two-round, modified Delphi study asked 47 experts to use the same scale to rate these 13 themes, and they were welcome to suggest additional items, resulting in the addition of Bioproducts.  Academia and industry responses were then compared, which revealed that their priorities were well aligned.  Alumni interviews and current student surveys were conducted to evaluate the bioenergy minor at OSU. Analysis of these responses provided input from the students’ perspective.  Findings indicated that students value the required research experience and the interdisciplinary nature of the minor degree, among other qualities of the program.  Bioenergy is an interdisciplinary, complex, and evolving field.  The Delphi studies distilled numerous technologies and associated topics into a college-level curriculum framework, while the case study examined an existing minor degree program and illustrated how the program has transformed based on student feedback.  Results are intended to bolster emerging bioenergy training programs to meet the needs of future employers.  The combination of methods provided a curriculum framework and example of an existing program, both of which may be adapted for region-specific technologies to support a forthcoming bio-based economy."
http://hdl.handle.net/1957/61691,"The purpose of this study was to discover the routes to certification and turnover intentions of Wisconsin agriculture teachers with fewer than three years of experience teaching agriculture. The study also evaluated the relationship between the routes to certification and turnover intentions. A census of all Wisconsin agriculture teachers with fewer than three years of experience was attempted to gain a deeper understanding of certification routes within the population.	Findings showed approximately a third of the respondents (n = 35) entered the agriculture classroom in the past three years with an alternative certification. The reasons for doing so included location of the teacher preparation program, finances, ability to work full-time, and not wanting to teach as an undergraduate student. Traditionally certified respondents noted they wanted to teach as an undergraduate student. Overall, the respondents had moderately low turnover intentions (M = 2.95, SD = 1.13). There was not a statistically significant difference between the routes to certification and turnover intentions of Wisconsin agriculture teachers with fewer than three years of experience teaching agriculture.The results in this study provide implications for further research in alternative certification. Additional research should be completed to understand reasons for alternatively certified teachers are entering the classroom and more detailed information on content and pedagogical training."
http://hdl.handle.net/1957/61693,"Columbian black-tailed deer (Odocoileus hemionus columbianus) are important economically, ecologically, and culturally as an indigenous species in western Oregon. Oregon Department of Fish and Wildlife (ODFW) observed declines in black-tailed deer populations since the late 1980’s and attributes these declines to reduction in quality and availability of habitat, following the decline of timber harvest on federal lands. Additionally, black-tailed deer pose a perceived economic impact on private industrial forests by browsing seedlings during stand establishment. In western Oregon, where wildlife habitat management is tied to forest management, effective management for black-tailed deer would be facilitated by investigating home range sizes and habitat use in forested landscapes. To understand habitat preferences and use by female black-tailed deer in western Oregon, I quantified their seasonal and annual habitat use in the Indigo and Alsea Wildlife Management Units (WMU). I conducted home range analysis for 32 individuals in the Alsea and 30 individuals in the Indigo WMU using compositional analysis to investigate second-(home range establishment) and third- (within home range) order habitat use in proportion to availability at annual and seasonal intervals. Mean annual home range sizes for female black-tailed deer in the Alsea and Indigo WMU was 64.26 ha (SD = 22.65) and 262.45 ha (SD = 419.50), respectively. Home range sizes increased with decreasing area of early seral (forest age 0-10 years) and mid-seral (forest age 11-20 years) habitat availability, and home ranges were larger with increasing amounts of federal land. Throughout their annual cycle, female deer in the Alsea WMU used forest ages 0-3 years and 11-20 years in greater proportion to its availability and more than other land cover categories in establishing home ranges. Female deer also spent disproportionately more time in the same forest types within their home ranges. In the Indigo WMU, female deer used all land cover categories in proportion to availability in establishing and within home ranges. During periods of anticipated deer herbivory (i.e., damage) to conifer plantations in early summer (May 20 to July 4) and winter (November 25 to March 17), female black-tailed deer also used early (forest age 0-3 years) and mid-seral (forest age 11-20 years) forest cover types in greater proportion than available within their home ranges. Although I did not quantify deer health or population dynamics, my results support the hypothesis that food and cover are more readily available and used by female black-tailed deer on industrial forestlands than federal forestlands in western Oregon. Future studies should investigate the effects that black-tailed deer habitat use is having on fitness at multiple scales."
http://hdl.handle.net/1957/61694,"Gender issues have recently received increased attention in human robot interaction(HRI). Because robots are becoming part of our homes and daily lives, it isimportant to understand how di erent groups of people use them. To the bestof our knowledge, almost no research has been done that investigates gender differencesin users information need, information processing strategy, self-e cacy,tinkering and their impact in human robot interaction. This thesis investigatesthese four aspects by examining object manipulation task from gender perspectiveusing a humanoid robot (PR2). We used both qualitative and quantitative approachesfor cross validation and methodological triangulation. Our experimentalresults show that females asked for more information before using the robot thanmales (p = 0.0002). Females processed information comprehensively and malesprocessed information selectively (p < 0.001) for using the robot. Males showedgreater self-e cacy than females (p = 0.0002). Males tinkered more with the robotthan females (p = 0.0021). We found that tinkering was positively correlated (p= 0.0068) with task success and negatively correlated (p = 0.0032) with taskcompletion time. Tinkering perhaps led to males greater task success and lowertask completion time with the robot. Findings from this research can be useful formaking design decisions for robots and open new research directions."
http://hdl.handle.net/1957/61695,"The Construction industry is one of the most hazardous industries in the US.Construction workers, on a daily basis, are exposed to numerous risks while performing arange of activities involving construction, alteration, and or repair. Dust and diesel exhaustemissions from construction equipment are considered harmful to the workers in the longrun. Several studies have highlighted the ill-effects of constant exposure to diesel fumes anddust, but without directly relating to the conditions at a construction site. This thesisevaluates the concentration levels of PM2.5 on a construction site in Central Western Oregonand their relation with weather conditions. The paper also analyses the different PM2.5concentrations the equipment operators are exposed to in the presence and absence of closedoperator cabins. The concentration levels of PM2.5 were measured using an aerosol monitor,TSI DustTrak II 8530. The measuring device was placed inside the operator cabin whilecollecting data from an excavator and inside the DustTrak II 8535 enclosure while collectingdata from an open, cabinless dozer. The conclusions from this study presented the impact ofweather on the concertation levels of PM2.5. The study revealed that temperature hadminimal impact on particle matter pollution while precipitation had a significant negativecorrelation with the same. The research also found that the operators inside an enclosed cabinwere exposed to higher levels of PM2.5 than those working in an open cabin. This thesis alsopresents several strategies that can be used by construction professionals to mitigateemissions from construction equipment."
http://hdl.handle.net/1957/61700,"There are generally two types of multiview video:(1) 3D Multiview Video (“3D MVV” also called “2D plus delta” or “stereo” multi-view video): 3D MVV is widely deployed in cinemas and in the TV industry.  3D MVV typically entails capturing video of an object using two cameras with differing view angles to allow for depth perception.(2) Free Viewpoint Multiview Video TV (“FTV”):  Free Viewpoint Multiview Video allows the user to freely pan horizontally based on an array of cameras.While advances have occurred for 3D MVV, and to a lesser extent, stored FTV [Cheung2011], the commercialization and advancement of live Free Viewpoint Multiview Video has stalled.  The failure of FTV is attributed to the lack of standardization and the high bandwidth requirements of the FTV content.This thesis provides a solution to obtain a significant reduction in FTV broadcast and P2P bandwidth utilization as compared to current proposed methods, while maximizing the user experience for the given bandwidth."
http://hdl.handle.net/1957/61701,"In recent years, there has been an increased interest in accurately measuring physical activity levels with accelerometers. Two distinct approaches have been used to estimate physical activity levels with accelerometers are vertical axis activity counts and vector magnitude (VM). Although previous studies evaluated these two distinct approaches for individuals without disabilities, employing VM may have a greater advantages for people with Down syndrome (DS) because of their unique movement pattern of increase movements along the mediolateral axis during walking. The purpose of this study was to identify which approaches, to physical activity monitoring, can better predict physical activity levels for people with and without DS while walking. A total of 37 participants completed the testing protocol, 18 participants with DS (age 19 – 64 years; 32.56  14.16) and 19 participants without DS (nDS; age 19 – 64 years; 31.61  12.90). All participants took part in one session of data collection involving walking at different speeds. Participants wore a GT3X+ triaxial accelerometer on their right hips to measure activity counts, a Oxycon Mobile System on the front of their body to measure energy expenditure, and a heart rate monitor to measure approximate relative intensity during testing protocols. All participants were asked to walk at three different speeds for six minutes at each speed of self-selected speed, slow speed (2 mph), and fast speed (4 mph) in a figure “8” shape with a five minute break between each trial. During the slow and fast speed trials, a trained pacer along with a calibrated wheel and speedometer walked in front of all participants to ensure maintenance of speed. The results showed the correlation between energy expenditure and accelerometer outputs, both vertical axis activity counts and VM for individuals without DS are 0.75 at a group levels using linear mixed effect models. And the correlation coefficient between energy expenditure and vertical axis activity counts and VM for people with DS are 0.53 and 0.64, respectively. There werer no significant difference between the correlations for the without DS group and a correlation approaching significance for the DS grou when comparing the correlation with energy expenditure between vertical axis activity counts and VM. Significant differences were found between groups when comparing correlation coefficients with energy expenditure and vertical axis activity counts using z – test (z = 1.99, p-value = 0.046). No significant difference was found between groups when comparing correlation coefficient between energy expenditure and VM (z = 1.06, p-value = 0.29). For people without DS, this study supported that using either approach yielded similar results. This result was surprising given the unique characteristics of people with DS. Additional studies are needed to continue to determine the accuracy of the accelerometer in measuring physical activity levels for people with DS accounting for their unique characteristic."
http://hdl.handle.net/1957/61702,"Society faces many complex management problems, particularly in the area of shared public resources such as ecosystems. Existing decision making processes are often guided by personal experience and political ideology rather than state-of-the-art scientific understanding. This dissertation envisions a future in which multiple stakeholders are provided with computational tools for formalizing their management preferences and computing optimal solutions based on state-of-the-art computational simulations. To make this vision a reality, advances are required in optimization and visualization, and this dissertation presents research on both topics within the formalism of the Markov decision process (MDP). First, it describes an interactive visualization system for understanding the MDP under user-defined management policies, reward functions, and transition dynamics. Second, it presents a method for optimizing management policies for the user-parameterized MDPs. The research is illustrated and validated using a combination of benchmark MDPs and an application to the management of wildfire in ponderosa pine forests. For the wildfire problem, an excellent high-fidelity model of forest growth and wildfire behavior is employed. However, this model is extremely slow, which prevents interactive visualization and optimization. To address simulation computational expense, the dissertation also presents a method for creating a fast surrogate model and shows that this model is sufficiently accurate to support policy optimization and visualization."
http://hdl.handle.net/1957/61703,"This dissertation addresses the problem of semantic labeling of image pixels. In the course of our work, we considered different types of semantic labels, including object classes (e.g., car, person), 3D depth values (in the range 0 to 80 meters), and affordance classes (e.g., walkable, sittable). Semantic pixel labeling is challenging as objects may appear in various poses, under partial occlusion, and against a cluttered background in the scene. To address these challenges in semantic segmentation, we developed approaches in a unified research theme that of incorporating domain knowledge in learning and inference. As our results show, domain knowledge helps to resolve various ambiguities in semantic segmentation. We addressed this problem in supervised and weakly supervised settings, where the former provides pixel-wise ground-truth annotations in training, and the latter provides ground truths only as image-level tags. Our approaches range from beam search based inference to deep convolutional neural networks (CNN). Our approaches achieved state-of-the-art performance on the benchmark datasets for all types of semantic segmentation problems.Our main contributions include:1. Efficient beam search based inference that guarantees to respect domain constraints.2. Novel deep neural architecture called neural regression forest, which integratesdecision forests with CNNs.3. Multi-scale CNN architecture for extracting and fusing diverse mid-level visualcues, including depth map, surface normals, and object localization.4. Constraint-based regularized learning of a CNN where constraints are defined asspatial relationships between objects in the domain.5. Weakly supervised learning of CNNs using neural attention cues.6. We introduced first manually annotated dataset for evaluating affordance segmentation."
http://hdl.handle.net/1957/61704,"Phosphate and peroxide stabilize new oxo-hydroxo niobium clusters in water at low pH. The clusters open a new chapter in aqueous niobium chemistry under acidic conditions. The clusters also produce atomically smooth, amorphous niobium oxide phosphate (NbPOx) thin films. Reaction pathways from cluster solutions to amorphous niobium oxide phosphate solids are elucidated.Four new peroxoniobium phosphate clusters – H6Nb5P1O13(O2)5 (Nb5P1), H10Nb7P3O23(O2)7 (Nb7P3), H6Nb4P2O14(O2)4 (Nb4P2), and H10Nb6P4O24(O2)6, (Nb6P4) – were synthesized at pH < 2. Crystal structures of two clusters as tetramethylammonium (TMA) salts, TMA5[HNb4P2O14(O2)4]·9H2O and TMA3[H7Nb6P4O24(O2)6]·7H2O, were determined by X-ray crystallography. Solution speciation and cluster stability as a function of pH, phosphate concentration, and counterion (H+ and TMA+) were investigated with electrospray ionization mass spectrometry, dynamic light scattering, and small-angle X-ray scattering. Pair distribution function analysis of niobium oxide phosphate gel powders providesinsights about how cluster condensation leads to amorphous niobium oxide phosphate solids.Thermochemical and physical properties of NbPOx thin films were explored as a function of Nb:P ratios and anneal temperature via temperature programmed desorption mass spectrometry, X-ray diffraction and reflectivity, spectroscopic ellipsometry, transmission and scanning electron microscopies, optical transmission and reflection spectroscopy, and atomic force microscopy. Wide tunability in refractive index and band gap of the films was demonstrated by controlling the phosphate concentration in precursor solutions. The NbPOx thin films may also be directly patterned via electron-beam exposures, and as an ultra-thin capping layer they enhance dehydration of solution-processed aluminum oxide phosphate (AlPO) thin films."
http://hdl.handle.net/1957/61705,"Lewis SempriniStream chemistry studies conducted in the forested Watershed 1 of the HJ Andrews Experimental Forest show a contribution of CO2 from the hyporheic zone. Hyporheic CO2 concentrations, measured as pCO2, have a seasonal trend as well as a responsiveness to storm events. Concentrations are highest at the end of the dry season (~14,000 µatm) and lowest during the wet season (~6,000 µatm). Hyporheic pCO2 has been observed in a well to respond to winter storm events with a sudden decrease followed by a sharp increase in pCO2. The increase in pCO2 exceeds pre-storm levels, suggesting an additional contribution of pCO2 into the hyporheic zone. Concentrations gradually return to pre-storm levels as stream discharge decreases. I hypothesize that surplus CO2 is flushed into the hyporheic zone from the overlying soil (vadose zone) during storm events. I tested the hypothesis by monitoring soil gas (pCO2) at equilibrium with soil water, temperature, water table height, and soil moisture content at various depths throughout the m2 soil column of our study site. I modeled well F2 dissolved CO2 concentrations to compare to observed F2 dissolved CO2 concentrations to determine the contribution of CO2 from the vadose zone to hyporheic flow during storm events. The findings from the study suggest that the connectivity from the vadose zone to the hyporheic zone is seasonal, dissolved CO2 contribution from the vadose zone to the hyporheic zone occurs when the soil is sufficiently saturated to enable complete percolation from the vadose zone to the hyporheic zone, our study column can be described as “dry”, “transitional”, and “wet”, and prior to complete saturation the system is a complex network with unidentified boundaries."
http://hdl.handle.net/1957/61708,"The dairy industry has indicated that milk hauling sporadically compromises milk quality, but often the reason is unknown.  Milk hauling practices are an underexplored area of research, and are in need of attention because during hauling milk is most exposed to the external environment in comparison with any other step of modern dairy processing. Milk hauling is defined as the activities associated with the transfer of raw milk from producer to tanker truck, which is then transported and unloaded into storage silos at a processing facility. Tanker are often used to haul several loads within a 24-h period without cleaning and sanitizing in between; a practice that is mandated by the Grade “A” Pasteurized Milk Ordinance (PMO). Repeated tanker usage between cleans is necessary in the modern dairy industry; less cleaning reduces chemical and water usage, and time. There is no specification on maximum loads hauled or idle time (empty and dirty) between loads. Additionally, many routine practices outlined in the PMO use vague wording (as needed) to describe frequency; this is to provide flexibility to industry since each facility is unique. However, this vagueness does not inform industry on what best practices entail; potentially leading to unexplained sources of contamination due to weaknesses in practices. 	The overarching hypothesis of our research is that milk hauling sanitation and operation practices have the potential to negatively contribute to the microbiological quality of raw milk and impact finished product quality. In the scope of our study, negative impact from hauling is defined as an increase in microbiological counts or microflora proteolytic and lipolytic enzyme activity. The aim of our research was to explore a vast range of hauling situations to see if they had potential to compromise raw milk quality; this was achieved by i) characterizing variability in industry hauling sanitation and operational practices, ii) identifying circumstances in which hauling contributes to a degradation in the microbiological quality of raw milk by analyzing two years of historic raw milk microbiological data from producers and tanker trucks of a Northwest co-op. and iii) investigating impact of worst-case hauling conditions (e.g. extended idle time between loads) by measuring raw milk microbiological counts and enzyme activity for two scenarios: a) a small-scale using stainless steel milk cans, b) commercial study using tanker trucks and a pre-selected route.As anticipated, variability in industry practices exists, especially for equipment that required manual cleaning, and preventative maintenance programs such as replacement of aged equipment and parts. Analysis of historic raw milk microbial counts indicated that microbiological counts were not likely to be influenced by hauling, but rather are influenced by on-farm milk quality. Low counts from the on-farm bulk tank will be maintained if best sanitation and operating practices implemented at every step of the process, including milk hauling. Our small-scale milk can study demonstrated that extended idle time (> 6 hours) between loads has potential to negatively impacts milk quality, and provided a proof-of-concept for scaling up to a commercial study. Negative impact on milk quality was demonstrated to not be measurable for commercial tankers remaining dirty and idle for periods of <6 h between loads. Current PMO regulations (clean per 24 hours) appears to be adequate as long best sanitation and operation practices are implement. Future advances in rapid microbiological testing may facilitate better methods for measuring raw milk quality, especially as we better understand influences of raw milk microflora on downstream quality of dairy products."
http://hdl.handle.net/1957/61709,"The aryl hydrocarbon receptor (AhR) is a ligand-activated transcription factor of the basic helix-loop-helix PER ARNT SIM (bHLH PAS) family and regulates a diverse set of genes. The AhR is best known for directing the transcription of drug-metabolizing enzymes, particularly upon activation by ligands such as 2,3,7,8-tetrachlorodibenzo-p-dioxin (TCDD) and polycyclic aromatic hydrocarbons (PAHs). However, the AhR also regulates gene programs upstream of organismal development, cellular differentiation, cell proliferation, and programmed cell death. The roles of AhR in mediating cellular fate coupled with its ability to respond to both exogenous and endogenous chemical signals make its behavior in the context of cancer particularly interesting. Recently, we reported that low expression of AhR correlates with poor prognosis for breast cancer patients, adding to the accumulating evidence that AhR is able to mediate tumor suppressive effects in tissues. The central hypothesis of this research is that the aryl hydrocarbon receptor functions as a tumor suppressor, and that the tumor suppressive activities of AhR can be therapeutically activated with selective AhR ligands.To test our hypothesis, we developed AhR-knockout mice lacking the tumor suppressor protein p53, mimicking the most common mutation event in the development of human cancers. The absence of AhR increased the tumor burden, tumor spectrum and reduced survival in p53-deficient mice, supporting a tumor modifier role for the AhR. Furthermore, the double-knockout of AhR and p53 resulted in reduced embryonic survival and neonatal fitness. These findings suggest important roles for the AhR in tumor suppression and development, and have significant clinical implications. To test the hypothesis that AhR is a molecular target for anti-cancer therapeutics, we screened chemical libraries for small molecules capable of both activating the AhR and inhibiting the growth of cancer cells. Of interest were the compounds that caused growth arrest or apoptosis in triple-negative breast cancer (TNBC) cells, as patients with TNBC have an extremely bleak prognosis characterized by poor responses to currently available therapeutics and a rapid rate of relapse. A short list of compounds that induced AhR-dependent anti-cancer effects was investigated to determine their mechanisms of action. One compound activated AhR-dependent transcription of cyclin-dependent kinase inhibitor 1B (CDKN1B p27Kip1), a cell cycle inhibitor and a tumor suppressor. As transcriptional regulation of p27Kip1 is a poorly understood phenomenon with implications for cancer treatment, we performed promoter analyses to determine regions critical to regulation of p27Kip1, and found evidence of transcriptional activation of p27Kip1 by the AhR. Given the potential for drug development, we then investigated the structural analogs of the p27Kip1-inducing compound for activation of AhR and subsequent transcriptional induction of p27Kip1, and restriction of TNBC cell growth. We selected ten analogs from a list of 517 based upon docking scores obtained from an in silico ligand screen using a model of the AhR ligand binding domain optimized for the binding of agonists. All ten were capable of activating the AhR, and eight showed efficacy in reducing TNBC cell viability. Further characterization revealed that several of these compounds also induced the transcription of p27Kip1 in an AhR-dependent manner. These findings suggest that AhR can be selectively activated by small molecules to induce specific anti-cancer genes.Collectively, this research establishes a role of the AhR in tumor suppression and provides evidence in support of the AhR as a therapeutic target in cancer. AhR modifies the phenotype of tumors driven by loss of the major tumor suppressor p53, and is thus a tumor modifier, if not a tumor suppressor. A novel AhR ligand that induces the transcription of p27Kip1 has been identified, and its efficacy against triple-negative breast cancer cell lines has been established. Overall, these studies support therapeutic targeting of the AhR for the treatment of cancers with defective p53 signaling. In addition, selective AhR ligands that induce the expression of p27Kip1 have the potential to treat cancers that respond poorly to currently available therapeutics."
http://hdl.handle.net/1957/61710,"Arctic sea ice concentration and volume have declined due to greenhouse gas radiative forcing and an overall positive climate feedback. At the same time, there have been noteworthy weather and climate circulation anomalies both within the Arctic and extending through the midlatitudes and even into the tropics, leading some studies to conclude that the circulation anomalies are caused by sea ice changes. However, the direct link between sea ice and the atmosphere (i.e. the energy exchange) has not been heavily studied. Our study evaluates the Arctic surface energy budget using a large 33-member ensemble of the fully-coupled Community Earth System Model 1-Community Atmosphere Model version 5 (CESM1-CAM5). From this dataset, mean ensemble trends were calculated from 2011-2040 which is the time period of most severe and consistent sea ice loss. The spatial and seasonal distribution of both the climatology and the trends in the Arctic surface energy budget vary substantially for the radiative and turbulent fluxes (shortwave, longwave, sensible heat, and latent heat), though much of this seasonal and spatial heterogeneity can be understood to coincide with spatial and seasonal changes in sea ice. Four disparate regions stand out and the seasonal dependence of both the climatology and trend are investigated in detail: the Central Arctic, the Chukchi Sea, the Barents Sea, and the Greenland-Iceland-Norwegian Seas. Areas with year-round ice coverage in 2040 (i.e. Central Arctic) have a simple energy budget in which shortwave absorption is offset by a steady amount of longwave release throughout the year which does not change much over the course of the 30-year time period of interest. The Chukchi and Barents Seas transition from persistent to marginal and seasonal ice coverage in the projections, resulting in increased summer shortwave absorption that is generally overcompensated primarily via enhanced turbulent heat flux in the late fall and early winter. Marginal sea ice in the northern Greenland-Iceland-Norwegian Seas is effectively removed in the projections, resulting in highly variable but generally strong decreases in the upward turbulent and longwave fluxes as the sea ice is removed even in winter; the strong variability depends on the sea ice distribution projected in each individual ensemble member. Averaged over the whole Arctic, the change in the energy budget is qualitatively similar to that of the Central Arctic: loss of Arctic sea ice results in increased shortwave absorption during the summer which is mostly offset through enhanced longwave release, but how these fluxes are altered is highly geographically and seasonally dependent.	This study strongly suggests that fully-coupled models are essential to recreate physically realistic atmospheric, oceanic, and sea ice conditions as the Arctic continues to experience drastic changes. Drawing physically conclusive links between sea ice concentration declines and impacts on oceanic atmospheric circulations requires further understanding of the Arctic energy budget, particularly which components are modified and where when these changes take place with respect to reduced sea ice."
http://hdl.handle.net/1957/61711,"There is currently a revolution in archaeological morphometric research. As advances in technology are making more in-depth analyses both time and cost efficient. In this work, a collection of artifacts from the Pilcher Creek site (35UN147) in eastern Oregon was digitized using high resolution three-dimensional scanning. These scans were then processed through GLiMR (GIS-based Lithic Morphometric Research) to generate a large set of morphometric data. This data was then examined to look for any significant uniformity or variation within different artifact classifications. Comparisons were then made to an assemblage of artifacts from the nearby Cooper’s Ferry site (10IH73). This morphometric data, along with the high resolution three-dimensional scans, can enhance a variety of future archaeological research, especially as assemblages from other sites become digitized, leading to a better understanding of how artifact morphometric patterns may change across both time and space."
http://hdl.handle.net/1957/61713,"In this thesis, I investigate the organization of eelgrass (Zostera marina L.) and mesograzer communities across local and regional scales in three upwelling- influenced estuaries located along the Oregon coast, USA. Eelgrass ecosystems are an important source of primary production in estuarine systems, providing numerous ecosystem services, including nursery habitat for commercial fish, water quality improvement, and sediment stabilization. Community structure in eelgrass systems, i.e., the diversity, abundance, and composition of primary and secondary consumers, is influenced by a combination of local to regional scale variability in environmental and biotic factors. Thus, an important consideration in the management of these systems is to understand the organization of community structure across spatiotemporal scale and the implications for top-down (consumer) versus bottom-up (resource) control. In upwelling-influenced estuaries of the Pacific Northwest coast of the United States, eelgrass systems are exposed to latitudinal variability in oceanographic inputs, but the degree to which these regional effects versus local effects organize eelgrass community structure is poorly understood. Here I investigate      the relationship between primary producers (eelgrass, ulvoid macroalgae, and epiphytes), epifauna mesograzers, and fish predators within and across three estuaries located on the Oregon Coast, USA (Netarts Bay, Yaquina Bay, and Coos Bay). Specifically, I asked: 1) What is the relative importance of local (within estuary) versus regional (across estuaries) scale patterns to eelgrass community structure (i.e., primary producers, epifaunal mesograzers, and fishes) in upwelling-influenced estuaries in Oregon?, 2) What is the potential role of regional oceanography versus trophic interactions in regulating eelgrass community structure, and is this dependent on spatial scale?, and 3) What are the management implications for eelgrass communities when regional and local scales are considered?I found that while local effects were important, regional (estuary) scale patterns strongly influenced community structure in eelgrass communities, providing support that regional oceanographic bottom-up forcing dominates eelgrass communities. Additionally, I found evidence for top-down control by the opisthobranch Phyllaplysia taylori on primary producers at one site within Netarts Bay. I suggest that eelgrass beds in these estuaries are mostly bottom-up systems, and further investigations should focus on quantifying the mechanistic relationship between mesograzers and primary producers at local to regional scales."
http://hdl.handle.net/1957/61714,"One of the greatest challenges in the West is the sustainable management of limited water resources. In recognition of localized responses to natural resource challenges, there has been considerable work in the area of adaptive capacity and collaborative governance to help understand a community’s capacity to manage change. This study combines the adaptive capacity and collaborative governance frameworks to create a new questionnaire to assess “adaptive governance capacity.” Mixed-methods, factor, reliability analyses, null hypothesis statistics, and effect size statistics from case data in Upper Deschutes in Oregon and the Big Wood River in Idaho were used to 1) develop a questionnaire to assess capacity, 2) compare the adaptive capacity and collaborative governance frameworks, 3) evaluate the survey’s performance under different collaborative contexts, and 4) provide information to water users engaged in a water planning effort. Overall, this research provides local stakeholders and managers with an applied tool to prioritize resources, develop more effective water management strategies that address site-specific needs, and identify barriers and opportunities for change while implementing place-based management. Additionally, this research provides managers with a questionnaire that can assist in the evaluation of change in capacity over time; this is especially needed in times of budgetary constraints and the need to justify engagement processes."
http://hdl.handle.net/1957/61715,"As blueberry (Vaccinium sp.) production has increased in recent decades, a new interest has developed in the cultivation of blueberry in soilless substrate containers. Historically, blueberry has been propagated and grown in soilless substrate at nurseries, but nursery production is short in duration and plants are small relative to a mature blueberry. There is little literature on the subject of substrate blueberry production, and because blueberry is a long-term perennial that prefers soil pH in the range of 4.5-5.5, it is likely requirements are different than most other small fruit crops grown in soilless substrate for fruit production. Three studies were conducted in Corvallis, OR with container grown northern (V. corymbosum L.) and southern highbush blueberry (interspecific hybrids of V. corymbosum L. and V. darrowii Camp.) to investigate how media and fertilizer composition influence growth and nutrient uptake.In two studies we investigated the effects of various substrate ingredients on blueberry growth and nutrition in a greenhouse for 3-4 months. The first study evaluated cultivar ‘Snowchaser’ in eleven unique treatments, 10 from combining sphagnum peat moss,coconut coir (Cocos nucifera L.), and douglas fir bark [Pseudostuga menzii Mirb. (Franco)] with 10% perlite by volume and one commercially available mix. The second study evaluated 16 different mixtures of peat moss, coir, and perlite on one northern highbush cultivar (‘Liberty’) and one southern highbush (‘Jewel’). Treatments in the second study consisted of four levels of perlite (0, 10, 20, and 30% by volume) and four ratios of peat:coir (1:0, 2:1, 1:2, and 0:1). All plants in both studies were fertigated with a complete nutrient solution suitable for blueberry and target leachate drainage was 25%. Every 2 weeks, leachate was collected from treatments and analyzed for pH and electrical conductivity (EC). Plants were destructively harvested and dry weight and nutrient content were measured. In the first study, total dry weight of the plants was similar among the treatments at 72 d after transplanting but was nearly twice as much, on average, in the commercial mix, and media with ≥ 60% peat or coir than in those with ≥ 60% bark at 128 d. Bark had lower porosity and water holding capacity than peat, coir, or the commercial mix. Increasing bark in the medium also reduced nutrient uptake efficiency of N, P, K, S, Ca, Mg, Fe, Mn, B, Cu, and Zn relative to peat or coir. The effects of bark on nutrient uptake efficiency were largely driven by differences in dry weight. In the second study, increasing the amount of perlite in the media decreased dry weight in ‘Jewel’ and had no effect on dry weight in ‘Liberty’. When media contained perlite, the proportion of peat and coir in the media had no effect on dry weight of either cultivar, supporting the results of the first study. When no perlite was in the media, increasing the amount of peat (decreasing coir) in the media increased dry weight in ‘Liberty’. Increasing peat (decreasing coir) in the media improved nutrient uptake efficiency for P, K, Mg and Zn for both cultivars, and N, Ca, S, and B in ‘Liberty’. Inaddition, increasing the amount of peat in the media increased whole-plant concentration of P and Mg in ‘Jewel’ and N, P, K, and B in ‘Liberty’. The amount of perlite in the media had no effect on leachate pH. In both studies leachate pH was lowest for peat-containing mixes and highest for coir mixes; however, pH was similar in all mixes by the end of the studies. Results from our two media studies indicate that high levels of perlite or bark in the media can negatively impact initial growth of young blueberry plants through their influence on media water holding capacity. Initial growth of young blueberry plants is similar in media containing peat or coir; however nutritional differences between the two media components may necessitate differences in nutrient management.The third study evaluated the effects of K fertilizer source and rate, in combination with two N sources on shoot growth, fruit yield, fruit size and fruit firmness of ‘Liberty’ blueberry from 2015 to 2016. Plants were grown in 25 L containers with a substrate mixture of 3 sphagnum peat: 1 coir : 1 perlite. The three K sources used were potassium sulfate (KS), potassium thiosulfate (KTS), and potassium acetate (KA) at rates of 0, 50, and 150 ppm K in ammonium sulfate and urea. Additionally, KTS and KS were applied at 100 and 200 ppm K in ammonium sulfate. Every two weeks leachate from pots was collected and analyzed for pH and EC. During the second growing season fruit yield, quality (size and firmness), and nutrient content, and shoot growth (dry weight) and leaf nutrient concentrations were determined. When the plants were fertilized with ammonium sulfate, shoot dry weight increased with a moderate rate (50 ppm K) of KS or KA (396 and 370 g dry wt. per plant, respectively) versus the 0 ppm K control (269 g dry wt. per plant ), but there was no effect of K fertilization on fruit yield or quality. Whenplants were fertilized with urea, K fertilizer had no influence on shoot growth, yield, or fruit quality. Increasing concentration of K in fertilizer increased leaf K concentrations and decreased leaf Ca and Mg concentrations in both N fertilizers. Increasing fertilizer K also increased fruit K concentration in urea but not in ammonium sulfate. Leaf and fruit S concentrations were enhanced by the addition of KTS (X̅ = 0.3% and 0.10%, respectively) but not KS (X̅ = 0.2% and 0.09%, respectively). Both KTS and KS reduced leachate pH (X̅ = 4.58 and 5.01, respectively) relative to no K (X̅ = 5.44), whereas KA had no effect on leachate pH. Fertilizing substrate grown blueberry with K can have positive benefits on early growth and nutrition provided the appropriate K source and rate and N source are used."
http://hdl.handle.net/1957/61717,"In this thesis, the spatial patterns of vegetation and soils of reference and restored tidal marshes were compared to determine the extent to which restored sites differ from the reference site after 40 years of restoration. Vegetation surveys of 1m x 1m plots were conducted along previously-established transects of salt marshes for four different sites; three restored salt marshes (Y-Marsh, Mitchell Marsh, Salmon Creek Marsh) and one reference site (Reference Marsh). Additionally, vegetation data were collected from three 20m x 50m modified Whittaker plots at each of the four sites. Soil samples were collected at transect plots, processed according to National Soil Survey Center protocol, and analyzed for pH, bulk density, salinity, conductivity, and carbon nitrogen content. Vegetation and soil characteristics (bulk density, salinity, conductivity) were used to compare spatial patterns in vegetation diversity for restored and reference salt marshes. Results indicate significant differences     between the vegetation of reference and restored tidal marshes surveyed; differences in vegetation were associated with differences in elevation, soil salinity, and disturbance history. Outcomes indicate that restored marshes are more heterogeneous in species composition. Marsh surface elevation does not differ significantly among sites that were restored at different times in this estuary. The highest soil salinity and lowest elevation occurs in Y-Marsh, the marsh closest geographically to the mouth of the estuary. Vegetation of restored salt marshes is significantly less diverse and more spatially homogeneous than that of reference sites, even four decades post-restoration. Site hydrology, time since restoration, and prior land-use history influence the vegetation community composition at Salmon River Estuary."
http://hdl.handle.net/1957/61718,"Manufacturing exists as a stronghold for continuous growth and development of economies, a trend that is likely to continue as the demand for commodities and products grow. Manufacturing drives innovation and productivity in developed nations, as well as promoting economic stability and development in developing nations. However, manufacturing activities pose a significant demand on the environment (e.g., using resources), which can be accounted for and reduced through the application of sustainable manufacturing principles to analyze and improve the performance of manufacturing systems. Additive manufacturing is a rapidly emerging alternative to conventional manufacturing, including subtractive processes, often attributed to its claim for sustainable product development, e.g., reduced cost, reduced energy and material use, and the distributed production of tailored consumer products. However, these claims remain unsubstantiated for high volume production since benefits are product-specific and vary extensively. Hence, to ensure industrial efficiency with the growth of additive manufacturing, informed design and manufacturing decision making tools integrated with life cycle product and process data are required. Thus, the purpose of this research is to enable energy efficient design for additive manufacturing through 1) cradle-to-gate characterization of the environmentalperformance of additive manufacturing processes to identify the key contributors to environmental impacts, 2) characterization and modeling of additive manufacturing process energy use, and 3) development and demonstration of a design decision support tool for evaluation of additively manufactured products and additive manufacturing processes. This research enables systemic characterization of additive manufacturing process inputs and outputs, and associated environmental impacts. Modeling of additive manufacturing process time and energy use was driven by product design and process data and information, and supported the development of a design decision support tool. The tool is capable of informing designers about process energy consumption based on the key interrelationships between design and manufacturing parameters, determined under this research. Underpinning models within the tool encompass four commercially available additive manufacturing processes. This research demonstrates that informed decision making for additive manufacturing can support sustainable product development."
http://hdl.handle.net/1957/61719,"Internal curing is a term used to describe a process in which curing water is provided to a concrete mixture from inside the mixture. Internal curing water has typically been provided in North America mixtures by using prewetted porous materials, like fine lightweight aggregate (FLWA). Alternative materials, such as superabsorbent polymers or absorptive fibers, have been suggested as potential alternative methods to supply internal curing water. Water moves from the FLWA to the cement paste when capillary suction develops in concrete mixtures as a result of self-desiccation. This capillary suction draws water out of the FLWA and into the paste of the concrete mixture. Internal curing is primarily used in low water-to-cementitious ratio concrete material applications, as these mixtures are more susceptible to early age autogenous shrinkage and cracking. Internal curing has received considerable research attention over the past two decades. Applications for internal curing include: bridge decks, water tanks, repair materials and pavements. The most common mixture design methodology for internally cured mixtures is based on an approach proposed by Bentz and Snyder. This design methodology provides a volume of internal curing water that is equivalent to the volume of the ultimate chemical shrinkage of the mixture. While this approach can reduce the autogenous shrinkage and early age cracking potential, it is believed to be conservative. For applications like concrete pavements where large volumes of materials are involved, it may be possible to reduce the volume of internal curing water while still maintain the benefits of internal curing. This thesis explores the benefits of using only a portion of the typical volume of internal curing water for internally cured mixtures with lightweight aggregates and superabsorbent polymers. A design methodology is examined that uses the pore size distribution of the cementitious matrix to quantify the volume of internal curing water needed to reduce shrinkage to a specific level. Results from mixtures that use a portion of water associated with the volume of chemical shrinkage reveal significant benefits in terms of increased relative humidity and reduced autogenous shrinkage. A relationship between the pore size distribution of the cement paste and the reduction in autogenous shrinkage is established. A comparison is made between the model and the experimental results to reveal that only a fraction of the provided internal curing water fills the vapor filled pores that are responsible for the autogenous shrinkage. Other factors, such as the increased degree of hydration of cement, increased degree of reaction of SCM and the partial desorption of the internal curing agent also need to be considered.The model was modified to take into account these additional factors. While further studies are needed to better quantify the impact of various factors which consume or restrict the availability of the internal curing water, the proposed design method shows promise as, by advancing the comprehension of internal curing and its effects, provides a way to safely reduce the volumes of internal curing water while still maintain the majority of the benefits."
http://hdl.handle.net/1957/61720,"Hydropower is the one of the oldest renewable energy technologies and is wrongly thought of today as having little room to grow. The opportunity for new hydropower capacity is immense through both technology advancement and run-of-river new stream reach projects. Despite the age of hydropower, a divide in opinion is forming regarding how we should proceed with generating power from smaller undisturbed rivers and canals. Hydropower generation techniques have been primarily fixed speed since its inception in the late 19th century, but it seems as though variable speed generation could hold the key to more efficiently utilizing new stream reach resources. This research aims to provide a cost benefit analysis of fixed speed vs. variable speed hydropower generation topologies, and distinguish the performance advantages that variable speed generation could hold in other aspects of hydropower. Simulation results are validated with hardware."
http://hdl.handle.net/1957/61721,"Emerging adults often encounter obstacles and adversity in pursuit of occupational identity. College counselors are responsible for delivering mental health, wellness, and career services to distressed students facing unprecedented challenges to enter the workplace. The purpose of this study was to investigate how counselors can promote career resilience in emerging adults struggling to overcome career-related adversity. The first manuscript explored the aspects and impact of career-related adversity and how protective buffers already identified in psychosocial resilience relate to the construct of career resilience. A line of inquiry is proposed to promote career resilience in emerging adults facing career-related adversity. An argument is made to ground career resilience as a subdomain under the larger framework of psychosocial resilience. The second manuscript investigated the impact of a conflict resolution skills training intervention on the career decision self-efficacy of college students experiencing career decision difficulties due to conflict with parents. A non-concurrent multiple baseline across subjects single subject research design examined the impact of a conflict resolution skills intervention on college student career decision self-efficacy. The A-B design enabled the investigators to measure student career decision self-efficacy during and after a conflict resolution skills training evaluated against a baseline. The data collected showed steady increase in the career decision self-efficacy of three college students who engaged in five sessions of conflict resolution skills training. The career decision self-efficacy of two participants increased from moderate confidence with positive trends during intervention and both reached high confidence levels post-intervention. The third participant reported low confidence during baseline that increased to moderate confidence during intervention and continued to improve during follow-up."
http://hdl.handle.net/1957/61722,"Bovine respiratory disease complex (BRD) is an infection of both the upper and lower respiratory tract and includes components of rhinitis, otitis, tracheitis, and pneumonia. Bovine respiratory disease (BRD) is one of the most common causes of morbidity and mortality of calves in the United States and world-wide. Besides the financial and animal losses, BRD has negative implications for animal welfare. Clinical diagnosis of pulmonary disease in calves with BRD is challenging as clinical respiratory scoring systems, thoracic auscultation, and bronchoalveolar lavage are only moderately sensitive and specific for pulmonary disease detection. Thus, alternative diagnostic testing methods (i.e., thoracic radiography, ultrasonography, and computed tomography) are needed for early detection and treatment of BRD.Thoracic radiography is the most commonly utilized technique to evaluate the thorax for the presence of pulmonary disease. However, in large animal patients including calves, pulmonary ultrasound is currently more frequently performed due to its ease of use, real time imaging, ability to monitor disease, and availability in field conditions. In human patients, computed tomography (CT) is considered either the goldstandard or method of choice to evaluate for pulmonary disease. This is likely similar in veterinary patients but has not been established yet.In the first study, the objective was to evaluate if thoracic radiography provides accurate information about the severity and extent of lung disease compared to CT in calves with naturally occurring respiratory disease. The goal of the study was to assess if thoracic radiography could be used as a potential on-farm diagnostic tool for pulmonary disease detection in calves with naturally occurring respiratory disease. As CT is considered the method of choice to for detecting pulmonary disease, it was used as a reference standard. Additionally, we were interested if current clinical respiratory scoring techniques allow for detection of pulmonary disease in acute and chronic pulmonary diseased calves to a similar degree as thoracic computed radiography (CR) and CT.First, a CT protocol was established utilizing an intravenously injected sedation protocol using xylazine, butorphanol, and ketamine. The feasibility and safety of performing contrast-enhanced thoracic multidetector computed tomography (CT) examinations in sedated calves was evaluated. Finally, radiographic pulmonary disease detection rates were compared with those of thoracic CR and the Wisconsin respiratory scoring system.Lateral thoracic CR was performed on fifteen awake, standing Jersey calves with acute or chronic respiratory disease as diagnosed on-farm with the Wisconsin respiratory scoring system. Once calves were sedate, thoracic CT was performed pre- and post- intravenous iodinated contrast medium administration using a 64-multidetector CT.We observed that thoracic CT was superior to CR for pneumonia detection in acute and chronic respiratory diseased calves due to the lack of summation in all areas of the lungs. However, a diagnosis of pneumonia was made with equal rate on both thoracic CR and CT. The intravenous sedation protocol enabled acquisition of CT images of diagnostic quality, without the need for re-scanning. Although mild differences in classification of lung pattern and extent of lung disease were seen when comparing an experienced and a less experienced evaluator, the overall differences were not statistically significant. The best intra- and inter-observer agreement was noted when evaluating the cranioventral aspects of the lungs in either modality. Wisconsin Calf Respiratory Scoring was not able to diagnose chronic pneumonia in calves.Lung ultrasonography (US) has been used to diagnose and monitor pulmonary disease in large animal veterinary species as well as in humans. In the second study, the objective was to evaluate US as a potential on-farm diagnostic tool for pulmonary disease detection in calves. To accomplish our objective, US lung lesion detection rates of 16 Jersey calves with and 6 Jersey calves without clinical sigs of respiratory disease were compared to those with digital radiography (DR), CT, histopathology, and Wisconsin Calf Respiratory ScoringIn the second study, we observed that lung US was successfully performed in all calves without sedation and in standing position. Clinically healthy calves with low respiratory scores (<2) were diagnosed with pulmonary parenchymal changes on all imaging modalities and histopathologically, but the observed changes were smaller and less severe than in calves with clinical respiratory disease. Accurate assessments of severity and distribution of pneumonia, and differentiation of lung pattern types could bemade with US and correlated well with DR, CT and histopathology. Pulmonary US is an easy to perform, feasible and accurate technique diagnosing pulmonary disease in calves and allows differentiation between clinically healthy and respiratory diseased calves. However, US does not allow identification of intraparenchymal bullae or abscesses.In this study, thoracic DR, pulmonary US, and thoracic CT performed similarly well for pneumonia detection by each evaluator, and a more experienced evaluator had a better overall sensitivity for pneumonia detection with all imaging modalities. This supports the use of US as a potential diagnostic tool for pneumonia detection in calves."
http://hdl.handle.net/1957/61723,"Apple launched their ﬁrst “tap-and-pay” mobile payment solution called “ApplePay” in October 2014 in the United States. Quickly catching up with the popularity of Apple Pay, Google launched their own mobile “tap-and-pay” paymentsolution called “Android Pay”. Both the companies claim that their tap-and-paysolutions are more convenient and more secure than swipe-and-pay with traditional debit or credit cards. In this work, we investigated security, privacy andusability aspects of why people use and do not use mobile tap-and-pay in stores.We used both qualitative and quantitative approaches for cross validation andmethodological triangulation.The results of our online survey with 860 participants (349 for Apple Pay and511 for Android Pay) suggest that the top reason for not using mobile tap-and-payis security. However, Apple Pay users did not feel insecure using it in stores. Acommon security misconception we found among the non-users was that they feltstoring card information on their phones is less secure than physically carryingcards inside their wallets. Our security knowledge questions revealed that suchparticipants lack knowledge about the security mechanisms being used to protectcard information. This suggests the possibility that technology adoption rates mayimprove with increased awareness of security protections, given that our studyresults show usability was the most important reason for using tap-and-pay overtraditional swipe-and-pay.We also found a positive correlation between the participants gender and adoption rate, suggesting that males are more likely to prefer and use tap-and-pay thanfemales."
http://hdl.handle.net/1957/61724,"This thesis investigates a novel cycloid electric machine that integrates both cycloid gear drive and permanent magnet synchronous machine (PMSM), and proposes to apply the machine in robotic transmission system.       Cycloid gear drive is a transmission device that is commonly used to boost up the output torque. It has been widely applied in many industrial applications including ship power transmission, robotic actuation, hybrid electric vehicle and renewable energy due to advantages of high mechanical efficiency, low backlash, compact size and high ratio mechanical transmission. The structure of cycloid gear is different from common gears which engage externally, it engages internally and operates in cycloidal motion. In robotic industry, requirements on compact size and high transmission ratio result in the application of cycloid gear drives. Chapter 2 would introduce it in detail.      Synchronous electric machine has been widely applied and investigated for more than a century. In industry, synchronous machines are used for power generating, electric power drive and many other electro-mechanical transformations. In particular, permanent magnet synchronous machine (PMSM) is the most common one because the control strategy is relatively simple with the help of booming power electronics. Commonly, PMSM is used as mechanical power input in robotic industry. Chapter 3 would elaborate it.      Typical human-sized legged locomotion needs an output torque around 300 N∙m to accomplish motions. The direct drive design uses only one high-torque electric machine with multi-stage transmission cannot meet the size and weight requirement of the leg actuation. This research proposes a novel cycloid electric machine to replace the conventional motor transmission system. An estimated 40 percent size and weight reduction is expected [19]."
http://hdl.handle.net/1957/61725,"The eruptive history of the Quaternary Cascades arc has been relatively well characterized. However, much less is known about the frequency and sizes of explosive eruptions produced by earlier stages of the arc. The Late Neogene Deschutes Formation of Central Oregon preserves a remarkable record of heightened pyroclastic activity during the initial stages of High Cascades volcanism, following an eastward shift in volcanic activity ~7.5 Ma. Extensive fieldwork, 40Ar 39Ar geochronology, and geochemical analyses allow us to reconstruct this unusually explosive phase of the earliest Central Oregon High Cascades.Plagioclase 40Ar 39Ar ages for eight laterally-extensive marker ignimbrites that stratigraphically bracket the many pyroclastic deposits exposed within the Deschutes Formation, indicate that almost all of these explosive eruptions occurred within only ~800 k.y., between 6.25± 0.07 and 5.45± 0.04 Ma. Combining these age data with multivariate statistical tephra correlation methods, I establish a comprehensive tephrostratigraphy of the Deschutes Formation. These correlations suggest that at least 67 distinct explosive eruptions (possibly as many as 120) occurred within the 800 k.y. explosive pulse.Using a new ArcGIS-based method that I developed for calculating ignimbrite volumes, I find that a total volume of 82 km3 (62 km3 DRE) for just 26 of the ignimbrites deposited distally into the Deschutes Basin. If these ignimbrites also deposited an equal volume to the west and had a tephra fall:flow ratio of betweenii0.5:1 and 1.9:1 (similar to Mount Pinatubo and Valley of Ten Thousand Smokes), the total volume of all 26 eruptions was likely between 246 and 475 km3, or a rate of 6-12 km3 m.y. km. This rate is approximately 2-8 times higher than the production rate of all compositions over the entire Quaternary Cascades and is the highest rate in Oregon over at least the last 17 Ma.The unique timing and location of this pulse, approximately 1 m.y. after an eastward shift of the arc axis, and in a region undergoing extension, may explain the anomalous explosivity recorded in the Deschutes Formation. I suggest that such extension allowed for penetration of hot, low-K tholeiitic basalt magmas into shallow levels of the crust, which induced a period of enhanced shallow crustal melting and the production of large volumes of hot-dry-reduced rhyolites (high Fe, Na, Y, MREE, and low Eu Eu* and Sr). Thus, the anomalously high production of silicic magma and rate of explosive volcanism recorded in the Deschutes Formation is mirrored by the unusual geochemistry of the eruptive products, and are together indicative of magmatic processes driven by extension, that no longer operate during the Quaternary.In addition to constraining changes in geochemistry and style of volcanism through time, I used rigorous statistical methodology to assess the geochemical variability along-arc for the Quaternary Cascades. To do this, I compiled a dataset of over 11,000 samples and utilized a Monte Carlo approach with weighted bootstrap resampling to reduce the bias that over-sampled volcanoes have on overall trends. In in doing so, I assessed regional, rather than local processes. Our study develops a novel approach to assessing along-arc geochemical variability using entirely objective and statistically-based methodology. Using this new approach, I separated the Cascades arc into 5 segments such that the geochemical differences between each is maximized. This new segmentation scheme, which includes the North, Washington, Graben, Mazama, and South Segments is more statistically robust than previous segmentation schemes. By separating the arc into the most statistically distinct regions, one can better assess the spatially disparate processes that lead to geochemical heterogeneity. This, in turn, provides a better understanding of the fundamental processes involved in arc magma generation."
http://hdl.handle.net/1957/61726,"This study presents a comparison of differences in cognitive mapping as a result of navigating an unfamiliar space with GPS or with Google Glass. Using the Yerkes-Dodson law and attenuation theory, the study attempts to uncover how attention is diverted or focused through each of these wayfinding platforms. In addition to a better understanding of wayfinding technology, the study measures potential effects of these devices on spatial cognition and on wayfinding performance. 	Data were collected through field tests of both devices, lab tests, as well as semi-structured interviews. Field tests measured wayfinding performance, lab tests measured robustness of cognitive mapping, and interviews allowed qualitative feedback on wayfinding with both devices. The sample consisted of 20 men and 20 women mostly aged 18-29, the majority being freshmen at Oregon State University in Corvallis, Oregon. 	Participants’ sketch maps, accepted as representations of their spatial memories, was performed in both ArcGIS, as well as through traditional sketch map analysis. In the traditional method, Augmentation, Incompleteness, Distortion, were used as key variables. In ArcGIS sketch maps were georeferenced to a coordinate system and standard pattern analysis tools were also utilized to reveal descriptive statistical data. Further geoprocessing was performed to quantify the magnitude of error between sketch maps and the actual reality on the ground. 	Based on several tests of spatial cognition, users who navigated with Google Glass did so more carefully, and created fewer errors. When participants used GPS, environmental stimuli competed for their attention, at the expense of robust cognitive maps. When participants used Google Glass, their spatial recollections improved, as demonstrated through sketch maps. They drew sketch maps with greater accuracy and tended to estimate their distances between waypoints more accurately, after correcting for scale."
http://hdl.handle.net/1957/61727,"Photoelectric and Compton interactions are some of the common interaction mechanisms we observe when gamma radiation interacts with matter. These interactions are highly depended on the energy of the radiation and the atomic number of the detector material. Lower the energy of the photon and higher the atomic number of the detector; higher is the probability of a photoelectric events occurring. Higher the energy of the photon and lower the atomic number of the detector; higher is the probability of a Compton interaction. Conventional scintillation detectors like NaI(Tl) have a high Z atom and are useful in giving us spectroscopy information. From a manufacturing stand point we can’t manufacture huge blocks of NaI detectors and from an economic stand point, inorganic scintillators are expensive. These short comings can be overcome by using plastic scintillators, which are both easy to manufacture and costs effective. Traditionally plastic scintillators have not been good at detecting photo peaks because of the high number of Compton events the photon undergoes while it interacts with plastic (Carbon and Hydrogen; Low Z). Efforts at Sandia national lab have resulted in a plastic scintillator being produced that is made of polystyrene with a high Z material loaded in the plastic base. Therefore, from a spectroscopic point of view we observe a photo peak when we expose the detector to gamma photons. This material carries with it the ease of manufacturing coupled with low cost economics while providing us spectroscopic information. On comparing the spectroscopy ability of inorganic and organic scintillators, inorganic scintillators outperform organic (plastic) scintillators in terms of resolution and absolute efficiency. This study aims at understanding difference in pulse shapes between low Z and high Z materials. This understanding of differences can be used to perform pulse shape discrimination (PSD) between pulses from different materials. These differences can be employed to preferentially reject pulses from low Z materials while preserving counts under the photo peak thereby providing us a Compton suppressed spectrum. This correction helps us in obtaining an enhanced spectrum with few counts under the Compton continuum. This work explores the methods and algorithms used to perform pulse shape discrimination. Three single photon radionuclides; 198Au, 137Cs and 54Mn were used to provide us with a wide range of gamma photon energies. Multi photon measurements were also carried out with 22Na, 198Au-137Cs and 137Cs and 60Co. The three algorithms used to perform the discrimination include the classic charge integration method, pulse gradient analysis and the frequency gradient analysis. In the interest of reducing cost of the detection system, the ability to perform PSD at reduced sampling was also studied. The detector yielded the best resolution of 9.23% for the 662 keV peak of 137Cs. Preliminary results indicate that the algorithms were successful in suppressing the Compton continuum and preserving a large portion of the counts under the photo peak. In terms of energy dependence of the algorithm charge integration is the least energy dependent followed by pulse gradient analysis and frequency gradient analysis is the most energy dependent algorithm. 198Au has shown an improvement in the FOM by a factor of 1.7, followed by 137Cs that has shown a FOM improvement by 2.3 times, the corrected spectrum from 54Mn also shows an improvement in the FOM by around 1.8. Studies have also been carried out to perform PSD at reduced sampling frequency of 1.25 GHz and 833 MHz, initial results indicate that discrimination algorithms were successful at reduced sampling rates."
http://hdl.handle.net/1957/61728,"This paper contains a review of the literature that inspired and informed my final Master’s art project for Applied Ethics, as well as an explanation and analysis of the art project itself.  The review of literature begins with a lens into modern development, and how a history of colonization and exploitation to support development have led to modern systems of oppression and dehumanization. To explain these ideas, the literature then explores concepts of colonization through education, as well as the connection between oppression and the material values of development. Concepts of oppression and dehumanization are analyzed to understand oppressor and oppressed, and ideas of humanity are explained to make sense of what it means to de-humanize. The Culture of Silence is presented as an explanation for reenforced societal conformity, and creativity presented as an avenue for breaking silence and opening spaces for change. An analysis is also provided regarding the work of artists and art activists that challenge norms and form critical new spaces, as well as an example of how sex offenders within the prison system is still a gap in activism and art activism. Throughout the literature review, I use the criminal justice system, and in particular sex offenders, as an example of a system of structural oppression and dehumanization. This example demonstrates the connection between oppression and material values, and modern society’s perpetual dehumanization of the body and mind of those portrayed as “criminal”. The literature review ends with an analysis of the project born from these ideas, and its mission to create space for transformation toward a greater level of social justice."
http://hdl.handle.net/1957/61729,"This manuscript-style dissertation explores Diné (Navajo) education and teaching in the context of a research project that negotiated the demands of both Navajo Nation IRB and Oregon State University IRB.  In the first manuscript, the researcher examines his journey of using cultural resilience strategies to succeed in the education system on the Diné reservation and in urban cities.  He also details the development of his cultural and professional identities.  Four cultural resilient strategies are reflected in his story: 1) familial support, 2) cultural teachings, 3) spirituality, and 4) sacred Diné terms. In the second manuscript, 15 Diné elementary teachers’ perspectives on Diné-centered education are explored through the use of interviews and questionnaires.  The findings indicate: 1) ambivalent support among stakeholders on the teachings of Diné language, culture, and history, 2) improving students’ test scores on statewide assessments as the dominant curricular perspective, 3) curricular challenges in implementing Diné-based education, and 4) a need to train teachers on culturally responsive teaching and learning strategies.In the third manuscript, the author reflects on the challenges of negotiating the demands of two IRBs, representing two very different cultures.  Three key observations are generated. First, the IRB review and approval processes between the university and tribal IRBs were recursive which excessively delayed the author’s research project. Second, the university IRB requested original and modified documents of Navajo Nation IRB protocol, consent form, and approval letter, which also served to delay the research; similarly, the Navajo IRB required its own body of permits, letters of support, and public testimony as part of the process.  Third, the Navajo tribe is a sovereign government that exercises its own IRB regulations (e.g. Principal Investigator designation and ownership of research materials) which at times, conflicted with university (i.e., federal) IRB guidelines.  Overall, the three manuscripts provide description and new questions to an area of inquiry that has been on the margins of educational research: the experience of Navajo teachers in the age of the Common Core and other manifestations of education standardization."
http://hdl.handle.net/1957/61732,"The purpose of this study was to explore the connections between experiential learning and pedagogical content knowledge (PCK) in preservice agriculture teachers. More specifically, utilizing a conceptual model for teacher development as a framework, this research sought to explore the development of the knowledge bases needed for teaching through experiential learning opportunities, and examine how preservice teachers apply personal amplifiers and filters to develop PCK for teaching agricultural content. In addition, the importance of reflective observation (RO) and abstract conceptualization (AC) to the development of PCK was considered.The purposefully selected target population for this study included all preservice agriculture teachers at Oregon State University during the 2016-2017 school year (N = 10). Three sources of qualitative data were collected and analyzed for this study. Field notes, lesson plans, and interview transcripts worked in conjunction with one another to offer a comprehensive look at preservice agriculture teachers’ development of PCK. Context emerged as an important theme for describing the lived experiences of these preservice agriculture teachers. The context in which participants learned content and the context in which they planned for and taught content for student understanding were both evident, and quite different. The felt need to learn emerged as an important component within the context for learning. Context for teaching was shaped by three sub-themes that emerged from the data: the subject matters, context as a filter, and classroom environment.  In general, it was evident the participants had begun developing PCK, although it was unclear as to whether or not they could identify their own PCK, a common occurrence among preservice teachers. However, without an understanding of the conceptual framework or the PCK model, participants were unable to explain how they were merging content knowledge and pedagogical practices. Additionally, it is reasonable to assume the participants were only engaging in reflective practice because they were prompted to do so during the interviews. While the study provided evidence of the connections between experiential learning and PCK, along with the importance of reflective observation and abstract conceptualization to the development of expertise in teaching agriculture, findings support further exploration into the connections between experiential learning and PCK.In order for the conceptual framework to be useful, it is recommended that it be included as a guiding framework for student teacher preparation programs. Preservice teachers would need to be educated on the framework and given the tools to move beyond simply reflecting, to conceptualizing how educational and personal experiences can be used for breaking down content for student understanding."
http://hdl.handle.net/1957/61733,"The International Atomic Energy Agency (IAEA) is the leading organization for monitoring nuclear facilities worldwide, and the Agency’s methods are constantly developing and improving in an effort to more effectively safeguard nuclear material. As such, the IAEA addresses near and long term risks in order to advance the capabilities of the IAEA inspectors to identify quantities of diverted material, known as defects. Advanced techniques enable the inspectors to decrease the uncertainty in measurements, which translates to smaller detectable defects. Recently, digital-imaging techniques for qualitative inspections of irradiated fuel using Cherenkov light measurements have advanced the Agency’s ability to perform verification measurements following discharge of the fuel from power reactor facilities. However, one area that continues to be difficult for the IAEA is the non-invasive, in-core inspection of research reactors with the objective of verifying the quantity of fissile isotopes. Current techniques do not quantify the relative fissile material content and cannot characterize a reactor during operations, limiting their value for safeguards and nuclear material accountancy. Research reactors are typically smaller in size than power reactors, so identifying defects is innately more difficult. This study seeks to leverage existing optical measurement technology by assembling a new detecting method, the Cherenkov Radiation Assay for Nuclear Kinetics (CRANK) system, to identify and characterize Cherenkov light in an operating research reactor and to relate this signature to the quantity of fissile material in the reactor."
http://hdl.handle.net/1957/61735,"The Islamic State of Iraq and Syria (ISIS) is a formidable international force operating and perpetuating religious, military, and violent agendas. In 2014, ISIS established a worldwide Caliphate governing religious authority across Middle Eastern territories. ISIS operations are grandiose and large scale, longevity and survival are predicated on recruitment. One prominent ISIS recruiting tool is a printed and digitally produced magazine. Entitled Dabiq, the magazine represents the motives and ideologies behind ISIS; it symbolizes what ISIS hopes to accomplish. Dabiq includes powerful imagery and persuasive statements to draw readers in. The most cogent and dramatized elements in Dabiq reveal persuasion strategies. This study uses a rhetorical criticism; Fantasy Theme Analysis is the methodology chosen to examine the Dabiq series. The concepts of fantasy themes, fantasy types, master analogies, and rhetorical visions are considered to explore elements in Dabiq."
http://hdl.handle.net/1957/61736,"This dissertation was a qualitative case study focused on part-time faculty teachingdevelopmental mathematics courses in one large Pacific Northwest community college. Thecollege was selected for its size and maturity; the topic was selected for three related reasons:part-time faculty have been widely relied upon to teach these courses nationwide; students indevelopmental education courses tend to have higher risk factors and attrition rates; andmathematics courses form the bulk of developmental education (pre-college-level courses,formerly termed remedial). Research indicates that high reliance on part-time faculty (variouslytermed “contingent,” “fixed-term,” “contract,” “adjunct,” or “non-tenure track faculty,”) resultsin negative outcomes in terms of student success and completion. These outcomes are oftenattributed to poor integration of part-time faculty into the institution.The research questions guiding this study were:· In what ways are part-time faculty who teach developmental mathematicscourses integrated into the college on one campus of a large communitycollege in the Pacific Northwest?· In what ways does the integration affect their ability to perform their duties?· In what ways could the integration be improved?The guiding theoretical perspective for this study was organizational theory, informed bysystems theory. The research questions were informed by Wheatley’s (2006) three criticaldomains necessary for a healthy organization: the fundamental identity of the organization; theongoing urgency to connect members of the organization to information; and the importance ofdeveloping relationships throughout the organization. In order to gain a holistic view, the studyexamined the college context and interviewed part-time faculty, full-time faculty, facultydepartment chairs, an administrative aide, and a dean involved in developmental mathematicseducation. These collected data were then broken down into categories informed by Baron-Nixon’s (2007) principles for connecting part-time faculty to a college mission and analyzedaccording to three units of analysis: institutional, departmental, and individual.The key finding of this research was that while part-time faculty teaching developmentaleducation mathematics courses at this particular northwest college were well-integrated into thecollege identity, and while in this department many efforts were made to integrate them in termsof information sharing and relationships, barriers remained hindering full integration. Thesebarriers affected the ability of part-time faculty to optimally perform their duties, depending ontheir individual situation. The barriers were for the most part institutional and structural andneeded to be addressed at the institutional level."
http://hdl.handle.net/1957/61743,"This dissertation presents an analysis of transportable biomass conversion facility design to evaluate the conceptual and economic viability of a mobile and modular biomass conversion supply chain in the Pacific Northwest, USA. The main goal of this work is to develop a decision support system to more effectively and sustainably use residual biomass from commercial harvesting operations that are currently piled and burned as part of site preparation. To complete this research a comprehensive biomass supply chain landscape characterization, modeling and optimization study was completed to provide an analysis of transportable biomass conversion facility design and evaluate its potential economic viability from strategic, tactical and regional perspectives. The long-term goal of this research is to help enable a sustainable marketplace for forest harvest residuals to effectively utilize this waste material and support regional economies.To complete this research the following components were developed: a comprehensive supply chain characterization, a conversion technology and machine rate model, a plant facility costing model, regional spatial and biomass availability data and two economic optimization models. My specific contribution was to examine a spectrum of economic tradeoffs and supply chain considerations including move frequency, logistics, energy costs, moisture content, product viability considerations and regional context related to the implementation of transportable biomass conversion facilities that had previously not been evaluated. Transportable facilities ranging from 15,000-50,000 BDT year scale for three products (biochar, briquettes, torrefied wood) within Oregon, California and Washington are reviewed. The work considers various supply chain pathways including supply options at landings (burn, grind, chip, bale), centralized landings (grind chip), biomass conversion facilities (biochar, briquettes, torrefied wood) and delivery to final market. Within the body of this work, I present three papers where I systematically evaluate the implications of transportable facility design (scale, movement, biomass availability), the economic impacts on the supply chain (logistics, moisture content, product pricing, product production), and the intra-regional variations associated with the system under unique market, product, transportation and energy environments. This analysis was done in an effort to better understand the impacts of transportable conversion facilities and their potential economic viability.A mixed integer linear programming model was developed to characterize, evaluate and optimize biomass collection, extraction, logistics and facility placement over a landscape from a strategic level to evaluate the mobility concept over a five year time horizon. This model was then used to evaluate facility economics of scale, optimal movement frequency, and sensitivity to biomass availability within a Lakeview, Oregon case study facility producing biochar. Results indicated significant advantages with larger scale operations with grid-connected power and limited mobility being preferable to a more mobile facility.  Results depend greatly on the landscape, assumed harvest schedule, biomass composition and governing biomass plant assumptions. A tactical-level biomass supply chain model is also developed to evaluate and characterize the temporal, logistics and multi-product aspects of the proposed transportable facility design. The model solves a multi-period, multi-commodity, multi-echelon combinatorial problem to maximize net present value using a genetic algorithm. This model was used to evaluate competing biomass logistical systems, the impacts of moisture content on costs (transportation and drying) for a single facility as well as to evaluate the impacts of product conversion efficiencies, product pricing and co-product production economics for six plant configurations within the Lakeview, Oregon case study. Results generally indicated that system viability is largely dependent on market pricing, plant assumptions and conversion estimates while processing and transportation logistics are smaller, but important contributors for small scale biomass conversion faculty design configurations. Moisture content management was found to be an important factor contributing to conversion drying cost with co-generation of products benefiting from production and thermal efficiencies. It was also found that, given the revenue estimates, biochar was the most probable candidate for commercial success pending on market conditions.Finally, a regional study was completed to extend the transportable facility economic analysis to five sites (Lakeview, Oakridge, Warm Springs, Quincy, Port Angeles) encompassing three states over a five year time horizon with three product configurations and an assumed 50,000 BDT Year feedstock capacity. This research analyzes the effects of regional differences (logistics, biomass quality and quantity, energy rates, log markets) within the transportable system design to gauge potential economic viability and its sensitivities to fuel, energy and transportation distances. Overall, results indicate that there is a fairly small inter-regional product costing variation (<10%) with regions having close proximity to high quality feedstocks yielding the most cost effective products (Quincy, California and Oakridge, Oregon). Additionally it was found that a rise in diesel price, while incentivizing transportable conversion facilities due to more cost effective transportation, would be more than be offset by the higher cost energy consumption during the conversion process when compared with grid-power with the potential exception of biochar. For the products evaluated, biochar seems to be the most logical as it is less dependent on potentially expensive electrical energy, is the most cost effective to transporting converted material long distances and may support a higher market price. Overall, a transportable operation with grid-power could be the difference between a economically viable supply chain operation and one that is not."
http://hdl.handle.net/1957/61745,"Current literature supports the benefits of participation in extracurricular activities(Barnett & Weber, 2008). However, a report from the U.S. Government AccountabilityOffice (GAO) found that students with disabilities participated in athletics to varyingdegrees, but at consistently lower rates than students without disabilities (US GovernmentAccountability Office, 2010). In January 2013, in response to this report, the Departmentof Education released a policy statement in the form of a Dear Colleague letter clarifyingthe guarantee of equal accessibility based on Section 504 of the Rehabilitation Act of1973 as it applies to extracurricular physical activities for schools that receive federalfunds. The current study sought to a) examine the awareness and implementation of anequal opportunity policy regarding inclusive extracurricular athletics for students withdisabilities and b) explore the utility of integrated frameworks that built off the Theory ofPlanned Behavior (TPB) and evaluate which was able to better predict inclusivebehaviors of physical educators. Two hundred sixty-nine physical educators from acrossthe United States participated in an online survey assessing attitude, subjective norms,perceived behavioral control, intention, implementation intention, task efficacy, andbarrier efficacy toward inclusion in extracurricular athletics.The first manuscript examined teachers’ awareness of the policy and factorsaffecting their behavior regarding the inclusion of students with disabilities inextracurricular athletics. Teachers’ awareness was analyzed using percentages, 95%confidence intervals and Chi-square tests, while behavior used interclass correlations andseparate hierarchical regressions. Current channels of communication were effective, asthe majority of the teachers were aware of the policy, but more could be done to reach theremaining respondents (over 30%) who were still unaware. Undergraduate courseworkwas significantly related to physical educator teachers’ awareness of the policy. Theresults support the importance of undergraduate adapted physical education coursework.Results of the hierarchical regression revealed that intention, implementation intention,task efficacy, barrier efficacy, and coaching status significantly influenced behavior.Utilization of common physical education curricula might provide teachers anopportunity to practice inclusion techniques and promote sport participation by allowingstudents with disabilities to develop their motor skills.In order to successfully implement the inclusive extracurricular athletics policy,the programs should be based on a theoretical foundation. The purpose of the secondmanuscript was to compare four different conceptual models to determine which one fitthe data the best and better predicted physical education teachers’ implementation ofinclusive extracurricular athletics. Path analyses were used to evaluate the TPB (Ajzen,1991) and three independent integrated models (Jin, 2012; Pawlowski, 2016; Roberts,Maddison, Magnusson, & Prapavessis, 2010). Results indicated that none of the modelsmet all the goodness of fit criteria; however, Jin (2012) met 3 of 4 specified criteria. Theaddition of implementation intention and self-efficacy in the three proposed integratedmodels by Pawlowski (2016), Roberts et al. (2010), and Jin (2012) similarly explained asubstantially greater amount of behavior than the TPB alone, R2 = .35, .37, .36 and .11,respectively. Further studies are needed to elucidate the role of implementation intentionand self-efficacy and examine the arrangement of relationships in the proposed integratedframework. Future work should also examine those directly involved with extracurricularathletics and explore ways to reach those who remain unaware of the policy."
http://hdl.handle.net/1957/61747,"Oxo-hydroxo Group 5 metal clusters are an untapped resource to study and advance aqueous solution processing of metal oxide thin films. The tetramethylammonium (TMA) hexatantalate salt (TMA6[H2Ta6O19]) yields dense Ta2O5 films (~95% of the bulk ß-Ta2O5 density) with atomically smooth surfaces (<4 Å root mean square surface roughness). This same precursor produces single-digit-nanometer thick films at low solution concentrations. The diprotonated cluster TMA6[H2Ta6O19] cluster produces films much different from those of the triprotonated analog TMA5[H3Nb6O19]. One additional proton in [H3Nb6O19]5- yields rougher Nb2O5 films with nanoparticles at the surface. A temperature-programmed desorption study of TMA6[H2Ta6O19] elucidates the reaction pathway of precursor to solid oxide. Lastly, the acid-base, ion-exchange chemistry of the basic [H2Ta6O19]6- precursor enables a path to produce amorphous tantalum oxide films at temperatures as low as 200 °C."
http://hdl.handle.net/1957/61757,"In this research, a bi-criteria batching and scheduling problem is investigated in hybrid flow shop environments, where unrelated-parallel machines are run simultaneously with different capacities and eligibilities in processing, in some stages. The objective is to simultaneously minimize a linear combination of the total weighted completion time and total weighted tardiness. The first favors the producer’s interest by minimizing work-in-process inventory, inventory holding cost, and energy consumption as well as maximizing machine utilization, while the second favors the customers’ interest by maximizing customers’ service level and delivery speed. In particular, it disregards the group technology assumptions (GTAs) by allowing for the possibility of splitting pre-determined groups of jobs into inconsistent batches in order to improve the operational efficiency. A comparison between the group scheduling and batch scheduling approaches reveals the outstanding performance of the batch scheduling approach. As a result, contrary to the GTAs, jobs belonging to a group might be processed on more than one machine as batches, but not all machines may be capable of processing all jobs. A sequence- and machine-dependent setup time is required between each of two consecutively scheduled batches belonging to different groups. Based on manufacturing company policy, the desired lower bounds on batch sizes are considered for the number of jobs assigned to batches. Although, the direction in which all jobs move through production line is the same, some jobs may skip some stages. Furthermore, to reflect real industry requirements, the job release times and the machine availability times are considered to be dynamic, which means not all machines and jobs are available at the beginning of the planning horizon.The problem is formulated with the help of four mixed-integer linear programming (MILP) models. Two out of four MILP models are formulated as two integrated phases, i.e., batching and scheduling phases, with respect to the precedence constraints between each pair of jobs batches and or the position concept within batches. The optimal combination between batch compositions of groups are determined in the batching phase, while the optimal assignment and sequence of batches on machines and sequence of jobs within batches are determined in the scheduling phase, with respect to a set of operational constraints. A batch composition of a group corresponding to a particular stage, determined in the batching phase of the MILP model, represents the number of batches assigned to the group as well as the number and type of jobs belonging to each batch of that group. Since the first and second MILP models lead to unmanageable solution space, the relaxed MILP model, which allocates one and only one job to each batch of each group in each stage, can be developed to focus on the non-dominated solution space. The optimal solutions of MILP models and relaxed MILP model are equal, if and only if the optimal solution of the relaxed MILP model does not violate the desired lower bounds on batch sizes. Since the relaxed MILP model cannot guarantee the optimal solution of the MILP models, a third MILP model is developed by integrating batching and scheduling phases. This MILP model eliminates an exhaustive combination enumeration between batch compositions of all groups in all stages. Although the third MILP model converges to the optimal solution slower than the relaxed MILP model, it guarantees finding the optimal solution of the first and second MILP models. A comparison between four MILP models shows the superior performance of the third MILP model. However, since the problem is strongly NP-hard, it is not possible to find its optimal solution within a reasonable time as the problem size increases from small to medium to large, even by the relaxed MILP model or the fourth MILP model. Therefore, several meta-heuristic algorithms based upon basic local search, basic population-based search, and hybridization of local search and population-based searches are developed, which move back and forth between batching and scheduling phases. Tabu Search (TS) is implemented as a basic local search algorithm, while Tabu Search Path-Relinking (TS PR) is implemented as a local search algorithm enhanced with a population-based structure. TS is incorporated into the framework of path-relinking to exploit the information on good solutions. The TS PR algorithm comprises several distinguishing features including relinking procedures to effectively explore trajectories connecting elite solutions and the methods used to choose the reference solution. Particle Swarm Optimization (PSO) is implemented as a basic population-based algorithm, while Particle Swarm Optimization enhanced with a local search algorithm (PSO LSA) is developed to realize the benefits of batching and, consequently, enhance the quality of solutions.Since there is interdependency between positions of a job in different stages of a hybrid flow shop in batch scheduling, a meta-heuristic algorithm is not capable of capturing these interdependencies and, subsequently, its efficacy can be diminished. In order to capture this interdependency, the non-, partial- complete-, and stage-based interdependency strategy are developed. In the stage-based-interdependency strategy, a complete sequence related to all of the stages is gradually determined, stage by stage. An initial solution finding mechanism is developed to trigger the search into the solution space and generate an initial population. The performances of these algorithms are compared to each other in order to identify which algorithm(s) outperforms the others. Nevertheless, the performances of the best algorithm(s) are evaluated with respect to a tight lower bound obtained from a branch-and-price (B&P) algorithm. The B&P algorithm uses Dantzig-Wolfe decomposition (DWD) to divide the original problem into a master problem and several sub-problems (SPs) corresponding to each stage. The original problem is decomposed into the SPs by three DWDs corresponding to the three MILP models. Although, by applying DWD technique in the first and second MILP models, an exhaustive combination enumeration between batch compositions of all groups in all stages is excluded and, as a result, the SPs are easier to solve than the original problem, they are still strongly NP-hard because of an enormous number of combinations between batch compositions of all groups in each stage. However, the DWD technique corresponding to the relaxed MILP model not only drastically reduces the number of variables and constraints in the SPs, but also eliminates the batching phase of the first and second MILP models. Decomposing the original problem based on the relaxed MILP model and implementing the B&P algorithm cannot guarantee optimal solutions or tight lower bounds of problems unless the number of violations in the desired lower bounds on batch sizes is not significant. Therefore, the third MILP model is decomposed by DWD so that the B&P algorithm is capable of finding tight lower bounds even for large-size instances of the problem. A comparison between the lower bounds obtained from the B&P algorithm and CPLEX reveals the impressive performance of the B&P algorithm, particularly for large-size problems. The evaluation of the best algorithms based upon these tight lower bounds developed by the B&P algorithm, uncovers the outstanding performance of hybrid algorithms compared to the results obtained from CPLEX."
http://hdl.handle.net/1957/61758,"Background:   The leading cause of death 20 years after treatment for children surviving a cancer of the central nervous system was from a subsequent malignant neoplasm (SMN) (1).  Although it was been shown that proton therapy considerably reduces the risk of a fatal SMN in children receiving craniospinal irradiation compared to photon therapy, it has not been studied for intracranial tumors.   We hypothesized that proton therapy in a high-income country would provide no benefit in reducing the risk of a fatal SMN in children with intracranial tumors compared to photon therapy in a low- to middle-income country.  Methods:  We performed an in silico clinical trial comparing photon and proton treatments, in which we tested whether a cohort of 7 pediatric patients with intracranial tumors would not have a statistically-significant difference in the lifetime attributable risk, LARTotal, of a fatal SMN. These pediatric patients, ages 3-12, were treated at the American University of Beirut Medical Center (AUBMC) using photon 3DCRT and were retrospectively selected for this study.  The selection criteria included the diagnosis of a low grade localized brain tumor, age of 2-14 years old, availability of computed tomography image sets, and treatment plans constructed between January 1, 2009 to September 30, 2011.  For the photon therapy arm, plans were adjusted slightly to conform to the current standard of care and boost fields were removed.  For the proton therapy arm, treatment planning was performed at the University of Texas MD Anderson Cancer Center according to the standard of care for passive-scattering proton therapy.  The respective clinically-commissioned treatment planning systems (TPSs) were used to calculate the therapeutic dose from photon and proton therapies.  Due to missing anatomy in the patients’ computed tomography (CT) simulations, supplemental anatomy using a computational phantom was fused to each patient for calculation of stray radiation dose in out-of-field organs and tissues. To estimate stray radiation dose in photon therapy, we made measurements in an anthropomorphic phantom and derived a relationship between absorbed dose and distance from the field edge.  For proton therapy, the stray radiation of greatest concern was neutrons, and only neutron doses were considered.  To account for neutrons produced in the patient, an analytical model was trained and validated using previous Monte Carlo simulations of two children who received intracranial proton therapy fields.  To account for neutrons generated in the treatment unit, an analytical model from the literature was adjusted for clinical realism and validated using data from previously-published Monte Carlo simulations of the same two children.  Equivalent doses were estimated using the respective radiation weighting factors for photons, protons, and neutrons.  The equivalent doses from stray and therapeutic radiation were summed, and the mean equivalent dose in each organ and tissue, T, at risk for SMN was calculated.  Lifetime attributable risk of mortality, LART, from a SMN was determined for each cancer site using a widely applied model from the literature. The ratio (LARproton LARphoton) of the combined LART of all cancer sites, LARtotal, was used to compare the two modalities.Results:  We observed that supplement phantoms combined with analytical models were sufficient for estimating stray radiation in missing out-of-field anatomy.  The analytical model used to estimate stray radiation in photon therapy reproduced the 12-year-old boy’s in- anthropomorphic phantom measurements with a RMSD of 0.75 cGy Gy-1, i.e., 6.6% of the dose at the field edge.  Additionally, the equivalent doses estimated by the internal neutron model that we developed were within 13.5% of the Monte Carlo for distances between 3 cm to 10 cm and were within a factor of two for distances between 10 cm to 20 cm.  The equivalent doses estimated by the external neutron  analytical model that we adjusted for clinical realism deviated by less than a factor of two from the Monte Carlo results of two children with intracranial tumors.  We observed that both the internal and external neutron analytical models were of sufficient accuracy for estimating dose from stray neutrons.  For photon therapy, the largest mean organ equivalent doses were found in in the red bone marrow, remainder, skin, and thyroid and were greater than 0.8 Sv.  This was true for proton therapy as well except for the thyroid for which the average equivalent dose across all patients was 0.337 ± 0.154 Sv. The main result of these studies was that we found that proton therapy reduced the risk of developing a fatal SMN in these pediatric patients for which the ratio of LARtotal was 0.75 ± 0.22.  This led to the rejection of the null hypothesis (H0:  ratio of LARtotal =1) with a p-value of 0.011.  The primary contributors to LARtotal were leukemia and other solid tumors for which the ratio of LART were 0.80 ± 0.27 and 0.76 ± 0.26, respectively.  In general, the ratio of LART was less than one except for bladder cancer in all the children, ovarian and uterus cancers in the girls, and prostate cancer in the boys.  However, the LART for each of these cancer sites was small, i.e., less than 0.02%.  Other observations included that the LARtotal decreased as the age of the children increased.Conclusions:  We conducted an in silico clinical trial that disproved our hypothesis and implicated that children treated with intracranial photon fields in low- to middle-income countries would have a statistically-significant reduced risk of a fatal SMN if they were instead treated with intracranial proton fields.  Additionally, our findings from these studies suggest that applying supplemental anatomy and contours from generic computational phantoms and models of out-of-field dose may be used to determine organ doses in clinical and research radiotherapy studies when the actual patients’ anatomies are not available.   Furthermore, our methods demonstrated the feasibility of using commercial TPSs combined with analytical models to quantify therapeutic and stray radiation in proton and photon therapy.  This ability introduces the possibility of quickly comparing different modalities or optimizing treatment plans to minimize long-term morbidities, such as SMNs.  The internal neutron model that we developed as part of this study was most accurate within 10 cm of the treatment fields where the internal neutron dose contributes the most to overall exposures.  This model combined with the external neutron model, can be used to estimate the equivalent dose from stray neutrons produce in proton therapy with sufficient accuracy.  Future work includes programming the analytical models used in this study as add-ons for commercial TPSs."
http://hdl.handle.net/1957/61760,"Generalisation is a key component of mathematical activity. Mathematicians often seek general formulae or wonder if a rule that holds in a particular dimension also holds in dimension n. However, generalisation is not limited to professional mathematicians; kindergarteners engage in generalisation when they seek patterns and algebra is sometimes described as generalised arithmetic. Because generalisation is so critical to mathematical thought, research that investigates how people generalise is an important part of supporting student learning. In particular, students often struggle to form normatively correct generalisations (e.g., Dorko & Weber, 2014; Jones & Dorko, 2015; Kabael, 2011; Martínez-Planell & Gaisman, 2013, 2012; Martínez-Planell & Trigueros, 2012). Research can help us better understand what ways of thinking are productive for generalising and help us understand the nature of generalisation as a practise. To that end, this dissertation study focuses on how students generalise their notion of function from the single- to multivariable setting. I focus on function because functions are a fundamental mathematical concept and are relevant in everyday life.  	The first manuscript describes results from a longitudinal study regarding how five calculus students generalised what it means for a relation to be a function from the single- to multivariable setting. In keeping with the use of the term ‘generalisation’ to refer to both a product (e.g., a theorem) and a process (c.f. Harel & Tall, 1991; Mitchelmore, 2002), I describe both the mathematical ideas students generalised and the nature of their generalising activity. Findings indicate that students generalised mathematical ideas such as function-as-equation, function-as-pattern, the vertical line test (VLT), function notation, inputs and outputs, and univalence. Focusing on equations seemed to prevent students from developing a normative understanding of what it means to be a function in R3. In contrast, some students considered generalisations of the VLT (e.g., applying the VLT to traces, lines parallel to the y axis on an R3 graph) that, while not normatively correct, led to correct generalisations. Similarly, thinking about function notation and inputs and outputs supported students in forming correct generalisations. Findings about students’ generalising activity indicate that students engaged in what Ellis (2007) terms relating, searching, and extending. For example, some students made sense of the notation f(x, y) by relating it to the notation f(x). One student engaged in searching as she sought to generalise the vertical line test. She searched for a way to draw a line on an R3 graph that would intersect the graph exactly once. Other students extended the range of applicability of prior ideas (e.g., input and output) and their definitions of function. 	The second manuscript is more theoretical in nature. In this manuscript, I argue that Piaget’s constructs of assimilation and accommodation align with Harel and Tall’s (1991) framework for generalisation in advanced mathematics. Based on what they imagined to be the cognitive processes underlying generalisation, Harel and Tall proposed that generalisation might be expansive (occurring when a student expands the applicability range of an existing schema without reconstructing it), reconstructive (occurring when a student reconstructs a schema to widen its range of applicability), or disjunctive (occurring when a student constructs a new, disjoint schema to deal with a new context). I employ this framework to interpret data about how students generalise their notion of function from R2 to R3 and how they first think about graphing in R3. I then interpret the same instances through the lens of assimilation and accommodation, arguing that they provide explanatory mechanisms for generalisation. I conclude by discussing how assimilation and accommodation explain other empirical findings regarding students’ generalisation of function and graphing. 	Taken together, the two manuscripts provide different, complementary insight into the generalisation phenomenon. The first manuscript employs a framework that describes generalisation at a small grain size, while the second focuses on describing generalisation from a much larger grain size. While the first manuscript describes generalisation empirically, the second seeks to contribute to a theoretical explanation for how generalisation occurs. Notably, these investigations occur among a population (undergraduate students) and content area (single and multivariable calculus) in which generalisation has not typically been studied. As a whole, the dissertation extends the existing body of literature by both empirically and theoretically examining the phenomenon of generalisation with undergraduate students in a relatively advanced mathematical setting."
http://hdl.handle.net/1957/61761,"The fact that measuring a quantum system reduces it to apparently classical behavior,eliminating the interference patterns that are a hallmark of quantumness, cries out foran explanation. That explanation has been provided by the recognition of decoherence,whereby the interference is destroyed by the very interaction that acquires information.We begin by showing how this scenario plays out in a simple analytical model—designedto be pedagogical—of measurement in a double-slit experiment. This model illustratesthe continuous trade-oﬀ between information and interference in a concrete mathemat-ical framework that makes explicit the role of measurement-induced decoherence in theprocess, thereby providing a natural stepping stone to a discussion of environmentally-induced decoherence and the real target of this work: the origin and accessibility ofclassical reality.Quantum Darwinism, building on the decoherence program, provides an explanationfor the emergence of classicality within what we have come to recognize as a fundamen-tally quantum universe; that is, how some physical observables take on robust, objective,veriﬁable values despite the intrinsically fragile and subjective nature of observables inquantum theory. It does so by acknowledging the role of the environment as a witness,continuously monitoring certain “pointer observables” of the system, and as a communi-cation channel, amplifying information about those observables and distributing manycopies of it throughout the world. Past work in this area focused on the ability of the en-vironment to perform this ampliﬁcation and the amount of information potentially avail-able in fragments of the environment, but little focus has been placed on the observer’sability to actually collect that information. Here we show that redundant information isavailable to observers even when locality prohibits them from accessing quantum corre-lations within their fragment; a “bit-by-bit” measurement will suﬃce with only a slightincrease in the required fragment size. Moreover, we show that, except in the case ofa very low entropy environment, the decoherence process that produces these objective,classical states gives rise also to a convenient classical measurement toward which localobservers can evolve. Together, these results demonstrate that even local observers can,and indeed almost certainly will if given time to adapt, share in the objective, classicalreality that emerges when living in a large quantum universe, thereby providing anotherstepping stone in the bridge that quantum Darwinism is building between our quantumuniverse and classical experience."
http://hdl.handle.net/1957/61763,"The combined activities of diverse heterotrophic marine microorganismssignificantly shape global biogeochemical cycles, but models of these activities arecurrently limited to aggregate microbial community processes, and it remains unclearhow community structure and the functional roles of specific microbial taxa should beintegrated into these models. Therefore, understanding the contributions of specificmicrobial populations toward net community processes remains a critical step fordetermining the appropriate taxonomic resolution that should be employed in morecomplex models of ecosystem processes. The application of ‘omics’ methods, such asmetagenomics and metaproteomics, has revealed the phylogenetic diversity of naturalmicrobial communities and the functional potential of discrete populations. From theintegration of these observations, an understanding of microbial community dynamicshas emerged in which niche processes influence general patterns of community structureat broad taxonomic scales across spatial and temporal resource gradients. Within thesedynamic microbial systems, the partitioning of specific resources is governed by resourcepreferences and competitive interactions that cannot be ascertained with ‘omics’approaches alone. In order to link phylogenetic identity with ecological function, andcharacterize resource partitioning in coastal marine microbial communities, we appliednovel mass spectrometry techniques to stable isotope probing (SIP) experimentsconducted on microbes sampled from coastal North Pacific surface waters.Chapter 2 presents the first application of proteomic stable isotope probing(proteomic SIP) to track 13C-labeled substrates into the proteomes of planktonic marinemicrobial communities. We developed two metrics for describing observations of labelincorporation into peptides. Label frequency is a measure of protein synthesis activitythat is calculated as the ratio of labeled to total detected peptide mass spectra for adefined set of proteins. Average enrichment is a measure of substrate specialization, andis calculated from the average percent of stable isotope content measured for a set oflabeled peptides. Using these metrics, we compared the assimilation of 13C-labeled aminoacids by abundant microbial taxa over two time-points, 15 and 32 hours. Thecommunities sampled from Newport, OR and Monterey Bay, CA exhibited similarbehaviors. Alteromonadales and Rhodobacterales proteomes had significantly high labelfrequency at the first time-point but had diverging trajectories in the second time-pointindicating that Rhodobacterales held a competitive advantage as the amended substratebecame depleted.In Chapter 3, we examined the assimilation of six 13C-labeld substrates bymicrobial taxa sampled from Monterey Bay, CA. Comparisons between relativeabundance shifts and substrate assimilation were inconsistent, emphasizing the need forcaution when interpreting relative abundances shifts in microbial communityexperiments. Specialization patterns were significantly conserved among abundantpopulations within class level divisions, suggesting that resource preferences have deepevolutionary origins, but variation in the activities of individual species or strains withinthese lineages may be driven by other environmental factors, such as resourceconcentrations or temperature, or pressure from grazing and viral lysis. Although activitymeasures were also conserved among these classes, measures of activity divided theseclades into higher or lower activity, suggesting different strategies for responding toincreased nutrient availability.Finally, Chapter 4 explores physiological bases for observations of diverginglevels of activity among microbial taxonomic lineages. We found that substrate additionsresulted in reproducible taxonomic and functional changes in the whole communitymetaproteome, and that relative abundances of specific protein functional assignmentsdifferentiated abundant taxa. Comparisons of the protein functional profiles (i.e., therelative abundances of mass spectra assigned to functional categories) for specific taxa,between time-points and also between treatments, generally revealed minimal changes inthe expressed proteins, which suggests some inherent overall stability in the functions ofthese taxa, despite environmental changes. However, there were significantly differentamounts of variation observed in the proteomes of abundant taxa; higher levels of whichcorrelated with higher observed label frequency, greater numbers of detected ribosomes,and larger nitrogen requirements encoded in their genomes. Taken together, theseobservations suggest that the capacity of organisms to respond rapidly to increasednutrient availability relies on the ability to transition into states of increased proteinsynthesis, and that this strategy does not select for reductions in nitrogen requirements.However, these adaptations for exploiting abundant resources were not correlated withother physiological features, such as the abundance of transporters, motility proteins, andgene regulatory mechanisms.The outcome of these experiments, enabled by the concurrent use of ‘omics’ andnovel mass spectrometry methods, was a deeper understanding of how resourcepreferences of individual microbial taxa impact carbon cycling processes within complexmarine microbial communities. Although SIP approaches can only access assimilatoryprocesses, they complement established ‘omics’ techniques by revealing interactions suchas competition for and partitioning of resources that can only be examined bysimultaneous measuring of whole community dynamics and the relative contributions ofindividual populations."
http://hdl.handle.net/1957/61764,"In this research, a bi-criteria batching and scheduling problem is investigated in hybrid flow shop environments, where unrelated-parallel machines are run simultaneously with different capacities and eligibilities in processing, in some stages. The objective is to simultaneously minimize a linear combination of the total weighted completion time and total weighted tardiness. The first favors the producer’s interest by minimizing work-in-process inventory, inventory holding cost, and energy consumption as well as maximizing machine utilization, while the second favors the customers’ interest by maximizing customers’ service level and delivery speed. In particular, it disregards the group technology assumptions (GTAs) by allowing for the possibility of splitting pre-determined groups of jobs into inconsistent batches in order to improve the operational efficiency. A comparison between the group scheduling and batch scheduling approaches reveals the outstanding performance of the batch scheduling approach. As a result, contrary to the GTAs, jobs belonging to a group might be processed on more than one machine as batches, but not all machines may be capable of processing all jobs. A sequence- and machine-dependent setup time is required between each of two consecutively scheduled batches belonging to different groups. Based on manufacturing company policy, the desired lower bounds on batch sizes are considered for the number of jobs assigned to batches. Although, the direction in which all jobs move through production line is the same, some jobs may skip some stages. Furthermore, to reflect real industry requirements, the job release times and the machine availability times are considered to be dynamic, which means not all machines and jobs are available at the beginning of the planning horizon.The problem is formulated with the help of four mixed-integer linear programming (MILP) models. Two out of four MILP models are formulated as two integrated phases, i.e., batching and scheduling phases, with respect to the precedence constraints between each pair of jobs batches and or the position concept within batches. The optimal combination between batch compositions of groups are determined in the batching phase, while the optimal assignment and sequence of batches on machines and sequence of jobs within batches are determined in the scheduling phase, with respect to a set of operational constraints. A batch composition of a group corresponding to a particular stage, determined in the batching phase of the MILP model, represents the number of batches assigned to the group as well as the number and type of jobs belonging to each batch of that group. Since the first and second MILP models lead to unmanageable solution space, the relaxed MILP model, which allocates one and only one job to each batch of each group in each stage, can be developed to focus on the non-dominated solution space. The optimal solutions of MILP models and relaxed MILP model are equal, if and only if the optimal solution of the relaxed MILP model does not violate the desired lower bounds on batch sizes. Since the relaxed MILP model cannot guarantee the optimal solution of the MILP models, a third MILP model is developed by integrating batching and scheduling phases. This MILP model eliminates an exhaustive combination enumeration between batch compositions of all groups in all stages. Although the third MILP model converges to the optimal solution slower than the relaxed MILP model, it guarantees finding the optimal solution of the first and second MILP models. A comparison between four MILP models shows the superior performance of the third MILP model. However, since the problem is strongly NP-hard, it is not possible to find its optimal solution within a reasonable time as the problem size increases from small to medium to large, even by the relaxed MILP model or the fourth MILP model. Therefore, several meta-heuristic algorithms based upon basic local search, basic population-based search, and hybridization of local search and population-based searches are developed, which move back and forth between batching and scheduling phases. Tabu Search (TS) is implemented as a basic local search algorithm, while Tabu Search Path-Relinking (TS PR) is implemented as a local search algorithm enhanced with a population-based structure. TS is incorporated into the framework of path-relinking to exploit the information on good solutions. The TS PR algorithm comprises several distinguishing features including relinking procedures to effectively explore trajectories connecting elite solutions and the methods used to choose the reference solution. Particle Swarm Optimization (PSO) is implemented as a basic population-based algorithm, while Particle Swarm Optimization enhanced with a local search algorithm (PSO LSA) is developed to realize the benefits of batching and, consequently, enhance the quality of solutions.Since there is interdependency between positions of a job in different stages of a hybrid flow shop in batch scheduling, a meta-heuristic algorithm is not capable of capturing these interdependencies and, subsequently, its efficacy can be diminished. In order to capture this interdependency, the non-, partial- complete-, and stage-based interdependency strategy are developed. In the stage-based-interdependency strategy, a complete sequence related to all of the stages is gradually determined, stage by stage. An initial solution finding mechanism is developed to trigger the search into the solution space and generate an initial population. The performances of these algorithms are compared to each other in order to identify which algorithm(s) outperforms the others. Nevertheless, the performances of the best algorithm(s) are evaluated with respect to a tight lower bound obtained from a branch-and-price (B&P) algorithm. The B&P algorithm uses Dantzig-Wolfe decomposition (DWD) to divide the original problem into a master problem and several sub-problems (SPs) corresponding to each stage. The original problem is decomposed into the SPs by three DWDs corresponding to the three MILP models. Although, by applying DWD technique in the first and second MILP models, an exhaustive combination enumeration between batch compositions of all groups in all stages is excluded and, as a result, the SPs are easier to solve than the original problem, they are still strongly NP-hard because of an enormous number of combinations between batch compositions of all groups in each stage. However, the DWD technique corresponding to the relaxed MILP model not only drastically reduces the number of variables and constraints in the SPs, but also eliminates the batching phase of the first and second MILP models. Decomposing the original problem based on the relaxed MILP model and implementing the B&P algorithm cannot guarantee optimal solutions or tight lower bounds of problems unless the number of violations in the desired lower bounds on batch sizes is not significant. Therefore, the third MILP model is decomposed by DWD so that the B&P algorithm is capable of finding tight lower bounds even for large-size instances of the problem. A comparison between the lower bounds obtained from the B&P algorithm and CPLEX reveals the impressive performance of the B&P algorithm, particularly for large-size problems. The evaluation of the best algorithms based upon these tight lower bounds developed by the B&P algorithm, uncovers the outstanding performance of hybrid algorithms compared to the results obtained from CPLEX."
http://hdl.handle.net/1957/61766,"Seed dormancy is defined as the inability of viable seeds to germinate under conditionsotherwise favorable for germination. Dormancy provides a strategy for seeds to germinateat an appropriate time. Abscisic acid (ABA) is a major hormone involved in the regulationof seed dormancy. To elucidate the molecular mechanisms of dormancy, the twoexperimental systems, Gene Switch (GS), a chemically induced system and positivefeedback (PFB) system, a spontaneous system that does not require a chemical ligand,were created. Both systems were engineered to induce nine-cis-epoxycarotenoiddioxygenase (NCED), a rate-limiting enzyme of ABA biosynthesis. The GS systemincreased ABA levels in seeds more than 20 fold while PFB increases ABA more than 73fold, with both preventing imbibed seeds from germinating. To understand dormancymechanisms, the molecular consequences of NCED6 induction in the GS system wereinvestigated by RNA sequencing (RNA-seq). Many genes involved in ABA biosynthesisand signaling were identified. Other NCEDs, such as NCED5 and NCED9 and other ABAbiosynthesis genes, such as ZEAXANTHIN EPOXIDASE and ABSCISIC ALDEHYDEOXIDASE3, which function upstream and downstream of NCED, were upregulated inseeds by NCED6 induction. These results suggest that the distinct layers of PFB loops arecoordinately operating in the NCED6-induced seeds. In addition to known genes, manyuncharacterized genes including DELAY OF GERMINATION1 (DOG1)-LIKE-4 (DOGL4)and five long intergenic noncoding RNAs (lincRNAs) termed N6LINCRs were identifiedand characterized. DOGL4 shares only limited homology in amino acid sequence toDOG1, a major regulator of seed dormancy. Induction of DOGL4 alone in imbibed seedscaused expression of 70 seed maturation-specific genes, including those coding for themajor seed reserves, such as albumin, cruciferin, and oleosin, as well as sugar and lipidtransporters that are not affected by dog1-1 mutation. These results suggest that DOGL4 isa master regulator of reserve accumulation in seeds and has a distinct role from that ofDOG1. N6LINCR1, one of the lincRNAs identified by RNA-seq was preferentiallyexpressed from one strand and showed a clear response to ABA and gibberellin (GA) inseeds. RNA-seq analysis showed that induction of N6LINCR1 upregulated 26 genes anddownregulated 66 genes, suggesting that this lincRNA has a regulatory role in geneexpression in seeds, which potentially contributes to ABA regulation of germination.Besides their importance in basic research, the GS and PFB systems created in this thesisresearch provide efficient technologies, which can prevent preharvest sprouting (PHS),precocious germination in cereal crops. Moreover, DOGL4, a major seed maturationregulator identified by this study, also offers a great potential to increase protein and lipidcontents in grain crops and contribute to agricultural production and food security."
http://hdl.handle.net/1957/61768,"CLT is becoming global. New countries and regions increasingly realize the potentialof what can be done with CLT. As a result, new markets are forming and newcompanies are entering the industry. Every new region or country that opens itsdoors to CLT has its own challenges and opportunities. However, there is the uniqueopportunity to learn from the existing Original Market in Europe and the companiesthat have been successful there for many years. Especially the German-speakingalpine region was, and still is, the cradle of CLT innovation. Therefore, this research,using qualitative methods, analyzed market characteristics and business models ofthis region. Lessons learned over the years were identified such as the importanceof high-level timber education, the role of designing for building services, hypeversus reality with respect to tall wood buildings and how careful design processesare key to competitiveness of CLT buildings. Threats and challenges in the NorthAmerican CLT market were also identified there. The combined findings give anenhanced understanding of how the implementation of CLT in North America, as anexample of a new global market, can be fostered."
http://hdl.handle.net/1957/61769,"Direct anthropogenic stressors have caused drastic declines in wildlife populations over the past two centuries. In the face of these threats, spillover of infectious disease from domestic animals and livestock into wildlife, and novel interactions between parasites and pathogens within wildlife communities, have further suppressed already vulnerable populations.  As management officials and conservationists fight to counteract these influences, a sound understanding of how pathogens and parasites interact to shape host health, and the level of disease threat posed from outside species, has become paramount to ensuring long term population viability.  Here I use two model systems to examine these interactions.	The first study system (Chapters 1, 2, and 3) examines the potential implications of an immunosuppressive lentivirus, feline immunodeficiency virus (FIV), for structuring host health, immunity, and coinfection dynamics in a population of 219 free-ranging African lions (Panthera leo) living in Kruger National Park, South Africa.  Similar to HIV in humans, FIV has been linked to an AIDS-like syndrome in domestic cats characterized by decreased functional immunity; alterations to biochemical, histological, and serological markers; and increased susceptibility to other parasites and pathogens.  While recent evidence suggests similar mechanisms may be at play in FIV-infected lion hosts, less is known about the health implications of FIV for this species or what role coinfections may play in structuring disease outcome.  In Chapter 1 I set the stage for this investigation by expanding the available toolbox for lion health research and creating a set of normal reference intervals against which health metrics for free-ranging lions can be compared.  Using metrics and tools established in Chapter 1, I then use Chapters 2 and 3 to show that FIV exhibits wide scale immunosuppressive and negative health effects within lion hosts, but that parasite and pathogen communities facilitated by the virus may be of equal or greater importance for determining both health outcome and susceptibility to other coinfections when compared to FIV alone.  	In the second study system, I examine disease prevalence and incidence in a common, highly adaptable species, the feral cat (Felis catus), to determine its potential as a disease reservoir for sympatrically dwelling human and animal populations.  Using a healthy population of 129 feral cats presented at a local trap-neuter-release program in Portland, Oregon, I show that prevalence and incidence of viral and bacterial pathogens, as well as endo- and ectoparasites, is high among this untreated population.  Together, findings of these respective studies show potential points for disease intervention on both the parasite and host level."
http://hdl.handle.net/1957/61770,"In this dissertation, the spectroscopic properties and thermodynamic stability of a class of materials known as metal oxo and hydroxo clusters are studied. In aqueous solutions, many metals can aggregate into discrete clusters of metals bridged by oxo or hydroxo ligands. These clusters are of particular interest to us for their use as precursors for metal oxide thin films. Understanding the stability of these clusters, along with distinguishing ways to uniquely identify particular clusters via spectroscopy, is vital to improving the quality of cluster precursors and the metal oxide thin film products.Vibrational spectroscopy is an appealing technique for the identification of cluster species because of the relative ease to collect experimental IR and Raman spectra. However, uniquely identifying cluster vibrations is difficult due to the similarity of ligands types and vibrational modes between different clusters. Disclosed herein are two studies of vibrational spectroscopy applied to metal hydroxo clusters of Group 13 metals. These studies focus on one cluster structure in particular, the flat tridecamer, M13(OH)24(H2O)2415+, where M= Al3+ or Ga3+. The vibrations of the NO3- counterions used in these studies overlap with the frequencies associated with cluster vibration, which limits the uniqueness of the Raman and IR signals. Nonetheless, full assignment of peaks was made for solid state and solution phase flat tridecamers.NMR spectroscopy is an appealing technique for the identification and characterization of cluster species because of the amount of structural information that can be gleaned from NMR spectra. In one study, we used 1H-NMR to characterize flat tridecamers with a mixture of gallium and indium. Computations struggle to predict NMR spectra because these spectra reflect average structures over time, and static computations rely on single structures and are especially sensitive to small deviations in atom positions. In this study, we computed the 1H-NMR signals for the flat tridecamers Ga13-xInx(OH)24(H2O)2415+, and fully assigned the experimental proton signals to each proton coordination environment that is possible for these clusters. Quantum mechanical computations can also be used to understand the stability of different cluster species relative to each other. In this dissertation, the stability of Al, Ga, and Hf clusters is explored. Hf tetramer clusters, Hf4(OH)8(H2O)168+, were examined with peroxide substitution for a pair of hydroxide or water ligands. These calculations suggest that peroxide prefers to substitute for the terminal water ligands versus the bridging hydroxide ligands. This study also highlights the importance of accurate solvation models for computing the structures and stabilities of clusters in aqueous solutions.For the Group 13 metals aluminum and gallium, the stability of different clusters can be computed based on the identity and binding modes of the different ligands. Using ligand identities to compute hydrolysis energies can reproduce quantum mechanical computations of cluster stability with extremely high accuracy. However, these calculations do not include the cluster counterions, which can affect the stability of high-charge clusters. For a full determination of cluster speciation in solution, counterions are required for accurate speciation across all possible species. The speciation and structural conformations of Al clusters was studied with Cl-, NO3-, HSO4-, and ClO4- counterions."
http://hdl.handle.net/1957/61771,"Parcellization of the rural landscape threatens the provision of social, ecological and economic benefits to society due to loss of economies of scale. A continued provision requires new approaches to forest management for multiple, interconnected goals. I used interviews, archival records and field measurements to learn how select, experienced owners of small forests simultaneously manage for income and structural diversity. The analysis of six 25 to 150 acre forests in the Central Willamette Valley of Oregon revealed that each landowner had income sources other than timber from their forests and had integrated their forest in diverse financial portfolios. Deliberate management for structural diversity in the assessed forests resulted in the three categories ‘close-to-industry’, ‘close to preserve’ and ‘intermediate’. There were considerable differences in landowner’s approaches to generate income and structural diversity. However, I also identified twenty-four general resource and strategy patterns which I explain through three theoretical contributions on 1) landowner learning, 2) understanding of the architecture of the complex system of small forest management and 3) integration of actions to achieve management goals. I conclude that the forests under examination add structural diversity elements to a conifer-dominated landscape component while not necessarily sacrificing economic goals."
http://hdl.handle.net/1957/61773,"Cold air pools are spatiotemporal phenomena that occur when cold air from higher elevations roll down the slope to accumulate in lower elevations. Behaviors like this lead to microclimate anomalies such as the city of Corvallis (Oregon) experiencing persistent cold weather even on a sunny day. We analyze multivariate temperature time-series data and associated covariates from about 160 sensors from the HJ Andrews Research Forest (Oregon) through visualization and modeling to study this phenomenon. We develop detectors to localize cold air pools in both time and space, and carry out simulation studies to assess their performance under different microclimatic and sensor-performance conditions."
http://hdl.handle.net/1957/61774,"Rare plant reintroductions are a critical conservation tool for the augmentation of diminishing populations, or re-establishment of extirpated populations. Analysis of reintroduction failures suggests that a sophisticated understanding of species biology, ecology, and habitat is essential for producing self-sustaining rare plant populations. This study sought to generate that background knowledge for the declining rare perennial Rorippa columbiae (Brassicaceae), to improve the likelihood of success for future reintroduction efforts. Specifically, this research aimed to develop germination and propagation protocols for the production of ex situ material, and to quantify in situ habitat attributes to inform appropriate reintroduction site selection. Laboratory experiments were conducted to evaluate the influence of light exposure, cold stratification duration, temperature regime, and source site on optimal R. columbiae germination. Results revealed that R. columbiae seeds require light and a higher temperature regime to germinate successfully, and do not require cold-moist stratification to break dormancy. Source sites produced significantly different germination responses. A factorial greenhouse experiment examined optimal propagation requirements by measuring the effect of propagule type, substrate type, and source site on R. columbiae emergence, and vegetative and reproductive growth characters. Models demonstrated that rhizome propagules and LA4 nursery grow mix consistently produced the highest emergence and growth measures. Genetic divergence between source sites was demonstrated in a common garden analysis, and a reciprocal transplant analysis showed no evidence of home-site advantage, indicating response variation cannot be attributed to adaptation. An observational field study assessed population health, landscape, soil, and biological community attributes associated with occupied patches of R. columbiae in southern Oregon. The population health assessment showed significantly different population sizes among extant populations, and a positive correlation between population size and vegetative and reproductive growth metrics. Though values of measured attributes varied considerably in R. columbiae habitat, when habitat associated with R. columbiae presence and absence were compared, the majority of variables exhibited no significant differences. Exceptions included an association between large, high performing R. columbiae populations and lower elevation, a lower percentage cover of bare ground, and lower calcium, magnesium, and potassium concentrations. Extant populations appeared associated with lower calcium concentrations, higher iron concentrations, and a higher percentage cover of bare ground and native forbs. These attribute associations signaled potential habitat preferences for future Rorippa columbiae modeling and reintroductions."
http://hdl.handle.net/1957/61775,"Life on Earth intimately depends on the function of countless proteins. For the majority of studied proteins, function absolutely depends on conformation (i.e. 3-dimensional shape in solution). The exact nature of how a protein goes from an unfolded linear polypeptide chain to an organized folded molecule is still not known, and there is still much uncertainty about the details of folded protein structures. Answering both questions fully, especially by being able to accurately predict protein structures from sequence alone, is known as the protein folding problem. In this dissertation, the nature of protein structure research, especially as it pertains to model-building, entropy, and Boltzmann’s principle, is discussed. Original work is presented in three chapters in the form of primary research reports. In chapter 2, high resolution protein crystal structures are used to describe the details of a high-energy transition conformation that occurs during protein folding. These native structures were found to have stabilized individual residues in conformations that represented “snapshots” along the transition pathway, and could be used to model the transition. In chapter 3, the extent and reliability of observed non-planarity of the peptide bond is assessed, using ultra-high resolution protein crystal structures. This work continues a discussion on peptide planarity that exists in the literature, and sets the record straight on the occurrence of this “non-ideal” geometry. In chapter 4, the “Ensemblator” is described and demonstrated. This software package is capable of comparing and analyzing large numbers of related protein models simultaneously, and represents an invaluable tool to protein structure researchers. Lastly, in chapter 5, impacts and highlights of the reported work are discussed, along with directions for future work. The dissertation concludes with a reflection on the nature of problems being researched in protein structure, and a discussion on how the included original work relates to Boltzmann’s principle and model building in general."
http://hdl.handle.net/1957/61776,"Understanding the ecological role of Pacific oyster aquaculture (Crassostrea gigas) and eelgrass (Zostera marina L.) as important habitats in US Pacific Northwest estuaries is critical for management and regulatory decisions. The oyster aquaculture industry is currently restricted by regulations concerning impacts of their activities on Z. marina. This seagrass is protected under several legislative designations including Essential Fish Habitat (EFH) for federally managed fish species under the Magnuson Stevens Act. To date, federal and state regulations do not consider aquaculture as functional ecological habitat. While estuarine habitats serve multiple functions, the focus of our study was to evaluate fish and crab use. Underwater digital video surveys and minnow traps were used to quantify fish and crab abundance and behavior in longline oyster aquaculture, eelgrass beds, and the edge between these two habitats. Standardized predation tethering units (PTUs) were also deployed in each of these habitats to examine predation risk and refuge value.  Our objective was not only to determine what fish and crab species were present, but also to determine whether their behavior could be used to clarify the functional role of these habitats and compare results among estuaries. Although there were no differences among habitat types in minnow trap catch, shiner perch (Cymatogaster aggregata) and Pacific staghorn sculpin (Leptocottus armatus) were the most common fish taken in all three estuaries.  Shiner perch were sighted in Samish Bay video more frequently in longline aquaculture than in eelgrass while Pacific staghorn sculpin were more frequently sighted on the edge than in either oyster aquaculture or eelgrass.  Additionally, behavior of fish and crab did not differ among habitat types in Samish Bay. Results of predation assays suggested that predation pressure was highest in Tillamook Bay and lowest in Samish Bay where an apparent edge effect is consistent with higher abundance of Pacific staghorn sculpins. While benthic structure provided by both eelgrass and oysters has previously been shown to be important, our results suggest that the form of the benthic structure (e.g. off-bottom versus on-bottom) and features such as edge habitats may also play an important role in PNW estuaries."
http://hdl.handle.net/1957/61778,"When conditions for photosynthesis are unfavorable, excess solar radiation is dissipated as heat from leaves through a shift in xanthophyll pigments that result in reflecting rather than absorbing light at some wave lengths. The shift in xanthophyll pigments can be quantified as a photochemical reflectance index (PRI) by monitoring specific wavelengths in the visible part of the spectrum.In my research, I applied the photochemical reflectance index to assess changes in the degree of stress on tropical forests at two extremely different spatial resolutions: first, across the entire Amazon Basin using satellite-borne sensors, and secondly, above an individual stand of trees using a spectroradiometer mounted on a tower.The basin-wide analysis took advantage of NASA’s Moderate Resolution Imaging Spectroradiometer (MODIS) that sequentially monitored 1 x 1 km pixels at different viewing angles from two satellites. To correct for varying atmospheric conditions we used the most sophisticated algorithm available (Multi-angle Implementation of Atmospheric Correction Algorithm - MAIAC).  With these combined data sets, I was able to discern large differences in photosynthetic efficiency occurred at monthly intervals between 2000 and 2012 across the entire Amazon Basin.The analysis of PRI from an individual stand was limited to a 17-day period at the end of the dry period and beginning of the wet in the year 2012.  There was good agreement between average PRI reflectance patterns from  three separate tree canopies with measured  eddy-flux measurements of gross primary production over the selected period (r2 = 0.65, P <0.05). Moreover, the analysis demonstrated that the sunlit leaves were the ones most responsive to variation in climatic conditions whereas the reflectance patterns from more shaded parts of the canopy were relatively stable.The significance of my research is that it shows physiological responses to stress occur and can be monitored even if more conventional reflectance indices show no change.  This indicates that we have much greater opportunities to explain and predict how forests are responding to climate change than previously thought."
http://hdl.handle.net/1957/61784,"Most of today’s Internet of Things (IoT) applications assume that data will be moved offdevices into centralized cloud platforms. While existing IoT systems leverage cloud-based analytics for meaningful data reasoning, the assumption that data should always be moved off the devices is problematic. The amount of data to be moved from devices over Internet gateways to cloud platforms is huge which potentially make it cost inefficient. In other scenarios, privacy concerns of customers or organizational rules complicate the process of transferring data to third-party data centers.This dissertation proposes architectures and dynamic overlay network algorithms for in-networkand edge processing of data offered by the globally available IoT devices and provides a global platform for meaningful and responsive data analysis and decision making. The proposed techniques shift IoT analytics from a ”collect data now and analyze it later” scenario to directlyproviding meaningful information from the in-network processing of devices data at or near thedevices. The techniques serve future IoT use cases including distributed context awareness, on-demand data analysis, and in-network decision making.  The dissertation comprises three main components.The first component is a device management protocol for cloning devices’ data in proximateEdge Computing platforms. Unlike existing application-layer IoT management protocols theproposed protocol uses the LTE LTE-A radio frame structure, device-to-device communication,and IoT data properties to avoid excessive network access latency in existing technologies.The second component realizes distributed IoT analytics as overlay networks of devices clones. By means of virtual network embedding, it selects and interconnects devices’ clones to efficiently realize applications’ virtual topologies to achieve goals such as minimum latency, minimum infrastructure cost, or maximum infrastructure utilization.Finally, the dissertation presents a communication middleware that allows autonomous discovery, self-deployment, and online migration of devices’ clones across heterogeneous Edge computing platforms. The middleware ensures that communication latency between clones is kept minimum despite the uncontrolled variability of the network and hosting platforms conditions.We evaluate the proposed architectures and algorithms through simulations and prototypeimplementation of various components in controlled testbed environments, which we evaluateusing real user applications. We explore the feasibility of the proposed techniques from boththeoretical and practical perspectives."
http://hdl.handle.net/1957/61785,"This work presents a new data encoding scheme: Integrated Pulse Width Modulation (iPWM) for equalizing lossy wireline channels with the aim of achieving energy efficient wireline communication. The proposed scheme is able to overcome the fundamental limitations imposed by Manchester and Pulse Width Modulation (PWM) encoding on high data rate wireline transceiver design. A highly digital scalable encoder architecture is leveraged to implement the proposed iPWM encoding. An energy efficient wireline transceiver implementation of the proposed scheme is demonstrated with measured results over a data-rate range of 10 to 18 Gb s. Fabricated in a 65nm CMOS process, the transceiver operates with supply voltages of 0.9V, 1V and 1.1V. It is capable of equalizing over 27dB of channel loss while operating at 16 Gb s with an efficiency of 4.37pJ bit. The design occupies anactive die area of 0.21 sq. mm."
http://hdl.handle.net/1957/61786,"The Thin: In Three Fragments follows Daisy, our protagonist, as she battles to liberate herself, save her son from the cliff, and reclaim everything that has been taken from them. Having fallen in a rock climbing accident, Daisy, in her incorporeal form, hovers over her physical shell that lies on the operating room table. This is the moment when one portion of Daisy is still substantially constituted on the operating room table; the single solitary moment before she must choose to return to the corporeal form or enter the stone of her ancestry and be reincarnated. At the same time, we see a future version of her son, Jeremiah, standing atop a cliff waiting to jump, struggling with the challenges of growing up without his mother. Can Daisy solve the different potential outcomes of her future?"
http://hdl.handle.net/1957/61787,"The following is a book-length nonfiction collection of segmented prose exploring what it means to be a woman raised to participate in a patriarchal rape culture. Using an assemblage of personal narrative and wide-spread research, Sanctuary reveals both danger and safety: how women learn (or don’t learn) to recognize the difference between the two, and navigate their lives accordingly."
http://hdl.handle.net/1957/61788,"The following is a collection of thirty-nine lyrical essays and micro-essays (and one PSessay!) produced over the last two years in the OSU Cascades MFA Creative WritingProgram. The pieces are grounded in the queendom of the chicken coop located at theTumalo, Oregon ranche-ette that is home to my husband, Kyle, and me. Because I am avisual artist, one whose art and spirituality are integral to her life—relics, interior design andphotographs served as prompts for my writing. The resulting work is a pairing, in whichthe visual art becomes dependent on the prose and vice versa. My hope is that the pairingsteeps the reader in the kaleidoscopic pattern that comes with living, and feeling deeply,and all the joy, all the pain, all the in-between—the making sense of loss and abundancewith equal fervor."
http://hdl.handle.net/1957/61789,"Speculative Histories is a hybrid collection that combines fiction and creative nonfiction. It is comprised of flash, short, lyric, and segmented pieces, as well as visual art. As I worked on this project I found that I needed a multi-modal approach in order to explore the central questions of the collection: what does it mean to be whole or significant; how can we approach and come to know the unknown; can we move on from trauma?"
http://hdl.handle.net/1957/61790,"Understanding groundwater flow in faulted and fractured rock is an important frontier in the field of environmental remediation and in the management of water resources. One example of a site where this is particularly evident is the Santa Susana Field Laboratory (SSFL) in Ventura County, CA where environmental remediation activities have been underway for decades. A major challenge at the SSFL is accounting for the influences of various geological structures at the local scale. To support this effort, this study employs numerical modeling as a method to understand groundwater flow at one area of the SSFL where a well transect through a fault zone exhibits anomalous water levels. For this study, a two-dimensional cross-section continuum model was constructed along the well transect to simulate flow at the area. Several simulations were run to investigate several combinations of fault hydraulic character and fracture network connectivity. Water levels measured at wells in the transect were used as criteria for calibrating the simulation scenarios. Results suggests that at least the upper part of the fault zone is a barrier to groundwater flow. However, head matching alone was not sufficient to be able to say with certainty if the low-conductivity condition extends deeper along the fault zone or if there is significant connectivity in the fracture network to overprint rock matrix anisotropy. Simulation results were also viewed in light of which ones would be most likely to produce the shape of the existing contamination plume. These observations most strongly support a system with strong bedding parallel anisotropy. Some evidence seemed to suggest that the fault."
http://hdl.handle.net/1957/61792,"This dissertation works towards determining the mechanisms driving the Mo isotopic composition of soils, and how these signals may be used to refine the use of Mo as a proxy of biogeochemical processes. The first step towards quantifying Mo fractionation in soils is to determine the mechanisms controlling Mo accumulation, loss, and mobility. To do this, I first measured the abundance and isotopic composition of Mo across soil climatic gradients on the Hawaiian Islands. The Maui Climate Gradient (MCG) is a 410 kyr precipitation gradient where redox state (Eh) is well-constrained. I observed higher bulk soil Mo concentrations and greater mobilization of Mo in anoxic soils, and determined that Mo adsorption was two orders of magnitude greater onto organic matter relative to short range ordered (SRO) Fe- (oxyhyrdr)oxides. Since high rainfall coincides with an accumulation of organic matter, these results suggest a shift from Fe- (oxyhydr)oxides to organic matter control of Mo at high rainfall sites. I then focused on the Kona Climate Gradient (KCG), located on a 10 kyr lava flow where soils are undergoing initial stages of chemical weathering. Across the KCG, I observed net accumulation of Mo with increasing precipitation in surface soil horizons, suggesting that atmospheric inputs were a significant source of Mo in soils. The isotopic composition of soil Mo is also offset from bedrock values, confirming that Mo isotope shifts are occurring. The isotopically lightest Mo signature is found in the driest sites, and the isotopically heaviest Mo signature is found in surface horizons of the wettest sites. To reconcile these observations, I measured the Mo isotopic composition of precipitation, groundwater, and vegetation and concluded that while the Mo cycle is significantly affected by isotopic fractionation mechanisms within soils, it is also modulated by atmospheric inputs and subsequent Mo adsorption onto organic matter. 	My next research project followed up on these findings from Hawaiian soils by calculating the extent of Mo isotope fractionation during adsorption onto organic matter. At pH 4, fractionation between the solution and adsorbed phase (98Mo) was 1.4‰ and fit an equilibrium fractionation model. As pH increased from 2 to 7, Mo adsorption onto IHA decreased, but the degree of fractionation increased to a maximum of 1.8‰. I compared laboratory results to Mo isotope patterns in precipitation, foliage, organic horizon, surface mineral soils, and bedrock for 12 forested sites across the Oregon Coast Range. Fractionation of precipitation-derived Mo onto the organic horizon aligned well with laboratory results, suggesting that organic matter influences the Mo isotope composition of soils by preferentially adsorbing light Mo. The magnitude and direction of Mo fractionation during adsorption onto organic matter is similar to fractionation of Mo onto Fe- and Mn- (oxyhydr)oxides, which has implications for the interpretation of the sedimentary Mo record and its use as a paleoredox tracer. 	In addition to organic matter adsorption and desorption processes, the dissolution of Fe- (oxyhydr)oxides, colloid dispersion, and shifts in pH have the potential to mobilize Mo and other trace metals in soil. To determine trace metal mobilization as a function of redox, soil mineralogy, and colloid dynamics, I measured trace metal mobilization via colloids and the aqueous phase during two consecutive, 8-day redox cycles. In soils with high clay content and low permeability, reducing conditions drove trace metal mobility. Comparatively, in soils with low clay content and high permeability, trace metal mobilization was independent of redox state. My results provide evidence that lithology remains an overarching factor governing trace metal mobility in soils. The Mo isotopic composition of the soil solid, colloids, and the aqueous phase did not reflect the redox history of soils, suggesting that the additional fractionation mechanisms such as organic matter and atmospheric inputs complicate the utility of Mo as a tracer of redox in soils. 	My final research endeavor investigated the impact of Mo cycling in the terrestrial environment on the magnitude and isotope signature of the Mo flux to the oceans. I collected Mo from a series of rivers and groundwater sources along the Hawaiian Islands where the stage of chemical weathering varies as a function of lithological age. Groundwater dominates the Mo flux during initial stages of chemical weathering, and the dissolved Mo isotopic composition of groundwater is only slightly fractionated from bedrock. With increasing age, and stage of chemical weathering, rivers become the main vector for water transport to the oceans. Rivers draining predominately shallow flowpaths have Mo isotopic signatures that reflect fractionation processes as Mo cycles through the terrestrial environment. However, the input of groundwater to riverine base flow overprints small-scale fractionation mechanisms and narrows the range of the isotopic signature of the global Mo flux.	The chapters of this dissertation seek to address the mechanisms driving isotope fractionation patterns during terrestrial biogeochemical cycling. My data shows that Mo is fractionated within soils during adsorption onto organic matter, and that the input of isotopically heavy Mo from atmospheric inputs is a previously unrecognized source of Mo to soils that may alter the trajectory of fractionation patterns. These conclusions suggest that the utility of Mo as a redox tracer in soils is suppressed by additional fractionation mechanisms. Nevertheless, these insights into Mo biogeochemical cycling contribute to better understanding and prediction of how riverine isotope signatures have likely varied as a function of chemical weathering throughout Earth’s history."
http://hdl.handle.net/1957/61794,"Fossil fuels have been the main source of energy for a long period but due to growing concerns over climate change, oil depletion and energy security, the development of renewable sources of energy such as biofuels have been flourishing over the past few decades. Despite the fact that biofuels are perceived to be more sustainable than fossil fuels, three important issues should be considered if agricultural products are used to produce fuel. First, the environmental impacts of producing biofuels vary greatly with feedstock type and growing location. The second issue is the dilemma between food and fuel such that if food crops are used to make biofuels, food prices can increase dramatically. Third, if there is an increase in demand for a particular crop, non-agricultural land (e.g. forest, grassland, peatland) can be converted to agricultural land which increases the greenhouse gas emissions (GHG) due to land use change (LUC). In order to capture the effect of regional factors on life cycle assessment of biofuels,agroecosystem process-based models which can model soil emissions and predict yield can be used. Life cycle assessment (LCA) is a systematic set of procedures for compiling and examining the inputs and outputs of materials and energy and the associated environmental impacts directly attributable to the functioning of a product or service system throughout its life cycle. In the first objective of this study, the effect of regional factors on LCA of camelina seed production and camelina methyl ester production was assessed. While general conclusions from LCA studies point to lower environmental impacts of biofuels, it has been shown in many studies that the environmental impacts are dependent on location, production practices and even local weather variations. A cradle to farm gate and well to pump approaches were used to conduct the LCA. To demonstrate the impact of agro-climatic and management factors (weather condition, soil characteristics, and management practices) on the overall emissions for four different regions including Corvallis, OR, Pendleton, OR, Pullman, WA and Sheridan, WY, field emissions were simulated using the DeNitrification-DeComposition (DNDC) model. openLCA v.1.4.2 software was used to quantify the environmental impacts of camelina seed and camelina methyl ester production. The results showed that GHG emissions during camelina production in different regions vary between 49.39 to 472.51 kg CO2-eq. ha due to differences in agro-climatic and weather variations. The GHG emissions for 1 kg of camelina produced in Corvallis, Pendleton, Pullman, and Sheridan were 0.76±11%, 0.55±10%, 0.47±18% and 1.26±6% kg CO2-eq., respectively. The GHG emissions for 1000 MJ of camelina biodiesel using camelina produced in Corvallis, Pendleton, Pullman, and Sheridan were 53.60±5%, 48.87±5%, 44.33±7% and 78.88±4% kg CO2-eq., respectively. Other impact categories such as acidification and ecotoxicityfor 1000 MJ of camelina biodiesel varied across the regions by 43% and 103%, respectively. Since the results of LCA are highly site-specific, and it is recommended that conclusions from LCA studies be presented in the context of site-specific data. The second objective of this study was to model the soil emissions during camelina and wheat production in a three-year cycle in the Pacific North West region of the United States considering spatial variations in agro-climatic factors. DNDC model was used to estimate the soil emissions in different regions, and openLCA software was used to conduct a regional LCA for camelina biodiesel production in the State of Oregon. The results showed that change in soil organic carbon (dSOC) did vary across different locations and in most locations, lower initial SOC resulted in lower CO2 emissions. The global warming potential of camelina biodiesel varied between 39 to 84 kg CO2-eq. 1000 MJ across different locations and scenarios. Uncertainty analysis was carried out using Monte Carlo method, and the results showed that there could be up to 23% variation in soil emissions due to variation in air temperature and SOC. The break-even cost for a three-year crop rotation (winter wheat-fallow-camelina) was estimated to be 1715 $ ha 3years; therefore, locations with income equal or more than the break-even cost and low environmental impacts are suitable for the winter wheat-fallow-camelina rotation system. The last objective of this study was to integrate DNDC with LCA model using a GIS-based platform software, ENVISION. The integrated model helps LCA practitioners to conduct LCA in large regions while capturing the variability of soil emissions due to variation in regional factors during producing crops or biofuel feedstocks. In order to evaluate the integrated model, the corn-soybean cropping system in Eagle Creek Watershed, Indiana was studied and our integrated model was used to first model the soilemissions and then calculate the LCA as well as economic parameters based on the model results. The results showed that within one location, the variation in soil emissions due to variation in weather is high. Weather variability caused some locations to be carbon sink in some years and source of CO2 in other years. In order to test the model under different scenarios, two tillage scenarios were defined: 1) conventional tillage (CT) and 2) no tillage (NT) and analyzed with the model. The overall GHG emissions for the corn-soybean cropping system was simulated and results showed that the NT scenario has lower soil GHG emissions compared to CT scenario. Moreover, global warming potential (GWP) of corn ethanol from well to wheel varied between 57 and 92 g CO2-eq. MJ while GWP under the NT system was lower than that of the CT system. The cost break-even point was calculated as $3612.5 for each hectare of the 2 year corn-soybean cropping system and the results showed that under low and medium prices for corn and soybean most of the farms did not meet the break-even point."
http://hdl.handle.net/1957/61795,"Providing transformational learning opportunities for undergraduate students demands changes to teaching practices. In large-enrollment introductory courses, graduate teaching assistants (GTAs) play an important role in facilitating student learning in small group environments. However GTAs are not provided the pedagogical development necessary to support them to be effective in their teaching practices. In order to provide GTAs with pedagogical development opportunities, we need an in-depth understanding of GTAs’ current teaching practice and how they are making pedagogical decisions, which is based upon their epistemological perspective. As it currently stands, there is limited research on GTA practice and epistemology in engineering, particularly in environments that expect them to implement complex, interactive learning pedagogies such as Studios in engineering (Koretsky, 2015). This dissertation contributes to the current literature around teaching practices and epistemology by focusing on GTAs’ epistemology and practice in engineering since they play a significant role in undergraduate students’ experience. This dissertation provides an in–depth case study of two engineering GTAs within a second term junior level thermodynamics Studio. It also investigates the creation, implementation, and reception of a series of pedagogical development seminars within a first year graduate student professional development seminar.Engineering educators implement active learning strategies as a way to engage students and improve their learning gains (Prince, 2004). However, these teaching practices are complex and require time, preparation, and skill to be able to implement them effectively. Windschitl and Barton (2016) provide ambitious teaching as a framework for looking at teaching practices. The authors identify two assumptions that bind cases of successful teaching practice. The first is that the quality of teaching is assessed by the engagement of all learners, which aligns with the goals of an active learning environment. The second is that sustainable improvements in teaching require a “repertoire of practices” that are refined over time. This repertoire of practices should be a part of a larger system of instruction that supports student learning. At a large research university, Studios are part of a program-level course redesign aimed at increasing the frequency of interactive learning in the classroom. Teaching practices that are important to Studio pedagogy are attending to group dynamics and eliciting student thinking through productive dialogue (Chi, 2009; Fonseca & Chi, 2011; Windschitl & Barton, 2016) and providing effective feedback (Gilbuena et al., 2015). Chapter 2 details the observed practices of two GTAs, Dean and Jeff (pseudonyms), in a junior level thermodynamics Studio course within two structurally different Studios: Studio 1 was conceptually oriented and lab based, whereas Studio 2 was procedurally oriented and required students to engage with mathematical concepts. The nature of and the frequency of the teaching practices of attending to group dynamics, eliciting student thinking, and providing effective feedback are investigated.Traditionally epistemology has been studied from a unitary perspective (Perry, 1970; Magolda, 1992; Belenky et al., 1986; King & Kitchener, 1994; Kuhn, 1991; Hofer & Pintrich, 1997). Hammer and Elby (2002) provide an alternative framework that takes context into account by identifying resources (e.g. knowledge as fabricated, knowledge as transmitted) and frames, which are stabilized structures of resources across multiple contexts. Methodologically when investigating epistemology and practice, researchers focus on an “enacted” and “professed” epistemology (Louca et al., 2004; Speer, 2005). Speer (2005) makes an argument that solely focusing on enacted and professed epistemology does not capture the nuances of the decisions being made within the classroom. She suggests using stimulated recall interviews (SRIs) to better understand the connection between epistemology and practice and to contextualize in-the-moment decisions instructors make. Chapter 3 builds on the work in Chapter 2 by investigating the enacted, professed, and reflected epistemological resources and frames (Hammer & Elby, 2002) of Dean and Jeff using SRIs. Dean and Jeff’s resources and frames are addressed within the practices of attending to group dynamics, eliciting student thinking, and providing effective feedback.  Chapter 4 discusses the creation, implementation, and reception of a series of pedagogical workshops situated within a professional development seminar that all first year graduate students in an engineering school are required to take. These pedagogical workshops were created and implemented in an effort to “integrate researcher knowledge, practitioner experience, and new institutional structure for pedagogical experimentation” (Windschitl & Barton, 2016, p.1100) as part of the program level course redesign that includes Studios. The goals, seminar topics, main resources, and activities for the pedagogical development seminars are discussed. A survey was administered to graduate students to assess the contribution of the pedagogical seminars to the seminar goals and the effectiveness of seminar activities to the graduate students’ learning. The needs assessment model (Borich, 1980) was used to evaluate the effectiveness of the seminar in helping graduate students to develop pedagogical thinking."
http://hdl.handle.net/1957/61796,"The Columbia River delivers the greatest amount of freshwater to the coastal ocean along the U.S. Pacific coast. This freshwater forms the Columbia River plume, a mesoscale plume with significant implications on coastal ocean physical, biological, chemical, and geological processes. The plume is transported south and offshore during the upwelling season (The offshore Columbia River plume) in response to the dominant southward upwelling-favorable winds and associated surface circulation. Here a detailed investigation of the optics, structure and variability of the offshore plume is presented. A study of the interannual variability of river plumes off central-southern Chile is also included for comparison with another eastern boundary upwelling system with significant freshwater river outflows.Chapter 2 presents the main optical characterization of the offshore Columbia River plume, combining in situ observations from underwater gliders and MODIS satellite imagery. The cross-shore variability of relevant optical properties are described for the offshore Columbia River plume in comparison with ambient waters in absence of the plume off Newport, central Oregon. The plume thickens in the offshore direction, through a fresh and warm surface layer, which is concordant with the deepening of peaks in optical properties. This pattern has implications for the detection of the plume from ocean color remote sensing as the plume is practically undetectable from MODIS imagery by itself farther than ∼154 km from shore. Empirical algorithms, based on multivariate regression analyses of normalized-water leaving radiance (nLw(λ)) plus sea surface temperature (SST), are presented with more accurate results detecting offshore plume waters than previous studies using single visible bands.Chapter 3 contains a study of the structure and variability of the offshore Columbia River plume, with emphasis on the cross-shore structure off central Oregon, and its variability in response to wind forcing and river discharge. On average, the plume presents marked seasonal variability off central Oregon – early in spring it is located nearshore (inshore of 126◦W) whereas later in the upwelling season (July and August) its offshore extension increases to about 128◦W. On the interannual scale, anomalously fresh plume events occurred during the highest river discharges associated with spring snowmelt (i.e. 2008, 2011, 2012). Additional glider observations from the Ocean Observatories Initiative Endurance array and along-track Aquarius measurements provide new insights about the alongshore plume structure and its response to wind variability. Idealized numerical experiments of a large river plume during coastal upwelling, resembling the offshore Columbia River plume, are also presented with the objective of isolating the effects of differences in the strength of upwelling-favorable winds and discharge rates on the offshore plume.Chapter 4 inspects the interannual variability of freshwater plumes along the Oregon coast, including not only the offshore Columbia River plume but also the small coastal rivers along the entire Oregon coast with high accumulated winter discharges. Empirical Orthogonal Function (EOF) analysis reveals two dominant modes associated with (i) the winter plumes of coastal rivers which are merged along the entire Oregon shelf (EOF1) due to their dominant downstream direction of propagation as coastal-attached buoyancy-driven flows, and (ii) the offshore Columbia River plume occupying most of the coastal ocean off Oregon (EOF2) as it is transported south and offshore during spring-summer upwelling. Major plumes are found to correspond mainly with El Niño Southern Oscillation cycles, but longer time series are needed to better evaluate the influence of Pacific Decadal Oscillation and the North Pacific Gyre Oscillation because of their dominant decadal variability.Finally, Chapter 5 includes a comparative study of the influence of climate variability on the development of anomalous turbid river plumes off central-southern Chile, another eastern boundary upwelling system with significant freshwater input during the winter and spring seasons. Major turbid river plume events occur primarily during warm phases of the El Niño Southern Oscillation and Pacific Decadal Oscillation, and negative phases of the Antarctic Oscillation, when storm tracks are further north off central Chile. Anomalously large turbid plumes extend long distances offshore (∼70-80 km), and individual plumes coalesce into a continuous plume along the coast that covers the entire continental shelf."
http://hdl.handle.net/1957/61797,"The increasing demand for higher data-rates in spectrum-deficient indoor WiFi networks calls for the adaptation of hybrid systems, consisting of RF and optical wireless channels. The novel hybrid WiFi Free-Space Optical (WIFO) system was introduced to enhance the wireless capacity of indoor WiFi networks. In this thesis, an optical wireless channel was designed and implemented as part of the hybrid WIFO network. An optical wireless receiver was designed using a Si-PIN photodiode with a sensitivity of 0.6A W at 850nm wavelength and the transmitter was implemented with an 850nm laser diode. The receiver achieved a bit error rate of 1e-9 for a data rate of 100Mbps at a non-directed line-of-sight distance of 2 meters from the transmitter. To achieve a higher data rate of 2Gbps, an integrated optical receiver was designed in 65nm CMOS. The integrated receiver consists of four low-noise trans-impedance amplifiers (TIA) whose outputs were coalesced, resulting in a 6dB higher signal-to-noise ratio than in the case of a single-TIA receiver. In this novel approach, the four trans-impedance amplifiers get their input photo-currents from four individual Si-PIN photodiodes, each with a capacitance of 1.6pF and sensitivity of 0.4A W at 850nm wavelength. The simulated input referred noise current of each TIA was 90nA over a bandwidth of 1GHz."
http://hdl.handle.net/1957/61798,"Ecological resources available to freshwater fish shift spatially, temporally and across life stages. To better understand how spatial-temporal availability of resources influence fish, I examined the phenologies of hatching and emergence of Coho Salmon (Oncorhynchus kisutch) in streams with contrasting and strongly defined seasonal thermal variability. The study streams included groundwater dominated streams that were characterized by low spatial-temporal thermal variability, and surface-water dominated streams which had much higher variability in temperatures. In these streams, I quantified the timings of emergence and tracked individual fish and fish cohorts to understand the consequences of emergence phenologies for diets, bioenergetics (growth and consumption), body size and condition at the end of the growing season. Despite strong differences in thermal regimes hatch and emergence occurred at the same time among streams in the summer. In an attempt to understand the drivers behind this pattern I then evaluated spatial-temporal variability in thermal and trophic resources available to young-of year Coho Salmon post-emergence. Favorable growth temperatures (based on bioenergetic considerations) only occurred in the warmer surface-water stream in the summer months. However, individual growth (g·d-1) of young-of year Coho Salmon was not significantly lower in the colder groundwater stream in the summer, despite previous reports indicating such temperatures to be un-favorable for growth. Macroinvertebrate prey availability was highest overall in the groundwater stream in the summer, but there was significant variability among habitats, seasons and years in all streams. Coho Salmon fed on both larval and adult forms of macroinvertebrates from the benthos, drift, and riparian areas; with the dominant prey item being all life stages of the non-biting midges (F. Chironomidae, O. Diptera). In the last chapter, I incorporated the data collected from my earlier chapters into a bioenergetics model to employ a mechanistic approach in understanding how spatial-temporal resource variability affects juvenile salmon growth dynamics. The bioenergetics model was fit to empirical measurements of growth rates, diet composition, energy densities of the predator (fish) and prey (macroinvertebrates), and water temperatures experienced by fish. Estimated consumption rates (g·g-1·d-1) were higher in the surface-water stream in the summertime, due to the warmer temperatures and thus higher metabolic cost compared to fish growing in the groundwater stream. Further, there was a significant positive relationship between fish size and % lipid content in the groundwater stream only, suggesting that size is related to condition for fish surviving in the colder groundwater stream. Through this work I was able to quantify the consequences of synchronous emergence phenologies for young-of-year Coho Salmon in streams with contrasting thermal and trophic resources. Though fish emerged at similar times, they emerged into environments that offered dramatically different conditions for growth.  In spite of this, fish in these streams realized similar rates of growth (g·d-1) and body sizes (mm) at the end of the growing season, with fish in a colder stream exhibiting higher condition.  With respect to potential changes to thermal conditions in streams related to regional climate warming, my results highlight a high degree of flexibility in the response of young-of-year Coho Salmon.  Understanding this flexibility from a detailed empirical and mechanistic perspective provided important and novel insights into precisely how early life stages of Coho Salmon will potentially respond to changing climates."
http://hdl.handle.net/1957/61800,"The Willamette River Basin supports 70% of Oregon’s population and contains the richest native fish fauna in the state, (Hulse, Gregory, & Baker, 2002). The Basin is facing changes that stress its water management regimes. Is the Basin’s water management regime able to adapt in the face of these changes? Climate models project increasing air temperature, greater variability and intensity in winter rainstorm events, and decreased low elevation snowpack in the Basin (Sproles et al. 2012). Environmental streamflow requirements for federally listed fish species and municipal and agricultural water demand have closed several watersheds to new surface water allocations and reduced reliability of supplies. Sustainable water resources management requires networks of water managers who practice adaptive management by continually monitoring, assessing, and improving management procedures and outcomes. This requires adaptive governance capacity, which is “the ability of a resource governance system to first alter processes and if required transform structural elements to better cope with experienced or expected changes in the societal and natural environment,” (Pahl-Wostl et al., 2010, 572). To characterize adaptive governance capacity, a questionnaire was sent to 119 water managers at the basin scale and within three selected watersheds examining four key elements of adaptive governance capacity: social capital; human, financial, and physical capital; management tools and strategies; and governance strength (Pakenham- Stevenson, 2017). The availability of water for appropriation of new surface water rights was used to identify three watersheds that spanned low (McKenzie River), medium (North Santiam River), and high (Middle Fork Willamette River) levels of water availability. Questionnaire results suggest high levels of reciprocity, awareness of impacts, and trust in watershed councils across selected watershed and at the Basin level. The strength of networks among water managers was high at the watershed level. Trust in water managers was low at the Basin level and the availability of adequate financial capital was at the Basin level and across selectedwatersheds. Water managers also did not believe their stakeholder group can adapt to changes in supply and demand. Trust in specific stakeholder groups varied widely across watersheds, highlighting unique characteristics and networks at the watershed level. To further understand the barriers and opportunities for adaptive governance in the Basin, semi-structured interviews were conducted with 17 key water managers. Interviews highlighted uncertainty created by minimum perennial stream flows, challenges sharing information between federal, state, and local levels, and reduced financial capacity. Interviewees highlighted several organizations that are leading the way in adaptive water resources management and enhancing adaptive governance capacity at the local and state levels. To adapt to likely changes in supply and demand the water management regime will require trust building among specific stakeholder groups, increased network strength at the basin-level, and increased financial capacity."
http://hdl.handle.net/1957/61801,"Counselor educators have a responsibility to serve as effective gatekeepers to the counseling profession by graduating only those counselors professionally prepared to serve the public in a myriad of counseling roles.  However, despite its importance and the extant literature, gatekeeping still seems poorly understood and inconsistently applied.  Although the literature on what counselor educators should do during gatekeeping is robust, much less is known about what they experience during gatekeeping. The purpose of this dissertation is to learn more about counselor educators’ internal and microsystemic experiences of gatekeeping for problems of professional competence (PPC).This dissertation applies a grounded theory approach towards data collected from experienced counselor educators on their internal and microsystemic experiences during gatekeeping. The first study examining participants’ internal experiences led to the theory of striving to be an effective gatekeeper – avoiding, struggling, striving as counselor educators’ central internal experience during gatekeeping. This core category consisted of the sub-processes of: integrating identities and balancing responsibilities, practicing discernment, managing challenging emotions, and perceiving cohesion and capability in colleagues. The second study, addressing participants’ experiences of their colleagues and aspects of the faculty microsystem during gatekeeping led to the theory of collaboration – sharing the burden and a model of the Faculty Microsystem for Gatekeeping in Counselor Education Programs. The theory and model highlight the contextual conditions and interactive processes of gatekeeping especially between the conditions of faculty cohesion and faculty capability and the processes of individual CE actions- engaging vs. avoiding and collective CE actions- helping vs. hindering collaboration. How the faculty microsystemic conditions enhance or inhibit collaboration led to participants’ varying levels of experiencing collaboration – sharing the burden. This research will benefit counselor educators and counselor education programs; current and future counseling students; and most importantly, the public good by contributing to our understanding of gatekeeping in counselor education programs."
http://hdl.handle.net/1957/61808,"The trend towards higher resolution, faster refresh rate active-matrix liquid-crystal displays (AMLCDs) as well as the emergence of active-matrix organic light-emitting diode (AMOLED) displays is driving the demand for amorphous oxide semiconductor thin-film transistors (AOS TFTs) with higher mobility. A physics-based model for carrier transport in an amorphous semiconductor is developed to estimate the mobility limits of an AOS TFT to be 71 cm2 Vs. Only the effective mass and band tail state density need to be specified, relating to the disorder in the amorphous semiconductor. Three ways are identified to achieve a mobility higher than that of quaternary amorphous indium gallium zinc oxide (a-IGZO) with a cation ratio of 1:1:1. i) Quaternary systems with a higher indium ratio; ii) lower disorder ternary oxides (e.g., boron indium oxide); iii) dual active layer (DAL) TFTs. ITO-IGZO DAL TFTs are directly compared with a-IGZO TFTs. The ITO-IGZO DAL TFT exhibits significantly improved performance with mean mobility of 31 cm2 Vs, threshold voltage of -3.6 V, sub-threshold swing of 175 mV dec, minimal hysteresis, and good bias temperature stress stability. Technology computer aided design (TCAD) simulation is used to elucidate the density of states (DOS) of various types of AOS TFTs. A mapping technique is introduced to relate experimental transfer characteristics to the sub-bandgap DOS model."
http://hdl.handle.net/1957/61810,"Pyroprocessing is an advanced technology for recycling used nuclear fuel. Pyrochemical processes encompass a wide range of chemical, physical, and electrochemical methods to partition fission products and other components from used nuclear fuel, which allows for the reuse of the actinides in nuclear fuel. This dissertation investigates two chemical systems relevant to pyroprocessing. The first investigation explores the possibility of using molybdate melts containing sodium molybdate (Na2MoO4) and molybdenum trioxide (MoO3) to partition fission products from used nuclear fuel by crystallization. The difference in solubility of the fission product metal oxides compared to the uranium oxide or molybdate in the molybdate melt allows for these separations to occur. Uranium dioxide dissolves in the molybdate at high temperatures, and upon cooling, the uranium precipitates as uranium dioxide or molybdate, whereas the fission product metals remain soluble in the melt.  The feasibility of UO2 purification from the fission products was studied using small-scale experiments with gram quantities of uranium dioxide. The composition of the uranium precipitate as a function of molybdate melt composition was determined through a series of tests.  The effectiveness of the partitioning of several fission product surrogates between the uranium precipitate and molybdate melt for various parameters in the process was also studied. A melt consisting of 20 wt% MoO3- 50 wt% Na2MoO4-30 wt% UO2 heated to 1313 K and cooled to 1123 K for the physical separation of the UO¬2 product from the melt, and washed once with Na2MoO4 resulted in excellent separation of the UO2 from the surrogate fission products. The second investigation explored the phase equilibria of UCl3 and NpCl3 in the LiCl-KCl molten salt electrolyte used in electrorefining used nuclear fuel. The re-evaluation of the LiCl-UCl3, KCl-UCl3 and the LiCl-KCl-UCl3 phase diagrams and the first known evaluation of the KCl-NpCl3 system were performed. Samples of varying compositions within each of these systems were thermally analyzed by DSC to determine the temperature and types of the phase transitions. Samples were then analyzed by XRD to determine the identity of the phases formed, and ICP-OES or ICP-MS to establish the cation ratio. The LiCl-UCl3 system displayed a simple eutectic system. The KCl-UCl3 system displayed two eutectics and the K2UCl5 phase, which was identified by DSC and XRD. There was no evidence of a K3UCl6 phase. These LiCl-UCl3 and KCl-UCl3 phase diagrams were used to produce a portion of the LiCl-KCl-UCl3 phase diagram relevant to electrorefining.  The LiCl-KCl-UCl3 system displayed two ternary eutectics and was consistent with literature data. The KCl-NpCl3 system displayed two eutectics and the K2NpCl5 and K3NpCl6 phases, which were identified by DSC and XRD. The evaluation of these phase diagrams allows for an improved understanding of the LiCl-KCl-UCl3 and KCl-NpCl3 systems and their application to pyroprocessing."
http://hdl.handle.net/1957/61835,"In the study of any developmental process, whether in plants, animals, or other models, it is prudent to consider the developmental position of the subjects being measured. This is generally not taken into consideration in grapevine studies despite a growing body of literature documenting that fruits within clusters develop and ripen non-uniformly. What complicates such accounting is that grape berries develop and ripen within a complex, extensively branched panicle. In the studies that follow, a tagging strategy was deployed in which fruits were labeled on their dates of anthesis or developmental position at véraison (when 50% of a cluster has initiated ripening) and subsequently sampled. Using this approach, why fruits initiate ripening unevenly and how much variation persists late in the ripening process were explored. The ripening onset for individual berries and the hormonal shifts characteristic of the ripening onset were best associated with their seed content, with flowering time playing an inconsistent and small role. Late in ripening, the abundance of enologically meaningful metabolites were still able to distinguish berries based on their developmental position at véraison.Grape Leafroll-associated Virus 3 (GLRaV3) is the most consequential virus that affects grapevine globally, with reports showing infected vines yield less and produce poorer quality fruit. Furthermore, GLRaV3 is reported to affect grapevines in a developmentally specific way. Given the developmental heterogeneity within clusters and that viral symptoms in the fruit occur in a developmentally-sensitive manner, the aforementioned tagging strategy was used to study the impact of GLRaV3 in berries during ripening. RNA sequencing and small RNA sequencing libraries were constructed to capture transcriptome-wide changes in gene expression, small RNAs, and the production of viral small interfering RNAs, as well as to identify novel micro and other small RNAs abundant during ripening and affected by GLRaV3. The effects of GLRaV3 in terms of gene expression and small RNA abundance were most numerous at véraison and included ordered and disordered responses. Most modules of co-expressed genes exhibited ordered responses, with groups of genes becoming differentially expressed while remaining co-expressed. However, disordered responses were observed as well. Various regulatory strategies were indicted in the orchestration of GLRaV3 responses, as were genes involved in the crosstalk between metabolite biosynthetic pathways and hormone signaling pathways."
http://hdl.handle.net/1957/61837,"Meridians is a collection of short stories, with some of the stories functioning as linked narratives and others standing alone, but together, as a whole, they form a story cycle. Meridians, essentially, is a meditation on how we cross and re-cross imaginary lines and liminal spaces throughout our lives, often in our attempts to move on after points of trauma. In such instances, Meridians, focuses on the possibility of change after the trauma has occurred, raising questions such as how does one adjust after the fact, and is adjustment always possible, but principally, Meridians asks, how is the contrast between masculinity and vulnerability changing in our contemporary world?"
http://hdl.handle.net/1957/61838,"The following is a collection of poetry produced over the last two years in the OSU Cascades MFA Writing program. The poems are addressing the themes of chronic pain, maternal relations, and the female body."
http://hdl.handle.net/1957/61839,"Bitterbrush is the first 104 pages of a novel about Mercy and Richey Mason and Richey’s friend and former platoon mate, Gilbert Carson.  The story is set on the Mason family cattle ranch near Burns, Oregon, where Richey and Carson have gone after Richey’s release. Carson is physically disabled by wartime injuries.  Richey has been held prisoner by the Taliban for five years before being released.  Mercy has experienced childhood sexual abuse. The story explores resilience, war, family relationships, race, disability, spirituality, addiction, Native American traditions and the many ways people find healing."
http://hdl.handle.net/1957/61840,"Traditional analysis in population genetics evaluates differences among groups of individuals and, in some cases, considers the effects of distance or potential barriers to gene flow. However, many forces may shape genetic variation of organisms in riverine systems. Similarly complex research linking habitat heterogeneity and configuration to genetic structure has integrated methods from landscape ecology, population genetics, and spatial statistics in approaches known as landscape or seascape genetics. However, challenges exist when translating these approaches into freshwater river networks due to functional differences in riverscape topography that create constrained pathways for movement. The overall goal of my dissertation was to combine the approaches applied in population genetics to identify genetic diversity within and among populations, with concepts derived from network theory to better understand how the riverscape influenced spatial genetic structure of Chinook salmon (Oncorhynchus tshawytscha) populations in Siletz River. I provide a perspective on how riverscape genetics could be used to provide a more comprehensive conceptual and applied understanding of connectivity and dispersal in freshwater systems. I describe four thematic areas of study representing current and future research opportunities and propose a basic methodology for conducting riverscape genetics analysis. I applied the proposed riverscape genetics method to attempt a novel analysis of spatial genetic structure of Chinook salmon within Siletz River, Oregon and compared results with interpretation of spatial genetic structure using traditional population genetics methods.   	Chinook salmon are a culturally important and economically valuable fish that express diverse life histories characterized by the season of their return migration to spawning habitat (called a “run”) and duration of freshwater or estuarine residence. Population structure among Chinook salmon of alternate run times observed in the Siletz River was investigated using 11 microsatellite markers, 96 Single Nucleotide Polymorphisms (SNPs), and three candidate gene markers that are linked to spawn time and body size. Results from all marker types identified two genetically distinct populations in the watershed (microsatellites; FST = 0.02, p < 0.05) that included a previously unrecognized spring run. This finding is an important consideration for management of the species, as spring run populations have not been recognized in smaller watersheds. Using riverscape genetics methods I characterized the spatial relationships among fall run Chinook salmon. Analysis assessed the effect of indicators of hydrology on dispersal and identified patterns of genetic variation were associated with site-specific differences in elevation of spawning habitat (MRDM; R2 = 0.11 p < 0.05). Further investigation using path-based methodology identified that the cumulative changes in gradient among stream reaches also significantly affected spatial genetic structure (MRDM; R2 = 0.14 p < 0.01). The combination of approaches that were used to investigate spatial genetic variation highlighted the utility of riverscape genetics to enhance our understanding of the relationships that contributed to observed population structure. Although fall run Chinook salmon within Siletz River exhibited high gene flow and were considered a single spawning population using traditional population genetic methods, there was evidence of differential habitat use within the group that was driven by the location of spawning habitat and the resistance to dispersal caused by habitat between these locations. Chinook salmon that traveled over steeper gradients to reach spawning habitat at higher elevations were different than individuals that traveled over shallower gradients to reach spawning habitat at lower elevations. The riverscape genetics approach applied in this chapter enhanced our understanding of habitat heterogeneity in shaping gene flow and spatial genetic structure at a fine spatial scale. Expanding quantitative genetic research, in river systems to explicitly consider riverscape scale network configurations would help develop a clear understanding of the importance of these factors in terms of population persistence."
http://hdl.handle.net/1957/61841,"The photophysical properties of two-dimensional (2D) layered van der Waals (vdW) materials, and their heterostructures are manifestly distinct from crystalline bulk materials. Recently, the discovery of new 2D vdW materials and strongly-bound interlayer excitons in these materials has created a new branch in nanoscience. As such, there are a number of ways to stack 2D materials to produce novel heterostructures with ground-breaking interlayer electronic and photophysical properties. This dissertation explores the stacking and twisting degree of 2D vdW layers to engineer new interlayer electronic states that are not present in as-grown stacked materials. In particular, graphene is the prototypical highly conductive, metallic vdW material consisting of carbon atoms arranged in a hexagonal lattice. When two sheets of graphene are stacked at an off-axis angle, twisted bilayer graphene (tBLG) is formed with modified interlayer electronic properties from the orbital hybridization.This dissertation presents the first exploration and discovery of bound excitons in electronically hybridized interlayer states in tBLG. Using tBLG as a prototype, this      research provides new methodologies to understand the time-domain light-matter interactions in a 2D heterostructure. In particular, we film the journey of electrons in tBLG from excitation to relaxation with space-time and energy resolution to study fundamental interlayer electronic properties and many-body electronic effects.When two graphene sheets stack in a tBLG configuration, angle-tunable optical absorption resonances are generated owing to the rehybridization of interlayer orbitals. Early characterization of tBLG graphene was limited to optical absorption and Raman scattering studies. We apply advanced nonlinear optical techniques to tBLG for the first time to understand the underlying Physics of interlayer electronic interactions in stacked and twisted graphene materials. To accomplish this, we developed a novel ultrafast multi- photon transient absorption (TA) microscopy technique to map relative electron population in a single grain of tBLG with the space-time and energy resolution. Even though graphene is a semimetal, upon resonant excitation of interlayer excitons, surprisingly, we observe a clear electronic relaxation bottleneck that is not present in either ‘non-twisted’ Bernal stacked bilayer graphene or monolayer graphene. This bottleneck can be best explained by the existence of a strongly bound, dark excitonic state. To further investigate the nature of the excitonic states and the exciton binding energy, we employ near-IR excited state absorption (ESA) microscopy approach. By measuring the excited state absorption manifold in tBLG, we found exciton binding energy of ~ 0.5 eV. Such a large exciton binding energy in tBLG is comparable to other 2D semiconductor vdW materials such as transition metal dichalcogenides (TMDs) and an order of magnitude larger than the reported value in metallic carbon nanotubes (CNTs).Lastly, we report light emission from a semimetal tBLG for the first time. We developed a novel 2-photon photoluminescence (PL) microscopy technique to detect emission. The detected PL energy is tunable with the absorption resonance energy. We find that upon resonant two-photon excitation, the relatively slow process of PL is possible owing to the strongly-bound excitons with large binding energy and the corresponding long-lived recombination times measured.Collectively, our results demonstrate that resonantly excited tBLG functions as a unique 2D-hybrid material where free-electron continuum states may co-exist alongside strongly-bound and stable exciton states. The discovery of these remarkable interlayer interactions opens up possible new avenues for excitonic applications with graphene- based light harvesting technologies and fast photosensor development."
http://hdl.handle.net/1957/61842,"Arctic cod (Boreogadus saida) is an ecologically significant species that plays a critical role channeling energy throughout the Arctic marine food web. Arctic cod is uniquely adapted to occupy ice edge habitats, however, a basic understanding of its larval physiology and habitat requirements is lacking due to widespread sea ice cover which limits spring field sampling. Forecasted shrinkage of sea ice habitat could facilitate invasions of non-ice-obligate North Pacific gadids, such as walleye pollock (Gadus chalcogrammus). By assessing the sensitivity of the early life stages of fish species to environmental conditions affecting growth (i.e., temperature and food availability), it is possible to better understand larval survival, and thus the factors dictating success of the population in the face of climate change. To this aim, I conducted laboratory experiments to directly examine the growth and survival of Arctic cod and walleye pollock at two larval stages in response to forecasted changes in temperature and food availability. Critical rates obtained from these experiments demonstrate that larval Arctic cod has a competitive advantage over walleye pollock in terms of growth and survival at low temperatures. However, rising temperatures and altered productivity regimes associated with climate change have the potential to constrain the habitat that is available to Arctic cod.       Temperature-dependent growth models developed from this study emphasize the species-specific and stage-specific differences in the growth of larval gadids and provide a baseline for examining temperature-dependent growth in the field. Following laboratory experiments, I examined the morphometric and lipid condition of each species under the same experimental conditions, to investigate the effects of temperature and food availability on larval fish condition and the suitability of different condition indices. Temperature and food availability impacted larval condition and lipid storage in a species-dependent manner. Furthermore, later stage larval condition was more sensitive to changes in prey availability at higher temperatures, indicating that larval condition may be negatively impacted under a climate change scenario of combined warming and reduced availability of lipid-rich prey. Collectively, the physiological rates determined within my thesis will add to a better understanding of the mechanisms affecting condition and survival of gadid larvae at the Arctic-boreal interface. Knowledge of the habitat requirements of these ecological important species is essential for effective resource management, and is key to understanding the broader implications of global change."
http://hdl.handle.net/1957/61843,"Osteosarcoma (OSA) is the most common primary skeletal tumor in dogs accounting for 85% of bone tumors and nearly 6% of all canine neoplasms. They are highly aggressive tumors that carry a poor prognosis despite intensive treatment, highlighting the need for more effective diagnostic and therapeutic tools. Recent research in human medicine has underlined the importance of vesicular transport via exosomes, particularly related to their role in the progression of cancer and drug resistance. Exosomes are small vesicles with a phospholipid bilayer membrane that are secreted by many cells in the body, and have been shown to transfer oncogenic proteins and nucleic acids that play influential roles in tumorigenesis, metastasis, and response to treatment. More recently, exosome-associated proteins in biofluids have been studied for their potential as minimally invasive biomarkers for a variety of human neoplasms, including OSA. The objectives of our study were twofold. First, to determine if serum-derived exosomes contain a unique protein signature that can be ascribed to canine OSA patients, which could serve as a biomarker for disease and predict response to therapy. Second, we sought to evaluate if exosomes are capable of transferring chemotherapeutic resistance to susceptible osteoblasts, with the hypothesis that acquisition of resistance will correspond with a distinct proteomic profile.Exosomes that were isolated from sera of canine patients were measured using light scatter technology and determined to be of appropriate size. Proteomic analysis via mass spectrometry exhibited unique protein profiles for dogs with OSA, traumatic bone fracture, and normal animals. Additionally, 10 proteins were identified that could differentiate OSA from control patients (normal or traumatic fracture) with 85% accuracy. Select discriminating proteins were validated with western blot. Furthermore, unique exosomal protein signatures were evident for dogs with OSA at different disease stages (diagnosis, 2-weeks post-amputation, and detection of metastatic disease), with 2 proteins identified that could distinguish between the disease stages with 75% accuracy.A carboplatin-resistant cell line (HMPOS-R) was created by repetitive incubations of the cell line with increased concentrations of carboplatin and expansion of the survived cells. A viability assay demonstrated that HMPOS-R had considerably improved viability compared with its naïve equivalent (HMPOS-S). Exosomes isolated from HMPOS-R were incubated with HMPOS-S and subsequent viability assay showed increased viability of resistant exosome-treated cells (HMPOS-EX), suggesting exosomal transfer of resistance. Proteins contained in exosomal preparations had a distinctive profile in comparison to cell lysates. Additionally, proteomic profiling of exosomes and cell lysates at various stages in acquiring resistance demonstrated a unique change in protein expression that may contribute to chemotherapeutic resistance. In summary, our findings demonstrate the potential for circulating exosomes as powerful tools for discovery of novel biomarkers and potential therapeutic targets as a unique protein signature is ascribed to exosomal cargo from serum of dogs with OSA compared with control animals, and throughout various stages of disease. Our research also demonstrates the capability of exosomes to confer chemotherapeutic resistance on susceptible cells, similar to what has been demonstrated in many human malignancies. Further investigation into the biomarker potential and functional significances of exosomal cargo in veterinary medicine is warranted."
http://hdl.handle.net/1957/61844,"This thesis is separated into three distinct projects. First, synthetic studies towards the furanosteroid viridin shown in part I. Second, synthetic studies towards the diperene obtusanal shown in part II. Third, the analysis, characterization, and synthesis of coronene derivatives towards their application in organic batteries shown in part III.	Significant synthetic progress towards viridin has been made in our laboratory. We showcased the first total synthesis directed application of a proline sulfonamide-catalyzed, asymmetric Yamada-Otani cyclization as a key step to enantioselectively form the A ring of viridin from acyclic achiral aldehyde and enone precursors. In addition, we demonstrate an unprecendented, palladium-mediated oxidative furan formation to install the hallmark furan moiety from a diol and alkene functional groups.  	Significant progress towards obtusanal has been made in our laboratory culminating in the synthesis of the complete carbon bicyclic scaffold of obtusanal. In addition to using a common synthetic intermediate from the viridin project, we established several key transformations. First, a sequential two-step palladium-catalyzed functionalization of the bromo,chloro aromatic moiety. We successfully functionalized the aromatic moiety in high yield across multiple substrates through a Negishi cross-coupling selectively for the aryl bromide with minimal β-hydride elimination, followed by a palladium-catalyzed oxygenation of the aryl chloride. Second, we show a biomimmetically-inspired intramolecular aldol cyclization to set the complete scaffold of obtusanal as a single diasteromer. The intramolecular aldol reaction appears to be mediated by silica gel on an intermediate bearing a silyl enol ether and aldehyde functionality.	The dense and functionally diverse structure of the intermediates leading to obtusanal necessitated careful reagent selection and intermediate functional group selection. All told, we examined five separate approaches towards obtusanal, and synthetized an advanced intermediatebranched from the second generation “OMe series” sequence, differing from obtusanal only by differing a C6 alkene versus aldehyde, and C12-OMe verses OAc.	We report the synthesis of a new carbonylated PAH coronenehexaanhydride to be used as a cathode material in batteries and conducted NMR analysis of the coronene-based materials within organic batteries. We were able to produce coronenehexaanhydride over two steps from coronene; however, application of the material by the Ji laboratory reported low voltage potential for the material. Despite this setback, coronene was identified as a superior cathode material by the Ji laboratory, and NMR analysis prior and post discharge was conducted by our laboratory, which indicated no covalent changes to coronene."
http://hdl.handle.net/1957/61845,"This dissertation presents a different approach to understanding how amphibians are responding to disease through ontogeny. Although numerous efforts have been conducted to understand host responses to the fungus Batrachochytrium dendrobatidis (Bd), studies have been restricted to distinct developmental stages. This dissertation provides information on host response to Bd across life history transitions in native and invasive anuran species. My dissertation is an effort to understand several aspects of the host-pathogen dynamic in the amphibian- chytrid system from embryos to hatchlings, larvae, and juveniles to reproductive adults. I investigate how previous exposure at early life stages (embryos) carries over to impact host response in later life stages. Then, I explore how the virulence of the pathogen varies according to its origin and how this modifies host response. Finally I explore variation across geographic ranges in size at first reproduction, a life history trait that influences invasion potential, in the American bullfrog (Lithobates catesbeianus).Biodiversity loss threatens ecosystems worldwide and several factors, such as habitat transformation, overexploitation, and pollution contribute to this unprecedented crisis. Additional threats include emerging infectious diseases and the introduction of invasive species, both included as central topics of my dissertation research.I experimentally examined if embryonic exposure of anuran species to the fungus Batrachochytrium dendrobatidis (Bd) produces effects within the same stage. I exposed embryos of three anuran species found in the Willamette Valley, Oregon, to different strains of Bd at particular stages of embryonic development. I found that exposure to Bd resulted in direct effects on embryos; I found an increase in mortality after Bd exposure, and this response was conditioned by the host species, timing of exposure and Bd strain. I followed individuals through the hatching life history transition and into the larval stage. I detected both direct and latent effects of Bd exposure on the anuran larvae. Direct effects were observed in individuals exposed only as larvae, while latent effects were detected in individuals exposed only as embryos. Finally, repeated exposure to Bd as embryos and larvae resulted in species-specific mortality (Chapter 2).Research on variation in host response to pathogens isolated from conspecifics in different distributional ranges is needed to understand how pathogen origin can mediate host response. Chapter 3 explores the susceptibility of wild-caught invasive American bullfrogs to different Bd strains isolated from conspecifics in different distributional ranges. I found larval bullfrogs were susceptible to a novel Bd strain despite it being isolated from conspecifics. The finding of lower infection loads over time suggests bullfrogs are potentially able to clear Bd infection, but this response seems to be strain-specific. In an era of emerging diseases and globalization, understanding the impacts ofnovel strains provides information about the importance of evolutionary relationships between hosts and pathogens.In chapter 4, I studied the next anuran life history transition: reproductive adults. I quantified variation in a key life history trait, size at first reproduction, which contributes to reproductive, and thus invasion, success. I used field sampling and laboratory analysis to determine the minimum reproductive size in an invasive anuran species, the American bullfrog, in the Willamette Valley. I found the minimum reproductive size of bullfrogs is similar to the reported values for bullfrogs in other invaded ranges yet smaller than sizes reported from their native range at similar latitudes. The results obtained by this research may be applied to management actions towards controlling and minimizing the impacts of this invasive species over local species of conservation concern.Chapter 5 summarizes the findings and implications of the studies presented in this dissertation."
http://hdl.handle.net/1957/61846,"Missing data is one of the major methodological problems in longitudinal studies. It not only reduces the sample size, but also can result in biased estimation and inference. It is crucial to correctly understand the missing mechanism and appropriately incorporate it into the estimation and inference procedures. Traditional methods, such as the complete case analysis and imputation methods, are designed to deal with missing data under unverifiable assumptions of MCAR and MAR. The purpose of this dissertation is to provide an overview of procedures dealing with missing data. We especially focus on identifying and estimating attrition (missing) parameters under the non-ignorable missingness assumption using the refreshment sample in two-wave panel data. We propose a full-likelihood parametric approach which sets benchmarks for the performance of estimators in this setting. We also propose a semi-parametric method to estimate the attrition parameters by marginal density estimates with the help of two constraints from Hirano et al. (2001) and the additional information provided by the refreshment sample. We derive asymptotic properties of the semi-parametric estimators and illustrate their performance with simulations. Inference based on bootstrapping is proposed and verified through simulations. A real data application is attempted in the Netherlands Mobility Panel. Finally, we extend the semi-parametric method to incorporate a time-invariant binary covariate and evaluate its large-sample performance with simulations."
http://hdl.handle.net/1957/61847,"Nitric oxide (NO) is a signaling molecule that regulates blood pressure and vascular tone. Humans produce NO by endothelial nitric oxide synthase (eNOS), which is impaired in patients with cardiovascular disease leading to increased blood pressure, endothelial dysfunction, and an increased risk of adverse cardiovascular outcomes. Maintaining optimal levels of NO is critical for human health. Inorganic nitrate (NO3-) is reduced to NO and can be an alternate pathway to restore NO production. Diets high in nitrate reduce blood pressure and improve exercise performance in humans. In patients with advanced cardiovascular disease, organic nitrates such as nitroglycerin (glyceryl trinitrate, GTN) release NO and are essential for managing symptoms. This dissertation emphasizes mass spectrometry techniques to elucidate novel mechanisms for the effects of both organic and inorganic nitrate on cardiovascular health and exercise performance.Pharmaceutical Nitrate. Patients develop tolerance to GTN after several weeks of continuous use, limiting the potential for long-term therapy. The cause of nitrate tolerance is relatively unknown. I developed a cell culture model of nitrate tolerance that utilizes stable isotopes to measure metabolism of 15N3-GTN into 15N-nitrite. I performed global metabolomics to identify       the mechanism of GTN-induced nitrate tolerance and to elucidate the protective role of vitamin C. Metabolomics demonstrated that GTN impaired purine metabolism and depleted intracellular ATP and GTP. GTN inactivated the enzyme xanthine oxidase (XO), an enzyme that is critical for the metabolism of GTN into NO. Vitamin C prevented inactivation of XO, resulting in increased NO production from GTN. Vitamin C supplementation should be further investigated as a simple and inexpensive strategy to prevent nitrate tolerance.Dietary Nitrate. Inorganic nitrate improves exercise performance by reducing the oxygen cost of exercise. Although previous research has suggested that nitrate improves mitochondrial efficiency and stimulates mitochondrial biogenesis, we have an incomplete understanding of the mechanism. In a zebrafish (Danio rerio) model, nitrate reduced the oxygen cost of exercise during a vigorous 2-hour exercise test. Although there were no significant differences in mitochondrial function between control and nitrate-treated zebrafish, nitrate treatment increased resting ADP, ATP, and cyclic AMP levels. Metabolomics analysis of whole fish illustrated that nitrate stimulated glycolysis and ketogenesis. I conclude that nitrate reduces the oxygen cost of exercise by favoring glycolysis for energy production, thereby producing more ATP while consuming less oxygen. Nitrate-stimulated alteration of metabolic fuels for energy production is a novel mechanism for the improvement in exercise performance.Summary. This dissertation is a significant contribution to scientific knowledge because of the development of a novel assay to measure 15N-labeled nitrate and nitrite, which I have applied to study the metabolism of pharmaceutical and dietary nitrates. Using metabolomics, I elucidated the novel mechanism that vitamin C prevents nitrate tolerance by protecting XO from inactivation. Furthermore, I demonstrated that nitrate alters the utilization of metabolic fuels, leading to reduced oxygen consumption during exercise."
http://hdl.handle.net/1957/61850,"Every year thousands of people are killed or injured in work zone crashes in the US due to excessive speed, distraction, inattentiveness, low visibility, and other factors. Roadway construction and maintenance operations often occur at night when the traffic volume is low, creating less congestion and delay to the traffic. The operations commonly require workers to conduct their work in close proximity to ongoing traffic, and often reduce traffic flow to a single lane while work is undertaken in an adjacent lane. Nighttime brings a reduction in visibility for both workers and drivers. High speed roadways with low visibility and limited protection make an unsafe and dangerous situation for both motorists and workers. Safely controlling and reducing vehicle speeds through work zones decreases the safety risk associated with highway construction and maintenance work. Work zone speed control has been the subject of several research efforts in the past. As such, various techniques and procedures have been tested and evaluated. These include, but are not limited to, variation of traditional fixed signage, changeable message displays, radar units with speed sign messages, and a range of electronic devices to sense and display information related to speed.  The present research has been conducted to evaluate the effectiveness of a truck-mounted radar speed sign and additional lighting on speed control during construction and maintenance work. The first phase of the research included evaluating radar speed signs (RSSs) as a speed reduction measure through work zones. RSSs have been known as a way to slow down the traffic flow speed. In this study, the influence of truck-mounted RSSs on vehicle speed for mobile maintenance operation has been tested. In this regard, truck mounted RSSs were employed in two, multi-lane maintenance work zones in the state of Oregon in the US. In each case study, the authors conducted two periods of testing: one with the RSS display turned on (treatment) and one without the RSS display turned on (control), and recorded vehicle speeds. The second phase of the research involved investigating the impact of additional temporary lighting on vehicle speed in highway work zones. In addition, the impact of wearing personal lighting equipment was also examined during paving operations. Two common types of lighting equipment, a light tower and a balloon light, were set up in work zones and a personal, wearable light was used during two paving projects on Oregon highways. Traffic speed and other vehicle and lighting data were collected on different nights when the lighting equipment was turned on and also when it was turned off.Descriptive statistics were used in both studies to summarize collected data and to compare the speed difference between control and treatment cases. The research findings indicate that vehicle speeds are typically lower, and there is less variation in speeds between adjacent vehicles, with the RSS turned on. The results show that the RSS proves to be a promising device for controlling vehicle speed and making the work zones safer for both motorists and workers. Field observations confirmed that both additional temporary roadway lighting and personal lighting help to make workers more visible to motorists and equipment operators. Although a temporary light leads to slightly higher vehicle speeds, it makes the work zone and workers more visible for motorists and equipment operators. Statistical analysis revealed that there is no difference between mean vehicle speed with and without personal lights turned on. Personal, wearable lights are highly recommended for workers who are located away from large equipment and other light sources.The results of this research can be used by DOT Construction and Maintenance Offices for planning construction and maintenance work. The research output can also be used by the Transportation Safety Divisions and Transportation Safety Coordinators within DOTs as a resource for effectively designing work zones and planning construction and maintenance operations."
http://hdl.handle.net/1957/61851,"Soft keyboards come in different shapes, sizes, and layouts. Each layout is designed to help the users in different inputting tasks. Most of these layouts, however, focus on general text entry as opposed to computer programs. This dissertation addresses the problems with current input mechanisms on touchscreen devices. The dissertation presents the design and evaluation of different custom keyboards for inputting programs on touchscreen devices. It shows the advantages of using the soft custom keyboards over the default input techniques. The contributions include (1) Syntax-Directed Keyboard Extension—a novel keyboard design for inputting Java source code efficiently and accurately; (2) Evolution and Evaluation of the Syntax-Directed Keyboard—a longitudinal evaluation of an enhanced design of the Syntax-Directed Keyboard using Java source code statistics; and (3) Evaluation of A Visual Programming Keyboard—a soft keyboard alternative to the drag-and-drop method to input block-based programs and its evaluation. These custom keyboards were evaluated with empirical user studies involving human participants."
http://hdl.handle.net/1957/61852,"In ponderosa pine (Pinus ponderosa) forests of the western United States, prescribed fires are used to reduce fuel loads and restore historical fire regimes. The season in which prescribed burns are performed and the interval between burns can have complex consequences for the ecosystem, including soil carbon cycling through the production of pyrogenic carbon (PyC). PyC is a broad term that refers to a spectrum of thermally-altered organic matter. PyC plays a crucial role in soil carbon cycling, displaying turnover times that are orders of magnitude longer than unburned organic matter. This work investigated how the season of and interval between prescribed burns affects the formation and retention of pyrogenic carbon (PyC) in a ponderosa pine forest of eastern Oregon. In 1997 a season and interval of burn study was implemented in Malheur National Forest to examine the ecological effects of burning at 5 and 15-year intervals in either the spring or fall. In October 2015, both O-horizon and mineral soil (0-15 cm) samples were collected and analyzed for PyC concentration, content, and structure using the benzene polycarboxylic acid (BPCA) method. O-horizon depth, carbon and nitrogen concentration and content, pH, and bulk density were also measured. Compared to unburned controls, we estimate that fall burns increased the PyC concentration of the mineral soil by 8.4 g BPCA kg C (95% CI: 4.2,12.6 g BPCA kg C). No change in PyC concentration of the O-horizon was detected for the plots burned in either the spring or fall compared to the unburned￼￼￼￼￼￼controls; however, the chemical structure of the PyC in the O-horizon of the unburned control plots was significantly more condensed than that of the plots burned in either the spring or the fall."
http://hdl.handle.net/1957/61853,"The Comprehensive Nuclear-Test-Ban Treaty (CTBT) bans all nuclear explosion tests for military or civilian purposes. The International Monitoring System (IMS) was established to verify compliance with the treaty. It consists of several monitoring stations that detect: seismic activities, hydrocoustic activities, infrasound waves, and radionuclide particles and noble gases. Radioxenon detection provides the most robust evidence of a nuclear weapon test. There are four radioxenon isotopes of interest: 131mXe (t1 2 = 11.93 days), 133mXe (t1 2 = 2.19 days), 133Xe (t1 2 = 5.25 days) and 135Xe (t1 2 = 0.38 days). All of these radioxenons emit beta and gamma radiation in coincidence or conversion electrons and X-rays in coincidence during their decay process. In this research, a new radioxenon detection system was developed based on Si and CZT detectors. The system is made of the “PIPSBox” silicon gas cell recently developed by Canberra to detect beta and conversion electrons, and two coplanar CZT detectors to detect X-rays and gamma rays. The PIPSBox silicon gas cell offers many advantages such as: (1) increasing the frequency of air sampling at IMS stations because memory effect does not affect the PIPSBox gas cell like it does with plastic gas cells currently used at IMS stations, (2) reducing the Minimum Detectable Concentration (MDC) for radioxenons due to better energy resolution of silicon, and minimal background interference from previous measurements. The detection system was simulated using MCNP6 and was characterized by 131mXe to determine optimum operating voltages, proper gain, and the length of the coincidence window.Pulse waveforms of the silicon and CZT detectors were analyzed using two digital pulse processors: DPP2 and DPP8. DPP2 is a two-channel digital pulse processor with a 200 MHz sampling frequency and a 12-bit ADC resolution. DPP8 is an 8-channel, 125 MHz digital signal processor with a 14-bit ADC resolution. A coincidence firmware was implemented in the on-board FPGA to identify specific coincidences events between silicon and CZT detectors to generate 2D spectra for the four radioxenons of interest.  The resolution of the 129 keV conversion electron was measured to be 16.66% in silicon1 and 16.87% in silicon2. These resolutions are the best-known values reported from other radioxenon detection systems that were included in the literature review of this research. The minimum detectable concentration (MDC) of PIPSBox CZT detection system four all radioxenons of interest was measured to be less than the 1 mBq m3 IMS requirement. Specifically, 0.25 mBq m3 for 131mXe, 0.26 mBq m3 for 133mXe, 0.39 mBq m3 for 133Xe, and 0.72 mBq m3 for 135Xe."
http://hdl.handle.net/1957/61854,"Mycobacterium avium subspecies hominissuis (MAH) is an opportunistic pathogen that is ubiquitous in the environment and often isolated from faucets and showerheads. MAH mostly infects humans with an underlying disease, such as chronic pulmonary disorder (COPD), cystic fibrosis (CF), or are immunocompromised, though infections in patients without concurrent disease are increasing in prevalence. MAH is resistant to many antibiotics due to the impermeability of its envelope and the protection of its intracellular niche inside host macrophages, making the infections difficult to treat. Host macrophages produce nitric oxide and reactive oxygen intermediates to kill phagocytosed bacteria. However, MAH replicates in nitric oxide producing cells and is less virulent when inducible nitric oxide synthesis is suppressed in a murine host. To investigate the relationship between MAH and nitric oxide, an in vitro model was developed in murine macrophages. We show that MAH grows in macrophages stimulated with IFN-g and producing nitric oxide. A transposon library screen of MAH for mutants incubated with nitric oxide donor indicated        that inactivation of the gene MAV_4644 (MAV_4644:Tn) resulted in nitric oxide susceptibility. Characterization of MAV_4644:Tn revealed that it is required for virulence in host macrophages. In silico analysis revealed MAV_4644 is a dual-function channel protein with putative ADP-ribosyltransferase activity. Protein binding assays indicate that MAV_4644 protein interacts with the host lysosomal peptidase, cathepsin Z. Cathepsins are key regulators of inflammation and antigen presentation within immune cells. Pathogenic mycobacteria have been shown to suppress the action of other cathepsins to establish their intracellular niche. Knock-down of cathepsin Z in host macrophages rescued the attenuated phenotype of MAV_4644:Tn. The data suggests cathepsin Z is involved in early mycobacterial killing within host macrophages and virulence factor MAV_4644 protein abrogates this process."
http://hdl.handle.net/1957/61855,"1,4-dioxane, a probable human carcinogen at low (< 1ppb) concentrations, has emerged as a groundwater contaminant due to its historical use as a stabilizer for the chlorinated solvent 1,1,1-trichloroethane. Aerobic cometabolism, the use of a primary substrate to induce the production of microbial enzymes that fortuitously degrade other compounds, is a promising in situ treatment strategy for 1,4-dioxane because it has the potential to mineralize trace 1,4-dioxane concentrations to carbon dioxide. The effectiveness of biostimulation with isobutane (2-methylpropane) as a primary substrate and bioaugmentation with Rhodococcus rhodochrous strain ATCC 21198 was assessed in microcosms constructed with aquifer solids from Fort Carson, Colorado, a site with 1,4-dioxane and trichloroethene (TCE) co-contamination. Isobutane effectively stimulated native 1,4-dioxane-degrading microorganisms in the aquifer solids after a lag of approximately one week. Microcosms bioaugmented with 21198 showed immediate consumption of isobutane and cometabolism of 1,4-dioxane after isobutane was consumed below 0.15 mg L, indicating primary substrate inhibition. At a concentration of 200 μg L, TCE did not inhibit 1,4-dioxane degradation, however TCE was not readily cometabolized. 1,4-dioxane-cometabolizing microbial populations remained active in bioaugmented and biostimulated microcosms with repeated additions of isobutane over approximately 300 days, though transformation rates slowed without inorganic nutrient amendment. Modeling of simultaneous isobutane utilization, 1,4-dioxane degradation, and biomass growth according to Michaelis-Menten and Monod kinetics accurately simulated data from microcosms not experiencing inorganicnutrient limitation. Optimization of kinetic parameters yielded the following values: Kmax,1IB=2.58 mg mg day, Ks,IB=0.1 mg L, Kmax,14D=0.87 mg mg day, Ks,14D=4.35 mg L, KI=0.13 mg L, b=0.03 1 day, and Y=0.885 mg mg."
http://hdl.handle.net/1957/61856,"Natural resource challenges in the American West feature a suite of actors and processes operating at different spatial and political scales, and crossing several administrative jurisdictions. I applied concepts of new environmental governance to Oregon’s greater sage-grouse (Centrocercus urophasianus) conservation strategy, focusing, in particular, on features of voluntary conservation arrangements that motivated participation of private landowners in conservation, and how high-level objectives reached actors responsible for on-the-ground implementation. Data were obtained from one critical case in Lake County, Oregon through in-depth, semi-structured interviews with private landowners who had voluntarily participated in sage-grouse conservation, as well as with governmental and nongovernmental actors from low to high jurisdictional levels. I found that through voluntary conservation arrangements, landowners and mid- and lower-level actors had flexibility, autonomy, and financial and technical resources to carry out higher-level objectives, that is, conservation outcomes identified by the U.S. Fish and Wildlife Service (USFWS). Landowner participation in voluntary arrangements was largely motivated by well-funded program offerings that were largely aligned with production goals and gave them a sense of control over their own destinies in the context of a potential Endangered Species Act (ESA) listing of sage-grouse. Decentralization and devolution of implementation authority to mid- and local-level actors was facilitated by organizations acting as intermediaries between landowners and actors at high levels (e.g., the USFWS). This increased the capacity of lower-level actors who felt that they had flexibility to implement conservation while concurrently achieve their own objectives (i.e., continuing to make a living ranching). By aligning voluntary conservation offerings with the economic and cultural context of this case (e.g., using trusted intermediaries to deliver resources to landowners for improving ranching operations), voluntary conservation arrangements may enhance the capacities of local-level implementers and alleviate the need for some regulatory protections in contexts in which conservation and rural livelihoods intersect. This case, relying on voluntary conservation and decentralization of authority, is an example of how new environmental governance offers a way forward in cracking common property challenges. Further exploration of connections between higher levels of governance and local contexts will reveal important, new ways to connect policy-makers to those affected by policy."
http://hdl.handle.net/1957/61857,"Mobile video streaming has become an essential application in mobile wireless networks,making up most of the mobile data of today’s Internet traffic. Studies have shown thatmobile video data is projected to make up about 78 percent of the global mobile datatraffic, and that global mobile data traffic is expected to increase sevenfold by 2021.Massive small cell base station (SBS) deployments have emerged as a potential solutionpromising to fulfill these unprecedented mobile data demands, by offering great coverageenhancements and maintaining high quality of video streaming. However, due torelatively small cell sizes and high user mobility, mobile video streaming in dense SBSnetworks faces fundamental challenges such as intermittent connectivity and frequenthandoffs, causing degradation in video streaming quality. In this thesis, we tackle thisissue by introducing a hybrid proactive in-network caching framework that stores somepopular videos at the edge of the network, namely at the SBSs, while also pre-cachingvideo contents in advance to better service mobile users. The proposed framework essentially reduces the need for bringing every requested video from the core (original)network, which results in alleviating network congestion by reducing back-haul trafficand in improving mobile video streaming experience by avoiding service discontinuityduring handoffs. We develop a simulation framework using MATLAB to study theperformance of the proposed hybrid proactive caching technique, and show using simulations that the proposed technique can effectively improve video quality of experienceand reduce back-haul traffic."
http://hdl.handle.net/1957/61858,"Cancer risk at low-dose ionizing radiation has been the subject of great scientific controversy in the past century. The clear majority of national and international radiation protection regulators adopt the linear no-threshold (LNT) model based on the atomic-bomb survivors Life Span Study (LSS) for solid cancer risk assessment. The LNT model assumes a linear relationship between radiation dose and cancer risk including interpolation of high dose values down to zero dose with no ‘safe’ threshold. New scientific evidence in the fields of molecular biology and epidemiology challenge the validity of the LNT model suggesting beneficial effects at low doses of ionizing radiation in a process better known as ‘hormesis’. This paper investigates current evidence for radiation hormesis with respect to solid cancer risks in adults and proposes a modest study design to test the hormesis hypothesis in humans with the potential of using low dose ionizing radiation to reduce solid cancer incidence in a population, if hormesis is proven. Current evidence confirms that hormesis does occur at low dose and low dose rates of low LET ionizing radiation. Every effort should be made from scientists in related fields in order to make the best use of the hormesis phenomenon with the aim of benefiting and protecting the public as the main objectives."
http://hdl.handle.net/1957/61859,"Electrochemical capacitors and batteries are two major electrochemical energy storage technologies, which have been investigated extensively to meet the rapidly-growing demand for higher energy, higher power, lower cost and enhanced safety in the past few decades. With the charge storage mechanism of electrostatic charge adsorption desorption via electrical double layers, electrochemical capacitors deliver higher power, but store less energy, compared to batteries, where redox reactions usually take place inside bulk electrode materials. Depending on the electrolytes, electrochemical capacitors can be divided into aqueous and non-aqueous capacitors. Aqueous electrolytes are more electrically conductive, non-flammable, and more sustainable, compared to non-aqueous electrolytes. However, non-aqueous electrolytes are overwhelmingly dominating the electrochemical capacitor markets, because they provide a larger electrochemical window, and consequently enable capacitors to store more energy. To take advantages of aqueous electrolytes and facilitate safer and more sustainable electrochemical capacitors, tremendous research has been conducted toincrease energy density of aqueous capacitors. Traditional approach is to utilize redox-active electrodes, e.g. metal oxide and conducting polymers in pseudocapacitors, most of which increase energy density at the expense of largely sacrificing power and cycle life. It is important to make progress in one performance aspect of electrochemical capacitors, while retaining other desirable properties as much as possible.There are two effective ways to store more energy in electrochemical capacitors. One is by increasing capacitance, and the other one is by increasing operating voltages.Higher capacitance can be obtained when introducing redox reactions in electrochemical capacitors. Instead of employing redox-active electrodes, which may experience ion diffusion in solid, aqueous redox-active electrolyte was studied to retain high power while storing more energy. The redox pair of IOx- I- in 4 M KI and 1 M KOH is reported for the first time, which enables aqueous capacitors to store a maximum energy of 7.1 Wh kg, on a par with state-of-the-art non-aqueous capacitors, while delivering a maximum power of 6222 W kg, and retaining 93% capacitance after 14,000 cycles.Higher operating voltages are realized in aqueous electrochemical capacitors by maintaining pH 1 and pH 10 at the positive and negative electrode, respectively, with a bipolar assembly of ion-exchange membranes. The theoretical electrochemical window of aqueous electrolytes is expanded from 1.23 to 1.76 V. A practical operating voltage of 1.8 V is proved to be safe for aqueous capacitors with the bipolar assembly,which allows to store a specific energy of 12.7 Wh kg, as well as retain 97% capacitance after 10,000 cycles.Although batteries, especially lithium-ion batteries, have been successful in different fields, e.g. portable electronics, electric vehicles, etc., an intrinsic drawback still exists: low abundance of lithium and therefore high cost of lithium-ion batteries. To address this issue, different types of batteries have been studied, which utilize Earth-abundant elements, such as Na, K, Al, etc. In this dissertation, a novel battery is reported, where hydronium ions perform as charge carriers. For the first time, hydronium ions are found to be reversibly stored in 3,4,9,10-perylenetetracarboxylic dianhydride crystals, contributing 85 mAh g at 1 A g after an initial conditioning process. As an aqueous battery storing hydronium ions instead of metal cations, it may deliver higher power, significantly lower the battery cost, and increase the margin of safety. Although this technology is not as mature as lithium-ion batteries, it provides new opportunities and possible solutions for future energy storage.A new deposition technology, namely ambient hydrolysis deposition, is also studied in this dissertation, which enables nanoparticles grown in porous substrate in a simple and cost-effective way. As a proof-of-concept, by controlling the amount of pre-adsorbed water vapor in the porous carbon, various amount of TiO2 nanoparticles are grown in porous carbon. The TiO2 nanoparticles can be converted into TiN nanoparticles by nitridation, which improve the electrical conductivity of porous carbon. Electrodesprepared from porous carbon with TiN nanoparticles coating exhibit enhanced rate capability in electrochemical capacitors."
http://hdl.handle.net/1957/61860,"Markov chains have long been used to sample from probability distributions and simulate dynamical systems. In both cases we would like to know how long it takes for the chain's distribution to converge to within varepsilon of the stationary distribution in total variation distance; the answer to this is, called the mixing time of the chain. After this time, we can sample the Markov chain's position to approximate sampling the underlying stationary distribution, and the chain's dynamics exhibit equilibrium behavior. In this dissertation we study the effect that the system size (diameter of the state space, say) has on the mixing time of a sequence of Markov chains which have locally-finite lattice state spaces, and transition probability functions converging to those of a gradient dynamical system. In lieu of a precise functional form for the mixing time, the problem we study is the asymptotic growth rate as infty.This dissertation offers a novel solution utilizing the weak scaling limits of the Markov chains and local central limit theory for random walks on lattices. By separating the state space into high-drift and low-drift regions where weak limits are valid, and utilizing martingale theory to approximate the chain's behavior in the intermediate regions, we determine the time required for the distribution to converge weakly to to stationarity. This decomposition of the state space makes evaluating the existence of cutoff straightforward as well. Then a local limit theorem is used to strengthen the weak convergence to total variation convergence. The theory developed is then applied to recover recent mixing time results for statistical mechanical models, giving independent proof of known mixing behavior in the mean-field Ising and Potts models, as well as a full description of the mixing behavior of the Blume-Capel model."
http://hdl.handle.net/1957/61861,"The contribution of delayed adaptive reiteration to crown maintenance was explored across a wide range of adjacent open space conditions in early-mature (approximately 60 year old) Douglas-fir located on the eastern slope of Oregon’s Coast Range.  The stands had experienced uniform thinning in 1964-65 and 1980-81 to release dominant and codominant trees, and again in 1993 to create a wide range of stand density and spatial uniformity conditions. A subset of plots had been re-thinned in 2001 to return them to target densities. A combination of ground-based, in-crown, and needle cohort measurements were employed to characterize branch and foliage characteristics. Epicormic branches were present throughout tree crowns but contributed less than 10 percent of total branch length and only 2.4 percent of foliage mass. Very few epicormic branches occurred below the base of the regular crown in the sample trees, and those present were too small to impact log or lumber quality. However, reiteration of foliage from dormant buds (delayed adaptive reiteration) was ubiquitous, occupying 60 percent of total branch length and accounting for more than 40 percent of total foliage mass. The extent of adjacent open space did not influence patterns of branch length or location for either original or epicormic branches, nor did it affect the proportion of branch length occupied by delayed foliage. Increasing adjacent open space may have had a modest negative impact on the proportion of sequential (regular) foliage occurring on original branches (p=0.0548).Paired samples of delayed and sequential (regular) foliage were compared to determine if they differed in structure or physiological performance. Regardless of crown position, delayed foliage had higher average specific leaf area (SLA) and exhibited higher levels of discrimination against 13C (Δ13C), lower intrinsic water use efficiency (iWUE), and higher δ18O, than sequential foliage. The results indicated that delayed foliage was, on average, more shade adapted than sequential foliage. In addition, cohorts of both types of foliage demonstrated distinct reductions in average SLA with increasing age of their leaf cohort, a result attributed to more rapid shedding of high-SLA needles. Year-to-year variation in Δ13C, iWUE, and δ18O was correlated with weather conditions, but trends were complicated by the integration of isotope signals across multiple growth seasons. Delayed foliage provides Douglas-fir with an ongoing source of new leaf area and the capacity to adapt to changing growth conditions. It provides a significant proportion of the species’ photosynthetic capacity, and very likely increases its ability to recover from crown damage, foliage disease, and herbivory. It may allow Douglas-fir to more readily utilize the increased levels of CO2 available in the earth’s atmosphere, and to respond positively to other environmental changes at both local (site-level) and global (climatic) scales."
http://hdl.handle.net/1957/61862,"Spotted wing drosophila (SWD), Drosophila suzukii, is an economically damaging pest on small fruits. The estimated economic impact is hundreds of millions of dollars annually in the U.S. alone, and increasing every year. Current control of SWD relies heavily on chemical insecticides which have many negative impacts on environmental and human health. Therefore, this should be replaced or at least complemented with biologically-based alternatives. The current project has focused on investigating non-nutritive sugars including erythritol as an environmentally-friendly control agent against SWD.The study found a potential insecticidal effect from non-nutritive sugars and sugar alcohols, erythritol and erythrose, to decrease the survivorship of D. suzukii. In a dose-dependent feeding, erythritol and erythrose significantly reduced the fly longevity with 1 M - 0.05M doses for 7 days. When sugar solutions were provided separately to flies, there was no effect on survivorship regardless of erythritol concentrations. However, with a serial combination of sucrose and erythritol solutions, fly survivorship was significantly decreased. In a no-choice feeding assay, the fly ingested more erythritol than sucrose or water, and erythritol and sucrose-fed flies gained more weight than water-fed flies. However, in two-choice assays, the amount of erythritol ingested was less than sucrose or water.Total sugar and glycogen levels among the body of erythritol and erythrose-fed flies were significantly less than flies fed nutritive sugars of mannitol, sorbitol, and xylitol. The result indicates that the two non-nutritive sugars can't be used as a substrate for enzymes involved in sugar metabolism. Although the metabolism of erythritol and erythrose is unknown in insects, the mortality of D. suzukii flies ingesting these sugars might be caused by two potential physiological changes: 1) starvation from the feeding of non-metabolizable erythritol and erythrose; and 2) abnormal osmotic pressure increased in the hemolymph with erythritol transported from the midgut.Chapter 3, sucrose and erythritol were applied to blueberries and effects of these combinations on fly mortality and fecundity were monitored in the lab and greenhouse. In the lab test, two sucrose erythritol combinations (0.5M sucrose 2M erythritol, 1M sucrose 2M erythritol) resulted in the highest mortality and the lowest fecundity in SWD adults. Two combinations, therefore, were selected for further evaluation with blueberry bushes and fruits in the greenhouse. The fly fed on 0.5M sucrose 2M erythritol significantly decreased their survivorship than 1M sucrose 2M erythritol-fed flies in the greenhouse. This result indicates that flies could move more in the bigger cage accelerating the exhaustion of energetic reserves in the body.The presence of erythritol in the hemolymph and frass was determined to investigate the nutritional metabolism and absorption of erythritol in D. suzukii. Unlike sucrose, a large amount of erythritol was observed in the hemolymph of the fly ingested the 0.5M sucrose 0.5M erythritol. Not sucrose, erythritol was found in the frass in the same fly. The results imply that erythritol might be directly transported from the midgut without being metabolized and stored, but is accumulated in the hemolymph which in turn elevates the osmotic pressure in the fly hemolymph.Overall, this research found the sucrose erythritol combination would be more effective than erythritol alone for practical application, because the combination tastes sweeter to elicit more feeding. This erythritol formulation can be a potential insecticide used alone or as a delivery agent combined with conventional orbiological insecticides to enhance their efficacy. While the present research focuses on D. suzukii, it can be expanded to other Dipteran pests as well."
http://hdl.handle.net/1957/61864,"In small forested streams, changes in age and structure of riparian vegetation covering the stream have been shown to directly influence the amount of light reaching the stream benthos. Light has the potential to impact in-stream resources that support secondary production through constraints on primary productivity. The influence of landscape changes in riparian vegetation cover and their effect on in-stream light has been evaluated; however smaller, patchy changes of in-stream light have yet to be thoroughly explored. We worked to clarify the role of light as a bottom-up driver of in-stream food webs in the western Cascade Mountain range streams, in Oregon, through exploring how decreased light availability, via patchy shading, affected in-stream biota. With patchy decreases in the amount of light reaching the stream benthos we expected to see a reduction in the growth of in-stream autotrophs through the summer and subsequently a decrease in macroinvertebrates, cutthroat trout (Oncorhynchus clarkii clarkii) and salamanders as a result of decreasing resource availability in the manipulated reaches. We established three sets of paired stream reaches and experimentally manipulated light in one reach from each pair by adding patches of shade. We then evaluated how periphyton, invertebrates, fish, and total vertebrate predators responded in the manipulated reach relative to the unmanipulated reference reach in a before-after control-impact (BACI) study design. Our patchy shading manipulation significantly decreased light, causing a decrease in algal biomass and subsequently invertebrate, fish, and salamander biomass. Local decreases in light fluxes to forested headwater streams along a larger reach decreased biota throughout the aquatic food-web. This trend was consistent in streams bordered by both second-growth and old-growth forests. This research indicates that smaller changes in riparian forest structure which impact in-stream light, such as those that occur in forests develop processes, can impact in-stream biota."
http://hdl.handle.net/1957/61865,"In Intense Pulsed Light (IPL) sintering, pulsed large-area visible light from a xenon lamp is absorbed by nanoparticle films or patterns and converted to heat, resulting in rapid sintering of the nanoparticles. This work experimentally characterizes IPL sintering of silver nanoparticle films. A newly observed turning point in the evolution of film temperature during IPL sintering is correlated to the observation, in literature and in this work, that film densification levels off beyond a critical pulse fluence and number of pulses. A computational model is developed that couple electromagnetic finite element analysis, heat transfer models and densification models to predict the evolution of film temperature and density during IPL. This model is able to capture the experimentally observed turning point in temperature during IPL, whereas current models of IPL are unable to do so. It is shown that the temperature turning point occurs due to a coupling between optical absorption and densification in the nanoparticle film, mediated by a change in nanoscale shape of the deposited nanoparticles due to interparticle neck growth. Further, it is found that the optical fluence per pulse has a greater effect on the achievable film density in IPL, as compared to the number of pulses"
http://hdl.handle.net/1957/61866,"In this study, I seek to examine undergraduate STEM majors’ beliefs about and attitude towards mistakes in the context of counting. This is a particularly fruitful setting for such an investigation both because combinatorics is widely applicable to various fields such as physics, biology, chemistry, and computer science (Kapur, 1970), and because it is acknowledged by many in the field of math education research that students struggle with learning to count (Hadar & Hadass, 1981; Lockwood, 2014; Batanero, Navarro-Pelayo, & Godino, 1997). Specifically, given that students tend to display negative affect towards mistakes (Turner, Thorpe, & Meyer, 1998), despite the beneficial nature of mistakes (Borasi, 1987, p. 2), and that affective factors like attitudes and beliefs have a significant impact on students’ problem-solving activity (Carlson and Bloom, 2005), enumerative combinatorics is an ideal setting to study individuals’ mindsets (as in Dweck, 2006 and Boaler & Dweck, 2016). I helped to interview five students, asking them to engage in combinatorial problem solving, and reflect on their prior experiences with counting. I found that students’ self-reported mindsets and beliefs towards mistakes affected their counting activity. Furthermore, I also found evidence to support that the concept of mindset is a spectrum, rather than a dichotomy. These results serve to inform the existing literature, provide implications for the teaching and learning of enumerative combinatorics, and offer opportunities for future research."
http://hdl.handle.net/1957/61867,"Zebrafish (Danio rerio) are one of the most commonly used animal models in biomedical research. Zebrafish resource facilities, like the Zebrafish International Resource Center (ZIRC) in Eugene, Oregon, are the main providers and keepers of numerous zebrafish wild-type, mutant, and transgenic lines. Although ZIRC maintains live zebrafish at various life stages, sperm cryopreservation allows them to maintain the vast array of zebrafish lines that they receive from outside facilities. Hence, there is a concern about the potential of vertical transmission of pathogens capable of surviving the freezing and thawing process.My first study was to determine whether zebrafish pathogens are capable of surviving the sperm cryopreservation process used by ZIRC (i.e., the ZIRC method). I assessed the survival of two strains of Mycobacterium chelonae (H1E1 and H1E2), one strain of Mycobacterium marinum (OSU 214), one strain of Edwardsiella ictaluri, Pseudocapillaria tomentosa eggs and Pseudoloma neurophilia spores, which are all￼￼￼￼pathogens of concern in zebrafish research facilities. These pathogens were also frozen and thawed without cryopreservant, and the pathogens were frozen at either -80oC or - 20oC with only a small amount of Phosphate Buffered Saline (PBS).Each bacterial species survived both freezing and thawing methods, however the samples subjected to the ZIRC method had the higher percentages of bacterial survival compared to the freezing without cryopreservant samples. The mycobacteria had higher survival rates compared to Gram-negative E. ictaluri in both freezing methods. E. ictaluri exhibited a 1-2 log decrease in concentration following the freezing without cryopreservant.For the P. tomentosa eggs, survival was based on larvation. Eggs were examined at Day 0 (immediately after collecting or thawing) and at Day 7 (a week after being collected or thawed). No larvation was observed on Day 7 with eggs processed by the ZIRC method or simple freezing (-80oC in 1X PBS and no cryopreservant). In contrast, the positive controls, kept at 28oC, showed 80-93% larvation at Day 7. Most of the eggs observed in either freezing method were unlarvated and intact, however some, exhibited signs of internal deformation of the egg contents.In 2014, our lab conducted a similar cryopreservation study on the ZIRC cryopreservation method in place at that time. In that study P. neurophilia spores were tested for their ability to survive cryopreservation. I repeated this study in 2017 using the 2017 ZIRC cryopreservation protocol. In both experiments, two fluorescent stains, SYTOX and Fungi-Fluor, and presence of a spore vacuole were used to determine spore viability. SYTOX green is a fluorescent nucleic acid stain, and cells are scored as dead when the dye enters the cells and results in green fluorescence. P. neurophilia spores alsocontain a long, coiled, polar filament or tube that is thought to aid in infecting hosts cells when extruded. Spores are scored as alive if they are stained with Fungi-Fluor, exposed to ultra violet light, and then expel their polar tubes. Presence of a vacuole observed by light microscopy indicated that spores were alive.The 2014 and 2017 experiments yield very similar results, and some spores were able to survive the ZIRC cryopreservation method. Spore survival varied depending on the fluorescent stain used. Samples stained with SYTOX yielded higher percentages of survival than those stained with Fungi-Fluor or quantified using vacuole presence. Nevertheless, in both the 2014 and 2017 experiments, about 10% of the spores were scored as alive using the more conservative Fungi-Fluor and vacuole presence tests following the ZIRC cryopreservation method. Very few spores were scored as alive following freezing without cryopreservant with any method.The second study I conducted entailed working with the Oregon State University Veterinary Diagnostics Laboratory (OSU VDL) to evaluate the clinical sensitivity of their real-time quantitative PCR (qPCR) assays for three Mycobacterium spp: M. chelonae, M. marinum, and M. haemophilum. To test the clinical sensitivity of these assays, we spiked actual zebrafish tissue samples with known concentrations of diluted bacterial samples and determined the lowest detectable bacterial concentration. For this study M. chelonae (H1E2) and M. marinum (OSU 214) were diluted and spiked into minced zebrafish tissue. These samples were then assayed using qPCR. M. haemophilum was not used in this study due to difficulties with culturing. For M. chelonae, 61,000 colony forming units (CFUs) mL and 437 CFUs per PCR reaction was the lowest detectableconcentration. On the other hand, 3,700 CFU mL and 27 CFUs per PCR reaction was the lowest detectable concentration for M. marinum.In this thesis research, I showed that M. chelonae, M. marinum, E. ictaluri, and P. neurophilia spores can survive the ZIRC cryopreservation method and in some cases freezing without a cryopreservant, but P. tomentosa eggs did not survive freezing. Given these results, I recommend that zebrafish and fish facilities that implement sperm cryopreservation consider testing sperm samples prior to freezing them or using them for in vitro fertilization. We also determined the clinical sensitivity of the Mycobacterium qPCR assay used by the OSU VDL. Although this assay can identify Mycobacterium species in fish tissue, specifically M. chelonae and M. marinum, it showed rather moderate sensitivity. I therefore recommend these tests for species identification of mycobacteria in fish in which mycobacteria are first detected by other methods (e.g., acid fast staining) rather than for screening zebrafish for the presence of bacteria in fish with no other indications of infection."
http://hdl.handle.net/1957/61885,"AN ABSTRACT OF THE DISSERTATION OFBrooke N. Lundquist for the degree of Doctor of Philosophy in Counseling presented onAugust 31, 2017.Title: A Phenomenological Exploration of the Experiences of Counselor EducationDoctoral Student Mothers with Young ChildrenAbstract approved: ______________________________________________________Kok-Mun NgThe number of women in doctoral programs is increasing each year and womennow comprise the majority of doctoral students in America (U.S. Department ofEducation, 2015). Previous research has shown the high levels of complexities andstresses that female doctoral students face during their studies (Mallinckrodt & Leong,1992) and this has found to be even more so for doctoral student mothers (Brown &Watson, 2010). Of the studies that have been done on counselor education doctoralstudent mothers, no studies were found to have specifically explored the experiences ofcounselor education doctoral student mothers who have young children. Being that youngchildren have unique needs from their mothers or primary caregivers, and many doctoralstudents are of prime childbearing years (Hoffer et al., 2006), it is important tounderstand the experiences of these doctoral student mothers in order to better supportthis population during their doctoral studies. It is also important to give voice to thesestudent mothers through research methods that value their lived experiences. Throughtwo phenomenological studies, this dissertation is an exploration of (a) the motheringexperience and (b) the student experience of counselor education doctoral studentmothers with children under the age of five. There were 11 participants interviewed andthe same 11 participated in both phenomenological research studies.iiThe first study is an exploration of the mothering experience of counseloreducation doctoral student mothers with a child or children under the age of five. Theresults of Study 1 identified six major common themes that described the experience ofthe 11 women who participated in the research study. These themes included: (a)ambivalence, where the priority of the mothering role meets that of the strong desire to bea successful doctoral student and professional in the counselor education field; (b)increasing and accepting give and take: negotiating expectations while increasing copingmechanisms; (c) the teeter-totter of mothering-student roles; (d) “Superwomansyndrome”; (e) indistinguishable roles (those of mother and student) combine together tocreate identity; and (f) the importance of leading by example.The second study is an exploration of the student experience of counseloreducation doctoral student mothers with a child or children under five years of age. Thefindings from Study 2 resulted in five common themes that existed for the participants,including (a) experiencing ambivalence about being a doctoral student while mothering ayoung child children; (b) experiencing constant pressures due to responsibilities that canbe conflicting, complimentary, or both; (c) responding by increasing coping mechanismsto accommodate the doctoral student role; (d) believing in the importance of leading byexample; and (e) acknowledging and accepting that they have a different experience thantheir doctoral student peers.Despite findings in Study 1 and Study 2 that were similar or overlapped, therewere differences found between the experiences of the participants in their different roles.These results provided insights into the experiences that counselor education doctoralstudent mothers with children under the age of five have during their doctoral programs.iiiIt is hoped that this information will help doctoral program administrators, faculty,student peers, and even doctoral student mothers gain a better understanding of theunique experiences that these students face. It is important that doctoral program facultyand administration not only better understand this population of students, but also realizethe importance of engaging with these students as “whole people” (Springer et al., 2009,p. 453), which includes who they are outside of their student roles. Universitydepartmental systems and programs should be evaluated, enhanced, or put into place forthese students to help support them during their doctoral studies. This could includefamily-friendly policies, child care options, parental support groups, and furthereducating faculty and staff about the unique experiences that these students face while intheir doctoral programs (Lester, 2013)."
http://hdl.handle.net/1957/61886,"Lilacs are a group of ornamental trees and shrubs in the Oleaceae family consisting of 22 to 30 species. There are six series within genus Syringa: Pubescentes, Villosae, Ligustrae, Ligustrina, Pinnatifoliae, and Syringa. Fertility and cross-compatibility among cultivars, species, and series have yet to be formally investigated. Over three years, a cross-compatibility study was performed using elite cultivars and species of shrub-form lilacs in series Syringa, Pubescentes, and Villosae. We report the success of each of these combinations and the fertility estimates of viable crosses. This study is a comprehensive investigation of lilac hybridization, and the knowledge gained on cross-compatibility will aid future efforts in lilac cultivar development.Genome size variation can be used to investigate biodiversity, genome evolution, and taxonomic relationships among related taxa. In addition, plant breeders use genome size variation to identify parents useful for breeding sterile or improved ornamentals. Reports conflict on genome evolution, base chromosome number, and polyploidy in lilac. Flow cytometry was used to estimate holoploid (2C) genome sizes in series, species, cultivars, and seedlings from parents with three ploidy combinations: 2x x 2x, 2x x 3x, and 3x x 2x. Monoploid (1Cx) genome sizes were calculated by dividing 2C genome size by ploidy, which was confirmed in a subset of taxa using root tip microscopy. Pollen diameter was measured toinvestigate the frequency of unreduced gametes in diploids and triploids. Interploid crosses between ‘Blue Skies’ (2x) and ‘President Grévy’ (3x) produced an aneuploid population with variable 2C genome sizes. One viable seedling was recovered from a cross between ‘President Grévy’ (3x) and ‘Sensation’ (2x). This near pentaploid (5x) seedling had a larger 2C genome size than either parent, and the largest 2C genome size currently reported in lilac. Pollen diameter measurements revealed that ‘Sensation’ produced 8.5% unreduced pollen. Increased ploidy may provide a mechanism for recovering seedlings from incompatible taxa in lilac breeding.Common lilac, Syringa vulgaris, is an important flowering shrub that accounts for a large share of spring sales in the U.S. nursery industry. However, little research has focused on shortening generation time for lilac breeders. In a previous cross-compatibility study, observations revealed that first-year hybrid seedlings undergo a quiescent phase of growth, producing few leaves but an extensive root system. This study investigated the effects of six germination and post-germination treatments of green seed and dry, dehisced seed on seed germination and subsequent growth in lilacs. Green seed extracted 20 weeks after pollination had the highest germination rate and an increase in vegetative growth compared to controls. Our results indicate that green seed sowing may provide a new tool for shortening juvenility and reduced breeding time in common lilac.Remontancy (reblooming) and disease resistance are two important traits in the dwarf lilacs (Syringa pubescens). Marker-assisted selection could prove useful at producing more disease-resistant, floriforous lilacs for future breeders. To aid future efforts at at marker discovery, genotyping-by-sequencing was applied to a bi-parental mapping population from S. meyeri ‘Palibin’ x S. pubescens Bloomerang® which varies for remontancy and resistance to bacterial blight. SNP-based genetic linkage maps were created for each parent, and maps will continue to be improved with further sequence data. Future efforts to phenotype the mapping population will be combined with these findings for marker-trait association.Althea (Hibiscus syriacus) is an ornamental shrub prized for its winter hardiness and large colorful summer flowers. Althea are primarily tetraploids (2n = 4x = 80) with higher level polyploids reported from experiments with spindle-fiberinhibitors. Previous studies report anatomical variation among althea polyploids, including changes in stomata size. The purpose of this study was four-fold. The first was to identify genome size and ploidy variation in althea cultivars via flow cytometry and root tip chromosome counts. The second was to create a ploidy series consisting of 4x, 5x, 6x, and 8x cytotypes using a combination of interploid hybridization and autopolyploid induction via colchicine and oryzalin. The third was to investigate the ploidy series for variation in stomatal guard cell length, stomatal density, and copy number of fluorescent rDNA signals. The fourth was to investigate segregation patterns in rDNA signals in a subset of pentaploid seedlings. Results of this study revealed ploidy differences among available cultivars. Polyploid induction and interploid hybridation were successful for producing a ploidy series that varied in stomata size, stomata density, and number of 5S and 45S rDNA signals. The rDNA loci confirmed ploidy levels in each cytotype of our ploidy series, and random segregation of rDNA loci provides evidence of random chromosome segregation in interploid hybrids of althea.Despite its attractive, ornamental flowers, althea produces capsules with numerous, fertile seeds that germinate and cause a nuisance in production and the home landscape. Breeding for sterile forms of althea has long been a goal for Hibiscus breeders, yet many popular “sterile” cultivars have been reported as weedy. The purpose of this study was to evaluate female and male fertility for tetraploid and hexaploid cultivars, and to evaluate the female fertility of pentaploid seedlings resulting from 4x x 6x and 6x x 4x crosses. Self- and cross-incompatibilities were discovered, as was variation in seeds per capsule and seeds per pollination. In addition, significant differences were found among flower forms (single, semi-double, and double) for fertility estimates. Double-flowered forms had reduced female fertility, which may indicate that breeding for increased petaloid stamen may result in a reduction in female fertility. Previously reported sterile taxa were also found to be fertile, including ‘Aphrodite’, ‘Diana’, ‘Helene’ and ‘Minerva’. Two hexaploids, ‘Pink Giant’ and Raspberry Smoothie™, were found to have reduced female fertility compared to tetraploids. Fertility testcrosses of pentaploid seedlings revealed a reduction in fertility compared to controls. The reduction in fertility ofpentaploids will likely lead to new, near sterile cultivars for the nursery industry. The combination of double flowers with pentaploid cytotypes will likely lead to completely sterile cultivars of althea.Although floral traits are most important for breeders of althea, little is known about their segregation patterns. The objectives of this study were to determine segregation patterns in eyespot presence, flower color, and flower form. Over four years, thousands of flowering seedlings were observed representing F1, F2, and backcross families. Based on our results, we propose that eyespot presence is controlled by a single locus and that a recessive allele called spotless results in a complete elimination of color. The gene controlling spotless is likely located upstream in the flavonoid biosynthetic pathway. We also propose that flowers with white to blush-pink petal body color and a red eyespot are controlled by a single recessive allele called geisha. This trait exhibits incomplete dominance and is under epistatic control by spotless. It is likely located downstream in the delphinidin biosynthetic pathway, responsible for lavender, dark pink, and blue pigments. In addition to color segregation, depth of color irrespective of hue (CIE L*) was also investigated (spotless and geisha seedlings removed). The deepest pigments were measured in crosses among hexaploid ‘Pink Giant’, taxa homozygous dominant for geisha, and taxa heterozygous for geisha. Conversely, the lightest pigments were observed in crosses between taxa homozygous recessive for geisha and taxa heterozygous for geisha. Future efforts at eliminating the geisha allele from a breeding population may allow for quantitative improvement in total anthocyanin production. Observations on petal number inheritance revealed that seedlings produced a continuous distribution of petal numbers between the petal numbers of the two parents, with occasional transgressive segregants. The highest average petal numbers were found in seedlings resulting from the cross of double-flowered taxa. Flower size (petal area), varied significantly among cross combinations and flower forms. The largest petals were observed in the seedlings of single-flowered by double-flowered crosses. Concomitant upregulation or expression of genes controlling laminar growth in stamen may not only result in petaloid stamen, but may also result in increased laminar growth in the true petals, resulting in wider,overlapping petals. However, further work must be undertaken to eliminate environmental effects on flower size estimates."
http://hdl.handle.net/1957/61887,"Previous work introduced the GenderMag method, a software inspection method used to help software creators identify features within their software that are not gender-inclusive. Inclusiveness of software (gender or otherwise) matters because supporting diversity matters—it is well-known that the more diverse a group of problem-solvers, the higher the quality of the solution. In this thesis, we investigate the two component parts of GenderMag: the customized cognitive walkthrough and the gendered personas. To investigate the cognitive walkthrough component, we analyze data collected from a field study that explores the experience of teams of software professionals using GenderMag. We pinpoint situations that we term “detours” during which teams were 6 times more likely to make errors on the cognitive walkthrough forms than they did outside of detours. To investigate the personas component, we present a lab study that investigates the tension between gendered personas and inappropriate stereotyping. We explore a new approach to personas: one that includes multiple photos (of males and females) for a single persona. Our results are encouraging about the use of personas with multiple pictures to expand participants’ consideration of multiple genders without reducing their engagement with the persona. Between the two studies, we find answers to the question: How does each component part of GenderMag contribute to (or detract from) its overall goal of helping to identify gender biases in software?"
http://hdl.handle.net/1957/61888,"Small Unmanned Aircraft Systems (sUASs) equipped with optical sensors are capableof remotely sensing landscapes and wildlife at spatial and temporal resolutions that werepreviously inaccessible due to technical and budgetary limitations. Conventional remotesensing and photogrammetric workflows can be applied to the resulting high resolution imageryto facilitate new types of scientific inquiry. This dissertation explores three novel applicationsusing low-cost consumer grade and commercial grade sensors onboard an sUAS.The first application uses a quadcopter equipped with a consumer grade camera to detectSwiss needle cast disease (SNC) in Douglas-fir stands in western Oregon. Swiss needlecast is a non-fatal foliar disease in Douglas-fir that reduces annual growth and stumpagevalue. Conventional detection methods rely on manned aerial detection surveys that aretedious. However, sUAS technologies offer a potential alternative. The presented methodfuses sUAS technology with Structure from Motion, automatic stem segmentation and binomialclassification with generalized additive models. Four 1.6 ha sites containing morethan 3500 Douglas-fir trees were surveyed with a sUAS. Visibly infected trees were distinguishedfrom not visibly infected trees with much greater than random chance (kappa> 0.4) at the four sites surveyed. Near-infrared (NIR) information was not pertinent tosuccessful SNC detection, vastly simplifying the operational complexity of future surveys.The method described in this chapter facilitates mapping of individual Douglas-fir treesinfected with SNC in the mountains of western Oregon.The second application of sUAS technology expands upon the first by adding a narrowbandmultispectral camera (NMC), additional survey sites, and surveys in differentyears and months. The effectiveness of narrowband multispectral cameras for assessingvegetation condition has been heavily researched, but the application to Swiss needle castdetection in an industrial forest has not been previously described. Eight 1.6 ha sites encompassingmore than 6000 trees were surveyed with a consumer grade camera and a NMCin 2015 and 2016. SNC detection reliability tended to be better with the NMC (kappa difference> 0.10) than the consumer grade camera when surveys were conducted in fullysunny conditions, but the differences were negligible in cloudy conditions. Summer imagingwith the NMC yielded highly variable results in comparison to the more stable springsurveys and suggests that summer surveys are not operationally plausible. Detection surveysof the same sites in two different years revealed higher-than-expected levels of diseasestatus change between years. Employing stricter probability thresholds on the classificationrules reduced detected change from > 200 trees site to < 50 trees site at the cost ofcreating a third class of trees having an uncertain disease status. There was no evidencethat foliage retention related to classified diseased status although additional study is recommendeddue to the limited inferential power afforded by the small sample size (n <28). Many regulatory, technical, and computational hurdles must be overcome before largescale implementation of the method can be attempted.The third application uses the integrated camera on a DJI Phantom 3 sUAS to conductphotogrammetric measurements of baleen whale morphology, which is an indication ofwhale health. UAS photogrammetry has been previously explored and shown to produceaccurate measurements, but methods between surveys vary widely, indicating a need forstandardization. We imaged 89 gray and six blue whales with a Phantom 3 sUAS. Whaleswere measured within the images and scaled to metric units using barometric altitude. Linearmixed models with error terms for flight and date were used to to correct scaling error.Post-correction estimates of 1 m calibration object contained 0.17 m less error and 0.25 mless bias than no correction. Total propagated uncertainty analysis was used to examineerror contributions from scaling and image measurement (digitization) to determine thatdigitization accounted for 97% of total variance. Additionally, we present a new body sizemetric termed Body Area Index (BAI). BAI is scale-invariant and is independent of bodylength (R2 = 0:11), enabling robust comparisons of body size within and among populations,and over time. Along with this study we present a three-program analysis suitethat measures baleen whales and applies scale corrections to produce 11 morphometricattributes from UAS imagery. The photogrammetric method presented and associated softwarefacilitate efficient and standardized analysis of any whales that meet the assumptionof a parabolic shape.Environmental remote sensing with sUAS can produce survey data at very high detail(i.e., tree-level) and provide high measurement precision without the use of high-costsensors. However, regulatory limitations within the United States National Airspace combinedwith the low-endurance of most multirotor sUASs limits efficient use to small areas,or one or two whale sightings. sUAS survey data is of such high resolution that data storageand management because burdensome even when survey areas are small. Furthermore,low-cost sUAS systems suffer from reliability challenges and steep learning curves thatcan heavily limit technology accessibility. In spite of the tradeoffs relative to manned surveys,sUAS remote sensing provides researchers with unprecedented access to data of hightemporal and spatial resolution at low costs without putting human lives into the air."
http://hdl.handle.net/1957/61889,"Ornamental landscapes require considerable amounts of inputs, including but not limited to irrigation, mowing or pruning, fertilization, and pest management. However, school systems have limited budgets, which reduce their access to resources and labor hours. Therefore, the objective of this project is to identify ground covers that can compete with weeds and maintain aesthetic quality while under minimal maintenance.  To explore this objective, a field experiment was initiated in May 2015 at Corvallis, OR.  Experimental design was a randomized complete block design with 4 replications. Factors include year (2015 and 2016) and ground cover taxa.  Taxa included 3 turfgrasses (Festuca rubra L. ssp rubra ‘Chantilly’, Festuca rubra L. spp. commutata ‘Longfellow II’, Agrostis tenuis Sibth ‘Puritan’) and 7 forb or shrub plants (Vinca minor ‘Illumination’, Cotoneaster dammeri ‘Coral Beauty’, Euonymus fortunei ‘Kawensis’, Juniperus horizontalis ‘Blue Chip’, Herniaria glabra ‘Green Carpet’, Sedum spurium ‘Tri-Color, and Ceanothus glorious ‘Point Reyes’), which were selected using a school system stakeholder group.  All plots received daily irrigation for the first 4 months and subsequently discontinued in September 2015. Plots are weeded and fertilized (4.88 g nitrogen m-2) once annually.  Results determined that A. tenuis had the highest plant cover (68.1%), followed by F. Rubra ‘Chantilly’ (68.1%) and  F. Rubra ‘Longfellow’ (66%), then S. spurium (24%) and J. horizontalis (22.6%).  The remaining ground covers all provided less than 7% plant cover. A strong inverse correlation between plant ground cover and weed ground cover was identified in both years (R2= 0.978, R2= 0.948)."
http://hdl.handle.net/1957/61890,"Seafood is one of the most diverse and highly traded natural resources worldwide. Widespread evidence of increased seafood fraud and IUU fishing has placed enormous pressure on industry and governments to determine the authenticity, safety, and sustainability of seafood. The recently established US National Ocean Council has addressed several gaps in the patchwork of seafood regulations and policies among US government agencies through new legislative and executive efforts. While many challenges still remain, both mandatory and voluntary adoption of traceability systems in the US and internationally reveal a trend toward increased seafood product traceability and supply chain transparency in seafood systems in the global north. To date, much of the traceability efforts on the seafood industry have been largely focused on downstream firms and policy. To address these gaps, we investigated the current landscape of perspectives from industry professionals across value chains in the largest seafood hub in the United States. Results from background interviews, discussions, and an online questionnaire reveal a general lack of awareness of the Seafood Import Monitoring Program (SIMP), increasing importance of traceability with firm complexity, and an overall positive perception for the effectiveness of traceability to address large pressures and threats to the industry related to traceability. Unique characteristics regarding vertically integrated and larger firms were revealed, and small and upstream firms demonstrate a lack of traceability capacity over other firms. Whether market or regulatory driven, 92% of respondents to questionnaire agree or strongly agree that traceability is “here to stay.”  Given concerns of social, economic, and ecological sustainability, demand for seafood product information will likely continue to increase in seafood systems worldwide."
http://hdl.handle.net/1957/61891,"Additive manufacturing and 3D printing have become household names as both hobbyistsand industrial manufacturers utilize fast, inexpensive prototyping and production of functionalparts. Additive manufacturing is being revolutionized with 3D printers such as theMulti Jet Fusion 3D from HP, Inc., where each volume pixel, or voxel, can be independentlyfunctionalized. Voxel-by-voxel printing allows each voxel to be printed with characteristicsthat are independent from its neighbor, producing gradients in color, elasticity, surfaceproperties, strength, and higher-order functionality. Voxel-level functionality enables forproduction of high-value-added, highly customizable parts. The potential for higher-orderfunctionality (e.g., anisotropic material properties) revolutionizes 3D printed parts from beingconfined by material properties to being driven by the ability to vary material propertieswithin the printed part. Novel inks are currently being developed that provide functionalitywith the addition of inclusions, such as magnetic disks.Two common problems that are experienced while functionalizing inks with magneticdisk inclusions are sedimentation and chaining. Studying the timescales that are associatedwith particle sedimentation, orientation, and translation during the printing processpresents the need for development of a fluid that prevents sedimentation and translationwhile allowing for particle orientation. Characteristic flow behavior of non-Newtonian fluidsexhibit a range of performance regimes with their ability to suspend particles at rest whilealso allowing for inkjet ejection. Fluids that exhibit a yield stress, the specific stress thatmust be applied to achieve flow, have been shown to assist in preventing particle sedimentation.Weak yield stress fluids (xanthan gum T622 and gellan gum CG-HA, CP Kelco)were characterized using rotational rheometry to correlate bulk rheological behavior withphenomena that is exhibited in particle-orientation and particle-sedimentation experiments.A protocol to easily identify yield stress in a low-viscosity, high-molecular-weight fluid wasdeveloped. Effects of polymer concentration on the yield stress was examined. Standardrheological characterization under steady shear and small-amplitude-oscillatory shear is alsoreported. Finally, this work provides a proof-of-concept for utilizing a fluid with a weak yieldstress that prevents sedimentation and translation during directed alignment of magneticparticles in a rotating magnetic field. Magnetic particles with a random orientation distributionwere successfully aligned and uniformly oriented, without translation, to maintaincenter-of-mass particle distribution within the fluid."
http://hdl.handle.net/1957/61892,"Fluorescence has proven to be a robust and powerful method of analysis in numerous fields: forensics, pharmaceutics, geology, food science, and environmental sciences have all developed a large collection of fluorescence instruments and methods to overcome application-specific challenges. Biological applications saw the same development of a fluorescence toolkit with methods capable of multiplexing, in vivo sensing, or surpassing the diffraction limit. Using these new technologies, a new biomarker – microRNA (miRNA) – emerged as playing an important role in post- transcriptional gene regulation. Since then, miRNA have closely studied as early indicators of cellular diseases such as cancer. However, the several miRNA will need to be monitored if any useful information about how gene expression and cancer progression are related. This research is two-fold: 1) characterize the signal generation quenching by a biosensor developed in the Burrows group, and 2) reduce spectral cross-talk to increase the number of available colors for analysis.The development of sensitive, selective, and robust miRNA biosensors is a principle objective of the Burrows group. Our current understanding is that over- or under- expression of certain miRNA are indicative of the current state of a cell’s gene expression. However, most in situ miRNA detection methods are complicated by false signals arising from sensor degradation, off-analyte binding, and poor spatiotemporalresolution. The Burrows group initially developed a ‘Reporter+Probe Complex’ (R+P) miRNA biosensor that reduced degradation and off analyte binding. Chapter 2. of this dissertation focuses on the differences in analytical figures of merit when the using this biosensor in two opposing detection mechanisms: Signal generation vs. signal quenching. It was found that signal generation is slightly more sensitive, but the (R+P) biosensor (a signal quencher) had less off-analyte binding than the current ‘standard’ signal generation method, molecular beacons (MB). Furthermore, the comparison of theoretical thermodynamic (∆G) and equilibrium (K) values to experimental limits of detection (LOD) showed that the LOD could be further lowered by lowering the initial reporter and probe concentrations. However, there is a lower limit, as too dilute will eventually reduce the binding and total signal generated.Chapters 3. and 4. will discuss the development of an in silico prediction model and in situ experimental system that work together to reduce spectral cross-talk from samples with several co-localized fluorophores (dyes). CLEER (CoLocalized Excitation Emission Resolution) uses a custom MATLAB script to compare excitation-emission matrices (EEM) of dyes and generate a set of Dye-Specific Excitation Emission Coordinates (DyeSEECs). These coordinates are dye-specific excitation and emission wavelengths that are tuned in situ with a tunable ultra-fast laser and novel continuous variable filters (CVF). This research will show how some DyeSEECs are very effective at reducing cross-talk, while other DyeSEECs fail at this goal. The conclusion of this work will demonstrate how the fluorescent peak shape and emission filter cut-off profile play an important role in peak position accuracy, and how that eventually affects the spectral cross-talk."
http://hdl.handle.net/1957/61893,"The hydrologic function of a landscape is an important concept for understanding the presence, movement and availability of water. The Camp Creek Paired Watershed Study (CCPWS) site in Central Oregon has been utilized to investigate the impacts of western juniper on watershed hydrologic function since 1993. The research presented here builds upon the work done at the CCPWS to further investigate the hydrologic connections and gain a better understanding of the underlying hydrogeologic system in and surrounding the CCPWS site.This thesis is organized into two chapters. Each chapter is an individual manuscript detailing a portion of the overall study. The overarching goal of both chapters was to increase the base of understanding of surface water and groundwater interactions, subsurface hydrologic connections and the understanding of the role of local hydrogeology in a semiarid system in central Oregon. Both chapters are being prepared for journal submission.Hydrologic connectivity is the flow of surface water and subsurface water throughout a landscape [1] and is important for a wide variety of ecosystem services. Most investigations of hydrologic connectivity have focused on forested environments and more humid settings. This study investigated subsurface hydrologic connectivity in a semiarid rangeland system.Chapter one discusses the movement of both surface and subsurface water within the CCPWS and characterizes the temporary hydrologic connections present and looks at the impact of vegetation canopy cover on those connections. The objectives of this study were to 1) assess surface water and groundwater interactions in one watershed with juniper and one with juniper removed; and, 2) characterize the hydrologic connectivity of upland watersheds and the riparian valley below them.The hydrogeologic framework of an area describes the structure and properties of a groundwater system. This framework helps us to understand the way water moves through the subsurface and its availability for human and ecosystem needs. A wide-ranging study of groundwater system of the Upper Deschutes Basin was completed in 2002 [2]. However, the southeastern portion of the basin was left out of the larger basin wide study and many of the finer details of the system were not captured at this coarse scale. A better understanding of the hydrogeology in the area surrounding the CCPWS helps to place the more than 20 years of hydrologic research at this site into a proper context for further research and application.Chapter two describes the local hydrogeology of a region of interest in the southeast portion of the Upper Deschutes Basin. A combination of field data collection and synthesis of existing hydrogeologic data were used for this study. Study objectives were to 1) characterize the hydrogeologic framework of an area of interest surrounding the CCPWS; and, 2) evaluate mechanisms of shallow aquifer recharge and discharge at the CCPWS."
http://hdl.handle.net/1957/61894,"The Mars Hopper is an alternative extraterrestrial vehicle for the collection of samples from the Martian surface. This thesis studied the engine of the Mars Hopper to assess the validity of the current planned launch cycle according to current parameters. To do this, the engine was simplified to an average 1 16th channel of the Mars Hopper Engine. Using StarCCM+, a computational fluid dynamics software package, the physics of the channel was analyzed. As the beryllium thermal capacitor transfers energy to the carbon dioxide propellant, an initial start-up effect is observed over the first half a second. After the first half a second the velocity, pressure and temperature profiles show a linear decrease. Extrapolating the results, it appears the hopper will have useful thrust for 13.6 seconds. This is 6.4 seconds less than initial calculations conducted. Thus, the launch range expectations will need to be revised to account for the drop in overall flight time."
http://hdl.handle.net/1957/61895,"Research into the effect of automation on human multitasking performance is primarily focused on Decision Automation (a machine suggesting a certain course of action for a human operator to take) and Action Automation (a machine carrying out a certain course of action on behalf of the human operator) while Acquisition Automation (a machine provides assistance which helps a human operator in sensing information) and Analysis Automation (a machine provides information predicting the future state of a system) have been acknowledged as types of automation but largely ignored. The inclusion of the former in systems which require human multitasking is beneficial, while the effects of the latter are unclear. In order to determine said effects a study was conducted using a low fidelity simulation of a multitasking system with No Automation, Acquisition Automation, and Analysis Automation states, as well as failure states for those systems with automation included. Results show no statistically significant difference in performance between systems with the automation enabled versus those with the automation in a failed state, nor was there any statistically significant difference between the performance of groups with no automation present and those with automation present (in both active and failed states)."
http://hdl.handle.net/1957/61896,"Dynamic modeling is key to the successful operation and reliability of electrical grids by evaluating transient stability. Developing dynamic load models and identifying where they are necessary is a challenging task as loads are an aggregation of individual devices that change throughout the year. This thesis investigates how to develop those load models and provides preliminary guidelines for where to prioritize placement of dynamic load models in the system. A case study in Nome, Alaska is performed on developing a dynamic load model for their microgrid. Electricity cost in Alaska's rural communities reaches up to five times higher than the national average. Theses rural communities' microgrids are powered primarily by diesel generators causing high electricity costs. This thesis examines the community of Nome, Alaska which has installed wind turbines to combat their dependency on diesel. Intermittent generation from the wind turbines can compromise the grid's resiliency and reliability. Dynamic modeling and reliability analysis are necessary to analyze possible solutions for stabilizing the grid. Adequate fidelity for the load model is necessary to perform dynamic simulations. A static ZIP load model and composite load model are created in this paper and are compared for improved modelling. Additionally, this load benchmark is used to evaluate the integration of an energy storage device to Nome's microgrid for improved transient stability. Using the composite load model in the microgrid model, a battery is modeled using the PSS E CBEST energy storage model, demonstrating the transient stability improvement provided by installing an energy storage device to the grid. Any microgrid utility, such as in Nome, Alaska, can adapt and use this load model development process depending on available computation resources and necessary data resolution for a particular generation and demand portfolio."
http://hdl.handle.net/1957/61897,"Several frequency and amplitude estimation algorithms are presented for balanced and unbalanced three-phase power grid systems. All the estimators are dynamic in nature and are implemented in the complex domain by transforming the three-phase power signals using Clarke’s transform. Specifically, we first construct a non-linear dynamic model of the complex representation of the three-phase voltage (fundamental frequency components and harmonics) and then we use the unscented Kalman filter to estimate both the magnitude and the fundamental frequency and its harmonics. The performance evaluation of the algorithm shows the accurate tracking accuracy and convergence time when the frequency and amplitude of the grid voltage waveform change continuously or abruptly. Comprehensive simulations are implemented for both balanced and unbalanced conditions based on the real-world power grid system data. Specifically, 4 types of input amplitudes and 2 types of frequency changes are applied to test estimation algorithm performance."
http://hdl.handle.net/1957/61898,"Organizations are significantly influenced by corporate cultures of the interacting organizations. Both the construction industry and engineered wood products (EWP) manufacturing industry are generally known for operating in a traditional environment maintaining conservative corporate cultures, which can create friction when they try to interact with a more liberal architectural industry or the specifiers. This study assesses the cultural disparities and communication barriers between specifiers and EWP manufacturers in the Pacific Northwest, obtaining perceptive accounts of each other. The study follows a semi-structured interview protocol to decipher the cultures of companies and professionals from the two industries. The identified cultural characteristics are supported by responses to a questionnaire administered to executive members of each organization being studied. The responses are qualitatively analyzed and consolidated to identify specific patterns of organizational behavior. The study identifies a number of factors that affect the interaction between specifiers and manufacturers, chief among which, is the presence of material distributors as the intermediate party that facilitate the material sourcing process for a project. Many factors are tied to the reason why it is challenging to change from the currentbusiness practices. Low profit margins, lack of engineering and design competency, risk averseness and failure to create direct communication channels with architects are some of the reasons that challenge the manufacturing sector. In addition, learning disparities between the two sectors, the deficit of contemporary EWP knowledge creation and intense competition among manufacturers for EWP market share create difficulties for specifiers to use new EWP products in projects. Consolidated collective organizational behavioral knowledge of this study will benefit EWP manufacturers, specifiers and policy makers alike to close up the gap in communication and improve the cultural compatibility between these two members of the construction value chain."
http://hdl.handle.net/1957/61899,"Physical experimentation in various scientific and engineering areas continues to be a useful and often necessary approach that is applied in research, development, and for general problem solving. The experimental design process however, is iterative and often involves trial and error. Alternative designs are proposed and evaluated on cost and time requirements. They are also evaluated with respect to various statistical criteria such as statistical power for detecting effects if they exist. Selected experimental design alternatives then continue the design process and undergo additional modifications until the objectives of the experiment appear to be met, or are met as closely as time and cost constraints permit. The objective of this research is to develop a methodology for “Optimal Experimental System Design” where cost and time are integrated with experimental design selection so that optimal cost and time feasible experimental designs can be explored computationally."
http://hdl.handle.net/1957/61900,"Tropical peatlands play an important role in global climate system by storing an immense of carbon that had been accumulated over thousands of years. Peatlands provide another important ecosystem service by regulating the hydrology. It is believed that peatlands act like a giant sponge by absorbing substantial amounts of water in wet season and gradually releasing the water in the following dry season. Nonetheless, there is a lack of information about the hydrological processes that occur in tropical peatlands, especially the effects of land cover change on peat and peat hydraulic properties. In this study, I conducted field surveys to evaluate two main peat hydraulic properties: saturated hydraulic conductivity (Ks) and moisture retention characteristics at different land cover types in tropical peatlands of West Kalimantan, Indonesia. I also explored the potential of ground penetrating radar (GPR) to determine peat properties in tropical peatlands.      Across all sites, Ks varied over four orders of magnitude with depth (ca 0.001 – 13.9 m d-1). The saturated hydraulic conductivity in forested sites at the depth of 50-100 cm (1.08 ± 0.39 m day-1) was significantly higher than Ks at deeper layers. In addition, Ks at the upper layer of forested sites was significantly higher than Ks at the same depth in other land cover types, i.e., recently burned forests, seral community, and oil palm plantation. The best-approximating hierarchical model for estimating Ks included depth, forest cover, a depth and forest cover interaction, and the von Post degree of decomposition. There was no evidence that Ks was related to other peat physical and chemical properties.The peat moisture retention characteristics presented in the van Genuchten (VG) model indicated that bulk density was strongly and negatively related to the α parameter and there was no evidence that peat properties were strongly related to the m shape parameter of VG model. The proportion of macro-porosity in the drained sites with the distance < 50 m from canal was less than those the drained- seral sites > 50 m from canal and forested sites. Peat pore distribution (i.e., the proportion of macro-, meso- and micro-porosity) also was strongly related to bulk density.The GPR results indicated that dielectric varied from 5.8 to 84.9 across all sites and were significantly lower at the 50-100 cm depth than those measured at 300- 400 cm and 500-600 cm. Parameter estimates from hierarchical models indicated that ash content and carbon concentration were strongly positively related to dielectric and the relationship varied among sites.My results suggest that tropical peatlands provide essential environmental services by storing huge amounts of water. We estimated that the potential amount of water that can be stored by undrained peat swamp forests in Borneo, Sumatra, and Peninsular Malaysia was about 51.1 – 52.5 km3 of freshwater. However, the tropical peatlands release water relatively easily when the water table is lowered since it is mostly composed by macro-porosity. Therefore, maintaining the water table close to the peat surface is crucial to prevent water loss from peat. My results also suggest that GPR can be useful for mapping peatland distribution, providing estimates of peat depth and insights into its properties. However, the manual coring is still needed to improve the accuracy and quality of peat property measurement data."
http://hdl.handle.net/1957/61901,"Forest managers are challenged to restore resilience to forests with an elevated risk of stand-replacing fire by using mechanical thinning and prescribed fire. Implementation of these methods can be constrained by mandates to conserve sensitive wildlife species like the Pacific marten (Martes caurina). Martens avoid simplified forest stands created by these fuel reduction treatments, and populations in the northern Sierra Nevada and southern Cascades are already fragmented. Implementing fuel reduction treatments may therefore threaten forest-dependent species like the Pacific marten by reducing available habitat and habitat connectivity.A crucial question is whether reserving marten habitat from fuel treatment results in an elevated probability of large, intense wildfires compared to permitting treatment in these areas. I used a simulation framework to compare the potential for large fires when fuel treatments were implemented with and without marten habitat reserves, defined as areas where all treatment was prohibited. I also assessed wildfire risk to the dense, high elevation forests typical of marten habitat. I simulated fuel treatments in three watersheds (mean area: ~8,000 ha) and then used randomly-placed ignitions to measure each watershed’s capacity for fire spread. For each watershed, I varied the amount of area treated (10%, 20%, and 30% of the watershed) and the type of marten reserve (none; partial, where some marten habitat was reserved; and complete, where all marten habitat was reserved). I further expanded my simulations to a larger study area (~50,000 ha) to provide a complementary depiction of the relationship between habitat reserves and fuel treatment efficacy at the landscape scale.Prohibiting fuel treatment within marten habitat had no significant effect on the ability of treatments to control the spread of fire. I observed an increase in the capacity for fire spread only in one instance, when the most restrictive reserve strategy reduced the total area eligible for treatment below the target 30%, the most ambitious treatment scenario. These results are optimistic for managers— effective fuels management was possible with simultaneous retention of large blocks of marten habitat. In contrast, wildlife risk to marten habitat increased when fuel reduction treatments were allowed only outside of predicted habitat areas. My simulations provide evidence that allowing some fuel treatment in the margins of predicted habitat could largely eliminate this increased risk, without incursion into core areas where martens are most likely to reside. Silvicultural prescriptions that can retain canopy cover and elements of old forest structure, while also increasing resilience to fire, would be preferable for reducing wildfire risk while mitigating the short-term effects of management action in these areas."
http://hdl.handle.net/1957/61902,"Outflowing streams of matter or jets are a common phenomenon in the observeduniverse. The most extreme and powerful jets are relativistic, i.e., they travel at speedscomparable to the of speed light. Gamma Ray-Bursts (GRBs) and Active Galactic Nuclei(AGNs) are two sources of these relativistic jets. In this work I will explore the role playedby advected radiation   the radiation internal to the jet itself   in modifying the jetdynamics and creating the observed radiation spectrum. First, I present a Monte Carlocode designed to simulate the spectrum formed in a scattering dominated photon-leptonplasma. I demonstrate that non-thermal features in the emitted spectrum can arisefrom the interaction of thermal populations of photons and leptons, initially at differenttemperatures. I find the existence of a correlation between the spectral parametersthat suggests the presence of this mechanism in cosmic sources, for example, in promptspectra of GRBs. These simulations, however, do not account for the dynamical couplingbetween the radiation and matter within the jet, which is expected for outflows from bothGRBs and AGNs. In the second part of this dissertation, I show how radiation regulatesthe dynamical properties (such as structure, acceleration) of jets. I use a custom-madedynamic Monte Carlo code to study radiation (Compton scattering) driven expansionand acceleration in unexplored evolutionary stages of GRB jets. My results uncover newregimes of jet evolution and allow me to obtain analytical estimates to better parameterizethe jet dynamics in analytical and semi-analytical studies. In addition, I explore radiativeacceleration and deceleration as mechanisms to produce two-component structured AGNjets. I find that this radiation-driven regulatory mechanism plays a crucial role inexplaining the puzzling observation of high-energy emission from misaligned AGN jets."
http://hdl.handle.net/1957/61903,"Traditional faculty development programs aimed at disseminating research-based pedagogy and innovations at potential adopters have helped increase awareness of these innovations; however, their adoption into engineering classrooms has been limited. This paper aims to present an alternative, pull-oriented approach to faculty development where faculty participants co-develop curricular innovations with engineering education researchers aimed at engaging engineering students in mechanics of materials. In this pull-oriented approach, faculty have greater influence, or pull, over the innovation development process, their adoption decision making, and the resources provided for them with the goal that this approach will lead to adoption of more engaging teaching practices in the engineering classroom.  The purpose of this research is to describe how faculty participants interpret such an approach and how their contexts influence their adoption decision making. Multiple, descriptive-explanatory case studies were constructed from interviews with faculty during their adoption process and were evaluated using a constructivist framework. Findings from these case studies indicate that faculty development programs can be improved by empowering faculty in the innovation development and adoption process, engaging faculty throughout the entire adoption process, ensuring faculty have adequate resources for their adoption goals, and accommodating the unique contexts that faculty operate in. Additional findings seem to indicate that course-specific faculty development and multi-year faculty development programs are also beneficial for initiating dissemination and sustaining adoption efforts."
http://hdl.handle.net/1957/61904,"In the light of the changing climate, the importance of designing effective watershed management plans that are likely to be implemented is becoming ever more important.  This research introduces a new concept, consensus, for incorporation into stakeholder-guided interactive optimization of watershed management plans.  User preferences were mathematically simulated based upon scenarios of possible stakeholder attitudes in sub-basins of an agricultural watershed in Indiana, USA, and incorporated into an existing interactive genetic algorithm (GA) framework.  These simulated users along with the watershed hydrologic model were used to evaluate overall preference for and performance of hundreds of different possible distributions of wetlands throughout the Eagle Creek Watershed, weighing cost and environmental concerns on and off of their property.  Solutions generated using the interactive GA with the consensus measure performed at least as well as the non-interactively generated baseline solutions, and many out-performed the baseline solutions, with higher peak flow reductions for similar total wetland areas.  This result is opposite of what was expected.  Previous research has characterized adding stakeholders to the optimization process as a “tradeoff” process, where users sacrifice performance for certain intangible factors.  In addition to adding a consensus measure to the interactive GA as an additional objective function, this research also developed a method to select short climate model realizations that best represent extreme flow events arising from climate extremes in the projected future.  When the interactively and non-interactively generated solutions were subjected to these extreme climate years, their performance was reduced, even when adjusted for the different magnitudes of expected maximum peak flows.  Data issues arising from an interruption to the interactive optimization at generation 30 likely led to some irregularities in the results of this research.  Nevertheless, it appears that designing watershed management plans that perform well in the present does not necessarily lead to strong performance in the projected future.  Any attempts to address climate change in management plans must do so explicitly."
http://hdl.handle.net/1957/61905,"The need to detect trace amounts of target molecules is great, particularly when it comes to biosensing.  With the early detection of a disease, the odds of the successful treatment of an individual increases significantly.  To enhance the capability of biomolecular detection, we have created an optical biosensor capable of the enhancement of multi-modal optical signals.  Our substrate employs diatoms, a type of algae, with unique optical properties to achieve multi-modal enhancement.  Diatom shells, called frustules, are made of biosilica with quasi-periodic pores.  These frustules exhibit a very large surface area which allows for a large area of interaction for analytes.  Additionally, the porous structure of the frustule acts as a photonic crystal capable of enhancing optical signals.  Here we demonstrate the multi-modal enhancement capabilities of our biosensor through the detection of biological analytes using colorimetric shifts, surface enhanced Raman scattering and fluorescence biosensing."
http://hdl.handle.net/1957/61906,"This project examines the production histories of two films that Alfred Hitchcock directed, his Hollywood debut Rebecca (1940) and the memorable Psycho (1960). The first chapter explores how Hitchcock succeeded and failed at influencing the picture as he, despite directing the movie, had to follow the vision that his producer, David O. Selznick, wanted for their adaptation of the bestselling Daphne du Maurier novel. The chapter considers their relationship at each stage of the process of making Rebecca, and places the roles of Hitchcock and Selznick within the larger context of the American film industry during 1940. The second chapter considers how Hitchcock, as an established director and formidable celebrity twenty years later, created an innovative film with Psycho that resonated with its audience. It explores how he adapted the Robert Bloch novel as he, now acting as his own producer, saw fit, and how the marketing campaign that he and Paramount devised turned the low-budget shocker into a highly profitable spectacle. Ultimately, this project offers a way to examine Hitchcock’s career with films he directed both before and after he became a well-known Hollywood director."
http://hdl.handle.net/1957/61907,"In shared autonomy, a robot and human user both have some level of control in order to achieve a shared goal. Choosing the balance of control given to the user and the robot can be a challenging problem since different users have different preferences and vary in skill levels when operating a robot. We propose using a novel formulation of Partially Observable Markov Decision Processes (POMDPs) to represent a model of the user's expertise in controlling the robot. The POMDP uses observations from the user's actions and from the environment to update the belief of the user's skill and chooses a level of control between the robot and the user. The level of control given between the user and the robot is encapsulated in macro-action controllers. The macro-action controllers encompass varying levels of robot autonomy and reduce the space of the POMDP, removing the need to plan over separate actions. As part of this research, we ran two users study, developed a method to automatically generate macro-action controller values, and applied our user expertise model to provide shared autonomy on a semi-autonomous underwater vehicle. In our first user study, we tested our user expertise model in a robot driving simulation. Users drove a simulated robot through an obstacle-filled map while the POMDP model chose appropriate macro-action controllers based on the belief state of the user's skill level. The results of the user study showed that our model can encapsulate user skill levels. The results also showed that using the controller with greater robot autonomy helped users of low skill avoid obstacles more than it helped users of high skill. We designed a controller value synthesis method to generate the variables that control the levels of autonomy in the macro-action controllers. We found differences in how the users drive the robot using a decision tree generated from the data recorded in the first user study, and we used these differences to program simulated user ``bots'' that mimic users of different skill levels. The ``bots'' were used to test a range of variables for the controllers, and the controller variables were found from minimizing obstacles hit, time to complete maps, and total distance driven from the simulated data.For our second user study, we looked at users' satisfaction without robot autonomy, with the highest amount of autonomy, and with the autonomy chosen by our expertise model. We found users we classified as beginners ranked the autonomy more favorably than those ranked as experts. We implemented our expertise model on a Seabotix vLBV300 underwater vehicle and ran a trial off the coast of Newport, Oregon. During our trials, we recorded a user driving the vehicle to predetermined waypoints. When beginner actions were performed, the user expertise model provided an increased level of autonomy which either increased throttle when far from waypoints or decreased throttle when close to waypoints. This demonstrated an implementation of our algorithm on existing robot hardware in the field."
http://hdl.handle.net/1957/61908,"Shrapnel is an exploration through memory. It’s a work that bends and twists upon itself and, as memory often does, lands within worlds and experiences only for a moment before jumping to the next story or thought. This text is a hybrid work that doesn’t fit neatly within any specific genre confines: it’s too poetic to be categorized as traditional narrative but also too story- driven to be categorized as poetry. When you read Shrapnel you’ll discover worlds that—for better or worse—have been home to me throughout my life. In this work I address the associative way that memory often operates. I write of my military experiences in Afghanistan as well as my interactions with my drug-addled and alcohol-ridden family members. It’s not a pretty work, it can be quite dark at times. But it’s me: exposed. It’s my life: in whatever pieces that it exists. All these scattered bits."
http://hdl.handle.net/1957/61909,"Denitrifying bioreactors are an edge-of-field treatment technology particularly well suited for nitrate removal from subsurface (tile) drainage effluent of agricultural lands. The effectiveness of a proposed denitrifying bioreactor is site-specific and depends upon the complicated interplay of field and environmental parameters controlling discharge events, nitrate concentrations, subsurface temperatures, dissolved oxygen levels, pH levels, and the relative timing of each. Furthermore, denitrifying bioreactors will perform poorly still at sites well suited to their incorporation if they are not designed and operated using appropriate parameters for the drainage discharge and nitrate levels they intercept. This thesis discusses an automated workflow for the assisted creation and calibration of subsurface drainage simulations appropriate for use in planning the construction and operation of denitrifying bioreactors. The workflow was designed such that users of flexible backgrounds may 1) quickly build first-guess feasibility simulations for denitrifying bioreactor performance at a given site, 2) Calibrate the first-guess simulations using measurements of discharge and nitrate concentration until satisfied with the simulation performance, and 3) proceed to determine efficient design and operation parameters for a denitrifying bioreactor using the results of the calibrated simulation. To demonstrate and test the automated workflow concept, it was used to create simulations for four fields in the Oregon Willamette Valley. Results of the first guess feasibility simulations, 12-point calibrated simulations, and 20-point calibrated simulations were compared with measurements of tile drainage and nitrate concentrations collected in a previous study."
http://hdl.handle.net/1957/61910,"Arbuscular mycorrhizal fungi (AMF) may exert profound influences on ecosystem resilience and invasion resistance in western North American sagebrush steppe and other arid rangeland plant communities. Maintenance of plant community structure through ecological feedbacks such as facilitation of nutrient cycling and uptake by host plants, physical and chemical contributions to soil structural stability, and mediation of plant competition suggest AMF may act as keystone facilitators in stressful arid environments. A review of the existing scientific literature highlights the relevance to AMF in sagebrush steppe rangelands, with specific focus on impacts of land management, disturbance, and invasion on AMF communities. A mycologically-based approach to invasive plant management is proposed, based on an example root AMF analysis of the native perennial bunchgrass Pseudoroegneria spicata and the exotic invasive annual grass Taeniatherum caput-medusae along an invasion gradient in eastern Oregon. This example demonstrates AMF colonization of the foundation bunchgrass species and limited colonization of the annual grass, at least in the sitestudied. Taeniatherum caput-medusae may effect colonization rates of dark septate endophytes in the roots of neighboring P. spicata, although direction of influence varied between years. Hypothesis testing of possible effects of T. caput-medusae on soil structure and function was explored, finding correlations between increasing invasive plant cover, and increased soil moisture levels during periods of high soil moisture (i.e. April). During drought periods a relationship was only visible on one of three research hills, with increased invasive cover correlating with decreases in soil moisture percentage. Influences of soil texture on site invasibility is discussed, along with possible long term effects of a thatch-forming invasive annual grass with limited mycorrhizal colonization, and recommendations are made for future research."
http://hdl.handle.net/1957/61911,"This dissertation is divided into two major chapters. The first chapter covers the geologyof the Encuentro deposit with emphasis in the intrusion sequence, vein mineral assemblages and distribution, and age of mineralization. The data used for this section includes field mapping, petrography, elemental analysis of biotite, and isotopic geochronology. The second chapter focuses on the pressure-temperature evolution of the magmatic-hydrothermal system at Encuentro and reconstruction of the evolution path for the mineralizing fluids. The basis of this chapter is the application of different geothermometers in both porphyry dikes and different veins present in the deposit.The Encuentro porphyry Cu-Au-Mo deposit is part of the middle Eocene to early Oligocene porphyry copper belt of northern Chile. New core logging observations, together with geologically constrained U-Pb and Re-Os geochronology documents the intrusion sequence and the timing of Cu-Au and Cu-Mo mineralization. A sequence of five porphyry dikes (Eep-1 to Eep-5) of dacitic composition is synchronous with and genetically related to mineralization. The Encuentro porphyry Cu-bearing dikes span from 42.3 ± 0.7 Ma to 41.2 ± 0.6 Ma, based on U-Pb zircon ages via LA-ICP-MS. The earliest intrusion (Eep-1) contains the highest Cu and Au grades; the metal content decreases systematically from oldest to youngest porphyry intrusions. Each porphyry intrusion developed a similar sequence of veins: (1) biotite, (2) early dark micaceous halos (EDM), and (3) a series of A-type quartz-K-feldspar-anhydrite veins (A1 to A5). In each sequence, biotite veins and EDM halos are cut by A-quartz veins. Cu-bearing sulfides are present in all these veins; however, A-type quartz veins contribute most of the Cu-Au and are the most voluminous vein type in the deposit (up to 56 vol.%, averaging 5 vol.% in rocks with >0.3 wt.% Cu). A-type veins are most abundant within and surrounding the upper parts of the porphyry dikes, and displays a concentric distribution in which the volume % of A-type veins is well-correlated with the Cu and Au ore grade.Other veins that are also stable with K-silicate alteration, include the vein sequence (4) B- type quartz-chalcopyrite±molybdenite, (5) quartz-anhydrite-molybdenite ± Cu-sulfides (QAM), and (6) magnetite±chalcopyrite veins. These veins postdate all porphyry intrusions, and offset all earlier biotite veins, EDM halos, and A-quartz veins. QAM veins and to a lesser extent B-type veins contribute the bulk of molybdenum mineralization in the deposit. Four Re-Os ages of molybdenite in different veins types range from 41.3 ± 0.2 Ma to 40.9 ± 0.2 Ma. These dates are consistent with crosscutting vein relationships and also with the 41.2 Ma age of the youngest porphyry (Eep-5) that B-type veins and QAM veins cut. Hence, most of the Mo mineralization likely occurred as a protracted single event immediately following the emplacement of porphyry phase Eep-5.Late veins include the sequence (7) chalcopyrite-pyrite±sericite veins, (8) chlorite- sericite-chalcopyrite±pyrite veins, and (9) D-type sericite-pyrite±chalcopyrite veins, and are all part of the sericitic alteration event. They show a zonal arrangement, where chalcopyrite-pyrite veins are dominant in the core of the deposit and are outwardly surrounded by chlorite-sericite veins, which are surrounded by D-type sericite-pyrite veins occupying the most distal parts of the system. The spatial distribution and similar mineral assemblages suggest that these three types of veins were likely originated from the same fluid. Changes in mineral ratios and development of wider quartz-sericite selvages towards distal areas were caused by a decrease in pH, as a consequence of cooling and acid dissociation. An Ar-Ar plateau age of muscovite in a D-type vein of 41.26 ± 0.15 Ma, suggests that Mo deposition and sericitic alteration took place in a short period of time. A late hydrothermal breccia with a tourmaline matrix, which is associated with the youngest (10) tourmaline-pyrite±chalcopyrite veins, was emplaced in the eastern part of the deposit. The crosscutting relationships and an Ar-Ar plateau age of tourmaline of 40.62±0.43 Ma indicate that these veins are the youngest manifestation of magmatic-hydrothermal activity at Encuentro.The thermal evolution of the magmatic-hydrothermal system was estimated by the application of different geothermometers such as: Ti-in-zircon, Ti-in-quartz, and Ti-in-biotite thermometers in Encuentro porphyry dikes; and by combining fluid inclusion microthermometry, Ti-in-quartz, and SEM-cathodoluminisecence in the different vein types present at Encuentro. These results suggest that Encuentro porphyry dikes crystallized at temperatures between 650°- 770°C and emanated from a concealed magma chamber located at ~6 km depth and lithostatic pressure of 1.8 kb. At least five cycles of porphyry magma injection are recognized. These dikes are associated with exsolved magmatic-hydrothermal fluids that mostly cooled and depressurizedbelow the brine-vapor solvus, and formed biotite veinlets, EDM halos, and A-type veins at temperatures between 550° and 700°C and pressures of 0.5-0.7 kb equivalent to depths of 1.8 to 2.5 km under lithostatic pressure. These are the P-T conditions under which most of the Cu-Au mineralization occurred at Encuentro. Subsequent batches of fluid up-flow from the concealed magma chamber continued, followed similar evolutionary paths in the two-phase brine-vapor field, and precipitated veins at similar but slightly cooler temperatures. B-type veins formed at similar conditions to A veins, between 540°-670°C and 0.4-0.7 kb; whereas quartz-anhydrite- molybdenite (QAM) veins formed at 540°-620°C and pressures of ~0.4 kb, both under lithostatic pressures. Later fluid input, likely from a deeper magma reservoir, reached the ore zone with higher acidity and lower temperatures than earlier batches, and therefore formed veins stable with sericitic alteration under hydrostatic pressure conditions. Indirectly estimated temperatures for D- veins are about 450°C, with pressures of 0.25-0.35 kb at conditions intermediate between lithostatic and hydrostatic pressures. Finally, the last magmatic-hydrothermal fluid released remained as a single-phase fluid without brine-vapor separation, and triggered the formation of tourmaline breccias and veins along the eastern flank of Encuentro at temperatures between 350° and 450°C and hydrostatic pressures of 0.15-0.3 kb. This data suggest that Encuentro porphyry deposit formed at relatively high-temperature and shallow depths (~2 km)."
http://hdl.handle.net/1957/61912,"Bicyclists are one of the highest and most vulnerable road users. This is due to the higher likelihood of being seriously injured when involved in a crash. This research seeks to understand two different behavioral interactions of an implemented facility user: the motorist (secondary user) and bicyclist (primary user). The resulting model is for road segments only and does not include intersections. For the bicyclists behavior this research attempts to understand the use of available buffered bicycle lane; a bicyclists’ sway (or side to side movement) within a buffered bicycle lane; the passing of another bicyclist; and the behavior of vehicles adjacent to the travel lanes under different operating conditions of traffic densities, speeds, and facility design. For the motorist behavior, the research is seeks to understand the motorist and bicyclist behavior during a high-risk vehicle bicyclist conflict point to define near miss collisions. The data that is to be evaluated by an ANOVA are the non-truncated and truncated data sets for each buffered bicycle lane facility. A binary logistic regression (logit) model was used to evaluate the behavior of near miss collisions between a bicyclist and motorized vehicles."
http://hdl.handle.net/1957/61913,"Management goals for restoring populations of the federally-threatened northern spotted owl currently include experimental lethal removals of barred owls from demographic study areas within the overlapping ranges of the two species to examine northern spotted owl population response. As lethal removals of a bird species are time- and cost-intensive, predictive modeling of population responses is valuable for exploring potential long-term population impacts on both species and estimated recovery likelihood for northern spotted owls. I built a two-species model in the spatially-explicit, individual-based modeling framework HexSim incorporating competitive interactions and implemented lethal barred owl removals of different intensities within representative removal areas in the model landscape. Viable, long-term recovery of northern spotted owl populations was observed in two of the four modeled removal areas, and appears dependent on high removal intensities. Northern spotted owl recovery was correlated with the population growth status ofthe site-specific barred owl population at the time of removal implementation, with still-expanding barred owl populations negatively affecting northern spotted owl likelihood of recovery. This model can be further utilized to empirically parameterize barred owl population dynamics within removal areas to more accurately examine the likelihood of northern spotted owl population persistence and recovery in the long-term."
http://hdl.handle.net/1957/61914,"This thesis uses the manuscript option, and consists of a previously-published paper and a paper that has been accepted for publication. Manuscript One details an independent confirmatory study to Choo et al. (2014), which demonstrated that correlations exist between personality type and the outcome of concept ideation methods. This is confirmed by conducting a similar experiment with a larger sample size. Four concept ideation techniques were selected from those used in the previous research: individual and group brainstorming, and individual and group mind mapping. 90 junior level engineering design students completed a Meyers-Briggs Type Indicator (MBTI) sorter and concept ideation activities using each of the four ideation methods. The creativity of the output was measured with metrics for the quality, quantity, and variety of ideas produced. The resulting dataset was statistically analyzed to find how individual output from these activities correlated with MBTI results to investigate how personality type correlates with the creativity of output from concept ideation methods. Manuscript Two begins investigating the concept of team personality (the average personality of the team along each MBTI spectrum) and the effect it has on ideation creativity. We find evidence suggesting that a team whose average personality falls near the extremes of the Thinking-Feeling spectrum will produce more creative results, a team that is neutral along the Introversion-Extraversion spectrum can choose their method based on which creativity metric they wish to maximize, and a team with high personality variance can select a method create either more variety or higher quantity of ideas."
http://hdl.handle.net/1957/61915,"In this thesis, high resolution ocean models are used to evaluate and forecastcoastal ocean variability in two different applications.        In the first study, the 2-km resolution ocean circulation model for the EasternBering Sea is utilized to understand whether slope-interior exchange along the path ofthe Aleutian North Slope Current (ANSC) helps maintain the subsurface temperaturemaximum on the isopycnal surface 26.8 kg m-3, approximately 300-400 m deep. Thesimulation period is June-October of 2009. At the abovementioned isopycnal surface,the model shows the warmer pattern extending westward along the southern slope ofthe Aleutian Islands and then eastward along the northern slope as the seasonprogresses. The direct exchange from the south to the north through Amukta Pass onthis isopycnal surface is very limited. The model does not exhibit vigorous eddyshedding along the ANSC. However, there are several topographic features where thewarm slope current separates into the basin, particularly at 178˚ W (just east ofAmchitka Pass) and 174˚ W (Atka Island). Currents on the 26.8 kg m-3 isopycnalsurface are too slow to account for the warming pattern along the ANSC reaching theBering Canyon and the Bering Slope Current. The warming can be explained as acombination of faster advection of warmer waters above and downward verticalturbulent transport due to intensive tides. This hypothesis is confirmed by the heatequation term balance analysis and two-dimensional Lagrangian particle tracking onthe 26.8 kg m-3 surface and a shallower, 26.4 kg m-3 surface.        In the second study, a team of four graduate students, including two oceanmodelers, a cartographer, and a social scientist, work together as part of the NationalScience Foundation Research Trainee (NRT) program to develop new products basedon ocean forecasts, quantify their uncertainty and communicate this knowledge tocommercial fishermen. A 2-km resolution ocean prediction system for the Oregonand Washington coasts produces three-day forecasts of surface velocity, temperature,and salinity. Based on the social scientist’s communications with the commercialfishermen on their perceptions of risk and uncertainty, uncertainty in the surfacecurrent forecast is quantified by calculating the root mean square error of the forecastwith high frequency radar observations for each forecast horizon. This calculationreveals that the model performs better in the northern portion of the domain wherehigh frequency radar observations are available, with a noticeable source of errorbeing near the Columbia River Estuary. Additionally, the depth of the thermocline iscalculated with two different methods: as a depth at which the temperature is 2˚F lessthan the surface temperature (a definition provided by the commercial fishermen) andas a depth of the maximum buoyancy frequency squared.        Overall, the two parts of our thesis study complement each other showing thatcoastal ocean models can be used both for basic oceanographic research and foroperational prediction."
http://hdl.handle.net/1957/61916,"This work is a culmination of a series of published works related to the use of the Material Point Method (MPM) in modeling wood adhesive bonds. The use of wood as construction material has the potential to play a small role in the solution to the current CO2 and climate change crisis. Therefore, wood as an engineering and structural material appears to have increased popularity among green-minded architects and builders. Much of wood used as a structural or engineering material is in the form of a wood composite, common examples include plywood, oriented strand board (OSB), laminated veneer lumber (LVL), particle board, cross-laminated timber (CLT), and others.  Clearly, a vital component of all these products is the adhesive bond between the pieces of wood.  The motivation of this work is to thoroughly understand the mechanics and properties of a wood adhesive bond through the use of computational numerical modeling. A detailed and full-featured customized numerical modeling paradigm for wood adhesive bonds using MPM is introduced. The effective goal is to start with a specific wood structure and the liquid properties of an uncured adhesive, and to fully model and verify every aspect of the wood adhesive bond with MPM. This is a complex endeavor and has several intermediate steps, including modeling how adhesive flows into the wood structure and modeling the mechanical performance of the wood adhesive bonds.To improve the modeling of fluids and fluid-structure interaction in MPM, an advancement called XPIC (eXtended Particle In Cell) was invented and introduced to significantly reduce noise and high frequency oscillations in MPM simulations. XPIC was used to improve MPM simulations in all the chapters of this dissertation. MPM simulations were used to model the pressure-driven flow of uncured adhesive in a wood structure, created using XCT scans of actual wood adhesive bond segments.  These simulations are verified against experimental x-ray data.  To model the mechanical performance of a wood bond, mechanical properties are needed, ideally the properties of the particular piece of wood.  This is partially achievable with nanoindentation. However, the standard methods for analyzing nanoindentation don't apply to the anisotropic wood cell walls and further numerical modeling is needed. The use of MPM for modeling nanoindentation is investigated and it is found that MPM is well suited to handle this modeling and that numerical modeling is indeed important for accurate and consistent material properties. Finally, modeling the mechanical performance of a wood adhesive bond with the geometry created from the adhesive squeezing simulations or from XCT data is investigated. MPM simulations investigating the mechanical behavior of wood-adhesive bonds are compared with experimental data obtained from DVC analysis of XCT scans of wood specimens under load.  Not every step in the proposed overarching modeling paradigm has been fully completed but progress has been made toward each step. And the feasibility of each step is demonstrated.  Once the modeling paradigm has been fully implemented with MPM and verified with experiments, the next phase is to use this modeling to further the understanding of wood adhesive bonds, to suggest and inform additional experiments, and to optimize adhesives and bonding procedures."
http://hdl.handle.net/1957/61917,"The Brownian motion of micron-scale particles reflects the viscoelastic response of the local environment of the medium. Tracking the thermal fluctuations of these particles is a measure of the rheology of the material at the microscopic scale. This technique is called passive microrheology. Microrheology has been developed to assess the microscopic structural and mechanical properties of complex materials. This probing method is well suited for studying evolving materials and rare biological materials, since it only causes small deformations that are driven by the thermal energy and since it only requires micro-liter quantities of sample. Video microrheology is a method that involves recording the thermal fluctuation of the microscopic probes to track the particle motions. The trajectories of particles are analyzed from videos that are recorded by the video microscopy system and used to compute the mean-squared displacement that reflects the microscopic environment where the particles reside. Moreover, the properties of materials that are characterized by microrheological techniques are highly comparable to conventional macroscopic methods, such as conventional rheometry.We applied video microrheology to characterize the concentration-dependent rheology of artificial sputum medium (ASM) and transient microrheology of platelet poor plasma (PPP). The development of ASM is achieved by increasing the entanglement of polymers, but the plasma coagulation is caused by the addition of initiators, and the evolution of a fibrin clot is achieved by the time-dependent development of the crosslink of fibrin. Using video microrheology, we computed the shear modulus and identified the gel points of both materials."
http://hdl.handle.net/1957/61918,"This thesis is about visual relationship detection. This is an important task in computer vision. The goal is to detect all visual relationships in a given image between objects. This thesis presents a new approach to this problem. Our approach does not use an object detector as a common pre-processing step of prior work. In this way, we overcome the limitation of large computational complexity when considering a large object categories. We focus on relationships that can be specified as triplets $<subject, predicate, object>$. Our approach has four modules including object pair detection, triplet proposal, imposing common-sense constraints and ranking. To boost the performance of our system, we use Message Passing on the triplet proposal module. Our evaluation shows effectiveness of our approach. We also discuss some improvements of our visual relationship detection system in the future."
http://hdl.handle.net/1957/61919,"In this study, the effects of implementing different wind input or physics packages in a numerical wave model to recreate large wave conditions are explored. Three large wave events are simulated with WaveWatch III.  The wind inputs which are compared are NCEP's Global Forecasting System (GFS) with 0.5 degree resolution and Climate Forecast System Reanalysis (CFSR) with 0.312 degree resolution, and the physics packages which are compared are ST2 (Tolman and Chalikov, 1996) and ST4 (Ardhuin et al, 2010). The modelled output, including spectral shape and bulk parameter time series, are compared with National Data Buoy Center buoy observations offshore of Newport, OR. The atmospheric conditions which generate these large waves include a wind feature called a coastal jet along with a distant cyclone. The energetic contribution of these simultaneously occurring atmospheric features results in a wave field characterized by bi-modal energy spectra for two events and uni-modal energy spectra for the third event. The analysis of model output includes evaluates bulk parameter time series significant wave height, mean period and mean wave direction derived from partitioned energy spectra. A consistent underestimation in wave energy emanating from the  southwestern direction is found for the output associated  with all model configurations. This wave energy is generated by the coastal jet. An overestimation in swell energy emanating from the northwest is also found for all model configurations. The model configuration which features the combination of CFSR winds with Ardhuin et al (2010) physics results in the best performance for the largest wave heights, with a reduction in error for overall bulk parameters as well as partitioned bulk parameters."
http://hdl.handle.net/1957/61920,"This study examines different fate and transport processes of N and P based on uncultivated grass, contour crop, and livestock management across different topographies (i.e. 5% vs. 30% slope) found within the tropical mountains of volcanic pedogenesis in the Ambato river catchment. The hydrologic, cultural, and agricultural properties of the catchment are consistent with many other steep and isolated mountain catchments where subsistence farming creates important impacts on the quality of water flowing downstream to cities. This investigation identified dominant pathways of N and P export based on land use, topographic, and climate conditions in the Ecuadorian Andes through the use of numerical experiments simulated in the Agricultural Policy Environmental eXtender (APEX). The objective of this study was to ultimately consider effective resources to support management decisions to mitigate nutrient exports and better utilize applied fertilizer to reduce production costs for the benefit of the local land managers."
http://hdl.handle.net/1957/61921,"Sepsis is an inflammatory reaction occurring throughout the human body to infections caused by bacteria, fungi, and or other forms of pathogens. It is essential to find an alternative treatment method for sepsis, to lessen the dependence on antibiotics. Hemoperfusion is an absorbent device that removes select targets from blood, when passed through it. Recent studies are evaluating methods for treatment of antibiotic resistant bacteria using antimicrobial peptides and bacteriophage (viruses against bacteria) proteins, as an alternate to antibiotic treatment. A promising method is to combine a hemoperfusion device coated with PEO modified antimicrobial peptides and or bacteriophage proteins to remove endotoxins, released by bacteria but prevent plasma protein platelet adsorption through the PEO brush layer effect. For this purpose, antimicrobial peptide WLBU2 and bacteriophage derived protein Abc2 were studied. This study demonstrates the ability of WLBU2 to retain endotoxin and bacteria binding abilities when PEO is tethered to a surface. Circular Dichroism demonstrated that the secondary helical structure was retained in the presence of LPS when the peptide was PEGylated indicating that the flexibility of the peptide is not inhibited when PEGylated. PEGylated gold surfaces with terminal WLBU2 demonstrated bacteria and endotoxin capture through Scanning Electron Microscopy (SEM) and Quartz Crystal Microbalance with Dissipation (QCMD). Abc2 protein was modified using Genetic Code Expansion (GCE) to incorporate unnatural amino acid Azide-Phe, which uses click chemistry to bind to specific functional groups. This prevents non-specific binding of the protein on the surface, compared to standard bioconjugation methodologies that enable multiple conformations of the protein to the surface. Click chemistry retains the structure and function of the protein. Surface analysis methods using X-ray Photoelectron Spectroscopy (XPS) and QCMD demonstrated the ability of the protein to be immobilized using click chemistry to F127 with end group terminal Alkyne. LPS binding capabilities of the Abc2 modified surface was demonstrated using FITC-LPS solution depletion assay and QCMD. Polybutadiene-Polyethylene Oxide (PBD-PEO) co-polymers were studied for hemocompatibility on a C18 silane surface. The PBD groups can covalently bind using irradiation to biomedical plastics, unlike current Pluronics, which require expensive and toxic surface coatings. Three varied sizes of copolymers were studied and compared to F127. AFM and QCMD was used to monitor the immobilization dynamics of PEO-PBD diblocks compared to Pluronic F127. Generally, the diblocks had a much lower surface coverage, but P5431 exhibited similar topology and coverage as F127. Hemocompatability was studied by fibrinogen repulsion experiments using QCMD and FITC-fibrinogen solution depletion assays. Patelet activation was studied by SEM. P5843 was more efficient at fibrinogen repulsion but was not as efficient at platelet repulsion as P5431, due to the PEO length difference. These results provide further analysis of the endotoxin binding ability of tethered WLBU2, as well as offers a method to effectively tether Abc2 protein to a Pluronic surface for LPS binding. Finally, this work exhibits the hemocompatablility of covalently bound PEO-PBD for a hemoperfusion device. Overall, these results provide a methodology towards a commercial bioactive surface for the treatment of sepsis."
http://hdl.handle.net/1957/61922,"Atomically-thin graphene sheets have unprecedented characteristics for biosensing applications. These characteristics include mechanical flexibility and strength, optical transparency, electrical sensitivity and biocompatibility. The primary theme of this dissertation is the characterization and application of graphene field-effect transistors (FETs) in biologically-relevant physiological environments.Understanding the interface that forms between an electrolyte and graphene is critical to understanding biosensing mechanisms. The electronic signals measured by a graphene FET biosensor are typically the result of changes in the layer of dissolved ions near the graphene surface. The coupling between dissolved ions and a conductive surface is described by the electric double layer capacitance, CEDL. This interfacial capacitance has been studied for many years using conductive liquids and bulk metal surfaces. Only recently have careful studies of CEDL focused on the interface between graphene and conductive liquids. We use Hall effect measurements to determine the total capacitance at the interface and the tight-binding-model-based theory to separate the quantum capacitance, CQ, and CEDL. Based on this investigation, we find a CEDL of ~ 0.04 F m2 for biologically relevant fluids and ~ 0.11 F m2 for ionic liquids. Both of these values are lower than the typical value of 0.2 F m2 found with metals. This finding is also significant for choosing ideal fluids for graphene-based super capacitors.We have systematically characterized the noise and sensitivity of graphene FETs in aqueous electrolyte environments. We established the minimum attainable noise in this environment by determining the thermal noise limit. We then investigated charge carrier mobility, which is critical to device sensitivity. We performed Hall bar measurements on electrolyte-gated graphene assuming a Drude model, and find that the room temperature carrier mobility in water-gated, SiO2-supported graphene reaches 7000 cm2 Vs. This value is comparable to the best dry SiO2-supported graphene devices. Our results show that the electrical performance of graphene is robust, even in the presence of dissolved ions that introduce an additional mechanism for Coulomb scattering.We established two novel applications of graphene field-effect transistor biosensor. The first application is in-situ monitoring of the pH inside a living biofilm with fast temporal resolution (∼1 s) over multi-hour time periods. The atomically thin sensor is positioned between the biofilm and a supporting silicon oxide surface, providing noninvasive access to conditions at the base of the biofilm. We determine the transient changes in pH when the biofilm metabolizes substrate molecules and when it is exposed to biocide. The pH resolution is approximately 0.01 pH units when using 1 s time averaging; the sensor drift is approximately 0.01 pH units per hour. Our results demonstrate the potential of this technology to further the study of biofilm metabolism and improve monitoring of biofilm health.The second application for GFET biosensors that we established is wearable sensor patches for single cells. Recent advances in the fields of optics, biochemistry, and nanotechnology have instigated a multidisciplinary effort to understand the neural circuitry of the human brain. The electrodes currently used for in vivo single neuron sensing have not significantly advanced over the past century. The industry standard remains simple, insulated, conductive shafts with small, exposed tips. Graphene-based field-effect transistors are flexible yet strong, biocompatible, and able to locally amplify the electrogenic signals produced by neurons. This combination of material characteristics makes graphene ideal for next-generation biosensing applications.The graphene in our experiments is etched into patterns inspired by the Japanese paper art of kirigami to enable in-plane stretching. The devices are then stretched over cells, isolating the graphene from possible substrate noise while forming a conformal coating over the cell to obtain the optimal signal-to-noise ratio. The flexibility of these devices makes them promising as “wearable” electronics for cells with applications for both in vivo and brain-slice electrophysiological experiments. We present characterization and initial single cell measurements from these devices."
http://hdl.handle.net/1957/61923,"Among the suite of water resources management strategies, water banking can be a tool for water resource management in areas with high water demands or localized water scarcity. This research aims to further the understanding of water banking by conducting a review and analysis of relevant state legislation. This research identified legislation that explicitly mentions water banking and then assessed how states compare on the comprehensiveness of their water banking legislation.In this study over three hundred pieces of legislative documents referencing water banks and water banking were examined and coded to compare the nineteen states that use the Prior Appropriation Doctrine. Of the states examined, seven states had no mention of water banking in their legislation. The remaining twelve states were assessed and compared on a qualitative scale of comprehensiveness through twenty-eight categories. Washington, Arizona, and New Mexico rank consistently high in the individual categories, such as quantity and management, and the overall analysis determined that the state of Washington has the most comprehensive legislation regarding water banking.  Conducting this research has enabled the identification of policy elements and objectives most often associated with water banking and has provided a platform for further discussions on how the progression of water banking legislation can compare to the growth of water banking practices and other water resource management strategies."
http://hdl.handle.net/1957/61924,"Background:  The United States has been under-producing college graduates since at least 1980, with many challenges suppressing students’ self-efficacy.  One approach to improving student outcomes is through mentorship.  This dissertation applied Bandura’s Social Cognitive Theory (SCT) and Kram’s Mentor Relationship Development Theory (MRD) to discover whether students’ campus mentorship experiences were related to changes in student self-efficacy.  The literature was reviewed indicating a dearth of studies applying Kram’s MRD to the college experience.  Of particular interest was the need of college freshmen to make an immediate personal connection with someone who would build their confidence the way a mentor would.  Purpose: The research hypotheses sought to discover whether more frequent and satisfying experiences with potential mentors on campus were associated with changes in freshmen self-efficacy.  Subjects: College freshmen surveys from two and four year colleges nationwide totaling 15,855 subjects were studied regarding their mentorship interactions and their self-efficacy beliefs.  Research design:  Using existing data, over 15,000 students nationwide had been surveyed before and after the freshman year.  Six kinds of student self-efficacy were identified in the data: Academic self-confidence, Intellectual self-confidence, Social self-confidence, Emotional health, Drive to achieve, and Cooperativeness.  A variety of mentorship experiences included interactions with faculty, advisors, counselors, and staff.  Statistical analysis was conducted to explore these variables and identify relationships between mentorship experiences and student self-efficacy.Findings: Factor analysis indicated that student self-efficacy is multi-faceted.  Regression analysis indicated that the strongest positive influence on students’ academic self-efficacy at the end of the freshman year was their academic self-efficacy at the beginning of the freshman year.  The second strongest positive influence was incoming student grades, equal in impact to faculty believing in students’ ability to succeed.  Other positive influences included communicating regularly with professors, asking their advice after class, and interacting with them outside of formal class or office hours.  Faculty interactions that predicted decreases in self-confidence included showing concern about students’ progress and students’ attending office hours.  Career counseling had small positive influences.  The strongest negative influence was gender.  Being female was associated with lower academic self-confidence, made worse after mentorship experiences on campus.  Being Asian and being Hispanic were associated with slight decreases in academic self-confidence, but improved after campus mentorship experiences.  Conclusions:  Student self-efficacy was influenced by potential mentors on campus.  Consistent with literature (Sax et al., 2005), some contacts with faculty were associated with small positive changes, and some were associated with small negative changes.  The most valuable mentorship experience was faculty believing in students’ potential to succeed, consistent with Dweck (2007), Seligman (1998) and Steele (1997).  This study reinforced that faculty need to continue to develop methods to support freshmen, particularly women.  Mentorship on campus continues to be a powerful influence on student success, and is an area worthy of future research."
http://hdl.handle.net/1957/61926,"The electrical stability of amorphous indium-gallium-zinc oxide (a-IGZO) thinfilmtransistors (TFTs) is investigated for flat-panel display applications. Althoughproducts incorporating a-IGZO TFT backplanes are already commercially available,e.g., iMac with 5K retina display, technical challenges need to be addressed for nextgenerationapplications, e.g., active-matrix organic light-emitting diode displays.Device stability is one crucial issue. The objective of the research presented herein isto provide an in-depth assessment of the effect of DC and AC bias temperature stresson the stability of a-IGZO TFTs. It is found that TFT threshold voltage instability,ΔVTH, is reduced by decreasing the unipolar AC duty ratio, decreasing the operationtemperature, using a bipolar AC waveform rather than a unipolar waveform, oremploying an optimized passivation layer that suppresses moisture incorporation intothe a-IGZO channel layer. A two-parameter stretched-exponential expression is usedto describe the time-dependent instability trend. The long-term reliability of an a-IGZOTFT as a function of gate voltage, temperature, or duty ratio is successfully modeledusing the two-parameter stretched-exponential expression. The stretched-exponentialactivation energy is correlated with the Meyer-Neldel rule activation entropy.Technology computer-aided design (TCAD) simulation provides insight into thenatural of a-IGZO TFT instability from the perspective of the subgap density of states(DOS). It is found that less DOS change results in a more stable TFT."
http://hdl.handle.net/1957/61930,"Relationship health has many benefits, from physical and emotional health of the partners to their children’s wellbeing. Early intervention programs protect relationships from decline. These programs represent growing public health initiatives. However, most studies on wellness or early intervention overlook lesbian and gay male couples. Research that assumes lesbian and gay relationships are the same as heterosexual cisgender relationships, or that ignores lesbian and gay couples completely, leaves practitioners in the dark on how to intervene successfully. Programs that seek to promote wellness and prevent decline for diverse groups must be able to attune to critical differences, appropriately adapt materials, combat social prejudice, and encourage practitioners to manage unintentional personal bias. Research sheds light on which direction to go to accomplish these tasks. Intervention research with sexual and gender minority couples also encourages existing programs to effectively open and adapt their programs to include lesbian and gay couples in the populations they serve. This study fills this gap in the research on lesbian and gay couples and wellness checkups, offering information about these often-overlooked couples and promoting their inclusion. The study examines the question, “What is the impact of a relationship wellness checkup on gay and lesbian couples’ satisfaction?” The two arms of the study capture different groups – one group is lesbian couples and one group is gay male couples. The method employs a multiple probe, nonconcurrent multiple baseline design. The independent variable is an established relationship health intervention based on motivational interviewing principles, The Marriage Checkup (MC). The dependent variable is relationship satisfaction measured by the Couple Satisfaction Index. Three lesbian couples and three gay male couples participate in the study. The findings show the checkup has a moderate effect on satisfaction for both lesbian couples (NAP =.66) and for gay male couples (NAP = .73). Visual analysis of the data supports these results. The outcome shows a relationship wellness checkup, based on the MC, had a positive benefit for these six couples. The results confirm a relationship checkup for gay and lesbian couples can improve their satisfaction, just as it improves heterosexual couples’ satisfaction. In addition, these results suggest offering an MC to gay and lesbian couples specifically could be beneficial for these couples as wellness support operates in contrast to social stigma, discrimination, and prejudice."
http://hdl.handle.net/1957/61939,"The growth of Brettanomyces bruxellensis is a major cause of wine spoilage due tothe production of the volatile phenols 4-ethylphenol (4-EP) and 4-ethylguaiacol (4-EG), derivatives of p-coumaric acid and ferulic acid. During the winemaking process,some microorganisms can impact the concentration of the 4-EP precursors pcoumaricand coutaric acid (tartaric acid-esterified p-coumaric acid). This studyinvestigated the effect of certain wine microorganisms on these 4-EP precursors aswell as potential inhibitory relationships between B. bruxellensis and the winebacteria Oenococcus oeni. Saccharomyces cerevisiae strains with and withoutphenolic acid decarboxylase (PAD) activity as well as Oenococcus oeni strains withand without cinnamoyl esterase (CE) activity were used to perform sequential andsimultaneous Pinot noir alcoholic fermentations (AF) and malolactic fermentations(MLF). Simultaneous fermentation using PAD (+) S. cerevisiae and a CE (+) O. oeniresulted in the largest reduction of volatile phenol precursors. However, these samestrains when utilized in sequential fermentations resulted in the largest number ofprecursors in the form most readily usable by B. bruxellensis. Several commercial and non-commercial O. oeni were also screened for CE activity. Two of the elevenpreviously unscreened commercial O. oeni as well as one of the four non-commercialO. oeni exhibited cinnamoyl esterase activity, resulting in significantly higherconcentrations of free hydroxycinnamic acids in these wines. The stability of the 4-EP precursor compounds during aging was investigated by aging Pinot noir winesthat had undergone MLF using either a CE (+) or CE (-) O. oeni. Wines were adjustedto different pH and ethanol concentrations and stored at either 13 or 21C. During180 days of aging, the concentration of p-coumaric acid and coutaric acid remainedrelatively stable and were most impacted by the strain of O. oeni that had conductedMLF.While O. oeni can impact B. bruxellensis wine spoilage through the liberation oftartaric acid-bound hydroxycinnamic acids, it has also been noted that the presence ofO. oeni at the completion of MLF may inhibit B. bruxellensis growth. Experimentswere conducted to determine how long this inhibition lasted as well the sensitivity ofmultiple B. bruxellensis strains. Three different O. oeni strains were used to conductMLF in a Pinot noir wine. Upon completion of MLF, wines were pulled andinoculated with B. bruxellensis at 0, 34, and 112 days post-MLF. Growth of B.bruxellensis and O. oeni were monitored and volatile phenol (4-ethylphenol and 4-ethylguaiacol) concentrations in the wine were also measured. O. oeni populations inthe wines were high directly after the completion of MLF and B. bruxellensispopulations declined rapidly following inoculation. 34 days post-MLF, highpopulations of two O. oeni strains were still present in the wine but no culturable cells were detected in the wine for the third strain. When B. bruxellensis was inoculatedinto the wine containing no culturable O. oeni cells, it grew well. In contrast, B.bruxellensis populations rapidly declined when inoculated into wine where there werestill culturable O. oeni cells. 112 days post-MLF, no culturable O. oeni cells weredetected in any of the wines and B. bruxellensis grew well in all but one of the wines.The sensitivity of different B. bruxellensis strains to the presence of culturable O.oeni post-MLF was tested by inoculating six strains of B. bruxellensis into wine thathad undergone MLF by O. oeni or had not (control). Subsequent growth and volatilephenol production was tracked. The degree of inhibition on growth and volatilephenol production was strain dependent where the growth of some B. bruxellensisstrains in wine that underwent MLF was comparable to growth in the control wines.For other strains, there was reduced or no growth in wines that had undergone MLF.All six strains of B. bruxellensis produced significantly less volatile phenols in winesthat had undergone MLF compared to those that had not. These findings suggest thatMLF may offer limited protection against B. bruxellensis infection due to thepresence of live O. oeni cells post-MLF but that this may be dependent on the B.bruxellensis strain present. Additional research should involve screening a largernumber of B. bruxellensis strains for their sensitivity to live O. oeni cells. Focusingon B. bruxellensis strains which have been sequenced and better classified from an-omics point of view would likely provide better insight behind variations ininhibition as well as possible mechanisms of inhibition."
http://hdl.handle.net/1957/61940,"In this work we will analyze branching Brownian motion on a finite interval with oneabsorbing and one reflecting boundary, having constant drift rate toward the absorbingboundary. Similar processes have been considered by Kesten ([12]), and more recently byHarris, Hesse, and Kyprianou ([11]). The current offering is motivated largely by the utilityof such processes in modeling a biological population’s response to climate change. Webegin with a discussion of the beautiful theory that has been developed for such processeswithout boundaries, proceed through an adaptation of this theory to our finite setting withboundary conditions, and finally demonstrate a critical parameter value that answers thefundamental question of whether persistence is possible for our branching process, or ifextinction is inevitable. We also include a new and simple proof of Kesten’s persistencecriterion for branching Brownian motion with a single absorbing boundary. The bulk ofthe work is done by the distinguished path (or “spine”) analysis for branching processes."
http://hdl.handle.net/1957/61941,"In the U.S., childhood overweight and obesity has grown to epidemic levels. The National Survey of Children’s Health (NSCH) found that nationwide, approximately 32% of children 10–17 years old are identified as overweight, over half of them (nearly 17%) are obese. This is a concern because these rates continue to climb. In the last 25 years, obesity in children has tripled and presaged a reduction in overall health for this population. When examining risk factors for cardiovascular disease in children, 70% of obese children had at least one illness and 39% had at least two. This struggle can transcend into adulthood where it can develop into heart disease, diabetes, and cancer. For the first time in history, the current generation of children could have a shorter projected life expectancy than their parents.The main factors that influence weight are physical activity (PA) and dietary intake (DI). Many factors influence the levels of physical activity and types of food ingested. Several of these factors from the social ecological model can influence BMI, including acculturation, family       structure, socioeconomic status (SES), built environment, technology use, adolescent physical activity, and adolescent dietary intake. Potential moderators are ethnicity, age, and gender. The specific aims of this project were to 1) determine if significant associations of the exogenous variables with PA behavior and DI occur among adolescents in the 12–17-year-old age group, 2) test if acculturation, family structure, socioeconomic status, built environment, and technology use, had indirect effects on BMI; that is, functioned through PA and DI as mediators, and 3) examine the association of the exogenous variables with PA and DI by ethnicity, age, and gender and how the mediated pathways predicting BMI vary between levels of the moderators.I used the 2009 California Health Interview Survey (CHIS) in a cross-sectional design. I conducted tests for means, differences, proportions, and group differences to examine the study sample characteristics. To conduct path analysis, I identified indicators to represent the exogenous and mediator variables. For the exogenous variables, acculturation was created from the indicators of citizenship, primary language, and country of birth. For family structure, the only indicator was marital status of parents. For SES, only household poverty was considered. For built environment, neighborhood and park safety were the indicators. For technology use, it was the indicators of television video game use and computer use. For the mediators, PA was created from the indicator of physical activity in the past week. Lastly, fruits, vegetables, fast food, and soda intake were the indicators for DI. To examine the initial relationships of these variables with each other and on BMI, I used a combination of association matrixes and analysis of variance (ANOVA).I conducted path analyses for the entire sample and individually for ethnic, age, and gender groups to examine the associations of the exogenous variables with the mediators, and BMI. Invariance testing examined group differences among the parameters in the models. The likelihood ratio test examined further the group differences among ethnic, age, and gender groups. The mediation test examined the direct and indirect effects of the variables on BMI and the likelihood ratio test determined which variables (PA or DI) significantly mediated the effect of the exogenous variables on BMI.The first hypothesis was confirmed with the association of the several exogenous variables with PA and DI for the entire study sample. The variables associated with PA were SES, built environment, and technology use. SES, built environment, and technology use were also associated with DI. None of the paths from the mediators to BMI were significant. The second hypothesis was not confirmed because none of the associations of exogenous variables with BMI were mediated by PA or DI.The third hypothesis was partially confirmed in that the associations with PA and DI differed by ethnic group (Whites, Hispanics, Asians, and Others), age (12 – 14 year-olds and 15 – 17 year-olds), and gender (males and females), and the indirect effect occurred for ethnicity, age, and gender but for certain mediators. For ethnicity, the associations with PA were family structure (significantly for Asians only), SES (for Whites only), built environment (for Whites and Hispanics), and technology use (for Whites, Hispanics, and Others). The associations with DI were acculturation (for Whites, Hispanics, and Asians), family structure (for Hispanics only), SES (for Whites, Hispanics, and Asians), built environment (for Whites only), and technology use (for all groups). For age, the variables associated with PA were SES (for young adolescents only),built environment (for older adolescents only), and technology use (for both groups). The variables associated with DI were family structure (for older adolescents only), SES (for both groups), built environment (for both groups), and technology use (for both groups). For gender, the association with PA were SES (for females only), built environment (for males only), and technology use (for both groups). The variables associated with DI were acculturation (for females only), and SES, built environment, and technology use for both gender groups.The test for mediation resulted in indirect effects of the exogenous variables on BMI depending on the moderator and group. For ethnicity, the indirect effect occurred for SES and technology use for only Whites mediated by PA. For age, the indirect effect occurred for SES, built environment, and technology but only for young adolescents; and the effect were mediated by DI. For gender, the indirect effect occurred for technology use for males; the effect was mediated through only PA.The outcomes show that some variables have a greater influence on BMI compared to others. For this study, acculturation, family structure, SES, built environment, and technology use all have influence on PA and DI. However, the strength of the association varies when considering the entire sample and then by levels of the moderators. The different ethnic, age, and gender backgrounds, practices, and lifestyles make it challenging for effective healthy approaches. The different lifestyles and practices of each group present challenges for developing effective interventions for overweight and obese adolescents.The findings suggest that both PA and DI are mediators to BMI for the exogenous variables depending on the moderator. This suggests that specific groups and exogenous variables can be targeted for interventions. Diversity in the U.S. adolescent populationpresents a challenge in developing effective approaches but also provides opportunities to learn about each group’s habits, beliefs, and lifestyles.For future analyses, my hope is for better developed programs to promote healthy lifestyles for adolescents because of the consideration and awareness of group differences. The influences on adolescent BMI are different for each ethnic group and further differentiated by age and gender. I believe that better understanding of group differences with respect to cultural values and practices, family makeup, financial situation, access in neighborhoods, and media device usage will provide a foundation for intervention development. The hope is that the associations reported in this dissertation can provide a foundation for tailored interventions targeted to different ethnic, age, and gender groups of adolescents."
http://hdl.handle.net/1957/61942,"Many applications require not only representing variability in software and data, butalso computing with it. To do so efficiently requires variational data structures thatmake variability explicit in the underlying data and the operations used to manipulate it.Variational data structures have been developed ad hoc for many applications, but thereis little general understanding of how to design them or what tradeoffs exist among them.In this thesis, we introduce the concept of holes to represent variational data structuresof different sizes and shapes. Moreover, we strive for a more systematic exploration andanalysis of a variational data structure. We want to know how different design decisionsaffect the performance and scalability of a variational data structure, and what propertiesof the underlying data and operation sequences need to be considered.Specifically, we study several alternative designs of a variational stack and analyze howthese design decisions affect the performance of a variational stack with different usageprofiles. We evaluate variational stacks in a real-world scenario: in the interpreter VarexJwhen executing real software containing variability. Finally, we discuss different ways ofrepresenting variational priority queues and show how this affects the performance of thevariational Dijkstra’s algorithm."
http://hdl.handle.net/1957/61943,"Old-growth forests are structurally complex in both vertical and horizontal dimensions. This complexity arises from biological characteristics, typically branch and leaf structure, but also includes epiphytes with varying form and function. I characterized the biomass and species composition of epiphytes along the vertical axis of an old-growth Douglas-fir (Pseudotsuga menziesii) tree called the Discovery Tree (~60 m tall, estimated age 300 years). Epiphyte biomass was estimated approximately every 10m on both the trunk and the branches attached in a given zone, using calibrated visual estimates. The highest total epiphyte biomass and species richness was found at 30 m; the upper canopy had reduced bryophyte biomass, but an increased presence of lichens dominated, while the lower canopy had much less epiphytic biomass. The common genera (Dicranum, Neckera, Porella, and Isothecium) were used in a greenhouse watering and drying experiment to assess water retention of each species. Taxa that tend to be associated with old-growth forests (Dicranum and Neckera) had greater water absorption and longer durations of water retention by up to 2 days in a simulated 60 mm rain event. By retaining and storing more water in the canopy, these bryophytes may alter rates of evaporation, heating, and cooling, potentially buffering microclimates from extremes. The bryophyte drying experiment suggests that bryophyte species will affect its role in canopy water retention and evaporation.	To characterize microclimate gradients associated with these epiphytes, I installed microclimate sensors along the vertical axis of the same Douglas-fir tree at six microclimate stations, located 1.5, 10, 20, 30, 40 and 56 m above ground. These sensors measured air temperature, relative humidity, wind speed and direction, and leaf surface wetness from (August 2, 2016 – July 31, 2017), and I analyzed the data at the daily and quarter-monthly time scales. Using leaf wetness and temperature data, I used times-series cluster analysis and generalized additive models to assess how the microclimate stations differed and to establish zones within the canopy that had relatively consistent values among the microclimate stations. I classified canopy zones (low, middle and upper canopy) for four representative months (August, November, February and May).  Canopy zones changed in size and relative values across seasons.  The upper canopy experienced a greater range of microclimate variability than the lower canopy. In each of the four months, 56 m was identified as the only microclimate station in the upper canopy, while the middle and lower canopy zones expanded and contracted depending on the time of year. Relative humidity variation was greater at the top of the canopy than the lower canopy. Wind speed was much greater and consistently from the east at the top of the canopy, while the lower canopy has much lower wind speeds which came at different directions. 	Monitoring microclimates in conjunction with the bryophyte assessment allows for conjecture on feedbacks between the microclimate and vegetation. Because bryophytes that tend to be associated with old-growth forests held water longer, we can speculate that this increased water retention feeds back into the microclimate by buffering temperatures. This study also shows that the seasonality of microclimate partitioning may be an important factor in understanding vertical bryophyte distribution and potential climate feedbacks."
http://hdl.handle.net/1957/61945,"Background. As part of the nationwide student completion agenda, the Achieving the Dream (ATD) national reform network was established to help community colleges quickly institute sustainable change scaled to impact all students at the institution in a short period of time. Although ATD has been in existence for over a decade, the majority of colleges who have become part of ATD have not yet succeeded in increasing levels of student retention or completion or the closing of persistent achievement gaps.  Living systems theory provided a useful theoretical framework for this study. According to Capra (1996), living systems theory emphasizes that human systems, much like ecosystems, do not function well as hierarchical structure.  All components of a system are vital to its function, each individual having inherent value in the functioning of the whole. That said, individuals do play unique roles within living systems (Youngblood, 1998).  Each unique role plays an important part in creating effective systemic change. A keystone role in any process of change within an institution is that occupied by the senior leader.  It is the role of the chief executive officer (CEO) to set the stage and to provide the vision of what must change and why, and what is required of the system for continued external integration.  ATD’s intention is to help CEOs paint this picture for their colleges (Burke, 2014; MDRC, 2014). Purpose.  The purpose of this study was to determine what role CEOs play in significant change in student outcomes as defined by the Achieving the Dream national community college reform network’s stated objectives of creating a culture of evidence, raising retention and completion rates, and closing achievement gaps within community colleges.  The study identified leadership practices of CEOs which have contributed to significant movement in ATD's five key indicators: (a) increase retention rates, (b) increase precollege course completion rates, (c) increase completion rates of initial college-level or gatekeeper courses in subjects such as math and English, (d) increase college-level course completion, and (e) increase credential attainment. Setting.  Interviews took place via Skype with individuals from three ATD Leah Meyer Austin Award (LMAA)-winning colleges.  Subjects. The three community college CEOs who committed themselves, their core team leaders, and leadership coaches to participate came from colleges that varied in situation and size.  All participants were in their respective positions at the time their colleges won the LMAA.Research design.  A multiple-case study approach was used to examine leadership practices employed to increase student success through sustained innovations at three ATD LMAA-winning colleges. The study sought the perspectives of the college CEOs, core team leader, and ATD leadership coaches about leadership practices that contributed to an environment in which there was a measurable increase in student success. An additional source of data was any available documentation of these efforts. Data collection and analysis.  Using semi-structured interviews, interview data were subjected to two coding cycles that used the theoretical framework of living systems theory as a lens to interpret the data.  Comparing the literature with the findings provided a way to ensure the findings reliability as well as search for potential new themes that might emerge.  In addition, the individual interview process included member-checking using narrative accuracy to reflect and summarize the participants’ interviews.  A process of triangulation was made possible by interviewing three participants in the change process at each of the three colleges and incorporating relevant documents. Findings and implications.  Confirmed through a process of triangulation with nine interviews and documents from three different colleges, the practices can be generally organized into five broad themes: communicating the importance of improving student outcomes to the college community, commitment on the part of the CEO to increase the use of data to inform decision making, empowerment by the CEO of college personnel to lead institutional change efforts, effort on the part of the CEO to improve college connections to the community, and significant realignment of resources for ATD efforts.This qualitative study will aid future leaders in adopting effective leadership practices that will help more ATD and non-ATD colleges to move quickly to effectively increase student retention and completion and to reduce achievement gaps within the context of the student completion agenda. The colleges included here have quantifiably documented improvements in student outcomes as defined by ATD.Conclusions.  Based on the findings of this study, significant institutional change resulting in an increase in positive student outcomes is coupled closely with intentional practices executed by the college CEO. While there are differences in the individual stories of how each CEO led his or her respective college, there is overlap in the 92 relevant leadership practices that surfaced during the course of the nine interviews at the three LMAA-winning colleges. It is clear that CEOs’ actions were seminal in helping move the colleges to become leader colleges and LMAA winners within the ATD network.Keywords:    Completion agenda, Achieving the Dream, Leah Meyer Austin Award, Presidential CEO community college leadership, living systems theory, institutional change, change leadership, leadership practices."
http://hdl.handle.net/1957/61946,"Femtosecond stimulated Raman spectroscopy (FSRS) is an ultrafast vibrational technique which allows rapid collection of Raman spectra with simultaneously high temporal and spectral resolution. With the recent development of FSRS methodology, three FSRS techniques (conventional, tunable, and anti-Stokes) have been implemented in our laboratory to dissect the excited state structural events of two photochemical systems: green fluorescent protein (GFP) based Ca2+-biosensors (macromolecules) and a photoacid pyranine called HPTS (small molecule). In my early work, I used FSRS to investigate the excited state proton transfer (ESPT) process in an intensiometric Ca2+-biosensor with green fluorescence, G-GECO1.1. The conventional FSRS effectively monitors the decay of the protonated chromophore species (A*) and reveals that a small-scale proton motion occurs on the sub-picosecond time scale upon photoexcitation and the ensuing ESPT process takes longer time in the Ca2+-bound biosensor. By strategically tuning the Raman pump in wavelength-tunable FSRS to track the deprotonated species (I*) in the excited state, the ESPT reaction time lengthening in the Ca2+-bound G-GECO1.1 is confirmed. Besides ESPT, an ultrafast chromophore twisting process and conformational inhomogeneity on the electronic excited state (ES) are also revealed. Later, conventional FSRS was used to dissect the fluorescence modulation mechanism of an excitation-ratiometric Ca2+-biosensor, GEX-GECO1. The distinct A* decay dynamics observed in the Ca2+-free and bound biosensors indicate that more structural inhomogeneity exists in the Ca2+-bound species, which is supported by the molecular dynamics (MD) simulation result. The lifetime of the remaining A* which does not transfer proton and the vibrational cooling (VC) process are also illuminated. Despite Ca2+-biosensors, the ESPT and VC process of a small photoacid, HPTS, are examined by our newly developed anti-Stokes FSRS. The VC process is revealed to exhibit a biphasic dynamic with an initial low-frequency motion aided energy dissipation process followed by thermal cooling to bulk solvents on longer time scale. Several interesting phenomena such as Raman gain and loss sign flip with the progress of reaction are observed, which enriches our understanding of this relatively new field.  My future work includes: 1. Investigate the excited-state structural dynamics of an GFP S205V S65T variant and identify the effect of these mutations; 2. Elucidate the working mechanism of molecules with aggregation-induced emission (AIE) property; 3. Unravel the excited state process of a ferrous (II) porphyrazine complex in solution."
http://hdl.handle.net/1957/61947,"The first part of this manuscript is about the total synthesis of the Arundo donax bis(indole) natural products. The A. donax alkaloids were prepared using the first example of an ynindole Diels–Alder reaction. Each were then separated, isolated, and determined to have stable enantiomeric conformations at room temperature (Chen, J.; Ferreira, A. J.; Beaudry, C. M. Angew. Chem. Int. Ed. 2014, 53, 11931–11934). The Arundo alkaloids bear a hindered C–N biaryl axis which led to a racemization energy barrier sufficiently high that each pair of enantiomers isolated. The rate of racemization (krac), free energy barrier to racemization (DG‡rac), and the corresponding half-lives (t1 2) were experimentally determined for each of the natural products prepared. The DG‡rac values range from 23.3–24.3 kcal mol-1corresponding to t1 2 = 4150–25100 seconds at room temperature. The absolute configuration was determined for each of the alkaloids using circular dichroism (CD) spectroscopy and the exciton chirality method.The second part of this manuscript discloses our findings from a synthetic effort toward the Leuconotis alkaloid leuconoxine. Our strategy made use of a radical translocation-conjugate addition cascade to expediently assemble the tryptamine core of the natural product. Specifically, a vinyl radical was generated from homolysis of a      C–Br bond and underwent a 1,5-hydrogen atom abstraction (1,5-HAT) to form an a- amino radical. The free radical intermediate then performed a 5-exo-trig cyclization forming an indoline ring. Preliminary investigations centered around using a 1,6- HAT, which did not result in successful translocation. A 1,4-HAT was also evaluated, but did not lead to the desired bond formation."
http://hdl.handle.net/1957/61950,"Douglas-fir provides social, economic, and ecological benefits in the Pacific Northwest (PNW). In addition to timber, forests support abundant plant and animal biodiversity and provide socioeconomic viability for many rural communities. Products derived from Douglas-fir account for approximately 17% of the U.S. lumber output with an estimated value of $1.9 billion dollars. Employment related to wood production accounts for approximately 61,000 jobs in Oregon. Timberland also supports water resources, recreation, and wildlife habitat. Minor defoliation has previously been linked to Swiss Needle Cast, associated with the fungus Phaeocryptopus gaeumannii, however, unprecedented large-scale defoliation began in the 1990s and has increased since, leading to decreased growth and yield. Areas affected areas by SNC exceed 500,000 acres in Oregon. Defoliation symptoms are inconsistent with predicted effects of P. gaeumannii, and targeted chemical control has had mixed results. While the microbiome community of conifer needles is poorly described to date, we hypothesize the full interstitial microbiome complex is involved in disease response in conifers.   There are at least three known pathogenic endophytes of Douglas-fir, in addition to a large number of endophytes with undetermined host relationships. In order to understand the mechanistic dynamics of needle cast, it is necessary to uncover the underlying cause of the symptoms. The first step is establishing a baseline inventory of endophytes in PNW Douglas-fir needles.  Two-year old needles were collected from two sites each in Oregon and Washington, for a total of four sites. Study sites varied in elevation (185 – 860m) and mean annual precipitation (250 – 1,575 mm year). DNA extraction and sequencing revealed 46 unique isolates from 39 taxa in Douglas-fir needles gathered from four test sites in Oregon and Washington. Rates of infection for all needles was 39%, with infection ranging from 5% to 60% among seed sources. The results suggest that the probability of endophyte occurrence at the cool, wet site, was 2.8 (p < 0.0001) times higher than the warm, dry site, and 2.2 (p = 0.0007) times higher than the warm, wet site. Non-local needles at the warm, dry site were 13.6 (p < 0.0001) times more likely to be infected than needles from the local seed source. The environmental variable that seemed most positively correlated with endophyte presence was winter relative humidity. There was strong evidence for the influence of seed source type on the relationship between continentality (the difference between mean warmest month and mean coldest month temperatures) and mean average number of endophytes. Long-term silvicultural management of PNW forests will benefit as a result of this study. It is the first study to use modern molecular techniques to uncover the fungal endophytic communities of West-Coast Douglas-fir foliage. It is vital to understand the complete etiology of the needle cast disease affecting Douglas-fir, and whether to focus on mitigating a single-species pathogen, or a number of different pathogens. Because forests are a long-term strategy, it is critical to understand the ecological implications of disease in this important tree species."
http://hdl.handle.net/1957/61955,"Alaska pollock (Gadus chalcogrammus) is a schooling whitefish native to the Bering Sea that is prized for its fillets, surimi, roe, and milt. Fillets are frequently used for popular products such as fish and chips. If collected, roe and milt are commonly exported to South Korea and Japan. However, no markets currently exist for roe and milt in the United States. The Alaska pollock fishery is one of the largest and most sustainably managed in the world. The fish are caught during two seasons in the year, season A and season B, which correspond to pre- and post-spawning periods in the fish reproductive cycle.  To date, there has been no in-depth published data on seasonal changes in the composition of Alaska pollock fillets, roe and milt. In fact, there has been little data published on milt composition at all.This study found that the nutritional composition of Alaska pollock changes significantly from season A to season B, with only small changes within seasons. Fillets were higher quality in season B, with significantly higher protein, fat, vitamin D, omega-3 fatty acids, and essential amino acid index (EAAI) scores than in season A (p<0.05). Remarkably, the 1% increase in fat in season B correlated to a 20% increase in vitamin A, 99% increase in vitamin D and a 34 % increase in omega-3 fatty acids. The fat content in roe increased 71% from season A to season B, which correlated to significant increase in omega-3 and omega-6 fatty acids (p<0.05). However, vitamin D in roe decreased from the start to end of season A, with significant differences between Feb 3 and Mar 31 catch dates (p<0.05). Vitamin D content was significantly lower (64%) in season B than in season A (p<0.05). Milt composition remained remarkably consistent throughout season A, with only sporadic changes in fat, moisture and ash content (p<0.05). No other compositional changes were observed. Mineral content in fillets, roe and milt did not change significantly by catch date or season. On a dry basis, roe and milt have high protein, vitamin, mineral and omega-3 content, which could allow for the development of new nutritional supplements or functional ingredients."
http://hdl.handle.net/1957/6890,"I studied nest-site characteristics and habitat relationships for three species ofprimary cavity-nesting birds--hairy woodpecker (Picoides villosus), northern flicker (Colaptes auratus), and red-breasted sapsucker (Sphyrapicus ruber)-- over spatially heterogeneous landscapes in managed forests of the Southern Oregon Cascades during 1995 and 1996. The study was conducted on the Diamond Lake Ranger District of theUmpqua National Forest. I found 163 nests--68 nests of red-breasted sapsuckers, 63 ofnorthern flickers, and 32 of hairy woodpeckers. I evaluated characteristics of nest trees, habitat within a 0.04-ha circle surrounding nest trees, and the surrounding landscape and compared these to characteristics of randomly selected plots. Analysis revealed statistically significant differences between nest trees and random trees among species. Variables significantly influencing the probability of use of a tree were state of decay, diameter at breast height, and tree top condition (broken or intact). Red-breasted sapsucker nests were associated with large diameter (mean = 80.5 cm) trees with broken tops. Hairy woodpeckers used large diameter (mean = 80.4 cm) trees in decay class 3 for nesting. Northern flickers were associated with large diameter trees (mean = 77.7 cm) with broken tops. I investigated habitat associations at the landscape level using GIS coverages and FRAGSTATS spatial analysis to generate indices quantifying landscape structure for each study site. Higher numbers of woodpecker nests were found in landscapes with lower proportions of mature closed-canopy forest (trees> 53 cm, canopy closure > 40%), and possessing greater overall habitat complexity. I also detected a significant association between all three species of woodpecker and proximity to edge. Red-breasted sapsuckers exhibited the most dramatic affinity for edge habitat, choosingto use nest trees located on a habitat edge more often than would be expected if selection was due to chance alone (P < 5 x 1(f9). Nests of northern flickers and hairy woodpeckers were also significantly associated with habitat edges (P <0.004 and P <0.04 respectively). When managing for woodpeckers within managed forest landscapes, large snags (>80 cm) should be retained. Woodpecker needs for nesting habitat may not be met if retained snags do not represent a diversity of decay classes. Snags representing a variety of tree species and decay classes should be left following management activity. Additionally, management plans should incorporate the use of a variety of methods for stand regeneration. Using prescriptions such as shelterwoods, commercial thinning, and partial cuts, overall landscape diversity will increase, enhancing habitat conditions for nesting woodpeckers."
http://hdl.handle.net/1957/6891,"Purpose of the Study:  The purpose of this research was to present a documentary analysis of school district reorganization in Oregon during the period from August 2O, 1957, to July 1, 1964, and to develop a plan for further school district reorganization for Oregon. The major elements of this study were: 1. To describe the progress and present status of school district organization in Oregon from August 20, 1957, to July 1, 1964.2. To set forth criteria for effective school districts in Oregon. 3. To apply the criteria of an effective school district to adistricting system for Oregon. Procedures: This research study reviewed the progress of school district reorganization from 1957 to 1964 under the original and amended 1957Reorganization Act enacted by the Oregon legislature. The statistical data and much of the information needed were gathered from reports on file in the office of the State Department of Education. The final recommendation for further school districtreorganization submitted by the county reorganization committees were reaffirmed by each county superintendent through personal contact by the writer. Criteria for effective school districts in Oregon developed froma study of the literature are: 1. Each district should provide both elementary and secondary education. 2. The educational program should provide for both academicand vocational education. 3. Special programs, such as special education, kindergarten, and adult education should be provided, as needed. 4. Consideration should be given to the physical and social needs of the youth of the community. 5. An enrollment in excess of 1, 000 students should be maintained consistent with population density and geographical limitations. 6. Ample transportation should be provided to prevent pupils from spending an excessive amount of time going to and from school. It should be kept in mind that elementary and secondary students may share the same bus. 7. A central office staff should be provided that can give assistance and leadership necessary for the operation of an effective educational program and efficient administrative services. 8. There should be the greatest possible equalization of financial resources. 9. The boundaries of a district should be coterminous with or exceed the corporate boundaries of a community to avoid possible social and economic conflict. The projection of a state-wide districting system was based on three major factors: 1. The final recommendations for school district reorganization within the counties by the county reorganization committees, 2. Criteria for effective school districts, and 3. Conformance with school district reorganization statutes and subsequent amendments. Findings: 1. Oregon school districts have a wide range of ability tofinance an acceptable educational program. 2. Oregon school districts vary in organization and classification. 3. Oregon school districts vary widely in average dailymembership. Recommendations: 1. That all area in the state of Oregon be included in schooldistricts providing both elementary and secondary education. 2. That each district should have an enrollment in excess of1, 000 students consistent with population density and geographical limitations. 3. That there should be the greatest possible equalization of financial resources, 4. That the financial structure for school district support be studied. 5. That a guide be developed to assist local school officials inreorganizing and developing the educational program and staff services to make most effective use of the resources available should the proposed districting system for Oregon recommended in this investigation be implemented."
http://hdl.handle.net/1957/7136,"The F13L protein is the major envelope antigen of vaccinia virus, the prototypic member of the Orthopoxvirus genus. F13L is 372 residues in length and is essential for the formation of wrapped forms of virus. F13L contains a number of potential functional domains including a palmitylation site, a phospholipase domain and several tyrosine-based sorting signals (YxxΦ) including three YxxI motifs and a canonical YxxL late (L) domain-like motif. L domains have been identified in several other viruses, including HIV and EIAV, and function in the assembly and release of viral particles from infected cells. Since F13L is required for the formation of wrapped viral particles, it was hypothesized that one or more of these tyrosine-based motifs may possess L domain activity.Sequence analysis revealed that the YxxL motif is very highly conserved throughout the Chordopoxvirus subfamily suggesting that this sequence may convey some biological advantage to the virus. In contrast, the YxxI domains were much less conserved.A trans complementation assay was developed to analyze which residues within the candidate tyrosine-based motifs were required for functional F13L. Based upon targeted mutagenesis of residues within the YxxΦ domains, F13L function was shown to require the tyrosine residue and Φ residue within the YxxL motif and within one of the YxxI motifs. This is consistent with what has been published regarding L domains in other viral systems. The degree of complementation associated with each mutation was measured by both the size and number of plaques produced as well as by an enrichment of a viral population deficient in F13L expression.Co-immunoprecipitation experiments demonstrated a physical interaction between F13L and a cellular trafficking component, Alix. Recombinant viruses containing mutations within the YxxL motif displayed an accumulation phenotype that inversely related binding affinity to the rescue ability demonstrated by each mutation in the trans complementation assay. Furthermore, gradient fractionation of cells infected with the recombinant mutants revealed the presence of wrapped forms of virus. This indicated that the block in the release of enveloped virions associated with the tyrosine and leucine mutants occurred subsequent to the formation of intracellular enveloped virus."
http://hdl.handle.net/1957/7449,"The mechanisms by which the activities of phospholipase C-β (PLC-β) enzymes arenegatively regulated have not been well defined. We used cardiac-derived ratmyoblast H9c2 cells to investigate possible modes of regulation of PLC-β3 enzymes,the only endogenous β isoform abundantly found in these cells. The PLC-β3population in these cells was detected almost exclusively associated with membranewith only trace amounts being cytosolic. H9c2 cells responded to vasopressinstimulation through the PLC-β pathway in a concentration-dependent manner. Directactivation of endogenous protein kinase C (PKC) by phorbol 12-myristate 13-acetate(PMA) significantly diminished vasopressin effects on PLC-β3-mediated PIhydrolysis. However, phosphorylation of PLC-β3 at the Ser1105 residue, the widelyrecognized primary phosphorylation site on PLC-β3, was not observed upon PKCactivation. Other possible mechanisms by which the agonist-stimulated PLC-β3activity is modulated were also tested. Short-term or prolonged stimulation of thesecells with either vasopressin or stimulation of PKC by PMA did not promotetranslocation or down-regulation of the PLC-β3 population within the time frametested. Our observations imply that in H9c2 cells, activated PLC-β3 enzymes may benegatively regulated utilizing some other molecular mechanism not tested in thisstudy."
http://hdl.handle.net/1957/7450,"Over the past decade, changes in health, economic, and social policies haveshifted the dying process out of hospitals and into the community. This exploratory,hypothesis-generating study investigated positive and negative caregiving as well ascare management resources of community-based end-of-life caregivers and how theyrelated to caregivers' personal growth following the death of the care receiver.Retrospective, cross-sectional survey data were collected from 144 respondentsin Lane County, Oregon who reported having provided care for at least one terminallyill person. Data were analyzed using an adapted stress process conceptual framework.Factor analyses determined whether internally consistent measures could be obtainedfrom two new indices related to end-of-life care: a caregiving inventory and a caremanagement resource index. Hierarchical multiple regression analysis examined themediational relationships between care management resources and positive andnegative caregiving in predicting personal growth of end-of-life caregivers followingbereavement.Factor analyses verified that the investigator-developed caregiving inventorywas comprised of two conceptually distinct factors, negative caregiving and positivecaregiving, and the care management resource index was comprised of a single factor,care management resources. Factor scores were generated as a last step in factoranalyses. Hierarchical multiple regression analysis was then undertaken with personalgrowth as the dependent variable. Control variables (age, gender, ethnicity, education,income, and level of caregiving) were entered first, the care management factor scorewas entered next, and the positive and negative caregiving factor scores were enteredlast.As predicted, higher levels of care management resources were associated withmore positive caregiving and higher levels of positive caregiving were associated withgreater personal growth. There was no relationship between negative caregiving andpersonal growth, nor was negative caregiving related to care management resources.The regression analysis did not support a mediational model.Results from this study add to the evidence that positive and negative aspectsof caregiving should be treated separately and demonstrate the influence of positiveperceptions of end-of-life caregiving experiences on long-term bereavement outcomes.Findings suggest the value of interventions designed to promote and enhance positiveaspects of the end-of-life caregiving experience."
http://hdl.handle.net/1957/7500,"Recent developments in the field of clinical echocardiography allow theultrasonographer to objectively quantify both regional and global myocardialfunction. Regional deformation (Strain) and deformation rate (Strain Rate) arenovel indices of ventricular function that can be estimated non-invasively byultrasonographic interrogation of the heart. Deformation Imaging (DI)represents a family of echocardiographic techniques that can be employed todetect, quantify and display the characteristics of physical deformation of themyocardium. The objective of the studies described in this thesis was toinvestigate Doppler-derived deformation imaging in dogs.This Master's Degree thesis is structured in two separate studies. The initialstudy compared Doppler-derived DI measures of ventricular function withmore traditional invasive indices of cardiovascular function in healthy adultanesthetized dogs over a range of hemodynamic conditions created by serialpharmacologic manipulations. Five adult healthy dogs underwentsimultaneous cardiac catheterization and transthoracic echocardiographyunder general anesthesia. The following invasive indices were monitoredduring the study: cardiac output (CO), femoral arterial (FA) and left ventricular(LV) pressures, +dP dt[subscript]max, -dP dt[subscript]max, right atrial (RA) and pulmonary arterial(PA) pressures, and pulmonary capillary wedge pressure (PCWP). Sequentialmanipulations of systolic function, afterload and preload were performed,respectively, by means of dobutamine, nitroprusside, and hetastarch infusions.Significant changes were induced in the following invasive hemodynamicparameters: cardiac output (p<0.0001, range 2.600 - 9.340 L min), +dP dt[subscript]max(p=0.0152, range 953.7 - 3822 mmHg s), left ventricular end-diastolic pressure(LVEDP) (p<0.0001, range 0.210 -16.43 mmHg), mean right atrial pressure(p<0.0004, range -2.490 - 9.920 mmHg), systemic vascular resistance (SVR)(p<0.0001, range 510.0 - 2652 dyne*sec cm⁵), and pulmonary vascularresistance (PVR) (p<0.05, range 256.4 -1635 dyne*sec cm⁵). All dogsunderwent a complete echocardiographic exam before anesthesia, afterinduction of general anesthesia and after each hemodynamic manipulation. Atotal of 750 regions of interest (ROIs) were included in the final analysis.Measurable plots were obtained in 741 (98.67%) out of 750 ROIs. Peaksystolic strain rate (SSR) values obtained at the 6 ROIs did not differsignificantly from each other and the avSSR (average of the 6 ROIs)negatively correlated with +dP dt[subscript]max (r=0.9792, p=0.0208). Individual values ofSSR from the different ROIs also negatively correlated with +dP dt[subscript]max, with theexception of ROI 4 (basal portion of the interventricular septum). The lack ofcorrelation was attributed to high variability in the measurements obtainedfrom this specific ROI. The avSSR was significantly reduced, i.e. systolicfunction was increased, by the dobutamine infusion, but was not significantlychanged during nitroprusside and hetastarch infusions. The LVEDP wassignificantly reduced during infusion of nitroprusside, apparently notinfluencing avSSR, and suggesting the possible preload independence of thisparameter in the hemodynamic range generated in the study. Nitroprussideinfusion effected a significant reduction of systemic vascular resistance withoutalteration of avSSR, suggesting a possible afterload independence of thisparameter, at least in the hemodynamic range obtained in this study.Study 2 was conducted on healthy adult non-sedated dogs divided into fourgroups (group 1: Body weight (BW) < 15 kg, group 2: BW 15 - 30 kg, group 3:BW > 30 kg, and group 4: Doberman pinscher dogs). The aim of the studywas to collect information on the feasibility, repeatability and reproducibility ofDoppler-derived DI performed in a clinical setting. Of the initial 56 dogs fromwhich echocardiographic data were collected, 7 dogs (12.5%) were excludedbecause of poor image quality, and data from 49 (87.5%) dogs were includedin the final analysis. Of a total of 1470 ROIs analyzed, 4.65% yielded goodquality curves, 88.3% were characterized by a significant amount of noise butretained a discernible pattern, and 7.14% were considered non-interpretable.Some pair-wise comparisons of the SSR values obtained from the 6 ROIsreached statistically significant difference. DI values in the Doberman pinschergroup did not differ significantly compared to values obtained from a BWmatchedgroup. DI values in group 1 dogs, but not the traditional indices FSand EF, were significantly higher compared to groups 2 and 3. Results from aBland-Altman analysis revealed overall poor clinical repeatability andreproducibility, as a result of the wide variability of the data.Based on the results of study 1 we conclude that Doppler-derived SSRrepresents a useful load-independent index of global systolic function, asdemonstrated in anesthetized dogs. However study 2 suggests that, in apopulation of non-sedated dogs, with a relatively wide range of breeds andBW, Doppler-derived DI measurements are characterized by less than optimalintra-operator and inter-operator variability which may limit its value as a toolto evaluate myocardial function in a clinical setting. Comparison to other newlydeveloped non-invasive techniques to estimate regional myocardialdeformation is needed to determine the eventual clinical utility of the method."
http://hdl.handle.net/1957/7501,"Children who have multiple family risk factors are at increased risk for poordevelopmental outcomes, including poor academic achievement. The present studyfocused on charting the pathways through which early family risk – as indexed byethnic minority status, low maternal education, low family income, and chronicmaternal depressive symptoms – influences academic achievement in first grade usingdata on 1,364 children from the NICHD Study of Early Child Care and YouthDevelopment. In addition, the mediating role of children's social competency andbehavioral regulation at 54 months was explored.Structural equation modeling indicated that family risk factors during earlychildhood negatively influenced social competency, behavioral regulation, andacademic achievement in first grade, but the mechanisms by which each risk factorexerted influence on academic achievement varied. Child's ethnicity emerged as beingsignificantly and directly related to lower achievement. Maternal education and averagefamily income-to-needs ratio were primarily associated with lower achievement directlywith a small indirect effect through behavioral regulation. In contrast, maternal depression had a modest indirect effect through behavioral regulation, such that as the number of time points a mother showed significant depressive symptoms increased,children's behavioral skills decreased, which, in turn, was related to lower academicachievement in first grade.In addition, behavioral regulation significantly predicted better reading,mathematics, and vocabulary achievement in first grade after controlling for earlyfamily risk factors. Results suggest that strengthening a child's behavioral regulationskills prior to school entry may help to compensate for early exposure to family riskfactors and decrease the likelihood of poor academic adjustment and later academicfailure."
http://hdl.handle.net/1957/7540,"Analog-to-Digital Data Converters (ADCs) used in instrumentation andmeasurements often require high absolute accuracy, including excellent linearity andnegligible dc offset. Incremental data converters (IDCs) provide a solution for suchmeasurement applications. Since IDCs are essentially delta-sigma converterswith reset operation before each conversion, they retain most of the advantages ofconventional [delta sigma] converters, and yet they are capable of offset-free and accurateconversion.Most of the previous research on incremental converters is for single-channeland dc signal applications, where they can perform extremely accurate data conversionwith more than 20-bit resolution. In this thesis, the operation and the performance ofIDCs in both frequency and time domain is analyzed. Design techniques forimplementing multiplexed IDCs to convert narrow bandwidth ac signals are discussedtoo. It incorporates the operation principles, modulator topologies, digital filter designand signal-to-noise ratio optimization methodology. The theoretical analysis isverified by simulation results."
http://hdl.handle.net/1957/7582,"Fires set by Native Americans were important in shaping and maintaining Willamette Valley prairie plant communities. With fire exclusion after Euro-American settlement in the 1840's, composition of the remaining prairies shifted toward shrub and tree dominance with a concomitant decline in endemic prairie plant populations. I hypothesize that by restoring fire as an ecosystem process native prairie flora would be enhanced by invigorating vegetative growth of natives, by controlling exotic species, and by controlling successional invasion ofwoody species. Additionally, I hypothesize that native prairie composition might be better enhanced by multiple burns compared to a single burn. Initial vegetation composition, fuels, fire behavior, and subsequent changes in plant composition following fire were quantified in a total of five plant communities at Rose Prairie and Fisher Butte study sites near Eugene, Oregon.Three treatments were assessed over three years (unburned control, and once burned, and twice burned). A total of 205 species were observed. Species richness was dominated bynative forbs in all five plant communities. In contrast, vegetative cover was dominated by native perennial graminoids in all communities except one where exotic perennial graminoids dominated. Rosa nutkana was the most prevalent woody species in all communities. Initial preburn R. nutkana densities ranged from 30,519 to 50,963 plants ha -1 at Rose Prairie and from 17,156 to 53,067 ha -1 at Fisher Butte. Fisher Butte had more tree encroachment relative to Rose Prairie. Most trees at both sites were seedlings and saplings, ranging between 3 to 70 cm in height. Total tree density initially ranged from 0 to 568 trees ha -1 and from 430 to 1,071 ha-1 at Fisher Butte where Fraxinus latifolia was invading the wet Rosa Juncus community. Total above ground biomass of Willamette Valley wetland prairies wasgreater than that of many other North American grasslands ranging from 6,958 to12,038 kg ha-'. The first season following one burn, above ground biomass decreased significantly in one community (-25.4%) and increased significantly in another (+ 68%).Response to burning was often inconsistent and varied greatly by species among plant communities. Native as well as exotic species increased in frequency or cover with burning. Eight native perennials and three native annuals established or significantly increased frequency (p = 0.1) in burned areas in two or more plant communities. Four exotic perennials and one exotic annual increased significantly in frequency following fire. Although frequency of Deschampsia cespitosa increased in burn treatments, cover declined significantly in the first postfire year following one burn, indicating a shift from fewer large plants to a greater number of smaller plants immediately following burning.Significant increases in vegetative cover occurred in burned areas in two Rose Prairie communities and in one Fisher Butte community, due primarily to changes in cover of perennial graminoids. Total cover of exotic species increased following one or two burns in all but one community. Significant increases in exotic forb cover occurred in two communities. After two burns, relative frequency of native perennial forbs increasedsignificantly in three communities. Relative frequency of exotic perennial graminoids declined significantly in burn treatments in all but one community where they increased in the control treatment. Native annual forbs increased in burns in all but one community.Increases of woody biomass, frequency, and cover following burning suggest that Willamette Valley wetland prairie woody plants are highly resilient to burning and quickly recover and increase following fire. However, height of woody plants significantly declined following burning leading to an improved prairie structure. In addition, the number of Fraxinus latifolia seedlings and saplings were significantly reduced in burn treatments in the Rosa Juncus community. Fire behavior and fuel conditions in relation to vegetation response are required to develop optimal frequency and intensity of burn prescriptions. Information on the response of native, woody, exotic plants, and aboriginal food plants will assist land managers in determining optimal fire frequency for burning Willamette Valley wetland prairies to maintain and enhance desired species. Thisresearch initiates a long-term assessment of fire effects on Willamette Valley vegetation to determine optimal burn prescriptions for wetland prairies."
http://hdl.handle.net/1957/7583,"FISHNET (Facilities Integrated in a Shared Habitat) is a communication subnet architecture utilizing a hybrid application of point-topoint and broadcast communications to achieve a high degree of network performance. This objective is achieved through utilizing a dual bus structure: a data bus and a control bus. The data bus consists of a set of uni- or bidirectional direct links connecting unique pairs of nodes. Data is transfered via an arbitrary connection pattern of links dynamically established between network nodes by circuit switching. The control bus is a common bus on which all nodes may transmit data, receive data, and monitor control and acknowledgement responses of other nodes via message switching. A fully distributed routing and control algorithm allocates communicationresources to communicating nodes. FISHNET offers an environment in which the communication structure may easily be incrementally modified (and improved) by insertion and deletion of additional networkcomponents. FISHNET has the ability to sense system faults and modify routing procedures via an adaptive learning control. Hence, link or node faults will not terminate all network operations. FISHNET performance has been simulated and found to offer performanceimprovement over the centralized version of FISHNET (i.e. Jafari Loop [JAFA 77]), the Newhall Loop [FARM 69], Pierce Loop [PIER 72a], and DLCN [REAM 761."
http://hdl.handle.net/1957/7808,"During the early 19th Century, the fur trade brought many Iroquois to the Pacific Northwest as working primarily as voyageurs for the North West Company.  When the North West Company merged with the Hudson's Bay Company, the Iroquois employees merged as well.  After retirement, some settled in the Willamette Valley and surrounding areas.  These Iroquois have been an underrepresented group in the Pacific Northwest history.  When archaeological investigations are completed, the Iroquois are overlooked as possible occupants.  The purpose of this research is to reconstruct the history of the Iroquois and to create an archaeological description of what their material culture might look like in the Pacific Northwest.   Theories involving ethnicity in archaeology, along with documentary evidence and archaeological data, were used to complete body of knowledge that brings the Pacific Northwest Iroquois story to light, and create a catalog of the ethnic markers for archaeologists to look for."
http://hdl.handle.net/1957/7948,"Active participation and collaboration of community members are crucial to the continuation and expansion of open source software projects. Researchers have recognized the value of community in open source development and studied various aspects of it including structure of communities, motivations for participation, and collaboration among members. However, the majority of previous work is devoted to active contributors and little is known about newcomers to open source projects. In anattempt to bringing more attention to these potential contributors to open source andsupporting their joining process by enhancing their initial learning experience, we investigated the information needs of those who are considering joining an open source project as developers and use of software in fulfilling the needs and providing information that are important to perform software development maintenance tasks.Our controlled experiment has revealed that the tools and resources available from current open source projects are lacking in providing information that is embedded indevelopment artifacts such as discussion archives, trackers, and source code.Difficulty obtaining such information may have a negative impact on newcomers' motivation on learning and further their engagement in activities. Our investigation of information visualization in support of learning suggests that providing visualinformation to newcomers may alleviate the difficulties associated with managing alarge amount of information and enhance their learning experience."
http://hdl.handle.net/1957/8146,"The analysis of prehistoric stone features has suffered for two separate but related reasons. The first is the lack of stringency in defining the terms attributed to these structures and, second, the perception of a lack of formal attributes exhibited by them. These two factors have made it impossible to subject these structures to the kinds of rigorous analysis to which other components of archaeological excavations are routinely put.This thesis has two purposes. First, it defines 22 types of stone features. Second, in order to circumvent the analytical limitations imposed by the narrow spectrum of formal attributes exhibited by stonefeatures, it examines positional and selected ancillary attributes of those features in order to ascertain whether certain attributes might be used to assign functions to stone structures."
http://hdl.handle.net/1957/8486,"American women’s quest for equality came into focus in the early 1900s.  Amidst the cultural and societal forces pushing for suffrage, some chose the mechanism of theater.  This thesis is a work of rhetorical criticism.  It applies Lloyd Bitzer’s situational approach to two suffrage theater artifacts: Mary Shaw's The Woman of It; or, Our Friends the Anti-Suffragists (1914) and The Parrot Cage (1914).  The question that is the focus of this thesis is: how fitting were Mary Shaw’s plays as responses to the exigence of a lack of suffrage?  The analysis that follows demonstrates the continued importance of proper audience identification for social justice movements."
http://hdl.handle.net/1957/9094,"Decision support systems (DSS) have been used to a very limited extent in pond aquaculture. This study documents the development of a DSS (POND) which allows representation of an entire pond aquaculture facility, and provides analysis capabilities in the form of simulation models and an economics package. Simulation tools in POND include temperature, water budget, fertilization, and fish bioenergetics models. Verification of the water temperature model at sites in Thailand, Honduras and Rwanda indicated that it would accurately predict daily temperatures over entire seasons or diurnal temperatures over one day intervals if complete input weather datasets are available. Similarly, adequate estimates of water requirements can be obtained from the water budget model. Sensitivity analysis with the former model, and results obtained from the latter, indicate that input weather datasets should include air temperature, relative humidity, short-wave solar radiation, precipitation and wind speed measurements. The fertilization model estimates fertilizer application rates on the basis of nutrient concentrations, gross primary productivity and nutrient recycling processes. Model output was more conservative compared to rates used in Honduras, Thailand and the Philippines, suggesting that responsive fertilization strategies which account for ambient pond water conditions are more efficient than fixed input strategies. The bioenergetics model accounts for the effects of size, water temperature, photoperiod, dissolved oxygen and unionized ammonia on fish growth. The model was calibrated and validated for Nile tilapia (Oreochromis niloticus), tambaqui (Colossoma macropomum), pacu (Piaractus mesopotamicus), common carp (Cyprinus carpio), and channel catfish (Ictalurus punctatus). Model experiments generated useful information regarding supplemental feed initiation and fish feeding rates. A resource substitution function was also used in this model to analyze the consumption of endogenous and exogenous food resources by Nile tilapia. This function suggests that adding supplemental feed to tilapia ponds may increase phytoplankton biomass because feed is preferentially consumed. A genetic algorithm-based technique was developed to automatically calibrate the bioenergetics model. This technique generates best-fit parameters by comparing results of multiple model runs to observed data. In general, results obtained from all the models suggest that POND should be a useful tool for managers, planners and researchers involved with pond aquaculture."
http://hdl.handle.net/1957/9391,"Six headwalls in the central Oregon coast range were selected for study of soil engineering properties and vegetativecharacteristics important for analysis of slope stability. The headwalls were considered representative of those which would be candidates for timber leave areas due to geomorphic and topographic features, including steepness of slope and presence of a well defined constriction point on the downslope end. Of the six, only one headwall had evidence of recent debris-avalanche activity. No standing overstory species were found on any of the headwall blocks, the area of the headwall thought most susceptible to failure. Douglas-fir (Pseudotsuga menziesii),maple (Acer sp.), and red alder (Alnus rubra) were common on the headwall perimeters. Salmonberry (Rubus spectabilis) and swordfern (Polystichum munitum) dominate the understory plant community on the headwalls. Subsoils from two profiles on each headwall were sampled for index and classification properties. The soils are typically shallow, averaging under one meter in depth. They are silt-sand-gravel mixtures, with non-plastic fines. The soils all have exceptionally low density, and correspondingly high void ratio.Consolidated-undrained triaxial tests with pore pressure measurements were conducted using relatively undisturbed samples to determine the effective soil strengthparameters, angle of internal friction, ø', and cohesion, c'. Low consolidation pressures were chosen to model field overburden conditions. The arithmetic mean ø' was 31.1°.All the soils are considered to be slightly- to non-cohesive. There are no apparent correlations between index or classification properties and strength parameters. Variability of index properties and strength parameters appears to be as great within a particular headwall as between the six study sites. Variability in the results of the strength tests are thought to reflect natural variability resulting from colluvial soil formation processes, as well as difficultiesinherent in collecting and testing relatively undisturbed soil samples. Further investigations of strength parameters designed to include root contribution to strength are needed in order to more fully define stability characteristics of headwalls."
http://hdl.handle.net/1957/9394,"Buffer strips have been proposed as a method for controlling temperature changes in streams adjacent to clear-cuttings. Ninesmall mountain streams in Oregon's Coast Range and Cascade Mountains were studied to determine the influence of buffer stripson water temperature. Timber volume in the strip, strip width, and canopy density perpendicular to the sun's rays were comparedto the effectiveness of the strip in controlling temperature change. This effectiveness was not well correlated with timber volume or strip width. The density of the canopy in the path of the sun is the most important buffer strip characteristic for water temperature control. A method for measuring the density of the canopy in the path of the sun is described. The use of this method in the design of buffer strips will provide protection for the stream and maximum harvesting of the timber resource."
http://hdl.handle.net/1957/9416,"Individuals with Down syndrome (DS) have less atherosclerosis than others with and without mental retardation (MR). Why individuals with DS do not develop atherosclerosis similarly to others is not known. The insulin resistance syndrome (IRS), a common neuroendocrine disorder underlying cardiovascular disease, has not been investigated in adults with DS to determine if adults with DS possess a more protective CVD risk factor profile than other adults with MR. The CVD risk factor components of the IRS were measured in 145 adults with mild MR (N=70) and DS (N=75) who reside in community settings. The overall mean values for the CVD risk factors were relatively high for all participants, especially for women with MIR, who on average showed evidence of fasting hyperinsulinemia, abdominal obesity, and low high-density lipoprotein cholesterol. After adjusting for age, smoking status, residence type, and medication use, women with DS had lower fasting glucose, resting blood pressure, and abdominal fat than women with IVIR, indicating that women with DS may besomewhat protected against CVD due to lower IRS risk factors as compared to women with MR. Adults with MR with abdominal obesity were approximately 2-10 times more likely than adults with MR without abdominal obesity to have hyperinsulinemia, borderline high triglycerides, low HDL cholesterol andborderline hypertension (P<0.05). Furthermore, the associations between abdominal obesity and elevated  risk factors were independent of age, gender,presence of Down syndrome, smoking behavior, and medication use. Screening for abdominal obesity using simple anthropometric measures may be a cost-effective way to identify individuals with 1VIR with an intermediate to high risk for a future CVD event. Adults with MR who participated in the recommended frequency (>5 bouts week) of moderate to vigorous physical activity or who consumed a below average dietary fat intake (<35%) were approximately one third as likely to havehyperinsulinemia and abdominal obesity than adults with who participated in physical activity less than 5 times week or who consumed more than 35% of their total caloric intake from fats (P<0.05). Increasing physical activity and reducingdietary fat may help lower the risk for a future CVD event in adults with MR."
http://hdl.handle.net/1957/9486,"Stem form development of trees in response to wind has been established in the literature to be a response to stem sway induced by the wind. The response is manifested in modifications to height and diameter growth which strengthen the stem against wind stresses. Experiments in the literature show that significant responses result from short durations of sway daily. An experiment exploring the growth responses resulting from a wide range of daily durations of sway was conducted. Also, the influence of timing of periods of sway during the growing season and during different seasons was examined.The pooled mean leader length for seedlings swayed different durations daily at a rate of 0.8 Hz was 86 per cent of that for unswayedcontrols. Leader length for seedlings swayed only 10 seconds daily were not significantly different from unswayed controls. Growth during certain stages of apical bud burst seems to have been retarded by the longer durations of sway. Growth ring increment onthe compression side of the stem increased due to swaying, with the greatest response due to a 10 second daily duration and the least due to a 10 hour duration. Growth ring increment on the tension side responded in like manner, the longer durations of sway were not significantly different from the unswayed controls, but the short durations resulted in significant increases. In a separate experiment, seedlings were swayed 2.5 hours daily. Treatments were begun with the initiation of bud burst, and terminatedafter periods of 6, 12, and 18 weeks. Leader length growth was not found to differ between controls and the 6-week swaying treatment, but was reduced due to longer treatment periods. The stem diameter in the direction of sway increased as the period of swaying increased. These results suggest that the response system directing height and diametergrowth loses its effect, in time, if swaying is terminated before the completion of bud burst. A field experiment was conducted measuring growth responses of 17-year-old trees which were prevented from natural wind sway during certain seasons of the year. No differences between treatments were found, Wind strength at the study site may have been inadequate to provide measurable differences."
http://hdl.handle.net/1957/9657,"The Chelan Valley is one of several valleys located on theeastern slope of the Cascade Mountains contributing to the leadershipof Washington in apple production. Since the nature of theactivity in the Chelan Valley is typical of all these producing areas,it was selected as a case study of this important segment of theagricultural economy of Washington. The study presents an analysisof the principal factors, both environmental and human, basic to thelocalization of apple production in this valley. The structure,organization, and problems are examined and the potential isanalyzed.The principal findings are as follows: the physical requirementsof apples are nearly ideally met by the combined environmentalconditions of temperature, slope, soils, drainage andirrigation water supply. Development of the activity, however, hasbeen the responsibility of dedicated growers who have been quick both to perfect and to accept improved techniques in the interest ofselling a quality product on distant markets. This includes concentrationupon four varieties: Red Delicious, Golden Delicious, StandardDelicious, and Winesap. The Standard Delicious and Winesapwere the main early commercial varieties, but they are now beingreplaced by the Red and Golden Delicious varieties. It is the RedDelicious that has become famous as the Washington State apple.The typical orchard, in contrast to other forms of farming inthe nation, is small in acreage. A majority of units contain ten totwenty acres. Apple orchards in the Chelan Valley, however, rankamong the highest of the forms of agricultural land in value per acre.Much of the factual material presented in this thesis is applicableonly to the Chelan Valley, but conclusions and inferences areapplicable to the Washington State apple industry as a whole."
